{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.11日 23：08更新\n",
    "# 10.13日 11:34更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jKm3tqsMhDOA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class MyFCNet(nn.Module):\n",
    "\n",
    "    def __init__(self, l1_reg=0.01):\n",
    "        super(MyFCNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=100, kernel_size=(6, 1))\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(100, 200, kernel_size=(5, 1))\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(800, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.l1_reg = l1_reg\n",
    "\n",
    "    def forward(self, x, targets=None, epoch=None):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        if self.l1_reg > 0:\n",
    "            l1_loss = torch.tensor(0.0, requires_grad=True)\n",
    "            for name, param in self.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    l1_loss = l1_loss + torch.norm(param, p=1)\n",
    "            x = x + self.l1_reg * l1_loss\n",
    "        return x\n",
    "class MyFCNetEnsemble(nn.Module):\n",
    "\n",
    "    def __init__(self, l1_reg=0.01):\n",
    "        super(MyFCNetEnsemble, self).__init__()\n",
    "        self.fcnet1 = MyFCNet(l1_reg=l1_reg)\n",
    "        self.fcnet2 = MyFCNet(l1_reg=l1_reg)\n",
    "        # 再加一层MyFCNet\n",
    "        self.fcnet3 = MyFCNet(l1_reg=l1_reg)\n",
    "        self.fc = nn.Linear(3, 1)\n",
    "    def forward(self, x, targets=None, epoch=None):\n",
    "        x1 = self.fcnet1(x)\n",
    "        x2 = self.fcnet2(x)\n",
    "        x3 = self.fcnet3(x)\n",
    "        x = torch.cat((x1,x2,x3), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "# class MyLSTMNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MyLSTMNet, self).__init__()\n",
    "     \n",
    "#         self.lstm = nn.LSTM(4,64, 2, batch_first=True)\n",
    "#         self.fc = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x,targets=None, epoch=None):\n",
    "#         h0 = torch.zeros(2, x.size(0), 64).to(x.device)\n",
    "#         c0 = torch.zeros(2, x.size(0), 64).to(x.device)\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc(out[:, -1, :])  # 仅使用最后一个时间步的输出\n",
    "#         return out\n",
    "\n",
    "# # 定义模型参数\n",
    "# input_size = 4  # 输入特征的维度，等于通道数\n",
    "# hidden_size = 64  # LSTM隐藏层的单元数\n",
    "# num_layers = 2  # LSTM层的数量\n",
    "# output_size = 1  # 输出整数数值\n",
    "# def lstmnet1(**kwargs):\n",
    "#     return MyLSTMNet()\n",
    "def fcnet1(**kwargs):\n",
    "    return MyFCNetEnsemble(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWohJXZPYbY3"
   },
   "source": [
    "# Define the loss functions. Here we only need the L1 loss: |f(x) - y|."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7Kzc8PTjhDIH"
   },
   "outputs": [],
   "source": [
    "# loss.py: Define the loss functions (here we only need the L1 loss)\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_mse_loss(inputs, targets, weights=None):\n",
    "    loss = (inputs - targets) ** 2\n",
    "    if weights is not None:\n",
    "        loss *= weights.expand_as(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def weighted_l1_loss(inputs, targets, weights=None):\n",
    "    loss = F.l1_loss(inputs, targets, reduction='none')\n",
    "    if weights is not None:\n",
    "        loss *= weights.expand_as(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def weighted_focal_mse_loss(inputs, targets, weights=None, activate='sigmoid', beta=.2, gamma=1):\n",
    "    loss = (inputs - targets) ** 2\n",
    "    loss *= (torch.tanh(beta * torch.abs(inputs - targets))) ** gamma if activate == 'tanh' else \\\n",
    "        (2 * torch.sigmoid(beta * torch.abs(inputs - targets)) - 1) ** gamma\n",
    "    if weights is not None:\n",
    "        loss *= weights.expand_as(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def weighted_focal_l1_loss(inputs, targets, weights=None, activate='sigmoid', beta=.2, gamma=1):\n",
    "    loss = F.l1_loss(inputs, targets, reduction='none')\n",
    "    loss *= (torch.tanh(beta * torch.abs(inputs - targets))) ** gamma if activate == 'tanh' else \\\n",
    "        (2 * torch.sigmoid(beta * torch.abs(inputs - targets)) - 1) ** gamma\n",
    "    if weights is not None:\n",
    "        loss *= weights.expand_as(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def weighted_huber_loss(inputs, targets, weights=None, beta=1.):\n",
    "    l1_loss = torch.abs(inputs - targets)\n",
    "    cond = l1_loss < beta\n",
    "    loss = torch.where(cond, 0.5 * l1_loss ** 2 / beta, l1_loss - 0.5 * beta)\n",
    "    if weights is not None:\n",
    "        loss *= weights.expand_as(loss)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aunbes6NY_Pz"
   },
   "source": [
    "# Define some utility functions (not the focus of this course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "f3XXH8Yik4M9"
   },
   "outputs": [],
   "source": [
    "# utils.py: Define some utility functions (not the focus of this course).\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal.windows import triang\n",
    "import matplotlib.pyplot as plt\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_batch_fmtstr(num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def query_yes_no(question):\n",
    "    \"\"\" Ask a yes/no question via input() and return their answer. \"\"\"\n",
    "    valid = {\"yes\": True, \"y\": True, \"ye\": True, \"no\": False, \"n\": False}\n",
    "    prompt = \" [Y/n] \"\n",
    "\n",
    "    while True:\n",
    "        print(question + prompt, end=':')\n",
    "        choice = input().lower()\n",
    "        if choice == '':\n",
    "            return valid['y']\n",
    "        elif choice in valid:\n",
    "            return valid[choice]\n",
    "        else:\n",
    "            print(\"Please respond with 'yes' or 'no' (or 'y' or 'n').\\n\")\n",
    "\n",
    "def prepare_folders(args):\n",
    "    folders_util = [args.store_root, os.path.join(args.store_root, args.store_name)]\n",
    "    if os.path.exists(folders_util[-1]) and not args.resume and not args.evaluate:\n",
    "        if query_yes_no('overwrite previous folder: {} ?'.format(folders_util[-1])):\n",
    "            shutil.rmtree(folders_util[-1])\n",
    "            print(folders_util[-1] + ' removed.')\n",
    "        else:\n",
    "            raise RuntimeError('Output folder {} already exists'.format(folders_util[-1]))\n",
    "    for folder in folders_util:\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"===> Creating folder: {folder}\")\n",
    "            os.mkdir(folder)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    lr = args.lr\n",
    "    for milestone in args.schedule:\n",
    "        lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# def save_checkpoint(args, state, is_best, prefix=''):\n",
    "#     filename = f\"{args.store_root}/{args.store_name}/{prefix}ckpt.pth.tar\"\n",
    "#     torch.save(state, filename)\n",
    "#     if is_best:\n",
    "#         print(\"===> Saving current best checkpoint...\")\n",
    "#         shutil.copyfile(filename, filename.replace('pth.tar', 'best.pth.tar'))\n",
    "\n",
    "def calibrate_mean_var(matrix, m1, v1, m2, v2, clip_min=0.1, clip_max=10):\n",
    "    if torch.sum(v1) < 1e-10:\n",
    "        return matrix\n",
    "    if (v1 == 0.).any():\n",
    "        valid = (v1 != 0.)\n",
    "        factor = torch.clamp(v2[valid] / v1[valid], clip_min, clip_max)\n",
    "        matrix[:, valid] = (matrix[:, valid] - m1[valid]) * torch.sqrt(factor) + m2[valid]\n",
    "        return matrix\n",
    "\n",
    "    factor = torch.clamp(v2 / v1, clip_min, clip_max)\n",
    "    return (matrix - m1) * torch.sqrt(factor) + m2\n",
    "\n",
    "def get_lds_kernel_window(kernel, ks, sigma):\n",
    "    assert kernel in ['gaussian', 'triang', 'laplace']\n",
    "    half_ks = (ks - 1) // 2\n",
    "    if kernel == 'gaussian':\n",
    "        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n",
    "        kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n",
    "    elif kernel == 'triang':\n",
    "        kernel_window = triang(ks)\n",
    "    else:\n",
    "        laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n",
    "        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n",
    "\n",
    "    return kernel_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpbjtnotZUkk"
   },
   "source": [
    "# Define the data iterator (data loader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gqK8H1UghC_v"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve1d\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "class DNA_loader(data.Dataset):\n",
    "    def __init__(self, labels,dna, split='train', reweight='none',\n",
    "                 lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
    "        self.split = split\n",
    "        self.labels= labels\n",
    "        \n",
    "        self.dna = self.seq2onehot(dna)\n",
    "        \n",
    "        self.weights = self.weights = self._prepare_weights(reweight=reweight, lds=lds, lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = index % self.labels.shape[0]\n",
    "        feature = np.transpose(self.dna[index], (2, 0, 1))\n",
    "        label = self.labels[index]\n",
    "        weight = np.asarray([self.weights[index]]).astype('float32') if self.weights is not None else np.asarray([np.float32(1.)])\n",
    "        return feature, weight, label\n",
    "    \n",
    "\n",
    "    \n",
    "    def seq2onehot(self,seq):     #convert the cRBS sequences to one-hot encoding\n",
    "        module = np.array([[[1,0,0,0]],\n",
    "                           [[0,1,0,0]],\n",
    "                           [[0,0,1,0]],\n",
    "                           [[0,0,0,1]]])\n",
    "        i = 0\n",
    "        cRBS_onehot = []\n",
    "        for i in seq:\n",
    "            tmp = []\n",
    "            for item in i:\n",
    "                if item == 't' or item == 'T':\n",
    "                    tmp.append(module[0])\n",
    "                elif item == 'c' or item == 'C':\n",
    "                    tmp.append(module[1])\n",
    "                elif item == 'g' or item == 'G':\n",
    "                    tmp.append(module[2])\n",
    "                elif item == 'a' or item == 'A':\n",
    "                    tmp.append(module[3])\n",
    "                else:\n",
    "                    tmp.append([[0,0,0,0]])\n",
    "            cRBS_onehot.append(tmp)\n",
    "        cRBS_onehot=np.array(cRBS_onehot).astype('float32')\n",
    "        return cRBS_onehot\n",
    "\n",
    "    def _prepare_weights(self, reweight, max_target=40, lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
    "        assert reweight in {'none', 'inverse', 'sqrt_inv'}\n",
    "        assert reweight != 'none' if lds else True, \\\n",
    "            \"Set reweight to \\'sqrt_inv\\' (default) or \\'inverse\\' when using LDS\"\n",
    "        value_dict = {x: 0 for x in range(max_target)}\n",
    "        labels = self.labels.tolist()\n",
    "        # mbr   \n",
    "        for label in labels:\n",
    "            value_dict[min(max_target - 1, int(label))] += 1\n",
    "        if reweight == 'sqrt_inv':\n",
    "            value_dict = {k: np.sqrt(v) for k, v in value_dict.items()}\n",
    "        elif reweight == 'inverse':\n",
    "            value_dict = {k: np.clip(v, 5, 1000) for k, v in value_dict.items()}  # clip weights for inverse re-weight\n",
    "        num_per_label = [value_dict[min(max_target - 1, int(label))] for label in labels]\n",
    "        if not len(num_per_label) or reweight == 'none':\n",
    "            return None\n",
    "        print(f\"Using re-weighting: [{reweight.upper()}]\")\n",
    "        if lds:\n",
    "            lds_kernel_window = get_lds_kernel_window(lds_kernel, lds_ks, lds_sigma)\n",
    "            print(f'Using LDS: [{lds_kernel.upper()}] ({lds_ks}/{lds_sigma})')\n",
    "            smoothed_value = convolve1d(\n",
    "                np.asarray([v for _, v in value_dict.items()]), weights=lds_kernel_window, mode='constant')\n",
    "            num_per_label = [smoothed_value[min(max_target - 1, int(label))] for label in labels]\n",
    "        weights = [np.float32(1 / x) for x in num_per_label]\n",
    "        scaling = len(weights) / np.sum(weights)\n",
    "        weights = [scaling * x for x in weights]\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zcuwqp5paPk3"
   },
   "source": [
    "# Set up some default configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "T7mtQacPhBoW"
   },
   "outputs": [],
   "source": [
    "# train.py, Part 1: Set up some default configurations.\n",
    "import time\n",
    "import argparse\n",
    "#import logging\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import gmean\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from resnet import resnet50\n",
    "# from fcnet import fcnet1\n",
    "# from loss import *\n",
    "# from datasets import BostonHousing\n",
    "# from utils import *\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_WARNINGS\"] = \"FALSE\"\n",
    "\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# CPU only\n",
    "parser.add_argument('--cpu_only', action='store_true', default=False, help='whether to use CPU only')\n",
    "# imbalanced related\n",
    "# LDS\n",
    "parser.add_argument('--lds', action='store_true', default=False, help='whether to enable LDS')\n",
    "parser.add_argument('--lds_kernel', type=str, default='gaussian',\n",
    "                    choices=['gaussian', 'triang', 'laplace'], help='LDS kernel type')\n",
    "parser.add_argument('--lds_ks', type=int, default=9, help='LDS kernel size: should be odd number')\n",
    "parser.add_argument('--lds_sigma', type=float, default=1, help='LDS gaussian/laplace kernel sigma')\n",
    "\n",
    "# re-weighting: SQRT_INV / INV\n",
    "parser.add_argument('--reweight', type=str, default='none', choices=['none', 'sqrt_inv', 'inverse'], help='cost-sensitive reweighting scheme')\n",
    "\n",
    "# training/optimization related\n",
    "parser.add_argument('--dataset', type=str, default='bostonhousing', choices=['imdb_wiki', 'agedb'], help='dataset name')\n",
    "parser.add_argument('--data_dir', type=str, default='./housing.data', help='data directory')\n",
    "parser.add_argument('--model', type=str, default='fcnet1', help='model name')\n",
    "parser.add_argument('--store_root', type=str, default='checkpoint', help='root path for storing checkpoints, logs')\n",
    "parser.add_argument('--store_name', type=str, default='', help='experiment store name')\n",
    "parser.add_argument('--gpu', type=int, default=None)\n",
    "parser.add_argument('--optimizer', type=str, default='adam', choices=['adam', 'sgd'], help='optimizer type')\n",
    "parser.add_argument('--loss', type=str, default='mse', choices=['mse', 'l1', 'focal_l1', 'focal_mse', 'huber'], help='training loss type')\n",
    "parser.add_argument('--lr', type=float, default=1e-2, help='initial learning rate')\n",
    "parser.add_argument('--epoch', type=int, default=1000, help='number of epochs to train')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='optimizer momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4, help='optimizer weight decay')\n",
    "parser.add_argument('--schedule', type=int, nargs='*', default=[100,300,500,700,], help='lr schedule (when to drop lr by 10x)')\n",
    "#parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n",
    "parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n",
    "parser.add_argument('--print_freq', type=int, default=10, help='logging frequency')\n",
    "parser.add_argument('--img_size', type=int, default=224, help='image size used in training')\n",
    "parser.add_argument('--workers', type=int, default=32, help='number of workers used in data loading')\n",
    "# checkpoints\n",
    "parser.add_argument('--resume', type=str, default='', help='checkpoint file path to resume training')\n",
    "parser.add_argument('--evaluate', action='store_true', help='evaluate only flag')\n",
    "\n",
    "parser.set_defaults(augment=True)\n",
    "# ss\n",
    "args, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nWvzFoYJnwuF"
   },
   "outputs": [],
   "source": [
    "# args.cpu_only = True # Use CPU to train/test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtG61vP8ROkP"
   },
   "source": [
    "# Train 4 different models using the 4 options below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4Wv3tQjBp0dG"
   },
   "outputs": [],
   "source": [
    "# # Option 1: To train the basic model, use the default setting, don't need to do anything\n",
    "# args.reweight = 'none'\n",
    "# args.lds = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jYS6r4nyp36_"
   },
   "outputs": [],
   "source": [
    "# # Option 2: To train the inverse weighting model:\n",
    "# args.reweight = 'inverse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fTYBWlx4p6R3"
   },
   "outputs": [],
   "source": [
    "# # Option 3: To train the sqrt_inverse weighting model:\n",
    "# args.reweight = 'sqrt_inv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W2j6V3UEqSoP"
   },
   "outputs": [],
   "source": [
    "# Option 4: To train the Label Distribution Smoothing (LDS) model:\n",
    "args.reweight = 'sqrt_inv'\n",
    "args.lds = True\n",
    "args.lds_kernel = 'gaussian'\n",
    "args.lds_ks = 5 # 5\n",
    "args.lds_sigma = 2 # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-zCfrN5av1A"
   },
   "source": [
    "# Train/Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSrzhog1gxyY",
    "outputId": "607f363a-f0f4-43da-a8dd-8dccc4a6aa22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Preparing data...\n",
      "Using re-weighting: [INVERSE]\n",
      "Using LDS: [GAUSSIAN] (10/2)\n",
      "Using re-weighting: [INVERSE]\n",
      "Using LDS: [GAUSSIAN] (5/2)\n",
      "Using re-weighting: [INVERSE]\n",
      "Using LDS: [GAUSSIAN] (5/2)\n",
      "Training data size: 16639\n",
      "Validation data size: 2080\n",
      "Test data size: 2080\n",
      "=====> Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ly534/anaconda3/envs/pytorch_demo/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 0/65]\tTime   0.55 (  0.55)\tData 0.5436 (0.5436)\tLoss (MSE) 61130.723 (61130.723)\n",
      "Epoch: [0][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0579)\tLoss (MSE) 4185.846 (14616.213)\n",
      "Epoch: [0][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 238.718 (8340.141)\n",
      "Epoch: [0][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 40.749 (5717.704)\n",
      "Epoch: [0][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 25.368 (4335.327)\n",
      "Epoch: [0][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 10.546 (3488.127)\n",
      "Epoch: [0][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 10.076 (2918.170)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.150 (2.150)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.847\tL1 0.585\tG-Mean 0.272\n",
      " * Many: MSE 2.259\tL1 1.033\tG-Mean 0.905\n",
      " * Median: MSE 2.140\tL1 1.398\tG-Mean 1.343\n",
      " * Low: MSE 0.023\tL1 0.152\tG-Mean 0.152\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #0: Train loss [2739.2797]; Val loss: MSE [1.8474], L1 [0.5853], G-Mean [0.2722]\n",
      "Epoch: [1][ 0/65]\tTime   0.55 (  0.55)\tData 0.5433 (0.5433)\tLoss (MSE) 10.375 (10.375)\n",
      "Epoch: [1][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 6.555 (9.028)\n",
      "Epoch: [1][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 5.794 (8.308)\n",
      "Epoch: [1][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 21.677 (8.128)\n",
      "Epoch: [1][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.174 (8.062)\n",
      "Epoch: [1][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 8.407 (8.035)\n",
      "Epoch: [1][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 6.155 (8.049)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.177 (2.177)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.865\tL1 0.571\tG-Mean 0.244\n",
      " * Many: MSE 2.201\tL1 0.987\tG-Mean 0.854\n",
      " * Median: MSE 2.283\tL1 1.448\tG-Mean 1.395\n",
      " * Low: MSE 0.041\tL1 0.202\tG-Mean 0.202\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #1: Train loss [7.9599]; Val loss: MSE [1.8654], L1 [0.5713], G-Mean [0.2440]\n",
      "Epoch: [2][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 9.538 (9.538)\n",
      "Epoch: [2][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0600)\tLoss (MSE) 8.447 (9.115)\n",
      "Epoch: [2][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 4.725 (8.679)\n",
      "Epoch: [2][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 4.928 (8.191)\n",
      "Epoch: [2][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 8.027 (8.151)\n",
      "Epoch: [2][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 6.022 (7.710)\n",
      "Epoch: [2][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 5.033 (7.506)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.174 (2.174)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.864\tL1 0.572\tG-Mean 0.247\n",
      " * Many: MSE 2.206\tL1 0.991\tG-Mean 0.859\n",
      " * Median: MSE 2.270\tL1 1.444\tG-Mean 1.391\n",
      " * Low: MSE 0.039\tL1 0.198\tG-Mean 0.198\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #2: Train loss [7.5211]; Val loss: MSE [1.8636], L1 [0.5723], G-Mean [0.2470]\n",
      "Epoch: [3][ 0/65]\tTime   0.62 (  0.62)\tData 0.5986 (0.5986)\tLoss (MSE) 15.278 (15.278)\n",
      "Epoch: [3][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 3.979 (8.089)\n",
      "Epoch: [3][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 6.430 (7.516)\n",
      "Epoch: [3][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 9.561 (7.648)\n",
      "Epoch: [3][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 6.033 (7.439)\n",
      "Epoch: [3][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 7.291 (7.463)\n",
      "Epoch: [3][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 7.785 (7.536)\n",
      "Val: [0/9]\tTime  0.533 ( 0.533)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.864\tL1 0.572\tG-Mean 0.247\n",
      " * Many: MSE 2.205\tL1 0.990\tG-Mean 0.858\n",
      " * Median: MSE 2.272\tL1 1.445\tG-Mean 1.392\n",
      " * Low: MSE 0.039\tL1 0.199\tG-Mean 0.199\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #3: Train loss [7.4127]; Val loss: MSE [1.8640], L1 [0.5721], G-Mean [0.2466]\n",
      "Epoch: [4][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 6.448 (6.448)\n",
      "Epoch: [4][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 5.808 (6.902)\n",
      "Epoch: [4][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 7.499 (7.021)\n",
      "Epoch: [4][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 8.196 (7.016)\n",
      "Epoch: [4][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.629 (7.353)\n",
      "Epoch: [4][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 12.384 (7.196)\n",
      "Epoch: [4][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.167 (7.231)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.864\tL1 0.572\tG-Mean 0.246\n",
      " * Many: MSE 2.205\tL1 0.990\tG-Mean 0.857\n",
      " * Median: MSE 2.273\tL1 1.445\tG-Mean 1.392\n",
      " * Low: MSE 0.040\tL1 0.199\tG-Mean 0.199\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #4: Train loss [7.2977]; Val loss: MSE [1.8641], L1 [0.5720], G-Mean [0.2465]\n",
      "Epoch: [5][ 0/65]\tTime   0.55 (  0.55)\tData 0.5456 (0.5456)\tLoss (MSE) 7.547 (7.547)\n",
      "Epoch: [5][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 9.058 (7.391)\n",
      "Epoch: [5][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 6.312 (7.483)\n",
      "Epoch: [5][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.618 (7.053)\n",
      "Epoch: [5][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 8.760 (7.292)\n",
      "Epoch: [5][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 3.911 (7.141)\n",
      "Epoch: [5][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 7.567 (7.352)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.186 (2.186)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.872\tL1 0.568\tG-Mean 0.221\n",
      " * Many: MSE 2.184\tL1 0.972\tG-Mean 0.838\n",
      " * Median: MSE 2.328\tL1 1.464\tG-Mean 1.411\n",
      " * Low: MSE 0.047\tL1 0.218\tG-Mean 0.218\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #5: Train loss [7.2495]; Val loss: MSE [1.8719], L1 [0.5680], G-Mean [0.2210]\n",
      "Epoch: [6][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 5.781 (5.781)\n",
      "Epoch: [6][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0535)\tLoss (MSE) 11.832 (7.635)\n",
      "Epoch: [6][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 10.617 (6.759)\n",
      "Epoch: [6][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 3.430 (6.651)\n",
      "Epoch: [6][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.234 (6.779)\n",
      "Epoch: [6][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 7.750 (6.791)\n",
      "Epoch: [6][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 8.574 (7.067)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.167 (2.167)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.859\tL1 0.575\tG-Mean 0.238\n",
      " * Many: MSE 2.220\tL1 1.003\tG-Mean 0.872\n",
      " * Median: MSE 2.233\tL1 1.431\tG-Mean 1.377\n",
      " * Low: MSE 0.034\tL1 0.185\tG-Mean 0.185\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #6: Train loss [7.1985]; Val loss: MSE [1.8587], L1 [0.5754], G-Mean [0.2381]\n",
      "Epoch: [7][ 0/65]\tTime   0.57 (  0.57)\tData 0.5592 (0.5592)\tLoss (MSE) 3.612 (3.612)\n",
      "Epoch: [7][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 5.406 (7.515)\n",
      "Epoch: [7][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 7.835 (7.252)\n",
      "Epoch: [7][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 5.438 (6.909)\n",
      "Epoch: [7][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 7.021 (7.059)\n",
      "Epoch: [7][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 5.409 (7.112)\n",
      "Epoch: [7][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 9.255 (7.168)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.192 (2.192)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.876\tL1 0.567\tG-Mean 0.241\n",
      " * Many: MSE 2.174\tL1 0.963\tG-Mean 0.828\n",
      " * Median: MSE 2.355\tL1 1.473\tG-Mean 1.421\n",
      " * Low: MSE 0.052\tL1 0.227\tG-Mean 0.227\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #7: Train loss [7.1414]; Val loss: MSE [1.8760], L1 [0.5670], G-Mean [0.2413]\n",
      "Epoch: [8][ 0/65]\tTime   0.56 (  0.56)\tData 0.5504 (0.5504)\tLoss (MSE) 12.950 (12.950)\n",
      "Epoch: [8][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 7.321 (7.384)\n",
      "Epoch: [8][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 8.608 (7.545)\n",
      "Epoch: [8][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.295 (7.168)\n",
      "Epoch: [8][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.247 (7.177)\n",
      "Epoch: [8][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 9.878 (6.916)\n",
      "Epoch: [8][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.131 (7.197)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.182 (2.182)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.869\tL1 0.569\tG-Mean 0.221\n",
      " * Many: MSE 2.191\tL1 0.978\tG-Mean 0.845\n",
      " * Median: MSE 2.309\tL1 1.457\tG-Mean 1.405\n",
      " * Low: MSE 0.045\tL1 0.211\tG-Mean 0.211\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #8: Train loss [7.1349]; Val loss: MSE [1.8691], L1 [0.5691], G-Mean [0.2214]\n",
      "Epoch: [9][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 10.265 (10.265)\n",
      "Epoch: [9][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 5.734 (6.859)\n",
      "Epoch: [9][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 4.344 (6.846)\n",
      "Epoch: [9][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 9.880 (7.022)\n",
      "Epoch: [9][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 9.425 (7.369)\n",
      "Epoch: [9][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.688 (7.240)\n",
      "Epoch: [9][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 6.272 (7.120)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.179 (2.179)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.867\tL1 0.570\tG-Mean 0.239\n",
      " * Many: MSE 2.197\tL1 0.983\tG-Mean 0.850\n",
      " * Median: MSE 2.293\tL1 1.452\tG-Mean 1.399\n",
      " * Low: MSE 0.042\tL1 0.206\tG-Mean 0.206\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #9: Train loss [7.1145]; Val loss: MSE [1.8668], L1 [0.5704], G-Mean [0.2394]\n",
      "Epoch: [10][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 9.937 (9.937)\n",
      "Epoch: [10][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0576)\tLoss (MSE) 5.789 (6.901)\n",
      "Epoch: [10][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 7.081 (6.680)\n",
      "Epoch: [10][30/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 6.650 (6.876)\n",
      "Epoch: [10][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 7.537 (6.968)\n",
      "Epoch: [10][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.114 (6.854)\n",
      "Epoch: [10][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0104)\tLoss (MSE) 9.034 (6.958)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.151 (2.151)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.848\tL1 0.585\tG-Mean 0.272\n",
      " * Many: MSE 2.256\tL1 1.031\tG-Mean 0.903\n",
      " * Median: MSE 2.147\tL1 1.401\tG-Mean 1.346\n",
      " * Low: MSE 0.024\tL1 0.155\tG-Mean 0.155\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #10: Train loss [7.0920]; Val loss: MSE [1.8484], L1 [0.5845], G-Mean [0.2723]\n",
      "Epoch: [11][ 0/65]\tTime   0.55 (  0.55)\tData 0.5484 (0.5484)\tLoss (MSE) 4.620 (4.620)\n",
      "Epoch: [11][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 4.276 (6.320)\n",
      "Epoch: [11][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.744 (6.845)\n",
      "Epoch: [11][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 5.499 (6.724)\n",
      "Epoch: [11][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 10.552 (7.029)\n",
      "Epoch: [11][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.023 (6.974)\n",
      "Epoch: [11][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.583 (7.106)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.864\tL1 0.572\tG-Mean 0.246\n",
      " * Many: MSE 2.205\tL1 0.990\tG-Mean 0.857\n",
      " * Median: MSE 2.273\tL1 1.445\tG-Mean 1.392\n",
      " * Low: MSE 0.040\tL1 0.199\tG-Mean 0.199\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #11: Train loss [7.0492]; Val loss: MSE [1.8640], L1 [0.5721], G-Mean [0.2465]\n",
      "Epoch: [12][ 0/65]\tTime   0.55 (  0.55)\tData 0.5465 (0.5465)\tLoss (MSE) 7.588 (7.588)\n",
      "Epoch: [12][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0596)\tLoss (MSE) 5.678 (7.691)\n",
      "Epoch: [12][20/65]\tTime   0.01 (  0.04)\tData 0.0001 (0.0313)\tLoss (MSE) 6.003 (7.243)\n",
      "Epoch: [12][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 4.975 (6.888)\n",
      "Epoch: [12][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 4.668 (6.657)\n",
      "Epoch: [12][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 5.021 (6.736)\n",
      "Epoch: [12][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0108)\tLoss (MSE) 6.824 (7.033)\n",
      "Val: [0/9]\tTime  0.534 ( 0.534)\tLoss (MSE) 2.166 (2.166)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.858\tL1 0.576\tG-Mean 0.245\n",
      " * Many: MSE 2.222\tL1 1.004\tG-Mean 0.873\n",
      " * Median: MSE 2.229\tL1 1.430\tG-Mean 1.376\n",
      " * Low: MSE 0.034\tL1 0.184\tG-Mean 0.184\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #12: Train loss [7.0240]; Val loss: MSE [1.8581], L1 [0.5758], G-Mean [0.2451]\n",
      "Epoch: [13][ 0/65]\tTime   0.55 (  0.55)\tData 0.5437 (0.5437)\tLoss (MSE) 8.904 (8.904)\n",
      "Epoch: [13][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 5.612 (8.305)\n",
      "Epoch: [13][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 8.432 (8.027)\n",
      "Epoch: [13][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.257 (7.768)\n",
      "Epoch: [13][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 7.253 (7.415)\n",
      "Epoch: [13][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 6.981 (7.222)\n",
      "Epoch: [13][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 8.720 (7.060)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.152 (2.152)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.849\tL1 0.584\tG-Mean 0.272\n",
      " * Many: MSE 2.252\tL1 1.028\tG-Mean 0.900\n",
      " * Median: MSE 2.156\tL1 1.404\tG-Mean 1.349\n",
      " * Low: MSE 0.025\tL1 0.158\tG-Mean 0.158\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #13: Train loss [7.0312]; Val loss: MSE [1.8494], L1 [0.5836], G-Mean [0.2719]\n",
      "Epoch: [14][ 0/65]\tTime   0.56 (  0.56)\tData 0.5516 (0.5516)\tLoss (MSE) 2.320 (2.320)\n",
      "Epoch: [14][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0600)\tLoss (MSE) 7.418 (6.840)\n",
      "Epoch: [14][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 2.707 (6.406)\n",
      "Epoch: [14][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 6.835 (6.668)\n",
      "Epoch: [14][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 10.607 (6.570)\n",
      "Epoch: [14][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 12.014 (6.807)\n",
      "Epoch: [14][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 7.381 (6.991)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.188 (2.188)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.873\tL1 0.568\tG-Mean 0.211\n",
      " * Many: MSE 2.181\tL1 0.970\tG-Mean 0.835\n",
      " * Median: MSE 2.335\tL1 1.466\tG-Mean 1.414\n",
      " * Low: MSE 0.048\tL1 0.220\tG-Mean 0.220\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #14: Train loss [7.0163]; Val loss: MSE [1.8729], L1 [0.5676], G-Mean [0.2112]\n",
      "Epoch: [15][ 0/65]\tTime   0.56 (  0.56)\tData 0.5573 (0.5573)\tLoss (MSE) 6.992 (6.992)\n",
      "Epoch: [15][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 9.733 (6.678)\n",
      "Epoch: [15][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 6.033 (6.758)\n",
      "Epoch: [15][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.905 (6.803)\n",
      "Epoch: [15][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.722 (6.785)\n",
      "Epoch: [15][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 6.246 (6.982)\n",
      "Epoch: [15][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.683 (7.077)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.169 (2.169)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.860\tL1 0.574\tG-Mean 0.244\n",
      " * Many: MSE 2.215\tL1 0.998\tG-Mean 0.867\n",
      " * Median: MSE 2.246\tL1 1.436\tG-Mean 1.382\n",
      " * Low: MSE 0.036\tL1 0.190\tG-Mean 0.190\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #15: Train loss [7.0206]; Val loss: MSE [1.8604], L1 [0.5742], G-Mean [0.2444]\n",
      "Epoch: [16][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 7.458 (7.458)\n",
      "Epoch: [16][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 7.207 (6.924)\n",
      "Epoch: [16][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 6.887 (6.356)\n",
      "Epoch: [16][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 5.147 (6.307)\n",
      "Epoch: [16][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.068 (6.462)\n",
      "Epoch: [16][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.991 (6.827)\n",
      "Epoch: [16][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.582 (6.887)\n",
      "Val: [0/9]\tTime  0.562 ( 0.562)\tLoss (MSE) 2.174 (2.174)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.863\tL1 0.573\tG-Mean 0.247\n",
      " * Many: MSE 2.207\tL1 0.991\tG-Mean 0.859\n",
      " * Median: MSE 2.268\tL1 1.443\tG-Mean 1.390\n",
      " * Low: MSE 0.039\tL1 0.197\tG-Mean 0.197\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #16: Train loss [7.0009]; Val loss: MSE [1.8632], L1 [0.5725], G-Mean [0.2473]\n",
      "Epoch: [17][ 0/65]\tTime   0.56 (  0.56)\tData 0.5492 (0.5492)\tLoss (MSE) 4.533 (4.533)\n",
      "Epoch: [17][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0585)\tLoss (MSE) 9.101 (8.457)\n",
      "Epoch: [17][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 5.467 (7.556)\n",
      "Epoch: [17][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 5.227 (7.190)\n",
      "Epoch: [17][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 7.619 (7.325)\n",
      "Epoch: [17][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.093 (7.272)\n",
      "Epoch: [17][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 11.926 (7.126)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.210 (2.210)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.889\tL1 0.565\tG-Mean 0.261\n",
      " * Many: MSE 2.146\tL1 0.938\tG-Mean 0.800\n",
      " * Median: MSE 2.437\tL1 1.500\tG-Mean 1.449\n",
      " * Low: MSE 0.065\tL1 0.254\tG-Mean 0.254\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #17: Train loss [7.0635]; Val loss: MSE [1.8892], L1 [0.5646], G-Mean [0.2611]\n",
      "Epoch: [18][ 0/65]\tTime   0.63 (  0.63)\tData 0.6143 (0.6143)\tLoss (MSE) 9.898 (9.898)\n",
      "Epoch: [18][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 10.757 (7.622)\n",
      "Epoch: [18][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 5.072 (7.289)\n",
      "Epoch: [18][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 8.220 (7.343)\n",
      "Epoch: [18][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 5.832 (6.973)\n",
      "Epoch: [18][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 5.511 (6.998)\n",
      "Epoch: [18][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.429 (6.902)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.160 (2.160)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.854\tL1 0.579\tG-Mean 0.263\n",
      " * Many: MSE 2.234\tL1 1.014\tG-Mean 0.884\n",
      " * Median: MSE 2.200\tL1 1.419\tG-Mean 1.365\n",
      " * Low: MSE 0.030\tL1 0.173\tG-Mean 0.173\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #18: Train loss [7.0136]; Val loss: MSE [1.8545], L1 [0.5790], G-Mean [0.2633]\n",
      "Epoch: [19][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 8.471 (8.471)\n",
      "Epoch: [19][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 14.581 (8.311)\n",
      "Epoch: [19][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.629 (8.021)\n",
      "Epoch: [19][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.613 (7.480)\n",
      "Epoch: [19][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 8.304 (7.134)\n",
      "Epoch: [19][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.269 (7.079)\n",
      "Epoch: [19][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.485 (6.952)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.185 (2.185)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.871\tL1 0.568\tG-Mean 0.224\n",
      " * Many: MSE 2.185\tL1 0.973\tG-Mean 0.839\n",
      " * Median: MSE 2.324\tL1 1.462\tG-Mean 1.410\n",
      " * Low: MSE 0.047\tL1 0.216\tG-Mean 0.216\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #19: Train loss [7.0143]; Val loss: MSE [1.8713], L1 [0.5682], G-Mean [0.2238]\n",
      "Epoch: [20][ 0/65]\tTime   0.58 (  0.58)\tData 0.5716 (0.5716)\tLoss (MSE) 3.406 (3.406)\n",
      "Epoch: [20][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 5.922 (6.749)\n",
      "Epoch: [20][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 10.282 (6.932)\n",
      "Epoch: [20][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.352 (6.975)\n",
      "Epoch: [20][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 8.613 (6.942)\n",
      "Epoch: [20][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 8.554 (6.942)\n",
      "Epoch: [20][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.038 (6.820)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.153 (2.153)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.850\tL1 0.583\tG-Mean 0.272\n",
      " * Many: MSE 2.250\tL1 1.027\tG-Mean 0.898\n",
      " * Median: MSE 2.160\tL1 1.405\tG-Mean 1.351\n",
      " * Low: MSE 0.025\tL1 0.159\tG-Mean 0.159\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #20: Train loss [7.0062]; Val loss: MSE [1.8498], L1 [0.5832], G-Mean [0.2715]\n",
      "Epoch: [21][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 4.154 (4.154)\n",
      "Epoch: [21][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 5.622 (6.291)\n",
      "Epoch: [21][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 3.222 (6.936)\n",
      "Epoch: [21][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 6.347 (6.703)\n",
      "Epoch: [21][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 6.881 (6.904)\n",
      "Epoch: [21][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 6.554 (6.957)\n",
      "Epoch: [21][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 7.357 (6.973)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.229 (2.229)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.903\tL1 0.562\tG-Mean 0.259\n",
      " * Many: MSE 2.120\tL1 0.913\tG-Mean 0.773\n",
      " * Median: MSE 2.516\tL1 1.527\tG-Mean 1.476\n",
      " * Low: MSE 0.079\tL1 0.281\tG-Mean 0.281\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #21: Train loss [7.0471]; Val loss: MSE [1.9032], L1 [0.5623], G-Mean [0.2594]\n",
      "Epoch: [22][ 0/65]\tTime   0.59 (  0.59)\tData 0.5790 (0.5790)\tLoss (MSE) 9.868 (9.868)\n",
      "Epoch: [22][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 8.457 (8.054)\n",
      "Epoch: [22][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 8.168 (7.605)\n",
      "Epoch: [22][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 4.462 (7.436)\n",
      "Epoch: [22][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.457 (7.233)\n",
      "Epoch: [22][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 7.306 (7.176)\n",
      "Epoch: [22][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 8.289 (7.181)\n",
      "Val: [0/9]\tTime  0.618 ( 0.618)\tLoss (MSE) 2.173 (2.173)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.863\tL1 0.573\tG-Mean 0.247\n",
      " * Many: MSE 2.207\tL1 0.992\tG-Mean 0.860\n",
      " * Median: MSE 2.267\tL1 1.443\tG-Mean 1.389\n",
      " * Low: MSE 0.039\tL1 0.197\tG-Mean 0.197\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #22: Train loss [7.0535]; Val loss: MSE [1.8631], L1 [0.5726], G-Mean [0.2473]\n",
      "Epoch: [23][ 0/65]\tTime   0.55 (  0.55)\tData 0.5431 (0.5431)\tLoss (MSE) 5.525 (5.525)\n",
      "Epoch: [23][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0532)\tLoss (MSE) 10.216 (7.542)\n",
      "Epoch: [23][20/65]\tTime   0.01 (  0.03)\tData 0.0001 (0.0279)\tLoss (MSE) 3.612 (6.710)\n",
      "Epoch: [23][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 11.336 (7.397)\n",
      "Epoch: [23][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 4.469 (7.108)\n",
      "Epoch: [23][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 6.423 (6.996)\n",
      "Epoch: [23][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 6.490 (7.041)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.864\tL1 0.572\tG-Mean 0.246\n",
      " * Many: MSE 2.204\tL1 0.989\tG-Mean 0.857\n",
      " * Median: MSE 2.274\tL1 1.445\tG-Mean 1.392\n",
      " * Low: MSE 0.040\tL1 0.199\tG-Mean 0.199\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #23: Train loss [7.0139]; Val loss: MSE [1.8641], L1 [0.5720], G-Mean [0.2463]\n",
      "Epoch: [24][ 0/65]\tTime   0.55 (  0.55)\tData 0.5479 (0.5479)\tLoss (MSE) 2.316 (2.316)\n",
      "Epoch: [24][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0518)\tLoss (MSE) 8.717 (6.645)\n",
      "Epoch: [24][20/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 11.615 (6.491)\n",
      "Epoch: [24][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.679 (6.613)\n",
      "Epoch: [24][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.917 (6.653)\n",
      "Epoch: [24][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0112)\tLoss (MSE) 3.929 (6.992)\n",
      "Epoch: [24][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 7.416 (7.106)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.149 (2.149)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.847\tL1 0.585\tG-Mean 0.272\n",
      " * Many: MSE 2.260\tL1 1.034\tG-Mean 0.906\n",
      " * Median: MSE 2.139\tL1 1.398\tG-Mean 1.343\n",
      " * Low: MSE 0.023\tL1 0.152\tG-Mean 0.152\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #24: Train loss [6.9927]; Val loss: MSE [1.8474], L1 [0.5855], G-Mean [0.2721]\n",
      "Epoch: [25][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 5.483 (5.483)\n",
      "Epoch: [25][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0536)\tLoss (MSE) 4.931 (6.372)\n",
      "Epoch: [25][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 13.407 (7.270)\n",
      "Epoch: [25][30/65]\tTime   0.01 (  0.02)\tData 0.0001 (0.0191)\tLoss (MSE) 12.511 (7.187)\n",
      "Epoch: [25][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 8.071 (7.040)\n",
      "Epoch: [25][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 8.506 (6.924)\n",
      "Epoch: [25][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 8.844 (7.113)\n",
      "Val: [0/9]\tTime  0.533 ( 0.533)\tLoss (MSE) 2.178 (2.178)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.867\tL1 0.571\tG-Mean 0.240\n",
      " * Many: MSE 2.197\tL1 0.984\tG-Mean 0.851\n",
      " * Median: MSE 2.292\tL1 1.451\tG-Mean 1.398\n",
      " * Low: MSE 0.042\tL1 0.205\tG-Mean 0.205\n",
      "Best MSE Loss: 1.847\n",
      "Epoch #25: Train loss [7.0836]; Val loss: MSE [1.8666], L1 [0.5705], G-Mean [0.2400]\n",
      "Epoch: [26][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 7.590 (7.590)\n",
      "Epoch: [26][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 3.818 (8.566)\n",
      "Epoch: [26][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 4.399 (8.140)\n",
      "Epoch: [26][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 7.518 (7.674)\n",
      "Epoch: [26][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 6.251 (7.377)\n",
      "Epoch: [26][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.847 (7.081)\n",
      "Epoch: [26][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 9.609 (6.935)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.838\tL1 0.598\tG-Mean 0.288\n",
      " * Many: MSE 2.305\tL1 1.068\tG-Mean 0.943\n",
      " * Median: MSE 2.038\tL1 1.361\tG-Mean 1.305\n",
      " * Low: MSE 0.013\tL1 0.115\tG-Mean 0.115\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #26: Train loss [7.0239]; Val loss: MSE [1.8376], L1 [0.5984], G-Mean [0.2885]\n",
      "Epoch: [27][ 0/65]\tTime   0.55 (  0.55)\tData 0.5415 (0.5415)\tLoss (MSE) 8.650 (8.650)\n",
      "Epoch: [27][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0505)\tLoss (MSE) 3.768 (7.417)\n",
      "Epoch: [27][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0264)\tLoss (MSE) 4.504 (7.089)\n",
      "Epoch: [27][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 7.253 (7.413)\n",
      "Epoch: [27][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 11.126 (7.325)\n",
      "Epoch: [27][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 6.750 (7.151)\n",
      "Epoch: [27][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 5.952 (7.042)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.207 (2.207)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.887\tL1 0.565\tG-Mean 0.260\n",
      " * Many: MSE 2.150\tL1 0.942\tG-Mean 0.805\n",
      " * Median: MSE 2.424\tL1 1.496\tG-Mean 1.445\n",
      " * Low: MSE 0.063\tL1 0.250\tG-Mean 0.250\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #27: Train loss [7.0056]; Val loss: MSE [1.8868], L1 [0.5650], G-Mean [0.2601]\n",
      "Epoch: [28][ 0/65]\tTime   0.55 (  0.55)\tData 0.5432 (0.5432)\tLoss (MSE) 4.219 (4.219)\n",
      "Epoch: [28][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0512)\tLoss (MSE) 4.973 (6.960)\n",
      "Epoch: [28][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 7.247 (7.221)\n",
      "Epoch: [28][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 9.122 (7.081)\n",
      "Epoch: [28][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.305 (7.257)\n",
      "Epoch: [28][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.722 (7.141)\n",
      "Epoch: [28][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 9.375 (7.065)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.156 (2.156)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.852\tL1 0.581\tG-Mean 0.268\n",
      " * Many: MSE 2.241\tL1 1.020\tG-Mean 0.891\n",
      " * Median: MSE 2.180\tL1 1.412\tG-Mean 1.358\n",
      " * Low: MSE 0.028\tL1 0.167\tG-Mean 0.167\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #28: Train loss [6.9692]; Val loss: MSE [1.8517], L1 [0.5809], G-Mean [0.2682]\n",
      "Epoch: [29][ 0/65]\tTime   0.56 (  0.56)\tData 0.5568 (0.5568)\tLoss (MSE) 5.750 (5.750)\n",
      "Epoch: [29][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 6.030 (6.269)\n",
      "Epoch: [29][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 6.462 (6.839)\n",
      "Epoch: [29][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 7.002 (6.656)\n",
      "Epoch: [29][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.679 (6.624)\n",
      "Epoch: [29][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.912 (6.755)\n",
      "Epoch: [29][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.380 (6.985)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.157 (2.157)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.852\tL1 0.580\tG-Mean 0.266\n",
      " * Many: MSE 2.237\tL1 1.017\tG-Mean 0.888\n",
      " * Median: MSE 2.187\tL1 1.415\tG-Mean 1.361\n",
      " * Low: MSE 0.029\tL1 0.169\tG-Mean 0.169\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #29: Train loss [7.0004]; Val loss: MSE [1.8519], L1 [0.5801], G-Mean [0.2660]\n",
      "Epoch: [30][ 0/65]\tTime   0.56 (  0.56)\tData 0.5490 (0.5490)\tLoss (MSE) 5.243 (5.243)\n",
      "Epoch: [30][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0549)\tLoss (MSE) 7.781 (7.637)\n",
      "Epoch: [30][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 6.226 (7.596)\n",
      "Epoch: [30][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 7.916 (7.384)\n",
      "Epoch: [30][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.010 (7.220)\n",
      "Epoch: [30][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 6.646 (7.070)\n",
      "Epoch: [30][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 6.493 (6.865)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.154 (2.154)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.850\tL1 0.580\tG-Mean 0.263\n",
      " * Many: MSE 2.234\tL1 1.016\tG-Mean 0.887\n",
      " * Median: MSE 2.184\tL1 1.414\tG-Mean 1.360\n",
      " * Low: MSE 0.029\tL1 0.170\tG-Mean 0.170\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #30: Train loss [6.9820]; Val loss: MSE [1.8498], L1 [0.5797], G-Mean [0.2634]\n",
      "Epoch: [31][ 0/65]\tTime   0.56 (  0.56)\tData 0.5567 (0.5567)\tLoss (MSE) 7.097 (7.097)\n",
      "Epoch: [31][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 11.198 (6.797)\n",
      "Epoch: [31][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 7.725 (6.583)\n",
      "Epoch: [31][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 8.326 (6.598)\n",
      "Epoch: [31][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 12.950 (7.156)\n",
      "Epoch: [31][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 8.326 (7.140)\n",
      "Epoch: [31][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.640 (7.055)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.150 (2.150)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.846\tL1 0.580\tG-Mean 0.256\n",
      " * Many: MSE 2.231\tL1 1.017\tG-Mean 0.888\n",
      " * Median: MSE 2.174\tL1 1.410\tG-Mean 1.356\n",
      " * Low: MSE 0.029\tL1 0.170\tG-Mean 0.169\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #31: Train loss [7.0485]; Val loss: MSE [1.8456], L1 [0.5798], G-Mean [0.2564]\n",
      "Epoch: [32][ 0/65]\tTime   0.55 (  0.55)\tData 0.5479 (0.5479)\tLoss (MSE) 10.336 (10.336)\n",
      "Epoch: [32][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0530)\tLoss (MSE) 9.108 (8.140)\n",
      "Epoch: [32][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 5.695 (7.562)\n",
      "Epoch: [32][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 6.183 (7.361)\n",
      "Epoch: [32][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 3.503 (6.978)\n",
      "Epoch: [32][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.871 (7.083)\n",
      "Epoch: [32][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 6.017 (7.046)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.160 (2.160)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.853\tL1 0.573\tG-Mean 0.246\n",
      " * Many: MSE 2.201\tL1 0.994\tG-Mean 0.863\n",
      " * Median: MSE 2.239\tL1 1.433\tG-Mean 1.380\n",
      " * Low: MSE 0.038\tL1 0.195\tG-Mean 0.194\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #32: Train loss [6.9841]; Val loss: MSE [1.8527], L1 [0.5734], G-Mean [0.2464]\n",
      "Epoch: [33][ 0/65]\tTime   0.56 (  0.56)\tData 0.5515 (0.5515)\tLoss (MSE) 8.716 (8.716)\n",
      "Epoch: [33][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 11.243 (7.820)\n",
      "Epoch: [33][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.679 (7.291)\n",
      "Epoch: [33][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 8.169 (6.870)\n",
      "Epoch: [33][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 8.514 (6.924)\n",
      "Epoch: [33][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.951 (7.050)\n",
      "Epoch: [33][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 7.802 (6.892)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.147 (2.147)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.843\tL1 0.578\tG-Mean 0.255\n",
      " * Many: MSE 2.220\tL1 1.011\tG-Mean 0.881\n",
      " * Median: MSE 2.181\tL1 1.413\tG-Mean 1.359\n",
      " * Low: MSE 0.032\tL1 0.177\tG-Mean 0.175\n",
      "Best MSE Loss: 1.838\n",
      "Epoch #33: Train loss [7.0427]; Val loss: MSE [1.8435], L1 [0.5783], G-Mean [0.2545]\n",
      "Epoch: [34][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 4.979 (4.979)\n",
      "Epoch: [34][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 6.211 (7.043)\n",
      "Epoch: [34][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 6.268 (7.085)\n",
      "Epoch: [34][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.527 (6.949)\n",
      "Epoch: [34][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.849 (6.763)\n",
      "Epoch: [34][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.108 (6.583)\n",
      "Epoch: [34][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.984 (6.841)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.674 (0.674)\n",
      " * Overall: MSE 1.818\tL1 0.610\tG-Mean 0.298\n",
      " * Many: MSE 2.327\tL1 1.093\tG-Mean 0.971\n",
      " * Median: MSE 1.935\tL1 1.323\tG-Mean 1.265\n",
      " * Low: MSE 0.009\tL1 0.090\tG-Mean 0.076\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #34: Train loss [6.9439]; Val loss: MSE [1.8184], L1 [0.6099], G-Mean [0.2985]\n",
      "Epoch: [35][ 0/65]\tTime   0.56 (  0.56)\tData 0.5581 (0.5581)\tLoss (MSE) 8.840 (8.840)\n",
      "Epoch: [35][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 7.885 (7.465)\n",
      "Epoch: [35][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 7.137 (6.747)\n",
      "Epoch: [35][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 5.126 (6.638)\n",
      "Epoch: [35][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 11.127 (6.802)\n",
      "Epoch: [35][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0117)\tLoss (MSE) 4.825 (6.931)\n",
      "Epoch: [35][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 15.471 (7.054)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.824\tL1 0.600\tG-Mean 0.281\n",
      " * Many: MSE 2.298\tL1 1.071\tG-Mean 0.948\n",
      " * Median: MSE 1.999\tL1 1.347\tG-Mean 1.290\n",
      " * Low: MSE 0.013\tL1 0.112\tG-Mean 0.107\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #35: Train loss [7.0342]; Val loss: MSE [1.8242], L1 [0.6000], G-Mean [0.2809]\n",
      "Epoch: [36][ 0/65]\tTime   0.55 (  0.55)\tData 0.5493 (0.5493)\tLoss (MSE) 6.097 (6.097)\n",
      "Epoch: [36][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 8.119 (7.090)\n",
      "Epoch: [36][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 6.593 (7.363)\n",
      "Epoch: [36][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 2.769 (7.165)\n",
      "Epoch: [36][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 10.335 (7.181)\n",
      "Epoch: [36][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 4.042 (7.081)\n",
      "Epoch: [36][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.897 (7.046)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.824\tL1 0.598\tG-Mean 0.283\n",
      " * Many: MSE 2.289\tL1 1.065\tG-Mean 0.941\n",
      " * Median: MSE 2.009\tL1 1.350\tG-Mean 1.294\n",
      " * Low: MSE 0.015\tL1 0.119\tG-Mean 0.109\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #36: Train loss [7.0400]; Val loss: MSE [1.8241], L1 [0.5982], G-Mean [0.2829]\n",
      "Epoch: [37][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 9.234 (9.234)\n",
      "Epoch: [37][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 6.258 (6.304)\n",
      "Epoch: [37][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.973 (5.996)\n",
      "Epoch: [37][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 8.766 (6.662)\n",
      "Epoch: [37][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 7.234 (6.578)\n",
      "Epoch: [37][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 8.413 (7.006)\n",
      "Epoch: [37][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 7.752 (6.982)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.186 (2.186)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.871\tL1 0.566\tG-Mean 0.256\n",
      " * Many: MSE 2.140\tL1 0.945\tG-Mean 0.808\n",
      " * Median: MSE 2.377\tL1 1.481\tG-Mean 1.429\n",
      " * Low: MSE 0.062\tL1 0.248\tG-Mean 0.247\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #37: Train loss [6.9901]; Val loss: MSE [1.8712], L1 [0.5664], G-Mean [0.2556]\n",
      "Epoch: [38][ 0/65]\tTime   0.56 (  0.56)\tData 0.5509 (0.5509)\tLoss (MSE) 7.436 (7.436)\n",
      "Epoch: [38][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 8.576 (8.141)\n",
      "Epoch: [38][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 9.445 (8.162)\n",
      "Epoch: [38][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 4.215 (7.831)\n",
      "Epoch: [38][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 4.150 (7.478)\n",
      "Epoch: [38][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 6.671 (7.291)\n",
      "Epoch: [38][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.558 (7.187)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.138 (2.138)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.839\tL1 0.581\tG-Mean 0.258\n",
      " * Many: MSE 2.228\tL1 1.019\tG-Mean 0.890\n",
      " * Median: MSE 2.148\tL1 1.401\tG-Mean 1.347\n",
      " * Low: MSE 0.029\tL1 0.168\tG-Mean 0.166\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #38: Train loss [7.0756]; Val loss: MSE [1.8386], L1 [0.5809], G-Mean [0.2579]\n",
      "Epoch: [39][ 0/65]\tTime   0.55 (  0.55)\tData 0.5457 (0.5457)\tLoss (MSE) 3.751 (3.751)\n",
      "Epoch: [39][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 6.032 (6.046)\n",
      "Epoch: [39][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 7.552 (6.440)\n",
      "Epoch: [39][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 6.516 (6.636)\n",
      "Epoch: [39][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 16.648 (6.950)\n",
      "Epoch: [39][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 10.662 (6.973)\n",
      "Epoch: [39][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 7.855 (6.925)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.123 (2.123)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.828\tL1 0.588\tG-Mean 0.268\n",
      " * Many: MSE 2.248\tL1 1.037\tG-Mean 0.910\n",
      " * Median: MSE 2.078\tL1 1.376\tG-Mean 1.320\n",
      " * Low: MSE 0.024\tL1 0.149\tG-Mean 0.141\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #39: Train loss [6.9631]; Val loss: MSE [1.8281], L1 [0.5877], G-Mean [0.2678]\n",
      "Epoch: [40][ 0/65]\tTime   0.55 (  0.55)\tData 0.5484 (0.5484)\tLoss (MSE) 4.761 (4.761)\n",
      "Epoch: [40][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0582)\tLoss (MSE) 7.187 (6.096)\n",
      "Epoch: [40][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 4.462 (7.095)\n",
      "Epoch: [40][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 6.348 (7.453)\n",
      "Epoch: [40][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.289 (7.116)\n",
      "Epoch: [40][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.780 (6.765)\n",
      "Epoch: [40][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 7.418 (6.955)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.130 (2.130)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.833\tL1 0.584\tG-Mean 0.265\n",
      " * Many: MSE 2.237\tL1 1.028\tG-Mean 0.900\n",
      " * Median: MSE 2.112\tL1 1.388\tG-Mean 1.333\n",
      " * Low: MSE 0.026\tL1 0.159\tG-Mean 0.154\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #40: Train loss [7.0093]; Val loss: MSE [1.8328], L1 [0.5843], G-Mean [0.2646]\n",
      "Epoch: [41][ 0/65]\tTime   0.55 (  0.55)\tData 0.5420 (0.5420)\tLoss (MSE) 7.881 (7.881)\n",
      "Epoch: [41][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0550)\tLoss (MSE) 3.739 (6.954)\n",
      "Epoch: [41][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.897 (6.925)\n",
      "Epoch: [41][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 4.344 (6.825)\n",
      "Epoch: [41][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.303 (6.844)\n",
      "Epoch: [41][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.764 (6.799)\n",
      "Epoch: [41][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.895 (6.989)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.824\tL1 0.589\tG-Mean 0.270\n",
      " * Many: MSE 2.246\tL1 1.039\tG-Mean 0.912\n",
      " * Median: MSE 2.070\tL1 1.373\tG-Mean 1.317\n",
      " * Low: MSE 0.024\tL1 0.148\tG-Mean 0.135\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #41: Train loss [7.0240]; Val loss: MSE [1.8240], L1 [0.5886], G-Mean [0.2700]\n",
      "Epoch: [42][ 0/65]\tTime   0.55 (  0.55)\tData 0.5441 (0.5441)\tLoss (MSE) 5.307 (5.307)\n",
      "Epoch: [42][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 5.721 (6.002)\n",
      "Epoch: [42][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 11.953 (7.102)\n",
      "Epoch: [42][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 8.305 (7.136)\n",
      "Epoch: [42][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 8.271 (7.220)\n",
      "Epoch: [42][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 5.404 (7.418)\n",
      "Epoch: [42][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 6.056 (7.099)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.233 (2.233)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.908\tL1 0.560\tG-Mean 0.232\n",
      " * Many: MSE 2.079\tL1 0.885\tG-Mean 0.742\n",
      " * Median: MSE 2.580\tL1 1.548\tG-Mean 1.498\n",
      " * Low: MSE 0.098\tL1 0.312\tG-Mean 0.311\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #42: Train loss [6.9981]; Val loss: MSE [1.9078], L1 [0.5602], G-Mean [0.2319]\n",
      "Epoch: [43][ 0/65]\tTime   0.64 (  0.64)\tData 0.6290 (0.6290)\tLoss (MSE) 14.066 (14.066)\n",
      "Epoch: [43][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 5.907 (7.469)\n",
      "Epoch: [43][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 6.261 (7.343)\n",
      "Epoch: [43][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 6.624 (7.183)\n",
      "Epoch: [43][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 5.270 (6.878)\n",
      "Epoch: [43][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 8.035 (6.971)\n",
      "Epoch: [43][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.886 (6.990)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.196 (2.196)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.881\tL1 0.564\tG-Mean 0.249\n",
      " * Many: MSE 2.104\tL1 0.916\tG-Mean 0.777\n",
      " * Median: MSE 2.455\tL1 1.506\tG-Mean 1.455\n",
      " * Low: MSE 0.079\tL1 0.279\tG-Mean 0.276\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #43: Train loss [6.9718]; Val loss: MSE [1.8807], L1 [0.5637], G-Mean [0.2493]\n",
      "Epoch: [44][ 0/65]\tTime   0.56 (  0.56)\tData 0.5500 (0.5500)\tLoss (MSE) 5.526 (5.526)\n",
      "Epoch: [44][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 3.410 (6.723)\n",
      "Epoch: [44][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 9.735 (7.211)\n",
      "Epoch: [44][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 7.174 (7.316)\n",
      "Epoch: [44][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.246 (7.285)\n",
      "Epoch: [44][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.265 (7.276)\n",
      "Epoch: [44][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.899 (7.149)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.204 (2.204)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.886\tL1 0.563\tG-Mean 0.246\n",
      " * Many: MSE 2.100\tL1 0.911\tG-Mean 0.770\n",
      " * Median: MSE 2.476\tL1 1.513\tG-Mean 1.462\n",
      " * Low: MSE 0.082\tL1 0.284\tG-Mean 0.281\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #44: Train loss [7.1315]; Val loss: MSE [1.8864], L1 [0.5628], G-Mean [0.2458]\n",
      "Epoch: [45][ 0/65]\tTime   0.55 (  0.55)\tData 0.5494 (0.5494)\tLoss (MSE) 8.303 (8.303)\n",
      "Epoch: [45][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 3.531 (6.400)\n",
      "Epoch: [45][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 7.307 (6.904)\n",
      "Epoch: [45][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 7.352 (6.576)\n",
      "Epoch: [45][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.355 (6.466)\n",
      "Epoch: [45][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 6.353 (6.694)\n",
      "Epoch: [45][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 11.384 (6.892)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.835\tL1 0.578\tG-Mean 0.249\n",
      " * Many: MSE 2.205\tL1 1.006\tG-Mean 0.876\n",
      " * Median: MSE 2.166\tL1 1.407\tG-Mean 1.352\n",
      " * Low: MSE 0.035\tL1 0.182\tG-Mean 0.176\n",
      "Best MSE Loss: 1.818\n",
      "Epoch #45: Train loss [6.9990]; Val loss: MSE [1.8351], L1 [0.5785], G-Mean [0.2493]\n",
      "Epoch: [46][ 0/65]\tTime   0.56 (  0.56)\tData 0.5478 (0.5478)\tLoss (MSE) 7.544 (7.544)\n",
      "Epoch: [46][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 2.952 (6.625)\n",
      "Epoch: [46][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.694 (7.728)\n",
      "Epoch: [46][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 7.576 (7.503)\n",
      "Epoch: [46][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.435 (7.710)\n",
      "Epoch: [46][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.220 (7.448)\n",
      "Epoch: [46][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.330 (7.170)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.100 (2.100)\tLoss (L1) 0.667 (0.667)\n",
      " * Overall: MSE 1.814\tL1 0.602\tG-Mean 0.286\n",
      " * Many: MSE 2.292\tL1 1.073\tG-Mean 0.950\n",
      " * Median: MSE 1.972\tL1 1.337\tG-Mean 1.280\n",
      " * Low: MSE 0.014\tL1 0.111\tG-Mean 0.098\n",
      "Best MSE Loss: 1.814\n",
      "Epoch #46: Train loss [7.1278]; Val loss: MSE [1.8143], L1 [0.6016], G-Mean [0.2860]\n",
      "Epoch: [47][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 8.135 (8.135)\n",
      "Epoch: [47][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0604)\tLoss (MSE) 3.902 (6.768)\n",
      "Epoch: [47][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0316)\tLoss (MSE) 6.732 (7.062)\n",
      "Epoch: [47][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0214)\tLoss (MSE) 6.494 (6.807)\n",
      "Epoch: [47][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.193 (7.109)\n",
      "Epoch: [47][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 3.530 (7.075)\n",
      "Epoch: [47][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 9.853 (7.076)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.171 (2.171)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.862\tL1 0.567\tG-Mean 0.258\n",
      " * Many: MSE 2.125\tL1 0.941\tG-Mean 0.803\n",
      " * Median: MSE 2.364\tL1 1.476\tG-Mean 1.423\n",
      " * Low: MSE 0.066\tL1 0.253\tG-Mean 0.247\n",
      "Best MSE Loss: 1.814\n",
      "Epoch #47: Train loss [7.0775]; Val loss: MSE [1.8616], L1 [0.5674], G-Mean [0.2584]\n",
      "Epoch: [48][ 0/65]\tTime   0.56 (  0.56)\tData 0.5502 (0.5502)\tLoss (MSE) 4.299 (4.299)\n",
      "Epoch: [48][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0506)\tLoss (MSE) 6.544 (6.341)\n",
      "Epoch: [48][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 4.124 (7.070)\n",
      "Epoch: [48][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.591 (6.791)\n",
      "Epoch: [48][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 6.248 (7.190)\n",
      "Epoch: [48][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 12.042 (7.186)\n",
      "Epoch: [48][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 7.496 (7.040)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.176 (2.176)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.866\tL1 0.567\tG-Mean 0.259\n",
      " * Many: MSE 2.128\tL1 0.940\tG-Mean 0.803\n",
      " * Median: MSE 2.381\tL1 1.481\tG-Mean 1.429\n",
      " * Low: MSE 0.066\tL1 0.253\tG-Mean 0.249\n",
      "Best MSE Loss: 1.814\n",
      "Epoch #48: Train loss [7.0454]; Val loss: MSE [1.8665], L1 [0.5670], G-Mean [0.2592]\n",
      "Epoch: [49][ 0/65]\tTime   0.60 (  0.60)\tData 0.5841 (0.5841)\tLoss (MSE) 8.716 (8.716)\n",
      "Epoch: [49][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 5.208 (6.781)\n",
      "Epoch: [49][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.937 (7.279)\n",
      "Epoch: [49][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 8.407 (6.876)\n",
      "Epoch: [49][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.382 (7.028)\n",
      "Epoch: [49][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 6.328 (6.983)\n",
      "Epoch: [49][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 10.160 (6.979)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.149 (2.149)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.846\tL1 0.573\tG-Mean 0.253\n",
      " * Many: MSE 2.172\tL1 0.980\tG-Mean 0.847\n",
      " * Median: MSE 2.248\tL1 1.436\tG-Mean 1.383\n",
      " * Low: MSE 0.046\tL1 0.211\tG-Mean 0.206\n",
      "Best MSE Loss: 1.814\n",
      "Epoch #49: Train loss [6.9807]; Val loss: MSE [1.8457], L1 [0.5729], G-Mean [0.2532]\n",
      "Epoch: [50][ 0/65]\tTime   0.56 (  0.56)\tData 0.5532 (0.5532)\tLoss (MSE) 6.688 (6.688)\n",
      "Epoch: [50][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0574)\tLoss (MSE) 5.101 (7.237)\n",
      "Epoch: [50][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 8.389 (6.874)\n",
      "Epoch: [50][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 9.060 (6.742)\n",
      "Epoch: [50][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 11.263 (7.173)\n",
      "Epoch: [50][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 8.523 (6.899)\n",
      "Epoch: [50][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.919 (6.982)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.159 (2.159)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.855\tL1 0.569\tG-Mean 0.257\n",
      " * Many: MSE 2.147\tL1 0.958\tG-Mean 0.823\n",
      " * Median: MSE 2.314\tL1 1.459\tG-Mean 1.405\n",
      " * Low: MSE 0.057\tL1 0.234\tG-Mean 0.228\n",
      "Best MSE Loss: 1.814\n",
      "Epoch #50: Train loss [7.1265]; Val loss: MSE [1.8546], L1 [0.5693], G-Mean [0.2572]\n",
      "Epoch: [51][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 9.316 (9.316)\n",
      "Epoch: [51][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 5.996 (7.327)\n",
      "Epoch: [51][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 5.255 (7.007)\n",
      "Epoch: [51][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 7.200 (7.213)\n",
      "Epoch: [51][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.204 (7.016)\n",
      "Epoch: [51][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 8.391 (7.008)\n",
      "Epoch: [51][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 8.759 (6.804)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.091 (2.091)\tLoss (L1) 0.673 (0.673)\n",
      " * Overall: MSE 1.810\tL1 0.609\tG-Mean 0.296\n",
      " * Many: MSE 2.314\tL1 1.089\tG-Mean 0.967\n",
      " * Median: MSE 1.923\tL1 1.318\tG-Mean 1.260\n",
      " * Low: MSE 0.010\tL1 0.094\tG-Mean 0.080\n",
      "Best MSE Loss: 1.810\n",
      "Epoch #51: Train loss [6.9432]; Val loss: MSE [1.8100], L1 [0.6089], G-Mean [0.2961]\n",
      "Epoch: [52][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 9.403 (9.403)\n",
      "Epoch: [52][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0546)\tLoss (MSE) 4.753 (6.700)\n",
      "Epoch: [52][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 8.416 (6.709)\n",
      "Epoch: [52][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 4.969 (7.010)\n",
      "Epoch: [52][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 8.118 (7.165)\n",
      "Epoch: [52][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.421 (7.176)\n",
      "Epoch: [52][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.803 (7.287)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.126 (2.126)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.833\tL1 0.580\tG-Mean 0.260\n",
      " * Many: MSE 2.208\tL1 1.010\tG-Mean 0.880\n",
      " * Median: MSE 2.157\tL1 1.404\tG-Mean 1.349\n",
      " * Low: MSE 0.033\tL1 0.177\tG-Mean 0.170\n",
      "Best MSE Loss: 1.810\n",
      "Epoch #52: Train loss [7.1319]; Val loss: MSE [1.8326], L1 [0.5800], G-Mean [0.2595]\n",
      "Epoch: [53][ 0/65]\tTime   0.56 (  0.56)\tData 0.5529 (0.5529)\tLoss (MSE) 6.406 (6.406)\n",
      "Epoch: [53][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 5.822 (9.075)\n",
      "Epoch: [53][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 4.798 (8.287)\n",
      "Epoch: [53][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 8.181 (7.794)\n",
      "Epoch: [53][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.709 (7.181)\n",
      "Epoch: [53][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0120)\tLoss (MSE) 7.029 (7.003)\n",
      "Epoch: [53][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 9.555 (7.238)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.183 (2.183)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.872\tL1 0.565\tG-Mean 0.253\n",
      " * Many: MSE 2.119\tL1 0.931\tG-Mean 0.792\n",
      " * Median: MSE 2.414\tL1 1.493\tG-Mean 1.441\n",
      " * Low: MSE 0.070\tL1 0.262\tG-Mean 0.259\n",
      "Best MSE Loss: 1.810\n",
      "Epoch #53: Train loss [7.1831]; Val loss: MSE [1.8724], L1 [0.5649], G-Mean [0.2530]\n",
      "Epoch: [54][ 0/65]\tTime   0.56 (  0.56)\tData 0.5577 (0.5577)\tLoss (MSE) 7.921 (7.921)\n",
      "Epoch: [54][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0596)\tLoss (MSE) 3.108 (7.391)\n",
      "Epoch: [54][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 10.694 (7.200)\n",
      "Epoch: [54][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 8.155 (7.322)\n",
      "Epoch: [54][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 6.837 (7.254)\n",
      "Epoch: [54][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 10.163 (7.152)\n",
      "Epoch: [54][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 10.523 (7.205)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.156 (2.156)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.855\tL1 0.569\tG-Mean 0.257\n",
      " * Many: MSE 2.132\tL1 0.949\tG-Mean 0.813\n",
      " * Median: MSE 2.330\tL1 1.465\tG-Mean 1.412\n",
      " * Low: MSE 0.062\tL1 0.244\tG-Mean 0.238\n",
      "Best MSE Loss: 1.810\n",
      "Epoch #54: Train loss [7.1890]; Val loss: MSE [1.8550], L1 [0.5687], G-Mean [0.2573]\n",
      "Epoch: [55][ 0/65]\tTime   0.56 (  0.56)\tData 0.5510 (0.5510)\tLoss (MSE) 3.762 (3.762)\n",
      "Epoch: [55][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 8.444 (5.734)\n",
      "Epoch: [55][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 9.699 (6.559)\n",
      "Epoch: [55][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 8.762 (7.309)\n",
      "Epoch: [55][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 7.155 (7.352)\n",
      "Epoch: [55][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.471 (7.528)\n",
      "Epoch: [55][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.673 (7.373)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.087 (2.087)\tLoss (L1) 0.674 (0.674)\n",
      " * Overall: MSE 1.807\tL1 0.608\tG-Mean 0.292\n",
      " * Many: MSE 2.304\tL1 1.084\tG-Mean 0.962\n",
      " * Median: MSE 1.921\tL1 1.317\tG-Mean 1.259\n",
      " * Low: MSE 0.013\tL1 0.101\tG-Mean 0.084\n",
      "Best MSE Loss: 1.807\n",
      "Epoch #55: Train loss [7.3947]; Val loss: MSE [1.8069], L1 [0.6078], G-Mean [0.2925]\n",
      "Epoch: [56][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 7.329 (7.329)\n",
      "Epoch: [56][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 10.591 (6.953)\n",
      "Epoch: [56][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 8.399 (7.348)\n",
      "Epoch: [56][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 7.341 (7.743)\n",
      "Epoch: [56][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 8.416 (7.695)\n",
      "Epoch: [56][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 10.158 (7.418)\n",
      "Epoch: [56][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.821 (7.222)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.320 (2.320)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.983\tL1 0.581\tG-Mean 0.268\n",
      " * Many: MSE 1.972\tL1 0.772\tG-Mean 0.616\n",
      " * Median: MSE 2.937\tL1 1.659\tG-Mean 1.612\n",
      " * Low: MSE 0.189\tL1 0.432\tG-Mean 0.430\n",
      "Best MSE Loss: 1.807\n",
      "Epoch #56: Train loss [7.1929]; Val loss: MSE [1.9829], L1 [0.5808], G-Mean [0.2675]\n",
      "Epoch: [57][ 0/65]\tTime   0.56 (  0.56)\tData 0.5597 (0.5597)\tLoss (MSE) 9.348 (9.348)\n",
      "Epoch: [57][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0585)\tLoss (MSE) 5.847 (7.754)\n",
      "Epoch: [57][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0306)\tLoss (MSE) 7.318 (7.816)\n",
      "Epoch: [57][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 7.876 (8.315)\n",
      "Epoch: [57][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 10.156 (8.092)\n",
      "Epoch: [57][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 6.306 (7.836)\n",
      "Epoch: [57][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.147 (7.635)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.716 (0.716)\n",
      " * Overall: MSE 1.802\tL1 0.655\tG-Mean 0.354\n",
      " * Many: MSE 2.452\tL1 1.179\tG-Mean 1.066\n",
      " * Median: MSE 1.676\tL1 1.221\tG-Mean 1.160\n",
      " * Low: MSE 0.001\tL1 0.027\tG-Mean 0.016\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #57: Train loss [7.5842]; Val loss: MSE [1.8023], L1 [0.6554], G-Mean [0.3535]\n",
      "Epoch: [58][ 0/65]\tTime   0.56 (  0.56)\tData 0.5484 (0.5484)\tLoss (MSE) 8.155 (8.155)\n",
      "Epoch: [58][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 13.382 (6.928)\n",
      "Epoch: [58][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 11.977 (7.202)\n",
      "Epoch: [58][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 6.745 (7.159)\n",
      "Epoch: [58][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 8.450 (7.332)\n",
      "Epoch: [58][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.173 (7.205)\n",
      "Epoch: [58][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 11.893 (7.304)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.475 (2.475)\tLoss (L1) 0.710 (0.710)\n",
      " * Overall: MSE 2.112\tL1 0.622\tG-Mean 0.258\n",
      " * Many: MSE 1.896\tL1 0.646\tG-Mean 0.472\n",
      " * Median: MSE 3.390\tL1 1.790\tG-Mean 1.745\n",
      " * Low: MSE 0.326\tL1 0.568\tG-Mean 0.566\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #58: Train loss [7.4136]; Val loss: MSE [2.1118], L1 [0.6222], G-Mean [0.2578]\n",
      "Epoch: [59][ 0/65]\tTime   0.56 (  0.56)\tData 0.5550 (0.5550)\tLoss (MSE) 14.106 (14.106)\n",
      "Epoch: [59][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 6.345 (8.953)\n",
      "Epoch: [59][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 9.778 (8.393)\n",
      "Epoch: [59][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 7.811 (8.281)\n",
      "Epoch: [59][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.158 (8.243)\n",
      "Epoch: [59][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.216 (7.748)\n",
      "Epoch: [59][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 7.863 (7.366)\n",
      "Val: [0/9]\tTime  0.582 ( 0.582)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.816\tL1 0.599\tG-Mean 0.284\n",
      " * Many: MSE 2.280\tL1 1.064\tG-Mean 0.940\n",
      " * Median: MSE 1.991\tL1 1.343\tG-Mean 1.286\n",
      " * Low: MSE 0.016\tL1 0.119\tG-Mean 0.106\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #59: Train loss [7.3527]; Val loss: MSE [1.8159], L1 [0.5986], G-Mean [0.2839]\n",
      "Epoch: [60][ 0/65]\tTime   0.68 (  0.68)\tData 0.6745 (0.6745)\tLoss (MSE) 13.147 (13.147)\n",
      "Epoch: [60][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0668)\tLoss (MSE) 5.068 (7.687)\n",
      "Epoch: [60][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0350)\tLoss (MSE) 5.001 (7.531)\n",
      "Epoch: [60][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0237)\tLoss (MSE) 4.066 (7.595)\n",
      "Epoch: [60][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 6.708 (7.268)\n",
      "Epoch: [60][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 5.761 (7.110)\n",
      "Epoch: [60][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 9.484 (7.191)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.865\tL1 0.565\tG-Mean 0.245\n",
      " * Many: MSE 2.103\tL1 0.925\tG-Mean 0.785\n",
      " * Median: MSE 2.402\tL1 1.488\tG-Mean 1.435\n",
      " * Low: MSE 0.075\tL1 0.268\tG-Mean 0.260\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #60: Train loss [7.1279]; Val loss: MSE [1.8650], L1 [0.5655], G-Mean [0.2446]\n",
      "Epoch: [61][ 0/65]\tTime   0.56 (  0.56)\tData 0.5488 (0.5488)\tLoss (MSE) 5.808 (5.808)\n",
      "Epoch: [61][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 5.184 (6.847)\n",
      "Epoch: [61][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 11.616 (7.145)\n",
      "Epoch: [61][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 10.815 (7.317)\n",
      "Epoch: [61][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 11.757 (7.513)\n",
      "Epoch: [61][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.794 (7.622)\n",
      "Epoch: [61][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.461 (7.481)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.108 (2.108)\tLoss (L1) 0.657 (0.657)\n",
      " * Overall: MSE 1.821\tL1 0.589\tG-Mean 0.269\n",
      " * Many: MSE 2.243\tL1 1.039\tG-Mean 0.912\n",
      " * Median: MSE 2.067\tL1 1.372\tG-Mean 1.316\n",
      " * Low: MSE 0.023\tL1 0.146\tG-Mean 0.137\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #61: Train loss [7.4861]; Val loss: MSE [1.8207], L1 [0.5890], G-Mean [0.2692]\n",
      "Epoch: [62][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 5.590 (5.590)\n",
      "Epoch: [62][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0506)\tLoss (MSE) 7.111 (6.481)\n",
      "Epoch: [62][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 10.674 (6.985)\n",
      "Epoch: [62][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 3.823 (7.215)\n",
      "Epoch: [62][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 6.721 (7.482)\n",
      "Epoch: [62][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 10.315 (7.393)\n",
      "Epoch: [62][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 7.020 (7.225)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.165 (2.165)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.857\tL1 0.567\tG-Mean 0.250\n",
      " * Many: MSE 2.127\tL1 0.944\tG-Mean 0.807\n",
      " * Median: MSE 2.344\tL1 1.469\tG-Mean 1.417\n",
      " * Low: MSE 0.063\tL1 0.246\tG-Mean 0.239\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #62: Train loss [7.1051]; Val loss: MSE [1.8575], L1 [0.5670], G-Mean [0.2502]\n",
      "Epoch: [63][ 0/65]\tTime   0.55 (  0.55)\tData 0.5454 (0.5454)\tLoss (MSE) 9.810 (9.810)\n",
      "Epoch: [63][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 3.897 (7.250)\n",
      "Epoch: [63][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.272 (6.862)\n",
      "Epoch: [63][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 5.817 (7.058)\n",
      "Epoch: [63][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 8.350 (7.273)\n",
      "Epoch: [63][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 9.956 (7.493)\n",
      "Epoch: [63][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 8.714 (7.486)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.165 (2.165)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.857\tL1 0.568\tG-Mean 0.254\n",
      " * Many: MSE 2.122\tL1 0.941\tG-Mean 0.804\n",
      " * Median: MSE 2.353\tL1 1.471\tG-Mean 1.418\n",
      " * Low: MSE 0.065\tL1 0.249\tG-Mean 0.240\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #63: Train loss [7.4953]; Val loss: MSE [1.8572], L1 [0.5677], G-Mean [0.2542]\n",
      "Epoch: [64][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 11.808 (11.808)\n",
      "Epoch: [64][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 9.932 (7.179)\n",
      "Epoch: [64][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 4.016 (7.248)\n",
      "Epoch: [64][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 4.004 (7.289)\n",
      "Epoch: [64][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 12.072 (7.504)\n",
      "Epoch: [64][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.834 (7.764)\n",
      "Epoch: [64][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.001 (7.276)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.080 (2.080)\tLoss (L1) 0.684 (0.684)\n",
      " * Overall: MSE 1.805\tL1 0.621\tG-Mean 0.305\n",
      " * Many: MSE 2.352\tL1 1.115\tG-Mean 0.996\n",
      " * Median: MSE 1.849\tL1 1.290\tG-Mean 1.232\n",
      " * Low: MSE 0.006\tL1 0.067\tG-Mean 0.052\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #64: Train loss [7.3431]; Val loss: MSE [1.8052], L1 [0.6206], G-Mean [0.3053]\n",
      "Epoch: [65][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 7.450 (7.450)\n",
      "Epoch: [65][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0594)\tLoss (MSE) 5.476 (7.234)\n",
      "Epoch: [65][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 11.182 (7.598)\n",
      "Epoch: [65][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 4.092 (7.460)\n",
      "Epoch: [65][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 7.878 (7.324)\n",
      "Epoch: [65][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.075 (7.074)\n",
      "Epoch: [65][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 6.684 (7.133)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.311 (2.311)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.973\tL1 0.581\tG-Mean 0.263\n",
      " * Many: MSE 1.970\tL1 0.776\tG-Mean 0.619\n",
      " * Median: MSE 2.896\tL1 1.646\tG-Mean 1.598\n",
      " * Low: MSE 0.186\tL1 0.428\tG-Mean 0.424\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #65: Train loss [7.0967]; Val loss: MSE [1.9731], L1 [0.5806], G-Mean [0.2632]\n",
      "Epoch: [66][ 0/65]\tTime   0.57 (  0.57)\tData 0.5655 (0.5655)\tLoss (MSE) 8.931 (8.931)\n",
      "Epoch: [66][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0594)\tLoss (MSE) 3.330 (7.988)\n",
      "Epoch: [66][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 3.535 (8.228)\n",
      "Epoch: [66][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 7.923 (8.142)\n",
      "Epoch: [66][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 6.685 (8.020)\n",
      "Epoch: [66][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 8.642 (8.421)\n",
      "Epoch: [66][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 7.274 (8.182)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.157 (2.157)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.851\tL1 0.568\tG-Mean 0.257\n",
      " * Many: MSE 2.108\tL1 0.936\tG-Mean 0.798\n",
      " * Median: MSE 2.354\tL1 1.472\tG-Mean 1.418\n",
      " * Low: MSE 0.071\tL1 0.259\tG-Mean 0.244\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #66: Train loss [8.0848]; Val loss: MSE [1.8507], L1 [0.5680], G-Mean [0.2566]\n",
      "Epoch: [67][ 0/65]\tTime   0.55 (  0.55)\tData 0.5468 (0.5468)\tLoss (MSE) 4.968 (4.968)\n",
      "Epoch: [67][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0582)\tLoss (MSE) 6.750 (7.765)\n",
      "Epoch: [67][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 8.356 (7.217)\n",
      "Epoch: [67][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 7.170 (6.952)\n",
      "Epoch: [67][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.147 (6.947)\n",
      "Epoch: [67][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.739 (7.194)\n",
      "Epoch: [67][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 9.891 (7.279)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.158 (2.158)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.853\tL1 0.567\tG-Mean 0.252\n",
      " * Many: MSE 2.104\tL1 0.932\tG-Mean 0.794\n",
      " * Median: MSE 2.367\tL1 1.476\tG-Mean 1.423\n",
      " * Low: MSE 0.071\tL1 0.260\tG-Mean 0.247\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #67: Train loss [7.2501]; Val loss: MSE [1.8528], L1 [0.5667], G-Mean [0.2516]\n",
      "Epoch: [68][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 14.156 (14.156)\n",
      "Epoch: [68][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 4.721 (7.068)\n",
      "Epoch: [68][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 4.608 (6.826)\n",
      "Epoch: [68][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 6.443 (7.755)\n",
      "Epoch: [68][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 6.811 (7.660)\n",
      "Epoch: [68][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 6.420 (7.584)\n",
      "Epoch: [68][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.648 (7.497)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.126 (2.126)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.833\tL1 0.575\tG-Mean 0.263\n",
      " * Many: MSE 2.162\tL1 0.981\tG-Mean 0.848\n",
      " * Median: MSE 2.217\tL1 1.425\tG-Mean 1.371\n",
      " * Low: MSE 0.047\tL1 0.209\tG-Mean 0.195\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #68: Train loss [7.4454]; Val loss: MSE [1.8328], L1 [0.5746], G-Mean [0.2628]\n",
      "Epoch: [69][ 0/65]\tTime   0.56 (  0.56)\tData 0.5503 (0.5503)\tLoss (MSE) 7.023 (7.023)\n",
      "Epoch: [69][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 7.869 (6.896)\n",
      "Epoch: [69][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 8.577 (7.402)\n",
      "Epoch: [69][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 7.864 (7.815)\n",
      "Epoch: [69][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.092 (7.632)\n",
      "Epoch: [69][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 8.470 (7.480)\n",
      "Epoch: [69][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.218 (7.360)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.453 (2.453)\tLoss (L1) 0.702 (0.702)\n",
      " * Overall: MSE 2.091\tL1 0.614\tG-Mean 0.278\n",
      " * Many: MSE 1.915\tL1 0.669\tG-Mean 0.499\n",
      " * Median: MSE 3.303\tL1 1.766\tG-Mean 1.721\n",
      " * Low: MSE 0.297\tL1 0.544\tG-Mean 0.542\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #69: Train loss [7.5377]; Val loss: MSE [2.0915], L1 [0.6143], G-Mean [0.2777]\n",
      "Epoch: [70][ 0/65]\tTime   0.57 (  0.57)\tData 0.5604 (0.5604)\tLoss (MSE) 16.539 (16.539)\n",
      "Epoch: [70][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0556)\tLoss (MSE) 12.096 (8.430)\n",
      "Epoch: [70][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 7.529 (8.421)\n",
      "Epoch: [70][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 8.940 (8.293)\n",
      "Epoch: [70][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.027 (7.881)\n",
      "Epoch: [70][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0120)\tLoss (MSE) 9.357 (7.720)\n",
      "Epoch: [70][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 6.765 (7.598)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.073 (2.073)\tLoss (L1) 0.677 (0.677)\n",
      " * Overall: MSE 1.803\tL1 0.614\tG-Mean 0.301\n",
      " * Many: MSE 2.323\tL1 1.099\tG-Mean 0.978\n",
      " * Median: MSE 1.881\tL1 1.302\tG-Mean 1.244\n",
      " * Low: MSE 0.009\tL1 0.086\tG-Mean 0.072\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #70: Train loss [7.4763]; Val loss: MSE [1.8026], L1 [0.6136], G-Mean [0.3014]\n",
      "Epoch: [71][ 0/65]\tTime   0.56 (  0.56)\tData 0.5489 (0.5489)\tLoss (MSE) 10.583 (10.583)\n",
      "Epoch: [71][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0600)\tLoss (MSE) 5.572 (7.885)\n",
      "Epoch: [71][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0315)\tLoss (MSE) 5.162 (7.739)\n",
      "Epoch: [71][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 11.608 (7.952)\n",
      "Epoch: [71][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 3.075 (7.696)\n",
      "Epoch: [71][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 9.580 (7.695)\n",
      "Epoch: [71][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 8.516 (7.287)\n",
      "Val: [0/9]\tTime  0.534 ( 0.534)\tLoss (MSE) 2.138 (2.138)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.841\tL1 0.574\tG-Mean 0.257\n",
      " * Many: MSE 2.170\tL1 0.981\tG-Mean 0.848\n",
      " * Median: MSE 2.236\tL1 1.432\tG-Mean 1.379\n",
      " * Low: MSE 0.046\tL1 0.209\tG-Mean 0.201\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #71: Train loss [7.2842]; Val loss: MSE [1.8411], L1 [0.5736], G-Mean [0.2568]\n",
      "Epoch: [72][ 0/65]\tTime   0.57 (  0.57)\tData 0.5620 (0.5620)\tLoss (MSE) 8.924 (8.924)\n",
      "Epoch: [72][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0527)\tLoss (MSE) 6.701 (7.147)\n",
      "Epoch: [72][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 5.976 (7.037)\n",
      "Epoch: [72][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 7.455 (6.984)\n",
      "Epoch: [72][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.524 (6.873)\n",
      "Epoch: [72][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 10.707 (6.801)\n",
      "Epoch: [72][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 10.096 (7.010)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.826\tL1 0.579\tG-Mean 0.263\n",
      " * Many: MSE 2.185\tL1 0.999\tG-Mean 0.868\n",
      " * Median: MSE 2.156\tL1 1.404\tG-Mean 1.350\n",
      " * Low: MSE 0.040\tL1 0.191\tG-Mean 0.174\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #72: Train loss [7.0857]; Val loss: MSE [1.8259], L1 [0.5795], G-Mean [0.2630]\n",
      "Epoch: [73][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 5.455 (5.455)\n",
      "Epoch: [73][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 5.268 (6.451)\n",
      "Epoch: [73][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 6.617 (6.295)\n",
      "Epoch: [73][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 5.367 (6.980)\n",
      "Epoch: [73][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 12.473 (7.371)\n",
      "Epoch: [73][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0120)\tLoss (MSE) 9.250 (7.775)\n",
      "Epoch: [73][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 7.871 (7.610)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.822\tL1 0.582\tG-Mean 0.256\n",
      " * Many: MSE 2.213\tL1 1.019\tG-Mean 0.890\n",
      " * Median: MSE 2.111\tL1 1.387\tG-Mean 1.331\n",
      " * Low: MSE 0.030\tL1 0.168\tG-Mean 0.153\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #73: Train loss [7.4785]; Val loss: MSE [1.8216], L1 [0.5818], G-Mean [0.2564]\n",
      "Epoch: [74][ 0/65]\tTime   0.63 (  0.63)\tData 0.6195 (0.6195)\tLoss (MSE) 9.639 (9.639)\n",
      "Epoch: [74][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 7.293 (7.620)\n",
      "Epoch: [74][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 5.483 (7.436)\n",
      "Epoch: [74][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 7.001 (7.697)\n",
      "Epoch: [74][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 6.700 (7.471)\n",
      "Epoch: [74][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.734 (7.482)\n",
      "Epoch: [74][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.870 (7.239)\n",
      "Val: [0/9]\tTime  0.658 ( 0.658)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.756 (0.756)\n",
      " * Overall: MSE 1.808\tL1 0.701\tG-Mean 0.440\n",
      " * Many: MSE 2.574\tL1 1.250\tG-Mean 1.144\n",
      " * Median: MSE 1.493\tL1 1.144\tG-Mean 1.079\n",
      " * Low: MSE 0.009\tL1 0.081\tG-Mean 0.071\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #74: Train loss [7.3784]; Val loss: MSE [1.8081], L1 [0.7014], G-Mean [0.4402]\n",
      "Epoch: [75][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 8.598 (8.598)\n",
      "Epoch: [75][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0589)\tLoss (MSE) 10.850 (7.552)\n",
      "Epoch: [75][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0309)\tLoss (MSE) 8.273 (7.770)\n",
      "Epoch: [75][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 5.719 (7.890)\n",
      "Epoch: [75][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 7.191 (7.808)\n",
      "Epoch: [75][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 6.366 (7.649)\n",
      "Epoch: [75][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 6.743 (7.535)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.093 (2.093)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.815\tL1 0.589\tG-Mean 0.268\n",
      " * Many: MSE 2.231\tL1 1.035\tG-Mean 0.908\n",
      " * Median: MSE 2.074\tL1 1.374\tG-Mean 1.317\n",
      " * Low: MSE 0.026\tL1 0.154\tG-Mean 0.144\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #75: Train loss [7.4851]; Val loss: MSE [1.8149], L1 [0.5887], G-Mean [0.2683]\n",
      "Epoch: [76][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 3.950 (3.950)\n",
      "Epoch: [76][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 9.994 (7.478)\n",
      "Epoch: [76][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 7.639 (7.843)\n",
      "Epoch: [76][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 7.970 (7.600)\n",
      "Epoch: [76][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 10.193 (7.378)\n",
      "Epoch: [76][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.839 (7.379)\n",
      "Epoch: [76][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.651 (7.188)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.203 (2.203)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.886\tL1 0.563\tG-Mean 0.233\n",
      " * Many: MSE 2.079\tL1 0.897\tG-Mean 0.755\n",
      " * Median: MSE 2.487\tL1 1.518\tG-Mean 1.467\n",
      " * Low: MSE 0.091\tL1 0.298\tG-Mean 0.293\n",
      "Best MSE Loss: 1.802\n",
      "Epoch #76: Train loss [7.1754]; Val loss: MSE [1.8856], L1 [0.5635], G-Mean [0.2330]\n",
      "Epoch: [77][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 5.227 (5.227)\n",
      "Epoch: [77][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0550)\tLoss (MSE) 10.461 (8.074)\n",
      "Epoch: [77][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 8.760 (7.276)\n",
      "Epoch: [77][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 5.978 (7.140)\n",
      "Epoch: [77][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 7.050 (7.593)\n",
      "Epoch: [77][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 14.284 (7.794)\n",
      "Epoch: [77][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 17.046 (8.301)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.666 (0.666)\n",
      " * Overall: MSE 1.794\tL1 0.602\tG-Mean 0.285\n",
      " * Many: MSE 2.274\tL1 1.073\tG-Mean 0.950\n",
      " * Median: MSE 1.938\tL1 1.324\tG-Mean 1.266\n",
      " * Low: MSE 0.015\tL1 0.116\tG-Mean 0.104\n",
      "Best MSE Loss: 1.794\n",
      "Epoch #77: Train loss [8.2520]; Val loss: MSE [1.7940], L1 [0.6023], G-Mean [0.2850]\n",
      "Epoch: [78][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 5.587 (5.587)\n",
      "Epoch: [78][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0585)\tLoss (MSE) 8.084 (7.462)\n",
      "Epoch: [78][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 6.620 (7.355)\n",
      "Epoch: [78][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 13.512 (7.909)\n",
      "Epoch: [78][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 6.183 (7.719)\n",
      "Epoch: [78][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.622 (7.717)\n",
      "Epoch: [78][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.534 (7.578)\n",
      "Val: [0/9]\tTime  0.534 ( 0.534)\tLoss (MSE) 2.098 (2.098)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.815\tL1 0.593\tG-Mean 0.274\n",
      " * Many: MSE 2.257\tL1 1.050\tG-Mean 0.924\n",
      " * Median: MSE 2.017\tL1 1.354\tG-Mean 1.297\n",
      " * Low: MSE 0.020\tL1 0.137\tG-Mean 0.127\n",
      "Best MSE Loss: 1.794\n",
      "Epoch #78: Train loss [7.4773]; Val loss: MSE [1.8155], L1 [0.5926], G-Mean [0.2742]\n",
      "Epoch: [79][ 0/65]\tTime   0.55 (  0.55)\tData 0.5471 (0.5471)\tLoss (MSE) 5.186 (5.186)\n",
      "Epoch: [79][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 5.267 (6.854)\n",
      "Epoch: [79][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 11.031 (8.721)\n",
      "Epoch: [79][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 9.872 (8.419)\n",
      "Epoch: [79][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 6.209 (8.527)\n",
      "Epoch: [79][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 11.040 (8.493)\n",
      "Epoch: [79][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 5.695 (8.113)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.171 (2.171)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.863\tL1 0.567\tG-Mean 0.258\n",
      " * Many: MSE 2.126\tL1 0.941\tG-Mean 0.804\n",
      " * Median: MSE 2.374\tL1 1.479\tG-Mean 1.426\n",
      " * Low: MSE 0.065\tL1 0.252\tG-Mean 0.246\n",
      "Best MSE Loss: 1.794\n",
      "Epoch #79: Train loss [8.2279]; Val loss: MSE [1.8630], L1 [0.5669], G-Mean [0.2583]\n",
      "Epoch: [80][ 0/65]\tTime   0.56 (  0.56)\tData 0.5558 (0.5558)\tLoss (MSE) 6.315 (6.315)\n",
      "Epoch: [80][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0575)\tLoss (MSE) 4.694 (6.866)\n",
      "Epoch: [80][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 8.778 (7.328)\n",
      "Epoch: [80][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 7.500 (6.901)\n",
      "Epoch: [80][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 5.757 (6.844)\n",
      "Epoch: [80][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 9.050 (7.477)\n",
      "Epoch: [80][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 10.501 (7.403)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.174 (2.174)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.870\tL1 0.564\tG-Mean 0.235\n",
      " * Many: MSE 2.075\tL1 0.904\tG-Mean 0.762\n",
      " * Median: MSE 2.454\tL1 1.505\tG-Mean 1.452\n",
      " * Low: MSE 0.088\tL1 0.291\tG-Mean 0.277\n",
      "Best MSE Loss: 1.794\n",
      "Epoch #80: Train loss [7.5131]; Val loss: MSE [1.8698], L1 [0.5640], G-Mean [0.2349]\n",
      "Epoch: [81][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 8.676 (8.676)\n",
      "Epoch: [81][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 7.956 (8.364)\n",
      "Epoch: [81][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 8.226 (8.755)\n",
      "Epoch: [81][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.583 (7.990)\n",
      "Epoch: [81][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 7.090 (7.543)\n",
      "Epoch: [81][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 8.334 (7.427)\n",
      "Epoch: [81][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.235 (7.609)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.704 (0.704)\n",
      " * Overall: MSE 1.792\tL1 0.645\tG-Mean 0.345\n",
      " * Many: MSE 2.411\tL1 1.159\tG-Mean 1.044\n",
      " * Median: MSE 1.707\tL1 1.233\tG-Mean 1.171\n",
      " * Low: MSE 0.004\tL1 0.052\tG-Mean 0.041\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #81: Train loss [7.5318]; Val loss: MSE [1.7917], L1 [0.6451], G-Mean [0.3451]\n",
      "Epoch: [82][ 0/65]\tTime   0.55 (  0.55)\tData 0.5483 (0.5483)\tLoss (MSE) 16.744 (16.744)\n",
      "Epoch: [82][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0543)\tLoss (MSE) 8.934 (9.036)\n",
      "Epoch: [82][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 7.267 (8.804)\n",
      "Epoch: [82][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 4.801 (8.130)\n",
      "Epoch: [82][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 4.558 (7.883)\n",
      "Epoch: [82][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 12.503 (7.579)\n",
      "Epoch: [82][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 10.901 (7.605)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.110 (2.110)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.820\tL1 0.589\tG-Mean 0.270\n",
      " * Many: MSE 2.243\tL1 1.038\tG-Mean 0.911\n",
      " * Median: MSE 2.052\tL1 1.367\tG-Mean 1.311\n",
      " * Low: MSE 0.024\tL1 0.148\tG-Mean 0.133\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #82: Train loss [7.5482]; Val loss: MSE [1.8201], L1 [0.5890], G-Mean [0.2696]\n",
      "Epoch: [83][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 4.828 (4.828)\n",
      "Epoch: [83][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 6.376 (7.044)\n",
      "Epoch: [83][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 5.489 (6.772)\n",
      "Epoch: [83][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 6.458 (6.960)\n",
      "Epoch: [83][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 6.491 (7.234)\n",
      "Epoch: [83][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 8.528 (7.103)\n",
      "Epoch: [83][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 10.899 (7.317)\n",
      "Val: [0/9]\tTime  0.560 ( 0.560)\tLoss (MSE) 2.147 (2.147)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.849\tL1 0.572\tG-Mean 0.261\n",
      " * Many: MSE 2.159\tL1 0.970\tG-Mean 0.836\n",
      " * Median: MSE 2.274\tL1 1.446\tG-Mean 1.394\n",
      " * Low: MSE 0.051\tL1 0.222\tG-Mean 0.216\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #83: Train loss [7.3223]; Val loss: MSE [1.8492], L1 [0.5720], G-Mean [0.2607]\n",
      "Epoch: [84][ 0/65]\tTime   0.57 (  0.57)\tData 0.5617 (0.5617)\tLoss (MSE) 7.449 (7.449)\n",
      "Epoch: [84][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 7.871 (6.920)\n",
      "Epoch: [84][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 10.271 (6.909)\n",
      "Epoch: [84][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 9.220 (7.369)\n",
      "Epoch: [84][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.280 (7.326)\n",
      "Epoch: [84][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.473 (7.554)\n",
      "Epoch: [84][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 6.068 (7.460)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.821\tL1 0.593\tG-Mean 0.278\n",
      " * Many: MSE 2.259\tL1 1.049\tG-Mean 0.923\n",
      " * Median: MSE 2.048\tL1 1.364\tG-Mean 1.308\n",
      " * Low: MSE 0.020\tL1 0.137\tG-Mean 0.121\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #84: Train loss [7.4356]; Val loss: MSE [1.8208], L1 [0.5934], G-Mean [0.2782]\n",
      "Epoch: [85][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 5.168 (5.168)\n",
      "Epoch: [85][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 8.691 (6.418)\n",
      "Epoch: [85][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 5.645 (6.895)\n",
      "Epoch: [85][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 8.754 (6.969)\n",
      "Epoch: [85][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 10.142 (6.946)\n",
      "Epoch: [85][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 7.369 (7.108)\n",
      "Epoch: [85][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.995 (7.236)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.208 (2.208)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.897\tL1 0.563\tG-Mean 0.217\n",
      " * Many: MSE 2.035\tL1 0.862\tG-Mean 0.716\n",
      " * Median: MSE 2.584\tL1 1.549\tG-Mean 1.499\n",
      " * Low: MSE 0.118\tL1 0.338\tG-Mean 0.328\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #85: Train loss [7.1583]; Val loss: MSE [1.8973], L1 [0.5634], G-Mean [0.2168]\n",
      "Epoch: [86][ 0/65]\tTime   0.57 (  0.57)\tData 0.5662 (0.5662)\tLoss (MSE) 5.979 (5.979)\n",
      "Epoch: [86][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 9.020 (7.193)\n",
      "Epoch: [86][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.697 (6.987)\n",
      "Epoch: [86][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 9.709 (7.435)\n",
      "Epoch: [86][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.008 (7.538)\n",
      "Epoch: [86][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 6.182 (7.620)\n",
      "Epoch: [86][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.250 (7.447)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.063 (2.063)\tLoss (L1) 0.737 (0.737)\n",
      " * Overall: MSE 1.807\tL1 0.680\tG-Mean 0.406\n",
      " * Many: MSE 2.521\tL1 1.218\tG-Mean 1.108\n",
      " * Median: MSE 1.579\tL1 1.180\tG-Mean 1.117\n",
      " * Low: MSE 0.004\tL1 0.047\tG-Mean 0.032\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #86: Train loss [7.3487]; Val loss: MSE [1.8074], L1 [0.6802], G-Mean [0.4065]\n",
      "Epoch: [87][ 0/65]\tTime   0.57 (  0.57)\tData 0.5616 (0.5616)\tLoss (MSE) 7.159 (7.159)\n",
      "Epoch: [87][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 8.958 (7.363)\n",
      "Epoch: [87][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 7.736 (8.297)\n",
      "Epoch: [87][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 6.319 (8.336)\n",
      "Epoch: [87][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 4.757 (8.008)\n",
      "Epoch: [87][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 7.357 (7.704)\n",
      "Epoch: [87][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.051 (7.550)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.231 (2.231)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.914\tL1 0.564\tG-Mean 0.220\n",
      " * Many: MSE 2.042\tL1 0.857\tG-Mean 0.711\n",
      " * Median: MSE 2.629\tL1 1.563\tG-Mean 1.514\n",
      " * Low: MSE 0.120\tL1 0.343\tG-Mean 0.337\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #87: Train loss [7.4368]; Val loss: MSE [1.9141], L1 [0.5640], G-Mean [0.2203]\n",
      "Epoch: [88][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.907 (5.907)\n",
      "Epoch: [88][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0569)\tLoss (MSE) 7.215 (6.807)\n",
      "Epoch: [88][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 5.014 (7.350)\n",
      "Epoch: [88][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 4.603 (7.283)\n",
      "Epoch: [88][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 5.853 (7.221)\n",
      "Epoch: [88][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 8.906 (6.857)\n",
      "Epoch: [88][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 7.296 (7.008)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.085 (2.085)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.811\tL1 0.593\tG-Mean 0.272\n",
      " * Many: MSE 2.246\tL1 1.045\tG-Mean 0.919\n",
      " * Median: MSE 2.015\tL1 1.352\tG-Mean 1.295\n",
      " * Low: MSE 0.024\tL1 0.147\tG-Mean 0.130\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #88: Train loss [7.0885]; Val loss: MSE [1.8110], L1 [0.5926], G-Mean [0.2724]\n",
      "Epoch: [89][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 8.337 (8.337)\n",
      "Epoch: [89][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 6.401 (8.400)\n",
      "Epoch: [89][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 5.270 (8.070)\n",
      "Epoch: [89][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 7.993 (7.574)\n",
      "Epoch: [89][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 6.061 (7.551)\n",
      "Epoch: [89][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.519 (7.338)\n",
      "Epoch: [89][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 7.686 (7.551)\n",
      "Val: [0/9]\tTime  0.535 ( 0.535)\tLoss (MSE) 2.376 (2.376)\tLoss (L1) 0.678 (0.678)\n",
      " * Overall: MSE 2.024\tL1 0.594\tG-Mean 0.281\n",
      " * Many: MSE 1.949\tL1 0.732\tG-Mean 0.570\n",
      " * Median: MSE 3.075\tL1 1.700\tG-Mean 1.653\n",
      " * Low: MSE 0.229\tL1 0.477\tG-Mean 0.474\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #89: Train loss [7.4629]; Val loss: MSE [2.0245], L1 [0.5938], G-Mean [0.2813]\n",
      "Epoch: [90][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 8.016 (8.016)\n",
      "Epoch: [90][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 7.686 (8.263)\n",
      "Epoch: [90][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.673 (7.028)\n",
      "Epoch: [90][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 6.020 (6.875)\n",
      "Epoch: [90][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 10.657 (7.091)\n",
      "Epoch: [90][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.441 (7.167)\n",
      "Epoch: [90][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 9.161 (7.326)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.138 (2.138)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.843\tL1 0.572\tG-Mean 0.261\n",
      " * Many: MSE 2.136\tL1 0.959\tG-Mean 0.823\n",
      " * Median: MSE 2.282\tL1 1.448\tG-Mean 1.394\n",
      " * Low: MSE 0.058\tL1 0.235\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #90: Train loss [7.1713]; Val loss: MSE [1.8427], L1 [0.5717], G-Mean [0.2613]\n",
      "Epoch: [91][ 0/65]\tTime   0.56 (  0.56)\tData 0.5516 (0.5516)\tLoss (MSE) 6.668 (6.668)\n",
      "Epoch: [91][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 3.655 (5.897)\n",
      "Epoch: [91][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 6.736 (6.585)\n",
      "Epoch: [91][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 6.616 (6.943)\n",
      "Epoch: [91][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 6.416 (6.885)\n",
      "Epoch: [91][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 5.784 (6.857)\n",
      "Epoch: [91][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.715 (6.933)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.818\tL1 0.590\tG-Mean 0.271\n",
      " * Many: MSE 2.237\tL1 1.036\tG-Mean 0.909\n",
      " * Median: MSE 2.058\tL1 1.368\tG-Mean 1.312\n",
      " * Low: MSE 0.026\tL1 0.154\tG-Mean 0.143\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #91: Train loss [6.9307]; Val loss: MSE [1.8182], L1 [0.5899], G-Mean [0.2708]\n",
      "Epoch: [92][ 0/65]\tTime   0.56 (  0.56)\tData 0.5546 (0.5546)\tLoss (MSE) 6.836 (6.836)\n",
      "Epoch: [92][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0529)\tLoss (MSE) 7.903 (6.678)\n",
      "Epoch: [92][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 9.263 (6.839)\n",
      "Epoch: [92][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.172 (7.229)\n",
      "Epoch: [92][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.566 (6.957)\n",
      "Epoch: [92][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 3.227 (6.908)\n",
      "Epoch: [92][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 8.767 (7.270)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.823\tL1 0.583\tG-Mean 0.269\n",
      " * Many: MSE 2.183\tL1 1.000\tG-Mean 0.868\n",
      " * Median: MSE 2.154\tL1 1.404\tG-Mean 1.348\n",
      " * Low: MSE 0.041\tL1 0.193\tG-Mean 0.172\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #92: Train loss [7.1783]; Val loss: MSE [1.8227], L1 [0.5830], G-Mean [0.2689]\n",
      "Epoch: [93][ 0/65]\tTime   0.56 (  0.56)\tData 0.5480 (0.5480)\tLoss (MSE) 7.027 (7.027)\n",
      "Epoch: [93][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0558)\tLoss (MSE) 4.989 (6.765)\n",
      "Epoch: [93][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0292)\tLoss (MSE) 8.096 (6.792)\n",
      "Epoch: [93][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.863 (6.985)\n",
      "Epoch: [93][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 8.232 (6.936)\n",
      "Epoch: [93][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 6.489 (6.845)\n",
      "Epoch: [93][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 10.699 (6.969)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.122 (2.122)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.830\tL1 0.578\tG-Mean 0.260\n",
      " * Many: MSE 2.182\tL1 0.995\tG-Mean 0.863\n",
      " * Median: MSE 2.168\tL1 1.408\tG-Mean 1.353\n",
      " * Low: MSE 0.042\tL1 0.198\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #93: Train loss [6.9300]; Val loss: MSE [1.8302], L1 [0.5777], G-Mean [0.2603]\n",
      "Epoch: [94][ 0/65]\tTime   0.56 (  0.56)\tData 0.5564 (0.5564)\tLoss (MSE) 4.036 (4.036)\n",
      "Epoch: [94][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0530)\tLoss (MSE) 7.658 (6.587)\n",
      "Epoch: [94][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 6.191 (6.659)\n",
      "Epoch: [94][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 9.722 (6.497)\n",
      "Epoch: [94][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 7.154 (6.499)\n",
      "Epoch: [94][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.163 (6.427)\n",
      "Epoch: [94][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 7.118 (6.815)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.116 (2.116)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.827\tL1 0.579\tG-Mean 0.259\n",
      " * Many: MSE 2.182\tL1 0.997\tG-Mean 0.866\n",
      " * Median: MSE 2.173\tL1 1.409\tG-Mean 1.354\n",
      " * Low: MSE 0.041\tL1 0.197\tG-Mean 0.186\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #94: Train loss [6.8547]; Val loss: MSE [1.8267], L1 [0.5791], G-Mean [0.2594]\n",
      "Epoch: [95][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 4.636 (4.636)\n",
      "Epoch: [95][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 7.680 (7.664)\n",
      "Epoch: [95][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 9.869 (7.535)\n",
      "Epoch: [95][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 3.108 (7.136)\n",
      "Epoch: [95][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.993 (7.202)\n",
      "Epoch: [95][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 9.320 (7.101)\n",
      "Epoch: [95][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.777 (6.983)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.143 (2.143)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.847\tL1 0.574\tG-Mean 0.261\n",
      " * Many: MSE 2.162\tL1 0.972\tG-Mean 0.838\n",
      " * Median: MSE 2.255\tL1 1.439\tG-Mean 1.386\n",
      " * Low: MSE 0.051\tL1 0.218\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #95: Train loss [6.9987]; Val loss: MSE [1.8472], L1 [0.5738], G-Mean [0.2614]\n",
      "Epoch: [96][ 0/65]\tTime   0.55 (  0.55)\tData 0.5447 (0.5447)\tLoss (MSE) 4.115 (4.115)\n",
      "Epoch: [96][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 8.990 (7.054)\n",
      "Epoch: [96][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 7.235 (6.943)\n",
      "Epoch: [96][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.844 (7.110)\n",
      "Epoch: [96][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.584 (6.990)\n",
      "Epoch: [96][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.521 (7.048)\n",
      "Epoch: [96][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 18.629 (7.115)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.138 (2.138)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.843\tL1 0.573\tG-Mean 0.262\n",
      " * Many: MSE 2.144\tL1 0.963\tG-Mean 0.828\n",
      " * Median: MSE 2.271\tL1 1.444\tG-Mean 1.390\n",
      " * Low: MSE 0.056\tL1 0.229\tG-Mean 0.213\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #96: Train loss [7.0554]; Val loss: MSE [1.8433], L1 [0.5729], G-Mean [0.2616]\n",
      "Epoch: [97][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 4.621 (4.621)\n",
      "Epoch: [97][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 5.040 (6.310)\n",
      "Epoch: [97][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 6.289 (6.925)\n",
      "Epoch: [97][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 9.702 (6.977)\n",
      "Epoch: [97][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.960 (6.893)\n",
      "Epoch: [97][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 7.228 (7.123)\n",
      "Epoch: [97][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.861 (6.784)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.823\tL1 0.587\tG-Mean 0.263\n",
      " * Many: MSE 2.231\tL1 1.030\tG-Mean 0.902\n",
      " * Median: MSE 2.084\tL1 1.378\tG-Mean 1.322\n",
      " * Low: MSE 0.028\tL1 0.160\tG-Mean 0.151\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #97: Train loss [6.9020]; Val loss: MSE [1.8234], L1 [0.5872], G-Mean [0.2632]\n",
      "Epoch: [98][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 10.907 (10.907)\n",
      "Epoch: [98][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 10.671 (7.635)\n",
      "Epoch: [98][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 10.036 (7.201)\n",
      "Epoch: [98][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 10.321 (7.576)\n",
      "Epoch: [98][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.214 (7.251)\n",
      "Epoch: [98][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.096 (6.825)\n",
      "Epoch: [98][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 10.849 (6.950)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.089 (2.089)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.817\tL1 0.584\tG-Mean 0.266\n",
      " * Many: MSE 2.191\tL1 1.007\tG-Mean 0.876\n",
      " * Median: MSE 2.120\tL1 1.391\tG-Mean 1.335\n",
      " * Low: MSE 0.040\tL1 0.191\tG-Mean 0.175\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #98: Train loss [7.0209]; Val loss: MSE [1.8172], L1 [0.5842], G-Mean [0.2658]\n",
      "Epoch: [99][ 0/65]\tTime   0.56 (  0.56)\tData 0.5572 (0.5572)\tLoss (MSE) 4.239 (4.239)\n",
      "Epoch: [99][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.050 (6.556)\n",
      "Epoch: [99][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 8.882 (6.413)\n",
      "Epoch: [99][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.155 (6.573)\n",
      "Epoch: [99][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.495 (6.729)\n",
      "Epoch: [99][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 10.735 (6.608)\n",
      "Epoch: [99][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.863 (6.827)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.233 (2.233)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.914\tL1 0.566\tG-Mean 0.220\n",
      " * Many: MSE 2.040\tL1 0.857\tG-Mean 0.709\n",
      " * Median: MSE 2.631\tL1 1.565\tG-Mean 1.515\n",
      " * Low: MSE 0.123\tL1 0.346\tG-Mean 0.334\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #99: Train loss [6.9088]; Val loss: MSE [1.9136], L1 [0.5664], G-Mean [0.2199]\n",
      "Epoch: [100][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 7.853 (7.853)\n",
      "Epoch: [100][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0529)\tLoss (MSE) 5.123 (6.028)\n",
      "Epoch: [100][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 6.383 (6.822)\n",
      "Epoch: [100][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 13.774 (6.849)\n",
      "Epoch: [100][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.810 (6.810)\n",
      "Epoch: [100][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 12.275 (6.948)\n",
      "Epoch: [100][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 7.725 (6.924)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.831\tL1 0.581\tG-Mean 0.263\n",
      " * Many: MSE 2.191\tL1 1.000\tG-Mean 0.869\n",
      " * Median: MSE 2.158\tL1 1.406\tG-Mean 1.352\n",
      " * Low: MSE 0.041\tL1 0.195\tG-Mean 0.184\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #100: Train loss [6.7981]; Val loss: MSE [1.8306], L1 [0.5810], G-Mean [0.2629]\n",
      "Epoch: [101][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 5.317 (5.317)\n",
      "Epoch: [101][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 5.465 (6.328)\n",
      "Epoch: [101][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 6.318 (6.734)\n",
      "Epoch: [101][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 12.094 (6.878)\n",
      "Epoch: [101][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.847 (6.778)\n",
      "Epoch: [101][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 7.885 (6.731)\n",
      "Epoch: [101][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.286 (6.696)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.137 (2.137)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.846\tL1 0.574\tG-Mean 0.264\n",
      " * Many: MSE 2.148\tL1 0.964\tG-Mean 0.828\n",
      " * Median: MSE 2.266\tL1 1.443\tG-Mean 1.390\n",
      " * Low: MSE 0.057\tL1 0.233\tG-Mean 0.219\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #101: Train loss [6.7114]; Val loss: MSE [1.8458], L1 [0.5741], G-Mean [0.2639]\n",
      "Epoch: [102][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 4.243 (4.243)\n",
      "Epoch: [102][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0554)\tLoss (MSE) 5.119 (6.985)\n",
      "Epoch: [102][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 7.771 (7.203)\n",
      "Epoch: [102][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 6.268 (7.491)\n",
      "Epoch: [102][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.050 (7.203)\n",
      "Epoch: [102][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.437 (6.914)\n",
      "Epoch: [102][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 8.361 (6.826)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.119 (2.119)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.834\tL1 0.579\tG-Mean 0.262\n",
      " * Many: MSE 2.181\tL1 0.992\tG-Mean 0.859\n",
      " * Median: MSE 2.182\tL1 1.414\tG-Mean 1.359\n",
      " * Low: MSE 0.044\tL1 0.204\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #102: Train loss [6.6967]; Val loss: MSE [1.8337], L1 [0.5792], G-Mean [0.2617]\n",
      "Epoch: [103][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 5.989 (5.989)\n",
      "Epoch: [103][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0607)\tLoss (MSE) 5.117 (6.055)\n",
      "Epoch: [103][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0318)\tLoss (MSE) 4.641 (5.901)\n",
      "Epoch: [103][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0215)\tLoss (MSE) 7.434 (6.062)\n",
      "Epoch: [103][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 5.165 (6.783)\n",
      "Epoch: [103][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 8.185 (6.668)\n",
      "Epoch: [103][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 7.128 (6.783)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.124 (2.124)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.838\tL1 0.577\tG-Mean 0.264\n",
      " * Many: MSE 2.167\tL1 0.981\tG-Mean 0.847\n",
      " * Median: MSE 2.216\tL1 1.425\tG-Mean 1.371\n",
      " * Low: MSE 0.050\tL1 0.216\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #103: Train loss [6.7027]; Val loss: MSE [1.8385], L1 [0.5772], G-Mean [0.2638]\n",
      "Epoch: [104][ 0/65]\tTime   0.55 (  0.55)\tData 0.5454 (0.5454)\tLoss (MSE) 4.517 (4.517)\n",
      "Epoch: [104][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0505)\tLoss (MSE) 5.566 (7.082)\n",
      "Epoch: [104][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 5.434 (7.564)\n",
      "Epoch: [104][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 3.483 (7.078)\n",
      "Epoch: [104][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.975 (6.735)\n",
      "Epoch: [104][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 9.631 (6.560)\n",
      "Epoch: [104][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 7.430 (6.691)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.124 (2.124)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.839\tL1 0.578\tG-Mean 0.264\n",
      " * Many: MSE 2.174\tL1 0.985\tG-Mean 0.851\n",
      " * Median: MSE 2.206\tL1 1.422\tG-Mean 1.368\n",
      " * Low: MSE 0.047\tL1 0.211\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #104: Train loss [6.7015]; Val loss: MSE [1.8388], L1 [0.5779], G-Mean [0.2637]\n",
      "Epoch: [105][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 8.334 (8.334)\n",
      "Epoch: [105][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 6.933 (7.142)\n",
      "Epoch: [105][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 7.184 (7.249)\n",
      "Epoch: [105][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 11.075 (7.152)\n",
      "Epoch: [105][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.640 (6.714)\n",
      "Epoch: [105][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 5.378 (6.670)\n",
      "Epoch: [105][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 7.332 (6.754)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.121 (2.121)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.836\tL1 0.579\tG-Mean 0.262\n",
      " * Many: MSE 2.180\tL1 0.990\tG-Mean 0.857\n",
      " * Median: MSE 2.189\tL1 1.416\tG-Mean 1.362\n",
      " * Low: MSE 0.045\tL1 0.206\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #105: Train loss [6.6977]; Val loss: MSE [1.8364], L1 [0.5787], G-Mean [0.2621]\n",
      "Epoch: [106][ 0/65]\tTime   0.57 (  0.57)\tData 0.5606 (0.5606)\tLoss (MSE) 4.828 (4.828)\n",
      "Epoch: [106][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0527)\tLoss (MSE) 8.332 (5.599)\n",
      "Epoch: [106][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 7.673 (5.739)\n",
      "Epoch: [106][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 3.744 (5.876)\n",
      "Epoch: [106][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 6.799 (5.923)\n",
      "Epoch: [106][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 6.565 (6.273)\n",
      "Epoch: [106][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 7.814 (6.637)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.835\tL1 0.579\tG-Mean 0.262\n",
      " * Many: MSE 2.177\tL1 0.989\tG-Mean 0.855\n",
      " * Median: MSE 2.190\tL1 1.416\tG-Mean 1.362\n",
      " * Low: MSE 0.047\tL1 0.209\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #106: Train loss [6.6852]; Val loss: MSE [1.8352], L1 [0.5792], G-Mean [0.2624]\n",
      "Epoch: [107][ 0/65]\tTime   0.56 (  0.56)\tData 0.5554 (0.5554)\tLoss (MSE) 4.608 (4.608)\n",
      "Epoch: [107][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 3.592 (6.854)\n",
      "Epoch: [107][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 8.255 (6.763)\n",
      "Epoch: [107][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 5.538 (6.468)\n",
      "Epoch: [107][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 8.019 (6.545)\n",
      "Epoch: [107][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.414 (6.637)\n",
      "Epoch: [107][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.804 (6.747)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.105 (2.105)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.827\tL1 0.584\tG-Mean 0.264\n",
      " * Many: MSE 2.203\tL1 1.010\tG-Mean 0.878\n",
      " * Median: MSE 2.125\tL1 1.393\tG-Mean 1.337\n",
      " * Low: MSE 0.038\tL1 0.187\tG-Mean 0.174\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #107: Train loss [6.6817]; Val loss: MSE [1.8269], L1 [0.5837], G-Mean [0.2641]\n",
      "Epoch: [108][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 9.547 (9.547)\n",
      "Epoch: [108][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 6.007 (6.369)\n",
      "Epoch: [108][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 5.438 (5.791)\n",
      "Epoch: [108][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.935 (5.631)\n",
      "Epoch: [108][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.704 (5.905)\n",
      "Epoch: [108][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.892 (6.379)\n",
      "Epoch: [108][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 8.502 (6.665)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.831\tL1 0.582\tG-Mean 0.265\n",
      " * Many: MSE 2.189\tL1 0.998\tG-Mean 0.866\n",
      " * Median: MSE 2.160\tL1 1.406\tG-Mean 1.350\n",
      " * Low: MSE 0.043\tL1 0.199\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #108: Train loss [6.6836]; Val loss: MSE [1.8311], L1 [0.5822], G-Mean [0.2647]\n",
      "Epoch: [109][ 0/65]\tTime   0.56 (  0.56)\tData 0.5558 (0.5558)\tLoss (MSE) 7.278 (7.278)\n",
      "Epoch: [109][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 7.646 (7.763)\n",
      "Epoch: [109][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 8.236 (6.597)\n",
      "Epoch: [109][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.681 (6.640)\n",
      "Epoch: [109][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.234 (6.589)\n",
      "Epoch: [109][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.383 (6.568)\n",
      "Epoch: [109][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.118 (6.638)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.104 (2.104)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.828\tL1 0.585\tG-Mean 0.265\n",
      " * Many: MSE 2.209\tL1 1.013\tG-Mean 0.882\n",
      " * Median: MSE 2.123\tL1 1.392\tG-Mean 1.336\n",
      " * Low: MSE 0.037\tL1 0.182\tG-Mean 0.162\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #109: Train loss [6.6899]; Val loss: MSE [1.8279], L1 [0.5850], G-Mean [0.2646]\n",
      "Epoch: [110][ 0/65]\tTime   0.56 (  0.56)\tData 0.5547 (0.5547)\tLoss (MSE) 4.045 (4.045)\n",
      "Epoch: [110][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0569)\tLoss (MSE) 8.759 (5.403)\n",
      "Epoch: [110][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0298)\tLoss (MSE) 3.640 (6.406)\n",
      "Epoch: [110][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0202)\tLoss (MSE) 8.516 (6.679)\n",
      "Epoch: [110][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 9.575 (6.826)\n",
      "Epoch: [110][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 6.073 (6.964)\n",
      "Epoch: [110][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.450 (6.837)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.838\tL1 0.580\tG-Mean 0.263\n",
      " * Many: MSE 2.185\tL1 0.992\tG-Mean 0.859\n",
      " * Median: MSE 2.183\tL1 1.414\tG-Mean 1.359\n",
      " * Low: MSE 0.045\tL1 0.204\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #110: Train loss [6.6780]; Val loss: MSE [1.8378], L1 [0.5796], G-Mean [0.2629]\n",
      "Epoch: [111][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 5.701 (5.701)\n",
      "Epoch: [111][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0568)\tLoss (MSE) 7.414 (5.907)\n",
      "Epoch: [111][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 6.688 (6.211)\n",
      "Epoch: [111][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 10.795 (6.458)\n",
      "Epoch: [111][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 8.513 (6.511)\n",
      "Epoch: [111][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 6.115 (6.516)\n",
      "Epoch: [111][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 6.171 (6.692)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.105 (2.105)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.828\tL1 0.585\tG-Mean 0.265\n",
      " * Many: MSE 2.209\tL1 1.013\tG-Mean 0.881\n",
      " * Median: MSE 2.120\tL1 1.391\tG-Mean 1.335\n",
      " * Low: MSE 0.037\tL1 0.184\tG-Mean 0.166\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #111: Train loss [6.6865]; Val loss: MSE [1.8283], L1 [0.5849], G-Mean [0.2646]\n",
      "Epoch: [112][ 0/65]\tTime   0.56 (  0.56)\tData 0.5555 (0.5555)\tLoss (MSE) 3.098 (3.098)\n",
      "Epoch: [112][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 8.728 (6.940)\n",
      "Epoch: [112][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.360 (6.551)\n",
      "Epoch: [112][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 6.438 (6.377)\n",
      "Epoch: [112][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 10.067 (6.543)\n",
      "Epoch: [112][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 10.297 (6.468)\n",
      "Epoch: [112][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.853 (6.579)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.104 (2.104)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.828\tL1 0.584\tG-Mean 0.263\n",
      " * Many: MSE 2.207\tL1 1.011\tG-Mean 0.880\n",
      " * Median: MSE 2.117\tL1 1.390\tG-Mean 1.334\n",
      " * Low: MSE 0.038\tL1 0.185\tG-Mean 0.166\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #112: Train loss [6.6765]; Val loss: MSE [1.8281], L1 [0.5844], G-Mean [0.2633]\n",
      "Epoch: [113][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 10.100 (10.100)\n",
      "Epoch: [113][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 2.289 (7.187)\n",
      "Epoch: [113][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 3.183 (6.943)\n",
      "Epoch: [113][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 5.812 (6.940)\n",
      "Epoch: [113][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 9.038 (7.003)\n",
      "Epoch: [113][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 6.931 (6.739)\n",
      "Epoch: [113][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 7.532 (6.644)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.107 (2.107)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.830\tL1 0.585\tG-Mean 0.262\n",
      " * Many: MSE 2.214\tL1 1.015\tG-Mean 0.884\n",
      " * Median: MSE 2.118\tL1 1.390\tG-Mean 1.334\n",
      " * Low: MSE 0.035\tL1 0.180\tG-Mean 0.167\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #113: Train loss [6.6832]; Val loss: MSE [1.8305], L1 [0.5845], G-Mean [0.2619]\n",
      "Epoch: [114][ 0/65]\tTime   0.62 (  0.62)\tData 0.6143 (0.6143)\tLoss (MSE) 7.186 (7.186)\n",
      "Epoch: [114][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0599)\tLoss (MSE) 6.178 (6.501)\n",
      "Epoch: [114][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 6.239 (7.120)\n",
      "Epoch: [114][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 9.499 (6.554)\n",
      "Epoch: [114][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 6.632 (6.596)\n",
      "Epoch: [114][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 9.706 (6.714)\n",
      "Epoch: [114][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 6.933 (6.707)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.835\tL1 0.582\tG-Mean 0.265\n",
      " * Many: MSE 2.193\tL1 0.998\tG-Mean 0.865\n",
      " * Median: MSE 2.163\tL1 1.406\tG-Mean 1.350\n",
      " * Low: MSE 0.042\tL1 0.197\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #114: Train loss [6.6648]; Val loss: MSE [1.8350], L1 [0.5817], G-Mean [0.2649]\n",
      "Epoch: [115][ 0/65]\tTime   0.56 (  0.56)\tData 0.5575 (0.5575)\tLoss (MSE) 2.428 (2.428)\n",
      "Epoch: [115][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 7.663 (5.579)\n",
      "Epoch: [115][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 4.788 (5.463)\n",
      "Epoch: [115][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 9.764 (6.138)\n",
      "Epoch: [115][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 12.823 (6.571)\n",
      "Epoch: [115][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 8.539 (6.620)\n",
      "Epoch: [115][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 6.886 (6.575)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.835\tL1 0.582\tG-Mean 0.265\n",
      " * Many: MSE 2.190\tL1 0.996\tG-Mean 0.863\n",
      " * Median: MSE 2.167\tL1 1.408\tG-Mean 1.351\n",
      " * Low: MSE 0.045\tL1 0.204\tG-Mean 0.186\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #115: Train loss [6.6559]; Val loss: MSE [1.8353], L1 [0.5815], G-Mean [0.2646]\n",
      "Epoch: [116][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 6.294 (6.294)\n",
      "Epoch: [116][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 4.798 (6.890)\n",
      "Epoch: [116][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 4.236 (6.361)\n",
      "Epoch: [116][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 10.717 (6.717)\n",
      "Epoch: [116][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.328 (6.789)\n",
      "Epoch: [116][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.293 (6.609)\n",
      "Epoch: [116][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.972 (6.581)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.844\tL1 0.578\tG-Mean 0.265\n",
      " * Many: MSE 2.169\tL1 0.978\tG-Mean 0.843\n",
      " * Median: MSE 2.221\tL1 1.427\tG-Mean 1.371\n",
      " * Low: MSE 0.051\tL1 0.218\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #116: Train loss [6.6818]; Val loss: MSE [1.8439], L1 [0.5776], G-Mean [0.2653]\n",
      "Epoch: [117][ 0/65]\tTime   0.56 (  0.56)\tData 0.5509 (0.5509)\tLoss (MSE) 8.031 (8.031)\n",
      "Epoch: [117][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0513)\tLoss (MSE) 9.043 (7.378)\n",
      "Epoch: [117][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 7.593 (7.034)\n",
      "Epoch: [117][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 8.953 (6.900)\n",
      "Epoch: [117][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 9.738 (6.807)\n",
      "Epoch: [117][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.813 (6.787)\n",
      "Epoch: [117][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 11.352 (6.823)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.836\tL1 0.582\tG-Mean 0.263\n",
      " * Many: MSE 2.192\tL1 0.998\tG-Mean 0.865\n",
      " * Median: MSE 2.165\tL1 1.407\tG-Mean 1.350\n",
      " * Low: MSE 0.044\tL1 0.201\tG-Mean 0.184\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #117: Train loss [6.6627]; Val loss: MSE [1.8356], L1 [0.5817], G-Mean [0.2627]\n",
      "Epoch: [118][ 0/65]\tTime   0.56 (  0.56)\tData 0.5561 (0.5561)\tLoss (MSE) 13.597 (13.597)\n",
      "Epoch: [118][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 9.601 (7.362)\n",
      "Epoch: [118][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 4.868 (6.927)\n",
      "Epoch: [118][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.777 (6.514)\n",
      "Epoch: [118][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 10.019 (6.637)\n",
      "Epoch: [118][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.855 (6.500)\n",
      "Epoch: [118][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.927 (6.663)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.141 (2.141)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.853\tL1 0.575\tG-Mean 0.264\n",
      " * Many: MSE 2.151\tL1 0.962\tG-Mean 0.825\n",
      " * Median: MSE 2.273\tL1 1.445\tG-Mean 1.389\n",
      " * Low: MSE 0.060\tL1 0.238\tG-Mean 0.225\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #118: Train loss [6.6470]; Val loss: MSE [1.8526], L1 [0.5751], G-Mean [0.2635]\n",
      "Epoch: [119][ 0/65]\tTime   0.55 (  0.55)\tData 0.5474 (0.5474)\tLoss (MSE) 9.846 (9.846)\n",
      "Epoch: [119][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 7.717 (7.892)\n",
      "Epoch: [119][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 6.055 (7.294)\n",
      "Epoch: [119][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 10.985 (7.068)\n",
      "Epoch: [119][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.591 (6.616)\n",
      "Epoch: [119][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 6.882 (6.488)\n",
      "Epoch: [119][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 12.624 (6.512)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.124 (2.124)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.842\tL1 0.580\tG-Mean 0.264\n",
      " * Many: MSE 2.183\tL1 0.988\tG-Mean 0.854\n",
      " * Median: MSE 2.197\tL1 1.418\tG-Mean 1.362\n",
      " * Low: MSE 0.047\tL1 0.209\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #119: Train loss [6.6667]; Val loss: MSE [1.8421], L1 [0.5798], G-Mean [0.2643]\n",
      "Epoch: [120][ 0/65]\tTime   0.56 (  0.56)\tData 0.5516 (0.5516)\tLoss (MSE) 14.654 (14.654)\n",
      "Epoch: [120][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0513)\tLoss (MSE) 7.140 (7.339)\n",
      "Epoch: [120][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 7.060 (7.123)\n",
      "Epoch: [120][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 6.681 (6.952)\n",
      "Epoch: [120][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 7.063 (6.933)\n",
      "Epoch: [120][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.397 (6.882)\n",
      "Epoch: [120][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.003 (6.649)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.833\tL1 0.585\tG-Mean 0.264\n",
      " * Many: MSE 2.211\tL1 1.011\tG-Mean 0.878\n",
      " * Median: MSE 2.121\tL1 1.391\tG-Mean 1.333\n",
      " * Low: MSE 0.039\tL1 0.188\tG-Mean 0.171\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #120: Train loss [6.6553]; Val loss: MSE [1.8332], L1 [0.5851], G-Mean [0.2639]\n",
      "Epoch: [121][ 0/65]\tTime   0.56 (  0.56)\tData 0.5510 (0.5510)\tLoss (MSE) 8.325 (8.325)\n",
      "Epoch: [121][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 8.211 (6.466)\n",
      "Epoch: [121][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 5.434 (6.415)\n",
      "Epoch: [121][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.111 (6.746)\n",
      "Epoch: [121][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 9.406 (6.822)\n",
      "Epoch: [121][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.061 (6.492)\n",
      "Epoch: [121][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 8.166 (6.622)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.123 (2.123)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.840\tL1 0.581\tG-Mean 0.263\n",
      " * Many: MSE 2.190\tL1 0.994\tG-Mean 0.860\n",
      " * Median: MSE 2.187\tL1 1.414\tG-Mean 1.356\n",
      " * Low: MSE 0.044\tL1 0.201\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #121: Train loss [6.6549]; Val loss: MSE [1.8404], L1 [0.5811], G-Mean [0.2628]\n",
      "Epoch: [122][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 6.327 (6.327)\n",
      "Epoch: [122][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 5.802 (5.983)\n",
      "Epoch: [122][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 6.281 (6.175)\n",
      "Epoch: [122][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 9.712 (6.416)\n",
      "Epoch: [122][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 10.210 (6.383)\n",
      "Epoch: [122][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 8.513 (6.426)\n",
      "Epoch: [122][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 14.085 (6.708)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.130 (2.130)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.842\tL1 0.581\tG-Mean 0.262\n",
      " * Many: MSE 2.190\tL1 0.993\tG-Mean 0.859\n",
      " * Median: MSE 2.188\tL1 1.414\tG-Mean 1.355\n",
      " * Low: MSE 0.046\tL1 0.207\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #122: Train loss [6.6538]; Val loss: MSE [1.8425], L1 [0.5811], G-Mean [0.2625]\n",
      "Epoch: [123][ 0/65]\tTime   0.56 (  0.56)\tData 0.5578 (0.5578)\tLoss (MSE) 5.321 (5.321)\n",
      "Epoch: [123][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0570)\tLoss (MSE) 5.769 (6.764)\n",
      "Epoch: [123][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.577 (6.611)\n",
      "Epoch: [123][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 10.317 (6.863)\n",
      "Epoch: [123][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 7.153 (6.900)\n",
      "Epoch: [123][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.192 (6.748)\n",
      "Epoch: [123][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.787 (6.630)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.122 (2.122)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.842\tL1 0.580\tG-Mean 0.262\n",
      " * Many: MSE 2.189\tL1 0.992\tG-Mean 0.858\n",
      " * Median: MSE 2.189\tL1 1.414\tG-Mean 1.355\n",
      " * Low: MSE 0.046\tL1 0.207\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #123: Train loss [6.6345]; Val loss: MSE [1.8421], L1 [0.5803], G-Mean [0.2622]\n",
      "Epoch: [124][ 0/65]\tTime   0.59 (  0.59)\tData 0.5800 (0.5800)\tLoss (MSE) 9.094 (9.094)\n",
      "Epoch: [124][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0539)\tLoss (MSE) 4.906 (7.560)\n",
      "Epoch: [124][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 6.792 (7.304)\n",
      "Epoch: [124][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 7.662 (7.261)\n",
      "Epoch: [124][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.613 (6.929)\n",
      "Epoch: [124][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 5.472 (6.677)\n",
      "Epoch: [124][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 8.385 (6.580)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.087 (2.087)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.820\tL1 0.599\tG-Mean 0.279\n",
      " * Many: MSE 2.268\tL1 1.054\tG-Mean 0.926\n",
      " * Median: MSE 1.997\tL1 1.344\tG-Mean 1.282\n",
      " * Low: MSE 0.025\tL1 0.149\tG-Mean 0.132\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #124: Train loss [6.6258]; Val loss: MSE [1.8196], L1 [0.5987], G-Mean [0.2788]\n",
      "Epoch: [125][ 0/65]\tTime   0.55 (  0.55)\tData 0.5456 (0.5456)\tLoss (MSE) 2.904 (2.904)\n",
      "Epoch: [125][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 6.116 (6.444)\n",
      "Epoch: [125][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 8.143 (7.333)\n",
      "Epoch: [125][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 7.610 (6.992)\n",
      "Epoch: [125][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.481 (6.789)\n",
      "Epoch: [125][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.561 (6.975)\n",
      "Epoch: [125][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.186 (6.766)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.125 (2.125)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.839\tL1 0.581\tG-Mean 0.261\n",
      " * Many: MSE 2.190\tL1 0.994\tG-Mean 0.861\n",
      " * Median: MSE 2.177\tL1 1.410\tG-Mean 1.351\n",
      " * Low: MSE 0.046\tL1 0.204\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #125: Train loss [6.6382]; Val loss: MSE [1.8394], L1 [0.5811], G-Mean [0.2612]\n",
      "Epoch: [126][ 0/65]\tTime   0.56 (  0.56)\tData 0.5569 (0.5569)\tLoss (MSE) 7.783 (7.783)\n",
      "Epoch: [126][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 6.846 (5.928)\n",
      "Epoch: [126][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 9.610 (6.527)\n",
      "Epoch: [126][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.639 (6.407)\n",
      "Epoch: [126][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 8.288 (6.516)\n",
      "Epoch: [126][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 7.085 (6.594)\n",
      "Epoch: [126][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 10.758 (6.707)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.853\tL1 0.581\tG-Mean 0.268\n",
      " * Many: MSE 2.165\tL1 0.971\tG-Mean 0.832\n",
      " * Median: MSE 2.247\tL1 1.434\tG-Mean 1.375\n",
      " * Low: MSE 0.060\tL1 0.237\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #126: Train loss [6.6216]; Val loss: MSE [1.8527], L1 [0.5806], G-Mean [0.2678]\n",
      "Epoch: [127][ 0/65]\tTime   0.62 (  0.62)\tData 0.6015 (0.6015)\tLoss (MSE) 5.442 (5.442)\n",
      "Epoch: [127][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 7.259 (5.686)\n",
      "Epoch: [127][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 5.513 (6.455)\n",
      "Epoch: [127][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 4.071 (6.462)\n",
      "Epoch: [127][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 4.498 (6.848)\n",
      "Epoch: [127][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 5.653 (6.675)\n",
      "Epoch: [127][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.620 (6.647)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.132 (2.132)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.847\tL1 0.581\tG-Mean 0.264\n",
      " * Many: MSE 2.184\tL1 0.986\tG-Mean 0.851\n",
      " * Median: MSE 2.210\tL1 1.421\tG-Mean 1.362\n",
      " * Low: MSE 0.050\tL1 0.216\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #127: Train loss [6.6232]; Val loss: MSE [1.8469], L1 [0.5809], G-Mean [0.2639]\n",
      "Epoch: [128][ 0/65]\tTime   0.56 (  0.56)\tData 0.5511 (0.5511)\tLoss (MSE) 3.358 (3.358)\n",
      "Epoch: [128][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 6.468 (5.161)\n",
      "Epoch: [128][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 14.544 (5.747)\n",
      "Epoch: [128][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.717 (6.144)\n",
      "Epoch: [128][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.631 (6.442)\n",
      "Epoch: [128][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 8.486 (6.528)\n",
      "Epoch: [128][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.830 (6.664)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.159 (2.159)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.862\tL1 0.576\tG-Mean 0.265\n",
      " * Many: MSE 2.156\tL1 0.960\tG-Mean 0.821\n",
      " * Median: MSE 2.298\tL1 1.452\tG-Mean 1.395\n",
      " * Low: MSE 0.062\tL1 0.242\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #128: Train loss [6.6207]; Val loss: MSE [1.8624], L1 [0.5758], G-Mean [0.2648]\n",
      "Epoch: [129][ 0/65]\tTime   0.57 (  0.57)\tData 0.5687 (0.5687)\tLoss (MSE) 7.511 (7.511)\n",
      "Epoch: [129][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0580)\tLoss (MSE) 3.414 (6.197)\n",
      "Epoch: [129][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 9.078 (6.370)\n",
      "Epoch: [129][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 6.721 (6.769)\n",
      "Epoch: [129][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 6.772 (6.904)\n",
      "Epoch: [129][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.656 (6.795)\n",
      "Epoch: [129][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.377 (6.716)\n",
      "Val: [0/9]\tTime  0.588 ( 0.588)\tLoss (MSE) 2.162 (2.162)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.868\tL1 0.573\tG-Mean 0.260\n",
      " * Many: MSE 2.134\tL1 0.943\tG-Mean 0.803\n",
      " * Median: MSE 2.352\tL1 1.469\tG-Mean 1.411\n",
      " * Low: MSE 0.071\tL1 0.259\tG-Mean 0.245\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #129: Train loss [6.6035]; Val loss: MSE [1.8676], L1 [0.5729], G-Mean [0.2597]\n",
      "Epoch: [130][ 0/65]\tTime   0.68 (  0.68)\tData 0.6755 (0.6755)\tLoss (MSE) 8.443 (8.443)\n",
      "Epoch: [130][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0635)\tLoss (MSE) 4.709 (6.332)\n",
      "Epoch: [130][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0333)\tLoss (MSE) 6.353 (6.864)\n",
      "Epoch: [130][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0226)\tLoss (MSE) 2.319 (6.341)\n",
      "Epoch: [130][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0171)\tLoss (MSE) 8.535 (6.846)\n",
      "Epoch: [130][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.112 (6.773)\n",
      "Epoch: [130][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.209 (6.634)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.843\tL1 0.586\tG-Mean 0.264\n",
      " * Many: MSE 2.208\tL1 1.005\tG-Mean 0.870\n",
      " * Median: MSE 2.169\tL1 1.405\tG-Mean 1.343\n",
      " * Low: MSE 0.043\tL1 0.197\tG-Mean 0.174\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #130: Train loss [6.6006]; Val loss: MSE [1.8430], L1 [0.5858], G-Mean [0.2643]\n",
      "Epoch: [131][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 4.700 (4.700)\n",
      "Epoch: [131][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 6.683 (7.705)\n",
      "Epoch: [131][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 3.705 (7.063)\n",
      "Epoch: [131][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 12.035 (6.924)\n",
      "Epoch: [131][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.280 (6.705)\n",
      "Epoch: [131][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 6.523 (6.558)\n",
      "Epoch: [131][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 10.539 (6.491)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.111 (2.111)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.830\tL1 0.595\tG-Mean 0.270\n",
      " * Many: MSE 2.252\tL1 1.039\tG-Mean 0.908\n",
      " * Median: MSE 2.054\tL1 1.363\tG-Mean 1.296\n",
      " * Low: MSE 0.031\tL1 0.168\tG-Mean 0.154\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #131: Train loss [6.5952]; Val loss: MSE [1.8296], L1 [0.5946], G-Mean [0.2699]\n",
      "Epoch: [132][ 0/65]\tTime   0.58 (  0.58)\tData 0.5736 (0.5736)\tLoss (MSE) 6.148 (6.148)\n",
      "Epoch: [132][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0611)\tLoss (MSE) 11.280 (6.589)\n",
      "Epoch: [132][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0320)\tLoss (MSE) 7.111 (6.520)\n",
      "Epoch: [132][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0217)\tLoss (MSE) 3.712 (6.306)\n",
      "Epoch: [132][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 3.731 (6.625)\n",
      "Epoch: [132][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 7.730 (6.471)\n",
      "Epoch: [132][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 9.612 (6.591)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.127 (2.127)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.846\tL1 0.586\tG-Mean 0.264\n",
      " * Many: MSE 2.212\tL1 1.004\tG-Mean 0.869\n",
      " * Median: MSE 2.169\tL1 1.404\tG-Mean 1.338\n",
      " * Low: MSE 0.044\tL1 0.201\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #132: Train loss [6.6221]; Val loss: MSE [1.8465], L1 [0.5864], G-Mean [0.2639]\n",
      "Epoch: [133][ 0/65]\tTime   0.56 (  0.56)\tData 0.5490 (0.5490)\tLoss (MSE) 5.781 (5.781)\n",
      "Epoch: [133][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 7.629 (6.701)\n",
      "Epoch: [133][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.212 (7.131)\n",
      "Epoch: [133][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 9.135 (7.196)\n",
      "Epoch: [133][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 7.371 (7.000)\n",
      "Epoch: [133][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.714 (6.787)\n",
      "Epoch: [133][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.260 (6.502)\n",
      "Val: [0/9]\tTime  0.561 ( 0.561)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.848\tL1 0.584\tG-Mean 0.260\n",
      " * Many: MSE 2.208\tL1 1.001\tG-Mean 0.866\n",
      " * Median: MSE 2.176\tL1 1.408\tG-Mean 1.346\n",
      " * Low: MSE 0.045\tL1 0.205\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #133: Train loss [6.6062]; Val loss: MSE [1.8477], L1 [0.5845], G-Mean [0.2599]\n",
      "Epoch: [134][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 4.570 (4.570)\n",
      "Epoch: [134][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.877 (6.044)\n",
      "Epoch: [134][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 6.166 (6.187)\n",
      "Epoch: [134][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 7.077 (6.111)\n",
      "Epoch: [134][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.311 (6.162)\n",
      "Epoch: [134][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.203 (6.426)\n",
      "Epoch: [134][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.559 (6.412)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.832\tL1 0.599\tG-Mean 0.275\n",
      " * Many: MSE 2.270\tL1 1.050\tG-Mean 0.920\n",
      " * Median: MSE 2.037\tL1 1.356\tG-Mean 1.282\n",
      " * Low: MSE 0.028\tL1 0.157\tG-Mean 0.142\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #134: Train loss [6.5675]; Val loss: MSE [1.8317], L1 [0.5990], G-Mean [0.2754]\n",
      "Epoch: [135][ 0/65]\tTime   0.56 (  0.56)\tData 0.5562 (0.5562)\tLoss (MSE) 5.082 (5.082)\n",
      "Epoch: [135][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0556)\tLoss (MSE) 5.418 (7.030)\n",
      "Epoch: [135][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 6.455 (6.451)\n",
      "Epoch: [135][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 9.599 (6.439)\n",
      "Epoch: [135][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.677 (6.204)\n",
      "Epoch: [135][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 6.536 (6.505)\n",
      "Epoch: [135][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 8.868 (6.548)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.126 (2.126)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.840\tL1 0.589\tG-Mean 0.264\n",
      " * Many: MSE 2.229\tL1 1.018\tG-Mean 0.884\n",
      " * Median: MSE 2.117\tL1 1.381\tG-Mean 1.293\n",
      " * Low: MSE 0.041\tL1 0.193\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #135: Train loss [6.5540]; Val loss: MSE [1.8404], L1 [0.5895], G-Mean [0.2641]\n",
      "Epoch: [136][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 4.873 (4.873)\n",
      "Epoch: [136][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 5.433 (6.106)\n",
      "Epoch: [136][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 7.259 (6.945)\n",
      "Epoch: [136][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.688 (6.996)\n",
      "Epoch: [136][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 10.059 (6.690)\n",
      "Epoch: [136][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 3.832 (6.593)\n",
      "Epoch: [136][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 8.529 (6.639)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.125 (2.125)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.849\tL1 0.591\tG-Mean 0.263\n",
      " * Many: MSE 2.240\tL1 1.021\tG-Mean 0.886\n",
      " * Median: MSE 2.121\tL1 1.384\tG-Mean 1.299\n",
      " * Low: MSE 0.040\tL1 0.191\tG-Mean 0.178\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #136: Train loss [6.5949]; Val loss: MSE [1.8486], L1 [0.5915], G-Mean [0.2631]\n",
      "Epoch: [137][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 2.981 (2.981)\n",
      "Epoch: [137][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 4.721 (5.509)\n",
      "Epoch: [137][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.674 (5.614)\n",
      "Epoch: [137][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 8.470 (5.907)\n",
      "Epoch: [137][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.057 (6.375)\n",
      "Epoch: [137][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 8.664 (6.488)\n",
      "Epoch: [137][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 7.958 (6.478)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.108 (2.108)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.829\tL1 0.594\tG-Mean 0.271\n",
      " * Many: MSE 2.255\tL1 1.041\tG-Mean 0.912\n",
      " * Median: MSE 2.053\tL1 1.362\tG-Mean 1.296\n",
      " * Low: MSE 0.028\tL1 0.160\tG-Mean 0.146\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #137: Train loss [6.5743]; Val loss: MSE [1.8294], L1 [0.5945], G-Mean [0.2715]\n",
      "Epoch: [138][ 0/65]\tTime   0.57 (  0.57)\tData 0.5571 (0.5571)\tLoss (MSE) 5.603 (5.603)\n",
      "Epoch: [138][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.479 (7.179)\n",
      "Epoch: [138][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 6.503 (6.520)\n",
      "Epoch: [138][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.341 (6.191)\n",
      "Epoch: [138][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.585 (6.180)\n",
      "Epoch: [138][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 10.419 (6.254)\n",
      "Epoch: [138][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.788 (6.590)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.155 (2.155)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.862\tL1 0.580\tG-Mean 0.267\n",
      " * Many: MSE 2.176\tL1 0.972\tG-Mean 0.832\n",
      " * Median: MSE 2.251\tL1 1.432\tG-Mean 1.361\n",
      " * Low: MSE 0.059\tL1 0.237\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #138: Train loss [6.5396]; Val loss: MSE [1.8621], L1 [0.5796], G-Mean [0.2674]\n",
      "Epoch: [139][ 0/65]\tTime   0.65 (  0.65)\tData 0.6346 (0.6346)\tLoss (MSE) 7.501 (7.501)\n",
      "Epoch: [139][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0579)\tLoss (MSE) 4.544 (6.141)\n",
      "Epoch: [139][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 7.872 (5.808)\n",
      "Epoch: [139][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 7.574 (6.005)\n",
      "Epoch: [139][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 7.739 (6.149)\n",
      "Epoch: [139][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.476 (6.454)\n",
      "Epoch: [139][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.037 (6.487)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.132 (2.132)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.865\tL1 0.587\tG-Mean 0.272\n",
      " * Many: MSE 2.199\tL1 0.984\tG-Mean 0.842\n",
      " * Median: MSE 2.215\tL1 1.419\tG-Mean 1.353\n",
      " * Low: MSE 0.060\tL1 0.236\tG-Mean 0.219\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #139: Train loss [6.5230]; Val loss: MSE [1.8651], L1 [0.5869], G-Mean [0.2718]\n",
      "Epoch: [140][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 8.876 (8.876)\n",
      "Epoch: [140][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 8.271 (6.347)\n",
      "Epoch: [140][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 5.496 (6.708)\n",
      "Epoch: [140][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.980 (6.639)\n",
      "Epoch: [140][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 8.561 (6.414)\n",
      "Epoch: [140][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 7.678 (6.485)\n",
      "Epoch: [140][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 10.284 (6.585)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.156 (2.156)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.864\tL1 0.580\tG-Mean 0.263\n",
      " * Many: MSE 2.173\tL1 0.969\tG-Mean 0.830\n",
      " * Median: MSE 2.275\tL1 1.442\tG-Mean 1.383\n",
      " * Low: MSE 0.062\tL1 0.241\tG-Mean 0.231\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #140: Train loss [6.5371]; Val loss: MSE [1.8639], L1 [0.5798], G-Mean [0.2634]\n",
      "Epoch: [141][ 0/65]\tTime   0.56 (  0.56)\tData 0.5503 (0.5503)\tLoss (MSE) 5.848 (5.848)\n",
      "Epoch: [141][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 8.074 (7.308)\n",
      "Epoch: [141][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 5.168 (6.715)\n",
      "Epoch: [141][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 8.072 (6.629)\n",
      "Epoch: [141][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.999 (6.387)\n",
      "Epoch: [141][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.606 (6.327)\n",
      "Epoch: [141][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.846 (6.500)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.153 (2.153)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.869\tL1 0.587\tG-Mean 0.270\n",
      " * Many: MSE 2.201\tL1 0.984\tG-Mean 0.841\n",
      " * Median: MSE 2.236\tL1 1.428\tG-Mean 1.369\n",
      " * Low: MSE 0.058\tL1 0.233\tG-Mean 0.215\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #141: Train loss [6.5043]; Val loss: MSE [1.8690], L1 [0.5867], G-Mean [0.2703]\n",
      "Epoch: [142][ 0/65]\tTime   0.54 (  0.54)\tData 0.5383 (0.5383)\tLoss (MSE) 8.783 (8.783)\n",
      "Epoch: [142][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 7.461 (7.139)\n",
      "Epoch: [142][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 5.231 (6.813)\n",
      "Epoch: [142][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 4.680 (7.020)\n",
      "Epoch: [142][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 6.777 (6.732)\n",
      "Epoch: [142][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 7.659 (6.662)\n",
      "Epoch: [142][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 7.437 (6.499)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.853\tL1 0.590\tG-Mean 0.261\n",
      " * Many: MSE 2.239\tL1 1.017\tG-Mean 0.882\n",
      " * Median: MSE 2.140\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.040\tL1 0.193\tG-Mean 0.184\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #142: Train loss [6.4638]; Val loss: MSE [1.8529], L1 [0.5898], G-Mean [0.2607]\n",
      "Epoch: [143][ 0/65]\tTime   0.55 (  0.55)\tData 0.5476 (0.5476)\tLoss (MSE) 3.598 (3.598)\n",
      "Epoch: [143][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 11.217 (6.087)\n",
      "Epoch: [143][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 8.404 (6.820)\n",
      "Epoch: [143][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.620 (6.864)\n",
      "Epoch: [143][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.835 (6.551)\n",
      "Epoch: [143][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.045 (6.553)\n",
      "Epoch: [143][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.036 (6.539)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.159 (2.159)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.870\tL1 0.582\tG-Mean 0.268\n",
      " * Many: MSE 2.192\tL1 0.979\tG-Mean 0.839\n",
      " * Median: MSE 2.276\tL1 1.442\tG-Mean 1.385\n",
      " * Low: MSE 0.058\tL1 0.235\tG-Mean 0.225\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #143: Train loss [6.4887]; Val loss: MSE [1.8697], L1 [0.5825], G-Mean [0.2676]\n",
      "Epoch: [144][ 0/65]\tTime   0.57 (  0.57)\tData 0.5633 (0.5633)\tLoss (MSE) 2.546 (2.546)\n",
      "Epoch: [144][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.549 (4.985)\n",
      "Epoch: [144][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 9.560 (6.318)\n",
      "Epoch: [144][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 5.313 (6.744)\n",
      "Epoch: [144][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 5.816 (6.679)\n",
      "Epoch: [144][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 5.483 (6.679)\n",
      "Epoch: [144][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.378 (6.565)\n",
      "Val: [0/9]\tTime  0.666 ( 0.666)\tLoss (MSE) 2.144 (2.144)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.865\tL1 0.589\tG-Mean 0.261\n",
      " * Many: MSE 2.228\tL1 1.003\tG-Mean 0.864\n",
      " * Median: MSE 2.198\tL1 1.413\tG-Mean 1.352\n",
      " * Low: MSE 0.052\tL1 0.218\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #144: Train loss [6.4893]; Val loss: MSE [1.8650], L1 [0.5892], G-Mean [0.2611]\n",
      "Epoch: [145][ 0/65]\tTime   0.65 (  0.65)\tData 0.6473 (0.6473)\tLoss (MSE) 11.363 (11.363)\n",
      "Epoch: [145][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0610)\tLoss (MSE) 12.596 (7.584)\n",
      "Epoch: [145][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0320)\tLoss (MSE) 4.191 (6.897)\n",
      "Epoch: [145][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0217)\tLoss (MSE) 4.339 (6.600)\n",
      "Epoch: [145][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 6.196 (6.509)\n",
      "Epoch: [145][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 8.793 (6.476)\n",
      "Epoch: [145][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.288 (6.570)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.155 (2.155)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.856\tL1 0.592\tG-Mean 0.266\n",
      " * Many: MSE 2.235\tL1 1.013\tG-Mean 0.875\n",
      " * Median: MSE 2.153\tL1 1.398\tG-Mean 1.335\n",
      " * Low: MSE 0.045\tL1 0.204\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #145: Train loss [6.4459]; Val loss: MSE [1.8562], L1 [0.5920], G-Mean [0.2658]\n",
      "Epoch: [146][ 0/65]\tTime   0.55 (  0.55)\tData 0.5485 (0.5485)\tLoss (MSE) 3.750 (3.750)\n",
      "Epoch: [146][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 7.817 (5.723)\n",
      "Epoch: [146][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 8.101 (6.170)\n",
      "Epoch: [146][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 10.119 (6.369)\n",
      "Epoch: [146][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.527 (6.200)\n",
      "Epoch: [146][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 7.232 (6.303)\n",
      "Epoch: [146][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 9.990 (6.406)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.162 (2.162)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.869\tL1 0.586\tG-Mean 0.261\n",
      " * Many: MSE 2.217\tL1 0.993\tG-Mean 0.853\n",
      " * Median: MSE 2.212\tL1 1.419\tG-Mean 1.358\n",
      " * Low: MSE 0.052\tL1 0.221\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #146: Train loss [6.4243]; Val loss: MSE [1.8693], L1 [0.5858], G-Mean [0.2609]\n",
      "Epoch: [147][ 0/65]\tTime   0.55 (  0.55)\tData 0.5472 (0.5472)\tLoss (MSE) 2.999 (2.999)\n",
      "Epoch: [147][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0573)\tLoss (MSE) 4.983 (6.661)\n",
      "Epoch: [147][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 4.401 (6.349)\n",
      "Epoch: [147][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 7.573 (6.736)\n",
      "Epoch: [147][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.634 (6.566)\n",
      "Epoch: [147][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 5.239 (6.391)\n",
      "Epoch: [147][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.787 (6.461)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.147 (2.147)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.856\tL1 0.590\tG-Mean 0.262\n",
      " * Many: MSE 2.243\tL1 1.017\tG-Mean 0.881\n",
      " * Median: MSE 2.135\tL1 1.394\tG-Mean 1.337\n",
      " * Low: MSE 0.040\tL1 0.195\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #147: Train loss [6.4101]; Val loss: MSE [1.8560], L1 [0.5900], G-Mean [0.2624]\n",
      "Epoch: [148][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 6.852 (6.852)\n",
      "Epoch: [148][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 3.185 (6.564)\n",
      "Epoch: [148][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 7.305 (6.865)\n",
      "Epoch: [148][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 7.262 (6.564)\n",
      "Epoch: [148][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.512 (6.513)\n",
      "Epoch: [148][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 11.005 (6.422)\n",
      "Epoch: [148][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.300 (6.265)\n",
      "Val: [0/9]\tTime  0.535 ( 0.535)\tLoss (MSE) 2.137 (2.137)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.878\tL1 0.595\tG-Mean 0.259\n",
      " * Many: MSE 2.276\tL1 1.023\tG-Mean 0.882\n",
      " * Median: MSE 2.137\tL1 1.388\tG-Mean 1.316\n",
      " * Low: MSE 0.046\tL1 0.203\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #148: Train loss [6.3773]; Val loss: MSE [1.8785], L1 [0.5951], G-Mean [0.2590]\n",
      "Epoch: [149][ 0/65]\tTime   0.62 (  0.62)\tData 0.5995 (0.5995)\tLoss (MSE) 4.297 (4.297)\n",
      "Epoch: [149][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 9.166 (6.258)\n",
      "Epoch: [149][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 4.398 (6.270)\n",
      "Epoch: [149][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 9.770 (6.079)\n",
      "Epoch: [149][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 4.767 (6.439)\n",
      "Epoch: [149][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.261 (6.284)\n",
      "Epoch: [149][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.618 (6.310)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.120 (2.120)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.867\tL1 0.600\tG-Mean 0.271\n",
      " * Many: MSE 2.311\tL1 1.050\tG-Mean 0.914\n",
      " * Median: MSE 2.044\tL1 1.361\tG-Mean 1.302\n",
      " * Low: MSE 0.032\tL1 0.168\tG-Mean 0.162\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #149: Train loss [6.3337]; Val loss: MSE [1.8670], L1 [0.6002], G-Mean [0.2707]\n",
      "Epoch: [150][ 0/65]\tTime   0.57 (  0.57)\tData 0.5594 (0.5594)\tLoss (MSE) 8.235 (8.235)\n",
      "Epoch: [150][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 5.203 (7.077)\n",
      "Epoch: [150][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.679 (6.708)\n",
      "Epoch: [150][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 7.438 (6.681)\n",
      "Epoch: [150][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.966 (6.597)\n",
      "Epoch: [150][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 6.203 (6.478)\n",
      "Epoch: [150][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 7.143 (6.449)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.140 (2.140)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.881\tL1 0.592\tG-Mean 0.259\n",
      " * Many: MSE 2.258\tL1 1.011\tG-Mean 0.870\n",
      " * Median: MSE 2.189\tL1 1.409\tG-Mean 1.337\n",
      " * Low: MSE 0.050\tL1 0.213\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #150: Train loss [6.3212]; Val loss: MSE [1.8806], L1 [0.5916], G-Mean [0.2593]\n",
      "Epoch: [151][ 0/65]\tTime   0.64 (  0.64)\tData 0.6303 (0.6303)\tLoss (MSE) 6.183 (6.183)\n",
      "Epoch: [151][10/65]\tTime   0.00 (  0.08)\tData 0.0000 (0.0733)\tLoss (MSE) 5.305 (5.929)\n",
      "Epoch: [151][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0384)\tLoss (MSE) 7.143 (6.110)\n",
      "Epoch: [151][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0260)\tLoss (MSE) 3.436 (5.778)\n",
      "Epoch: [151][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 6.198 (6.095)\n",
      "Epoch: [151][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 5.997 (6.323)\n",
      "Epoch: [151][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 3.874 (6.350)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.135 (2.135)\tLoss (L1) 0.678 (0.678)\n",
      " * Overall: MSE 1.898\tL1 0.611\tG-Mean 0.273\n",
      " * Many: MSE 2.363\tL1 1.063\tG-Mean 0.922\n",
      " * Median: MSE 2.049\tL1 1.359\tG-Mean 1.288\n",
      " * Low: MSE 0.034\tL1 0.170\tG-Mean 0.155\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #151: Train loss [6.3278]; Val loss: MSE [1.8977], L1 [0.6109], G-Mean [0.2731]\n",
      "Epoch: [152][ 0/65]\tTime   0.56 (  0.56)\tData 0.5485 (0.5485)\tLoss (MSE) 10.165 (10.165)\n",
      "Epoch: [152][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0571)\tLoss (MSE) 8.690 (6.394)\n",
      "Epoch: [152][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 5.513 (6.270)\n",
      "Epoch: [152][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.284 (6.264)\n",
      "Epoch: [152][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 8.694 (6.105)\n",
      "Epoch: [152][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 11.814 (6.057)\n",
      "Epoch: [152][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.002 (6.406)\n",
      "Val: [0/9]\tTime  0.567 ( 0.567)\tLoss (MSE) 2.091 (2.091)\tLoss (L1) 0.669 (0.669)\n",
      " * Overall: MSE 1.881\tL1 0.609\tG-Mean 0.274\n",
      " * Many: MSE 2.346\tL1 1.062\tG-Mean 0.923\n",
      " * Median: MSE 2.045\tL1 1.358\tG-Mean 1.294\n",
      " * Low: MSE 0.047\tL1 0.174\tG-Mean 0.154\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #152: Train loss [6.3571]; Val loss: MSE [1.8812], L1 [0.6094], G-Mean [0.2744]\n",
      "Epoch: [153][ 0/65]\tTime   0.62 (  0.62)\tData 0.6128 (0.6128)\tLoss (MSE) 4.961 (4.961)\n",
      "Epoch: [153][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0650)\tLoss (MSE) 5.546 (5.266)\n",
      "Epoch: [153][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0341)\tLoss (MSE) 8.653 (5.548)\n",
      "Epoch: [153][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0231)\tLoss (MSE) 9.949 (5.807)\n",
      "Epoch: [153][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0175)\tLoss (MSE) 9.561 (6.026)\n",
      "Epoch: [153][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 6.511 (6.106)\n",
      "Epoch: [153][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.923 (6.202)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.168 (2.168)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.897\tL1 0.586\tG-Mean 0.266\n",
      " * Many: MSE 2.227\tL1 0.980\tG-Mean 0.836\n",
      " * Median: MSE 2.274\tL1 1.443\tG-Mean 1.385\n",
      " * Low: MSE 0.065\tL1 0.244\tG-Mean 0.231\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #153: Train loss [6.2462]; Val loss: MSE [1.8968], L1 [0.5857], G-Mean [0.2660]\n",
      "Epoch: [154][ 0/65]\tTime   0.55 (  0.55)\tData 0.5463 (0.5463)\tLoss (MSE) 10.017 (10.017)\n",
      "Epoch: [154][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0580)\tLoss (MSE) 5.968 (6.786)\n",
      "Epoch: [154][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 10.769 (6.946)\n",
      "Epoch: [154][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 4.994 (6.576)\n",
      "Epoch: [154][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 7.232 (6.581)\n",
      "Epoch: [154][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.784 (6.310)\n",
      "Epoch: [154][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.074 (6.249)\n",
      "Val: [0/9]\tTime  0.531 ( 0.531)\tLoss (MSE) 2.142 (2.142)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.895\tL1 0.593\tG-Mean 0.257\n",
      " * Many: MSE 2.286\tL1 1.016\tG-Mean 0.874\n",
      " * Median: MSE 2.158\tL1 1.398\tG-Mean 1.324\n",
      " * Low: MSE 0.057\tL1 0.213\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #154: Train loss [6.2566]; Val loss: MSE [1.8946], L1 [0.5925], G-Mean [0.2573]\n",
      "Epoch: [155][ 0/65]\tTime   0.56 (  0.56)\tData 0.5498 (0.5498)\tLoss (MSE) 7.547 (7.547)\n",
      "Epoch: [155][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0536)\tLoss (MSE) 3.730 (5.640)\n",
      "Epoch: [155][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 8.583 (6.109)\n",
      "Epoch: [155][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 6.918 (6.152)\n",
      "Epoch: [155][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 5.170 (5.990)\n",
      "Epoch: [155][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 6.346 (6.277)\n",
      "Epoch: [155][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 6.148 (6.268)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.113 (2.113)\tLoss (L1) 0.670 (0.670)\n",
      " * Overall: MSE 1.907\tL1 0.604\tG-Mean 0.264\n",
      " * Many: MSE 2.326\tL1 1.036\tG-Mean 0.892\n",
      " * Median: MSE 2.146\tL1 1.392\tG-Mean 1.300\n",
      " * Low: MSE 0.083\tL1 0.210\tG-Mean 0.182\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #155: Train loss [6.2363]; Val loss: MSE [1.9074], L1 [0.6041], G-Mean [0.2642]\n",
      "Epoch: [156][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 3.385 (3.385)\n",
      "Epoch: [156][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0530)\tLoss (MSE) 8.992 (5.502)\n",
      "Epoch: [156][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 7.390 (6.016)\n",
      "Epoch: [156][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 5.060 (5.993)\n",
      "Epoch: [156][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 11.233 (6.220)\n",
      "Epoch: [156][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.372 (6.153)\n",
      "Epoch: [156][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 7.641 (6.038)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.183 (2.183)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.924\tL1 0.580\tG-Mean 0.258\n",
      " * Many: MSE 2.206\tL1 0.949\tG-Mean 0.800\n",
      " * Median: MSE 2.365\tL1 1.472\tG-Mean 1.413\n",
      " * Low: MSE 0.076\tL1 0.270\tG-Mean 0.260\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #156: Train loss [6.2299]; Val loss: MSE [1.9244], L1 [0.5801], G-Mean [0.2581]\n",
      "Epoch: [157][ 0/65]\tTime   0.56 (  0.56)\tData 0.5488 (0.5488)\tLoss (MSE) 5.139 (5.139)\n",
      "Epoch: [157][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0507)\tLoss (MSE) 8.406 (7.090)\n",
      "Epoch: [157][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 2.982 (6.356)\n",
      "Epoch: [157][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 9.705 (6.191)\n",
      "Epoch: [157][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 7.281 (6.164)\n",
      "Epoch: [157][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.373 (6.258)\n",
      "Epoch: [157][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.627 (6.102)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.140 (2.140)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.920\tL1 0.588\tG-Mean 0.259\n",
      " * Many: MSE 2.282\tL1 0.997\tG-Mean 0.852\n",
      " * Median: MSE 2.239\tL1 1.432\tG-Mean 1.377\n",
      " * Low: MSE 0.055\tL1 0.224\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #157: Train loss [6.1251]; Val loss: MSE [1.9197], L1 [0.5882], G-Mean [0.2589]\n",
      "Epoch: [158][ 0/65]\tTime   0.57 (  0.57)\tData 0.5672 (0.5672)\tLoss (MSE) 8.851 (8.851)\n",
      "Epoch: [158][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 6.537 (6.252)\n",
      "Epoch: [158][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 4.580 (5.735)\n",
      "Epoch: [158][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 6.903 (6.103)\n",
      "Epoch: [158][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.520 (6.082)\n",
      "Epoch: [158][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.657 (5.952)\n",
      "Epoch: [158][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.459 (5.989)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.666 (0.666)\n",
      " * Overall: MSE 1.890\tL1 0.593\tG-Mean 0.259\n",
      " * Many: MSE 2.275\tL1 1.012\tG-Mean 0.869\n",
      " * Median: MSE 2.143\tL1 1.387\tG-Mean 1.307\n",
      " * Low: MSE 0.054\tL1 0.219\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #158: Train loss [6.0481]; Val loss: MSE [1.8903], L1 [0.5931], G-Mean [0.2586]\n",
      "Epoch: [159][ 0/65]\tTime   0.56 (  0.56)\tData 0.5517 (0.5517)\tLoss (MSE) 6.192 (6.192)\n",
      "Epoch: [159][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0588)\tLoss (MSE) 5.058 (6.446)\n",
      "Epoch: [159][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 5.743 (5.742)\n",
      "Epoch: [159][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 5.090 (5.871)\n",
      "Epoch: [159][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 9.535 (6.242)\n",
      "Epoch: [159][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.644 (6.042)\n",
      "Epoch: [159][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.449 (6.010)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.103 (2.103)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.953\tL1 0.597\tG-Mean 0.269\n",
      " * Many: MSE 2.319\tL1 0.998\tG-Mean 0.846\n",
      " * Median: MSE 2.268\tL1 1.433\tG-Mean 1.369\n",
      " * Low: MSE 0.083\tL1 0.251\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #159: Train loss [6.0657]; Val loss: MSE [1.9530], L1 [0.5970], G-Mean [0.2686]\n",
      "Epoch: [160][ 0/65]\tTime   0.57 (  0.57)\tData 0.5622 (0.5622)\tLoss (MSE) 4.413 (4.413)\n",
      "Epoch: [160][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0573)\tLoss (MSE) 3.314 (5.429)\n",
      "Epoch: [160][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 2.681 (6.139)\n",
      "Epoch: [160][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 9.498 (6.116)\n",
      "Epoch: [160][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.303 (5.943)\n",
      "Epoch: [160][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.752 (6.144)\n",
      "Epoch: [160][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.616 (6.215)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.981\tL1 0.598\tG-Mean 0.266\n",
      " * Many: MSE 2.329\tL1 0.988\tG-Mean 0.833\n",
      " * Median: MSE 2.359\tL1 1.466\tG-Mean 1.405\n",
      " * Low: MSE 0.093\tL1 0.259\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #160: Train loss [6.0874]; Val loss: MSE [1.9809], L1 [0.5979], G-Mean [0.2660]\n",
      "Epoch: [161][ 0/65]\tTime   0.55 (  0.55)\tData 0.5440 (0.5440)\tLoss (MSE) 6.599 (6.599)\n",
      "Epoch: [161][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 6.195 (6.520)\n",
      "Epoch: [161][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0305)\tLoss (MSE) 4.142 (5.924)\n",
      "Epoch: [161][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 15.061 (6.228)\n",
      "Epoch: [161][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.453 (6.350)\n",
      "Epoch: [161][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.599 (6.238)\n",
      "Epoch: [161][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 7.022 (6.053)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.133 (2.133)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.931\tL1 0.596\tG-Mean 0.261\n",
      " * Many: MSE 2.309\tL1 1.008\tG-Mean 0.862\n",
      " * Median: MSE 2.220\tL1 1.425\tG-Mean 1.368\n",
      " * Low: MSE 0.087\tL1 0.231\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #161: Train loss [6.0534]; Val loss: MSE [1.9313], L1 [0.5959], G-Mean [0.2607]\n",
      "Epoch: [162][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 5.654 (5.654)\n",
      "Epoch: [162][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 2.650 (6.079)\n",
      "Epoch: [162][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 5.826 (6.099)\n",
      "Epoch: [162][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 6.967 (5.965)\n",
      "Epoch: [162][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.145 (5.985)\n",
      "Epoch: [162][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.539 (6.130)\n",
      "Epoch: [162][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.131 (5.956)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.666 (0.666)\n",
      " * Overall: MSE 1.963\tL1 0.623\tG-Mean 0.283\n",
      " * Many: MSE 2.478\tL1 1.086\tG-Mean 0.942\n",
      " * Median: MSE 2.001\tL1 1.344\tG-Mean 1.282\n",
      " * Low: MSE 0.069\tL1 0.164\tG-Mean 0.139\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #162: Train loss [6.0199]; Val loss: MSE [1.9630], L1 [0.6226], G-Mean [0.2831]\n",
      "Epoch: [163][ 0/65]\tTime   0.57 (  0.57)\tData 0.5661 (0.5661)\tLoss (MSE) 4.047 (4.047)\n",
      "Epoch: [163][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0530)\tLoss (MSE) 6.470 (5.085)\n",
      "Epoch: [163][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 6.535 (5.641)\n",
      "Epoch: [163][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 5.661 (5.867)\n",
      "Epoch: [163][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.891 (5.730)\n",
      "Epoch: [163][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 7.892 (5.730)\n",
      "Epoch: [163][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.218 (5.828)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.089 (2.089)\tLoss (L1) 0.673 (0.673)\n",
      " * Overall: MSE 1.964\tL1 0.617\tG-Mean 0.279\n",
      " * Many: MSE 2.468\tL1 1.077\tG-Mean 0.931\n",
      " * Median: MSE 1.987\tL1 1.334\tG-Mean 1.260\n",
      " * Low: MSE 0.045\tL1 0.164\tG-Mean 0.149\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #163: Train loss [5.9140]; Val loss: MSE [1.9639], L1 [0.6165], G-Mean [0.2791]\n",
      "Epoch: [164][ 0/65]\tTime   0.55 (  0.55)\tData 0.5463 (0.5463)\tLoss (MSE) 7.716 (7.716)\n",
      "Epoch: [164][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 5.673 (6.442)\n",
      "Epoch: [164][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.513 (5.851)\n",
      "Epoch: [164][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 10.891 (5.770)\n",
      "Epoch: [164][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 9.447 (5.861)\n",
      "Epoch: [164][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.788 (5.718)\n",
      "Epoch: [164][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.236 (5.678)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.676 (0.676)\n",
      " * Overall: MSE 1.950\tL1 0.611\tG-Mean 0.272\n",
      " * Many: MSE 2.431\tL1 1.064\tG-Mean 0.921\n",
      " * Median: MSE 2.047\tL1 1.364\tG-Mean 1.307\n",
      " * Low: MSE 0.053\tL1 0.175\tG-Mean 0.157\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #164: Train loss [5.8834]; Val loss: MSE [1.9499], L1 [0.6108], G-Mean [0.2717]\n",
      "Epoch: [165][ 0/65]\tTime   0.58 (  0.58)\tData 0.5746 (0.5746)\tLoss (MSE) 3.997 (3.997)\n",
      "Epoch: [165][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0594)\tLoss (MSE) 3.438 (4.796)\n",
      "Epoch: [165][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 4.609 (5.262)\n",
      "Epoch: [165][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 4.839 (5.777)\n",
      "Epoch: [165][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 4.572 (5.700)\n",
      "Epoch: [165][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 5.528 (5.743)\n",
      "Epoch: [165][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 7.191 (5.802)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.163 (2.163)\tLoss (L1) 0.668 (0.668)\n",
      " * Overall: MSE 2.007\tL1 0.605\tG-Mean 0.259\n",
      " * Many: MSE 2.429\tL1 1.026\tG-Mean 0.872\n",
      " * Median: MSE 2.210\tL1 1.419\tG-Mean 1.361\n",
      " * Low: MSE 0.064\tL1 0.221\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #165: Train loss [5.8838]; Val loss: MSE [2.0074], L1 [0.6049], G-Mean [0.2594]\n",
      "Epoch: [166][ 0/65]\tTime   0.56 (  0.56)\tData 0.5599 (0.5599)\tLoss (MSE) 6.483 (6.483)\n",
      "Epoch: [166][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0586)\tLoss (MSE) 7.609 (5.559)\n",
      "Epoch: [166][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0307)\tLoss (MSE) 8.364 (5.795)\n",
      "Epoch: [166][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 4.086 (5.788)\n",
      "Epoch: [166][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 7.373 (5.753)\n",
      "Epoch: [166][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 6.529 (5.763)\n",
      "Epoch: [166][60/65]\tTime   0.01 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 5.940 (5.842)\n",
      "Val: [0/9]\tTime  0.641 ( 0.641)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 2.009\tL1 0.597\tG-Mean 0.263\n",
      " * Many: MSE 2.322\tL1 0.964\tG-Mean 0.804\n",
      " * Median: MSE 2.408\tL1 1.489\tG-Mean 1.435\n",
      " * Low: MSE 0.131\tL1 0.295\tG-Mean 0.276\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #166: Train loss [5.8260]; Val loss: MSE [2.0089], L1 [0.5972], G-Mean [0.2631]\n",
      "Epoch: [167][ 0/65]\tTime   0.66 (  0.66)\tData 0.6496 (0.6496)\tLoss (MSE) 5.139 (5.139)\n",
      "Epoch: [167][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0623)\tLoss (MSE) 6.325 (5.037)\n",
      "Epoch: [167][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0327)\tLoss (MSE) 8.984 (6.137)\n",
      "Epoch: [167][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0221)\tLoss (MSE) 6.761 (5.998)\n",
      "Epoch: [167][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0167)\tLoss (MSE) 5.201 (5.867)\n",
      "Epoch: [167][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 6.285 (5.981)\n",
      "Epoch: [167][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 3.218 (5.891)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.085 (2.085)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.922\tL1 0.589\tG-Mean 0.262\n",
      " * Many: MSE 2.247\tL1 0.974\tG-Mean 0.823\n",
      " * Median: MSE 2.305\tL1 1.455\tG-Mean 1.401\n",
      " * Low: MSE 0.075\tL1 0.260\tG-Mean 0.251\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #167: Train loss [5.8947]; Val loss: MSE [1.9223], L1 [0.5893], G-Mean [0.2618]\n",
      "Epoch: [168][ 0/65]\tTime   0.56 (  0.56)\tData 0.5575 (0.5575)\tLoss (MSE) 6.408 (6.408)\n",
      "Epoch: [168][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 11.460 (6.061)\n",
      "Epoch: [168][20/65]\tTime   0.01 (  0.03)\tData 0.0001 (0.0271)\tLoss (MSE) 3.393 (5.673)\n",
      "Epoch: [168][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 5.978 (5.825)\n",
      "Epoch: [168][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.878 (5.762)\n",
      "Epoch: [168][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 8.323 (5.784)\n",
      "Epoch: [168][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 7.013 (5.721)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.103 (2.103)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 2.045\tL1 0.602\tG-Mean 0.264\n",
      " * Many: MSE 2.423\tL1 0.996\tG-Mean 0.836\n",
      " * Median: MSE 2.263\tL1 1.441\tG-Mean 1.387\n",
      " * Low: MSE 0.100\tL1 0.260\tG-Mean 0.240\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #168: Train loss [5.6613]; Val loss: MSE [2.0449], L1 [0.6023], G-Mean [0.2640]\n",
      "Epoch: [169][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 7.143 (7.143)\n",
      "Epoch: [169][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 5.568 (5.782)\n",
      "Epoch: [169][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.464 (5.771)\n",
      "Epoch: [169][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.811 (5.734)\n",
      "Epoch: [169][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.344 (5.794)\n",
      "Epoch: [169][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.298 (5.945)\n",
      "Epoch: [169][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.850 (5.822)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.067 (2.067)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.951\tL1 0.601\tG-Mean 0.257\n",
      " * Many: MSE 2.363\tL1 1.023\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.397\tG-Mean 1.339\n",
      " * Low: MSE 0.077\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #169: Train loss [5.7257]; Val loss: MSE [1.9510], L1 [0.6010], G-Mean [0.2571]\n",
      "Epoch: [170][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 5.027 (5.027)\n",
      "Epoch: [170][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 7.242 (5.055)\n",
      "Epoch: [170][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 5.915 (5.473)\n",
      "Epoch: [170][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 5.509 (5.426)\n",
      "Epoch: [170][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.408 (5.616)\n",
      "Epoch: [170][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.183 (5.537)\n",
      "Epoch: [170][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 7.617 (5.793)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.679 (0.679)\n",
      " * Overall: MSE 1.974\tL1 0.619\tG-Mean 0.275\n",
      " * Many: MSE 2.474\tL1 1.076\tG-Mean 0.929\n",
      " * Median: MSE 2.006\tL1 1.344\tG-Mean 1.274\n",
      " * Low: MSE 0.082\tL1 0.179\tG-Mean 0.150\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #170: Train loss [5.6823]; Val loss: MSE [1.9740], L1 [0.6190], G-Mean [0.2747]\n",
      "Epoch: [171][ 0/65]\tTime   0.55 (  0.55)\tData 0.5461 (0.5461)\tLoss (MSE) 6.809 (6.809)\n",
      "Epoch: [171][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 5.953 (5.703)\n",
      "Epoch: [171][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.423 (5.475)\n",
      "Epoch: [171][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 9.326 (5.757)\n",
      "Epoch: [171][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 5.316 (5.789)\n",
      "Epoch: [171][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 7.819 (5.822)\n",
      "Epoch: [171][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.776 (5.704)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.095 (2.095)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.962\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.355\tL1 1.012\tG-Mean 0.861\n",
      " * Median: MSE 2.211\tL1 1.420\tG-Mean 1.361\n",
      " * Low: MSE 0.074\tL1 0.231\tG-Mean 0.215\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #171: Train loss [5.6633]; Val loss: MSE [1.9619], L1 [0.5993], G-Mean [0.2596]\n",
      "Epoch: [172][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.399 (5.399)\n",
      "Epoch: [172][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0550)\tLoss (MSE) 6.005 (4.967)\n",
      "Epoch: [172][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 6.168 (5.448)\n",
      "Epoch: [172][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.409 (5.733)\n",
      "Epoch: [172][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 5.667 (5.975)\n",
      "Epoch: [172][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 6.547 (5.963)\n",
      "Epoch: [172][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.767 (5.941)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.860\tL1 0.602\tG-Mean 0.273\n",
      " * Many: MSE 2.302\tL1 1.054\tG-Mean 0.921\n",
      " * Median: MSE 2.074\tL1 1.374\tG-Mean 1.319\n",
      " * Low: MSE 0.045\tL1 0.162\tG-Mean 0.145\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #172: Train loss [5.8861]; Val loss: MSE [1.8599], L1 [0.6022], G-Mean [0.2728]\n",
      "Epoch: [173][ 0/65]\tTime   0.56 (  0.56)\tData 0.5550 (0.5550)\tLoss (MSE) 5.868 (5.868)\n",
      "Epoch: [173][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0593)\tLoss (MSE) 2.489 (5.795)\n",
      "Epoch: [173][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 7.445 (6.228)\n",
      "Epoch: [173][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 3.948 (5.905)\n",
      "Epoch: [173][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 8.045 (6.076)\n",
      "Epoch: [173][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.745 (5.932)\n",
      "Epoch: [173][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.339 (5.944)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.085 (2.085)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.952\tL1 0.588\tG-Mean 0.261\n",
      " * Many: MSE 2.258\tL1 0.962\tG-Mean 0.811\n",
      " * Median: MSE 2.351\tL1 1.471\tG-Mean 1.417\n",
      " * Low: MSE 0.107\tL1 0.276\tG-Mean 0.261\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #173: Train loss [5.8856]; Val loss: MSE [1.9517], L1 [0.5879], G-Mean [0.2607]\n",
      "Epoch: [174][ 0/65]\tTime   0.55 (  0.55)\tData 0.5491 (0.5491)\tLoss (MSE) 4.470 (4.470)\n",
      "Epoch: [174][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 3.380 (5.280)\n",
      "Epoch: [174][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 5.066 (5.476)\n",
      "Epoch: [174][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 7.032 (5.482)\n",
      "Epoch: [174][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 5.545 (5.649)\n",
      "Epoch: [174][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 10.671 (5.826)\n",
      "Epoch: [174][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.983 (5.690)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.913\tL1 0.594\tG-Mean 0.257\n",
      " * Many: MSE 2.308\tL1 1.014\tG-Mean 0.868\n",
      " * Median: MSE 2.137\tL1 1.397\tG-Mean 1.342\n",
      " * Low: MSE 0.058\tL1 0.216\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #174: Train loss [5.7358]; Val loss: MSE [1.9132], L1 [0.5940], G-Mean [0.2567]\n",
      "Epoch: [175][ 0/65]\tTime   0.57 (  0.57)\tData 0.5681 (0.5681)\tLoss (MSE) 4.930 (4.930)\n",
      "Epoch: [175][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0593)\tLoss (MSE) 2.951 (4.577)\n",
      "Epoch: [175][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 8.111 (4.991)\n",
      "Epoch: [175][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 6.528 (5.330)\n",
      "Epoch: [175][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 4.692 (5.445)\n",
      "Epoch: [175][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 8.611 (5.477)\n",
      "Epoch: [175][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.825 (5.490)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 1.985 (1.985)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.863\tL1 0.606\tG-Mean 0.278\n",
      " * Many: MSE 2.331\tL1 1.065\tG-Mean 0.931\n",
      " * Median: MSE 2.018\tL1 1.350\tG-Mean 1.288\n",
      " * Low: MSE 0.040\tL1 0.155\tG-Mean 0.143\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #175: Train loss [5.5853]; Val loss: MSE [1.8630], L1 [0.6064], G-Mean [0.2781]\n",
      "Epoch: [176][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 5.372 (5.372)\n",
      "Epoch: [176][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0595)\tLoss (MSE) 10.397 (5.145)\n",
      "Epoch: [176][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 5.265 (5.664)\n",
      "Epoch: [176][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 6.524 (5.827)\n",
      "Epoch: [176][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 6.100 (5.746)\n",
      "Epoch: [176][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 8.920 (5.755)\n",
      "Epoch: [176][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 4.650 (5.766)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.071 (2.071)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.920\tL1 0.590\tG-Mean 0.262\n",
      " * Many: MSE 2.265\tL1 0.986\tG-Mean 0.838\n",
      " * Median: MSE 2.262\tL1 1.431\tG-Mean 1.338\n",
      " * Low: MSE 0.083\tL1 0.247\tG-Mean 0.235\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #176: Train loss [5.6418]; Val loss: MSE [1.9200], L1 [0.5902], G-Mean [0.2624]\n",
      "Epoch: [177][ 0/65]\tTime   0.55 (  0.55)\tData 0.5439 (0.5439)\tLoss (MSE) 8.256 (8.256)\n",
      "Epoch: [177][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 4.419 (5.690)\n",
      "Epoch: [177][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.658 (5.564)\n",
      "Epoch: [177][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.990 (5.687)\n",
      "Epoch: [177][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.145 (5.475)\n",
      "Epoch: [177][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.814 (5.288)\n",
      "Epoch: [177][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.282 (5.514)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.037 (2.037)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.956\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.342\tL1 1.006\tG-Mean 0.856\n",
      " * Median: MSE 2.201\tL1 1.415\tG-Mean 1.341\n",
      " * Low: MSE 0.078\tL1 0.232\tG-Mean 0.218\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #177: Train loss [5.5204]; Val loss: MSE [1.9564], L1 [0.5963], G-Mean [0.2600]\n",
      "Epoch: [178][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 4.064 (4.064)\n",
      "Epoch: [178][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0527)\tLoss (MSE) 6.865 (5.141)\n",
      "Epoch: [178][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.618 (5.101)\n",
      "Epoch: [178][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 11.443 (5.183)\n",
      "Epoch: [178][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 10.377 (5.498)\n",
      "Epoch: [178][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 7.827 (5.750)\n",
      "Epoch: [178][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.219 (5.516)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.953\tL1 0.591\tG-Mean 0.261\n",
      " * Many: MSE 2.315\tL1 0.991\tG-Mean 0.842\n",
      " * Median: MSE 2.236\tL1 1.424\tG-Mean 1.349\n",
      " * Low: MSE 0.075\tL1 0.241\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #178: Train loss [5.4810]; Val loss: MSE [1.9534], L1 [0.5912], G-Mean [0.2606]\n",
      "Epoch: [179][ 0/65]\tTime   0.55 (  0.55)\tData 0.5454 (0.5454)\tLoss (MSE) 5.860 (5.860)\n",
      "Epoch: [179][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 5.435 (5.794)\n",
      "Epoch: [179][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.369 (5.835)\n",
      "Epoch: [179][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 7.243 (5.743)\n",
      "Epoch: [179][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.390 (5.744)\n",
      "Epoch: [179][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.613 (5.564)\n",
      "Epoch: [179][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.060 (5.611)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.094 (2.094)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 2.020\tL1 0.606\tG-Mean 0.260\n",
      " * Many: MSE 2.475\tL1 1.041\tG-Mean 0.890\n",
      " * Median: MSE 2.138\tL1 1.396\tG-Mean 1.340\n",
      " * Low: MSE 0.048\tL1 0.195\tG-Mean 0.182\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #179: Train loss [5.5714]; Val loss: MSE [2.0202], L1 [0.6056], G-Mean [0.2596]\n",
      "Epoch: [180][ 0/65]\tTime   0.57 (  0.57)\tData 0.5595 (0.5595)\tLoss (MSE) 3.510 (3.510)\n",
      "Epoch: [180][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 4.418 (4.038)\n",
      "Epoch: [180][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 5.378 (4.677)\n",
      "Epoch: [180][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.534 (4.933)\n",
      "Epoch: [180][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.938 (4.913)\n",
      "Epoch: [180][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 8.323 (5.157)\n",
      "Epoch: [180][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 9.185 (5.471)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.155 (2.155)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 2.033\tL1 0.592\tG-Mean 0.249\n",
      " * Many: MSE 2.320\tL1 0.944\tG-Mean 0.782\n",
      " * Median: MSE 2.484\tL1 1.508\tG-Mean 1.449\n",
      " * Low: MSE 0.098\tL1 0.301\tG-Mean 0.293\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #180: Train loss [5.4668]; Val loss: MSE [2.0333], L1 [0.5922], G-Mean [0.2487]\n",
      "Epoch: [181][ 0/65]\tTime   0.64 (  0.64)\tData 0.6372 (0.6372)\tLoss (MSE) 6.728 (6.728)\n",
      "Epoch: [181][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0621)\tLoss (MSE) 6.519 (5.519)\n",
      "Epoch: [181][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0325)\tLoss (MSE) 6.073 (5.410)\n",
      "Epoch: [181][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0220)\tLoss (MSE) 7.879 (5.737)\n",
      "Epoch: [181][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0167)\tLoss (MSE) 6.682 (5.635)\n",
      "Epoch: [181][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0134)\tLoss (MSE) 5.172 (5.512)\n",
      "Epoch: [181][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.858 (5.597)\n",
      "Val: [0/9]\tTime  0.641 ( 0.641)\tLoss (MSE) 2.084 (2.084)\tLoss (L1) 0.680 (0.680)\n",
      " * Overall: MSE 2.020\tL1 0.633\tG-Mean 0.293\n",
      " * Many: MSE 2.582\tL1 1.110\tG-Mean 0.964\n",
      " * Median: MSE 1.910\tL1 1.306\tG-Mean 1.220\n",
      " * Low: MSE 0.081\tL1 0.138\tG-Mean 0.107\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #181: Train loss [5.5271]; Val loss: MSE [2.0196], L1 [0.6329], G-Mean [0.2930]\n",
      "Epoch: [182][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 2.625 (2.625)\n",
      "Epoch: [182][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 4.244 (5.260)\n",
      "Epoch: [182][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.666 (4.797)\n",
      "Epoch: [182][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.143 (5.043)\n",
      "Epoch: [182][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.410 (5.102)\n",
      "Epoch: [182][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 10.489 (5.352)\n",
      "Epoch: [182][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.728 (5.407)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.668 (0.668)\n",
      " * Overall: MSE 2.008\tL1 0.630\tG-Mean 0.286\n",
      " * Many: MSE 2.549\tL1 1.097\tG-Mean 0.946\n",
      " * Median: MSE 1.989\tL1 1.333\tG-Mean 1.260\n",
      " * Low: MSE 0.066\tL1 0.160\tG-Mean 0.130\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #182: Train loss [5.4023]; Val loss: MSE [2.0083], L1 [0.6300], G-Mean [0.2857]\n",
      "Epoch: [183][ 0/65]\tTime   0.55 (  0.55)\tData 0.5448 (0.5448)\tLoss (MSE) 5.461 (5.461)\n",
      "Epoch: [183][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 4.907 (4.762)\n",
      "Epoch: [183][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.352 (5.382)\n",
      "Epoch: [183][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.298 (5.019)\n",
      "Epoch: [183][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.984 (5.181)\n",
      "Epoch: [183][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 8.966 (5.237)\n",
      "Epoch: [183][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.708 (5.298)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.888\tL1 0.589\tG-Mean 0.255\n",
      " * Many: MSE 2.262\tL1 1.007\tG-Mean 0.867\n",
      " * Median: MSE 2.190\tL1 1.411\tG-Mean 1.349\n",
      " * Low: MSE 0.053\tL1 0.209\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #183: Train loss [5.3117]; Val loss: MSE [1.8879], L1 [0.5893], G-Mean [0.2553]\n",
      "Epoch: [184][ 0/65]\tTime   0.55 (  0.55)\tData 0.5453 (0.5453)\tLoss (MSE) 4.016 (4.016)\n",
      "Epoch: [184][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 3.058 (4.938)\n",
      "Epoch: [184][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 5.363 (4.962)\n",
      "Epoch: [184][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.119 (5.109)\n",
      "Epoch: [184][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 7.460 (5.311)\n",
      "Epoch: [184][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 9.721 (5.475)\n",
      "Epoch: [184][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.956 (5.340)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.116 (2.116)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 2.026\tL1 0.592\tG-Mean 0.256\n",
      " * Many: MSE 2.333\tL1 0.957\tG-Mean 0.797\n",
      " * Median: MSE 2.409\tL1 1.490\tG-Mean 1.436\n",
      " * Low: MSE 0.096\tL1 0.282\tG-Mean 0.270\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #184: Train loss [5.4583]; Val loss: MSE [2.0255], L1 [0.5925], G-Mean [0.2560]\n",
      "Epoch: [185][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 2.694 (2.694)\n",
      "Epoch: [185][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0579)\tLoss (MSE) 4.966 (5.254)\n",
      "Epoch: [185][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.620 (4.998)\n",
      "Epoch: [185][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.433 (4.661)\n",
      "Epoch: [185][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.924 (4.838)\n",
      "Epoch: [185][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.061 (5.385)\n",
      "Epoch: [185][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.266 (5.298)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.073 (2.073)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.959\tL1 0.609\tG-Mean 0.265\n",
      " * Many: MSE 2.427\tL1 1.055\tG-Mean 0.909\n",
      " * Median: MSE 2.073\tL1 1.367\tG-Mean 1.285\n",
      " * Low: MSE 0.064\tL1 0.182\tG-Mean 0.162\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #185: Train loss [5.2782]; Val loss: MSE [1.9585], L1 [0.6093], G-Mean [0.2646]\n",
      "Epoch: [186][ 0/65]\tTime   0.56 (  0.56)\tData 0.5536 (0.5536)\tLoss (MSE) 3.592 (3.592)\n",
      "Epoch: [186][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 4.553 (5.140)\n",
      "Epoch: [186][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 6.723 (4.882)\n",
      "Epoch: [186][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.969 (4.907)\n",
      "Epoch: [186][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 6.709 (5.323)\n",
      "Epoch: [186][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 8.414 (5.348)\n",
      "Epoch: [186][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 6.450 (5.399)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.994\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.339\tL1 0.984\tG-Mean 0.829\n",
      " * Median: MSE 2.335\tL1 1.463\tG-Mean 1.407\n",
      " * Low: MSE 0.099\tL1 0.261\tG-Mean 0.245\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #186: Train loss [5.3688]; Val loss: MSE [1.9938], L1 [0.5969], G-Mean [0.2606]\n",
      "Epoch: [187][ 0/65]\tTime   0.56 (  0.56)\tData 0.5496 (0.5496)\tLoss (MSE) 4.147 (4.147)\n",
      "Epoch: [187][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 6.616 (4.787)\n",
      "Epoch: [187][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 4.342 (5.103)\n",
      "Epoch: [187][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 4.178 (5.348)\n",
      "Epoch: [187][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.384 (5.312)\n",
      "Epoch: [187][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 5.197 (5.356)\n",
      "Epoch: [187][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.654 (5.417)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.067 (2.067)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.960\tL1 0.599\tG-Mean 0.259\n",
      " * Many: MSE 2.377\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.177\tL1 1.410\tG-Mean 1.354\n",
      " * Low: MSE 0.048\tL1 0.196\tG-Mean 0.182\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #187: Train loss [5.3239]; Val loss: MSE [1.9598], L1 [0.5994], G-Mean [0.2587]\n",
      "Epoch: [188][ 0/65]\tTime   0.56 (  0.56)\tData 0.5565 (0.5565)\tLoss (MSE) 5.494 (5.494)\n",
      "Epoch: [188][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 5.285 (4.811)\n",
      "Epoch: [188][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 4.052 (5.070)\n",
      "Epoch: [188][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.986 (4.874)\n",
      "Epoch: [188][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.976 (5.263)\n",
      "Epoch: [188][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 6.364 (5.389)\n",
      "Epoch: [188][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.773 (5.440)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.183 (2.183)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.973\tL1 0.582\tG-Mean 0.245\n",
      " * Many: MSE 2.224\tL1 0.929\tG-Mean 0.775\n",
      " * Median: MSE 2.485\tL1 1.516\tG-Mean 1.464\n",
      " * Low: MSE 0.096\tL1 0.298\tG-Mean 0.290\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #188: Train loss [5.3879]; Val loss: MSE [1.9726], L1 [0.5824], G-Mean [0.2453]\n",
      "Epoch: [189][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 3.925 (3.925)\n",
      "Epoch: [189][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 7.335 (5.548)\n",
      "Epoch: [189][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 6.188 (5.350)\n",
      "Epoch: [189][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 3.853 (5.101)\n",
      "Epoch: [189][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.077 (5.229)\n",
      "Epoch: [189][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.411 (5.237)\n",
      "Epoch: [189][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.140 (5.149)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.098 (2.098)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 2.037\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.434\tL1 1.010\tG-Mean 0.850\n",
      " * Median: MSE 2.225\tL1 1.420\tG-Mean 1.347\n",
      " * Low: MSE 0.086\tL1 0.243\tG-Mean 0.224\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #189: Train loss [5.2459]; Val loss: MSE [2.0366], L1 [0.6044], G-Mean [0.2624]\n",
      "Epoch: [190][ 0/65]\tTime   0.55 (  0.55)\tData 0.5465 (0.5465)\tLoss (MSE) 3.311 (3.311)\n",
      "Epoch: [190][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0586)\tLoss (MSE) 3.077 (5.144)\n",
      "Epoch: [190][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 4.863 (5.128)\n",
      "Epoch: [190][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 4.678 (5.108)\n",
      "Epoch: [190][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 6.918 (5.179)\n",
      "Epoch: [190][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 6.891 (5.252)\n",
      "Epoch: [190][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 8.380 (5.229)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.082 (2.082)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 2.057\tL1 0.616\tG-Mean 0.263\n",
      " * Many: MSE 2.534\tL1 1.055\tG-Mean 0.899\n",
      " * Median: MSE 2.115\tL1 1.381\tG-Mean 1.300\n",
      " * Low: MSE 0.056\tL1 0.187\tG-Mean 0.170\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #190: Train loss [5.1689]; Val loss: MSE [2.0570], L1 [0.6156], G-Mean [0.2627]\n",
      "Epoch: [191][ 0/65]\tTime   0.59 (  0.59)\tData 0.5841 (0.5841)\tLoss (MSE) 4.030 (4.030)\n",
      "Epoch: [191][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0541)\tLoss (MSE) 8.816 (5.292)\n",
      "Epoch: [191][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 4.722 (5.244)\n",
      "Epoch: [191][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 4.462 (5.140)\n",
      "Epoch: [191][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.252 (5.157)\n",
      "Epoch: [191][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.274 (5.262)\n",
      "Epoch: [191][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.110 (5.239)\n",
      "Val: [0/9]\tTime  0.597 ( 0.597)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 2.037\tL1 0.594\tG-Mean 0.261\n",
      " * Many: MSE 2.383\tL1 0.977\tG-Mean 0.819\n",
      " * Median: MSE 2.317\tL1 1.453\tG-Mean 1.384\n",
      " * Low: MSE 0.078\tL1 0.257\tG-Mean 0.240\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #191: Train loss [5.1672]; Val loss: MSE [2.0371], L1 [0.5943], G-Mean [0.2609]\n",
      "Epoch: [192][ 0/65]\tTime   0.55 (  0.55)\tData 0.5468 (0.5468)\tLoss (MSE) 6.386 (6.386)\n",
      "Epoch: [192][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 2.767 (5.271)\n",
      "Epoch: [192][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.062 (5.173)\n",
      "Epoch: [192][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.104 (5.164)\n",
      "Epoch: [192][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.581 (5.257)\n",
      "Epoch: [192][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.059 (5.252)\n",
      "Epoch: [192][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.118 (5.197)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.147 (2.147)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 2.037\tL1 0.603\tG-Mean 0.261\n",
      " * Many: MSE 2.448\tL1 1.014\tG-Mean 0.855\n",
      " * Median: MSE 2.187\tL1 1.404\tG-Mean 1.310\n",
      " * Low: MSE 0.073\tL1 0.227\tG-Mean 0.215\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #192: Train loss [5.1709]; Val loss: MSE [2.0375], L1 [0.6031], G-Mean [0.2608]\n",
      "Epoch: [193][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.077 (5.077)\n",
      "Epoch: [193][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 4.692 (5.555)\n",
      "Epoch: [193][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.918 (5.084)\n",
      "Epoch: [193][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.961 (4.963)\n",
      "Epoch: [193][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.300 (5.369)\n",
      "Epoch: [193][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.536 (5.324)\n",
      "Epoch: [193][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.076 (5.271)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.186 (2.186)\tLoss (L1) 0.674 (0.674)\n",
      " * Overall: MSE 2.038\tL1 0.614\tG-Mean 0.262\n",
      " * Many: MSE 2.504\tL1 1.050\tG-Mean 0.895\n",
      " * Median: MSE 2.132\tL1 1.395\tG-Mean 1.340\n",
      " * Low: MSE 0.067\tL1 0.192\tG-Mean 0.177\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #193: Train loss [5.2776]; Val loss: MSE [2.0380], L1 [0.6137], G-Mean [0.2625]\n",
      "Epoch: [194][ 0/65]\tTime   0.56 (  0.56)\tData 0.5570 (0.5570)\tLoss (MSE) 2.809 (2.809)\n",
      "Epoch: [194][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.766 (4.540)\n",
      "Epoch: [194][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.366 (4.438)\n",
      "Epoch: [194][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.416 (4.342)\n",
      "Epoch: [194][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.674 (4.514)\n",
      "Epoch: [194][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 10.222 (4.626)\n",
      "Epoch: [194][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.143 (4.808)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 1.990 (1.990)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 2.030\tL1 0.612\tG-Mean 0.263\n",
      " * Many: MSE 2.508\tL1 1.053\tG-Mean 0.904\n",
      " * Median: MSE 2.134\tL1 1.392\tG-Mean 1.330\n",
      " * Low: MSE 0.042\tL1 0.177\tG-Mean 0.165\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #194: Train loss [5.0145]; Val loss: MSE [2.0303], L1 [0.6118], G-Mean [0.2631]\n",
      "Epoch: [195][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 3.292 (3.292)\n",
      "Epoch: [195][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0578)\tLoss (MSE) 5.213 (4.817)\n",
      "Epoch: [195][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 3.728 (5.187)\n",
      "Epoch: [195][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 5.946 (5.037)\n",
      "Epoch: [195][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.113 (4.960)\n",
      "Epoch: [195][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.537 (5.033)\n",
      "Epoch: [195][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.623 (5.062)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.635 (0.635)\n",
      " * Overall: MSE 1.924\tL1 0.586\tG-Mean 0.261\n",
      " * Many: MSE 2.246\tL1 0.973\tG-Mean 0.827\n",
      " * Median: MSE 2.348\tL1 1.470\tG-Mean 1.418\n",
      " * Low: MSE 0.077\tL1 0.249\tG-Mean 0.237\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #195: Train loss [5.0612]; Val loss: MSE [1.9237], L1 [0.5863], G-Mean [0.2613]\n",
      "Epoch: [196][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 6.339 (6.339)\n",
      "Epoch: [196][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0599)\tLoss (MSE) 9.038 (5.579)\n",
      "Epoch: [196][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 3.924 (5.099)\n",
      "Epoch: [196][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 3.552 (5.057)\n",
      "Epoch: [196][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 7.899 (5.048)\n",
      "Epoch: [196][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.986 (5.017)\n",
      "Epoch: [196][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 6.628 (5.101)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.013 (2.013)\tLoss (L1) 0.675 (0.675)\n",
      " * Overall: MSE 1.912\tL1 0.630\tG-Mean 0.295\n",
      " * Many: MSE 2.471\tL1 1.112\tG-Mean 0.975\n",
      " * Median: MSE 1.913\tL1 1.314\tG-Mean 1.255\n",
      " * Low: MSE 0.037\tL1 0.117\tG-Mean 0.099\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #196: Train loss [5.1063]; Val loss: MSE [1.9118], L1 [0.6301], G-Mean [0.2945]\n",
      "Epoch: [197][ 0/65]\tTime   0.56 (  0.56)\tData 0.5572 (0.5572)\tLoss (MSE) 4.348 (4.348)\n",
      "Epoch: [197][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0569)\tLoss (MSE) 7.289 (5.370)\n",
      "Epoch: [197][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 3.940 (5.022)\n",
      "Epoch: [197][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 2.728 (4.709)\n",
      "Epoch: [197][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 8.202 (4.828)\n",
      "Epoch: [197][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.113 (4.945)\n",
      "Epoch: [197][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.670 (5.156)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 1.987 (1.987)\tLoss (L1) 0.630 (0.630)\n",
      " * Overall: MSE 1.944\tL1 0.594\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.007\tG-Mean 0.860\n",
      " * Median: MSE 2.224\tL1 1.428\tG-Mean 1.373\n",
      " * Low: MSE 0.074\tL1 0.223\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #197: Train loss [5.1395]; Val loss: MSE [1.9440], L1 [0.5944], G-Mean [0.2606]\n",
      "Epoch: [198][ 0/65]\tTime   0.55 (  0.55)\tData 0.5460 (0.5460)\tLoss (MSE) 5.267 (5.267)\n",
      "Epoch: [198][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 3.851 (4.823)\n",
      "Epoch: [198][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 2.986 (4.490)\n",
      "Epoch: [198][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 8.667 (4.833)\n",
      "Epoch: [198][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.705 (4.945)\n",
      "Epoch: [198][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.483 (4.952)\n",
      "Epoch: [198][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 7.110 (5.039)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 2.021\tL1 0.617\tG-Mean 0.275\n",
      " * Many: MSE 2.530\tL1 1.073\tG-Mean 0.925\n",
      " * Median: MSE 2.035\tL1 1.358\tG-Mean 1.296\n",
      " * Low: MSE 0.071\tL1 0.170\tG-Mean 0.147\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #198: Train loss [5.1193]; Val loss: MSE [2.0215], L1 [0.6169], G-Mean [0.2748]\n",
      "Epoch: [199][ 0/65]\tTime   0.55 (  0.55)\tData 0.5436 (0.5436)\tLoss (MSE) 6.083 (6.083)\n",
      "Epoch: [199][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0506)\tLoss (MSE) 6.957 (5.067)\n",
      "Epoch: [199][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 9.774 (5.086)\n",
      "Epoch: [199][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.972 (5.153)\n",
      "Epoch: [199][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.519 (4.803)\n",
      "Epoch: [199][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 4.122 (4.723)\n",
      "Epoch: [199][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 4.285 (4.796)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.081 (2.081)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 2.031\tL1 0.602\tG-Mean 0.257\n",
      " * Many: MSE 2.441\tL1 1.016\tG-Mean 0.863\n",
      " * Median: MSE 2.222\tL1 1.426\tG-Mean 1.371\n",
      " * Low: MSE 0.083\tL1 0.223\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #199: Train loss [4.8840]; Val loss: MSE [2.0308], L1 [0.6016], G-Mean [0.2574]\n",
      "Epoch: [200][ 0/65]\tTime   0.62 (  0.62)\tData 0.5984 (0.5984)\tLoss (MSE) 2.834 (2.834)\n",
      "Epoch: [200][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0582)\tLoss (MSE) 6.216 (5.047)\n",
      "Epoch: [200][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.623 (5.356)\n",
      "Epoch: [200][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 4.096 (5.055)\n",
      "Epoch: [200][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.914 (4.958)\n",
      "Epoch: [200][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.451 (4.969)\n",
      "Epoch: [200][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.757 (5.016)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.638 (0.638)\n",
      " * Overall: MSE 1.943\tL1 0.587\tG-Mean 0.263\n",
      " * Many: MSE 2.244\tL1 0.958\tG-Mean 0.807\n",
      " * Median: MSE 2.357\tL1 1.474\tG-Mean 1.420\n",
      " * Low: MSE 0.114\tL1 0.273\tG-Mean 0.256\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #200: Train loss [4.9161]; Val loss: MSE [1.9431], L1 [0.5866], G-Mean [0.2631]\n",
      "Epoch: [201][ 0/65]\tTime   0.55 (  0.55)\tData 0.5410 (0.5410)\tLoss (MSE) 2.997 (2.997)\n",
      "Epoch: [201][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 5.823 (5.331)\n",
      "Epoch: [201][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 5.526 (4.946)\n",
      "Epoch: [201][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.432 (5.080)\n",
      "Epoch: [201][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.876 (5.023)\n",
      "Epoch: [201][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.496 (5.135)\n",
      "Epoch: [201][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.020 (5.034)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.873\tL1 0.593\tG-Mean 0.258\n",
      " * Many: MSE 2.283\tL1 1.023\tG-Mean 0.883\n",
      " * Median: MSE 2.109\tL1 1.388\tG-Mean 1.332\n",
      " * Low: MSE 0.101\tL1 0.210\tG-Mean 0.184\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #201: Train loss [5.0683]; Val loss: MSE [1.8735], L1 [0.5931], G-Mean [0.2575]\n",
      "Epoch: [202][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 4.913 (4.913)\n",
      "Epoch: [202][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0571)\tLoss (MSE) 3.285 (4.951)\n",
      "Epoch: [202][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 5.275 (4.906)\n",
      "Epoch: [202][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 3.432 (4.986)\n",
      "Epoch: [202][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.899 (4.922)\n",
      "Epoch: [202][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 5.433 (4.916)\n",
      "Epoch: [202][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 9.455 (5.073)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.187 (2.187)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.999\tL1 0.601\tG-Mean 0.257\n",
      " * Many: MSE 2.418\tL1 1.022\tG-Mean 0.872\n",
      " * Median: MSE 2.200\tL1 1.418\tG-Mean 1.363\n",
      " * Low: MSE 0.079\tL1 0.218\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #202: Train loss [5.0467]; Val loss: MSE [1.9988], L1 [0.6007], G-Mean [0.2571]\n",
      "Epoch: [203][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 6.430 (6.430)\n",
      "Epoch: [203][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 4.803 (5.204)\n",
      "Epoch: [203][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 10.726 (5.945)\n",
      "Epoch: [203][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.349 (5.397)\n",
      "Epoch: [203][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 5.073 (5.327)\n",
      "Epoch: [203][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 6.109 (5.108)\n",
      "Epoch: [203][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.254 (4.943)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.926\tL1 0.609\tG-Mean 0.269\n",
      " * Many: MSE 2.387\tL1 1.056\tG-Mean 0.914\n",
      " * Median: MSE 2.098\tL1 1.383\tG-Mean 1.328\n",
      " * Low: MSE 0.056\tL1 0.173\tG-Mean 0.154\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #203: Train loss [5.0513]; Val loss: MSE [1.9259], L1 [0.6089], G-Mean [0.2689]\n",
      "Epoch: [204][ 0/65]\tTime   0.55 (  0.55)\tData 0.5474 (0.5474)\tLoss (MSE) 8.459 (8.459)\n",
      "Epoch: [204][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 6.470 (6.161)\n",
      "Epoch: [204][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 6.297 (5.291)\n",
      "Epoch: [204][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 4.634 (5.226)\n",
      "Epoch: [204][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.645 (5.261)\n",
      "Epoch: [204][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 5.072 (5.389)\n",
      "Epoch: [204][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.275 (5.294)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.893\tL1 0.614\tG-Mean 0.286\n",
      " * Many: MSE 2.383\tL1 1.078\tG-Mean 0.941\n",
      " * Median: MSE 2.023\tL1 1.355\tG-Mean 1.298\n",
      " * Low: MSE 0.026\tL1 0.139\tG-Mean 0.128\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #204: Train loss [5.2308]; Val loss: MSE [1.8934], L1 [0.6143], G-Mean [0.2856]\n",
      "Epoch: [205][ 0/65]\tTime   0.55 (  0.55)\tData 0.5433 (0.5433)\tLoss (MSE) 7.648 (7.648)\n",
      "Epoch: [205][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 4.795 (5.202)\n",
      "Epoch: [205][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 4.069 (4.781)\n",
      "Epoch: [205][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 9.751 (4.933)\n",
      "Epoch: [205][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.561 (5.045)\n",
      "Epoch: [205][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.297 (5.042)\n",
      "Epoch: [205][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.935 (5.105)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.025 (2.025)\tLoss (L1) 0.680 (0.680)\n",
      " * Overall: MSE 1.872\tL1 0.630\tG-Mean 0.303\n",
      " * Many: MSE 2.424\tL1 1.117\tG-Mean 0.985\n",
      " * Median: MSE 1.881\tL1 1.296\tG-Mean 1.211\n",
      " * Low: MSE 0.041\tL1 0.103\tG-Mean 0.080\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #205: Train loss [5.0960]; Val loss: MSE [1.8715], L1 [0.6301], G-Mean [0.3035]\n",
      "Epoch: [206][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 3.391 (3.391)\n",
      "Epoch: [206][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 5.639 (4.044)\n",
      "Epoch: [206][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 2.531 (4.483)\n",
      "Epoch: [206][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.367 (4.659)\n",
      "Epoch: [206][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.411 (4.584)\n",
      "Epoch: [206][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 2.808 (4.719)\n",
      "Epoch: [206][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.589 (4.835)\n",
      "Val: [0/9]\tTime  0.662 ( 0.662)\tLoss (MSE) 2.161 (2.161)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.985\tL1 0.593\tG-Mean 0.261\n",
      " * Many: MSE 2.314\tL1 0.970\tG-Mean 0.813\n",
      " * Median: MSE 2.332\tL1 1.457\tG-Mean 1.380\n",
      " * Low: MSE 0.089\tL1 0.269\tG-Mean 0.256\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #206: Train loss [4.9075]; Val loss: MSE [1.9846], L1 [0.5933], G-Mean [0.2613]\n",
      "Epoch: [207][ 0/65]\tTime   0.66 (  0.66)\tData 0.6497 (0.6497)\tLoss (MSE) 3.333 (3.333)\n",
      "Epoch: [207][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0605)\tLoss (MSE) 9.290 (4.879)\n",
      "Epoch: [207][20/65]\tTime   0.01 (  0.04)\tData 0.0000 (0.0317)\tLoss (MSE) 5.643 (4.975)\n",
      "Epoch: [207][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0215)\tLoss (MSE) 3.751 (4.973)\n",
      "Epoch: [207][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 2.532 (4.896)\n",
      "Epoch: [207][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 7.226 (4.992)\n",
      "Epoch: [207][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 4.971 (4.912)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.149 (2.149)\tLoss (L1) 0.664 (0.664)\n",
      " * Overall: MSE 1.964\tL1 0.596\tG-Mean 0.259\n",
      " * Many: MSE 2.343\tL1 1.004\tG-Mean 0.853\n",
      " * Median: MSE 2.244\tL1 1.437\tG-Mean 1.386\n",
      " * Low: MSE 0.081\tL1 0.228\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #207: Train loss [4.9800]; Val loss: MSE [1.9638], L1 [0.5964], G-Mean [0.2590]\n",
      "Epoch: [208][ 0/65]\tTime   0.62 (  0.62)\tData 0.6019 (0.6019)\tLoss (MSE) 3.624 (3.624)\n",
      "Epoch: [208][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0561)\tLoss (MSE) 5.636 (4.680)\n",
      "Epoch: [208][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0294)\tLoss (MSE) 3.309 (4.916)\n",
      "Epoch: [208][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 3.873 (4.644)\n",
      "Epoch: [208][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.798 (4.892)\n",
      "Epoch: [208][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 6.686 (5.032)\n",
      "Epoch: [208][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.498 (4.918)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.082 (2.082)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.971\tL1 0.614\tG-Mean 0.271\n",
      " * Many: MSE 2.449\tL1 1.063\tG-Mean 0.916\n",
      " * Median: MSE 2.073\tL1 1.376\tG-Mean 1.322\n",
      " * Low: MSE 0.049\tL1 0.167\tG-Mean 0.149\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #208: Train loss [4.8787]; Val loss: MSE [1.9712], L1 [0.6144], G-Mean [0.2713]\n",
      "Epoch: [209][ 0/65]\tTime   0.57 (  0.57)\tData 0.5586 (0.5586)\tLoss (MSE) 9.318 (9.318)\n",
      "Epoch: [209][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0530)\tLoss (MSE) 2.435 (4.573)\n",
      "Epoch: [209][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 7.049 (5.268)\n",
      "Epoch: [209][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.251 (5.108)\n",
      "Epoch: [209][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.725 (5.098)\n",
      "Epoch: [209][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 7.512 (5.058)\n",
      "Epoch: [209][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.027 (4.897)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.960\tL1 0.590\tG-Mean 0.263\n",
      " * Many: MSE 2.304\tL1 0.981\tG-Mean 0.830\n",
      " * Median: MSE 2.288\tL1 1.451\tG-Mean 1.399\n",
      " * Low: MSE 0.077\tL1 0.246\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #209: Train loss [4.9804]; Val loss: MSE [1.9600], L1 [0.5905], G-Mean [0.2626]\n",
      "Epoch: [210][ 0/65]\tTime   0.57 (  0.57)\tData 0.5595 (0.5595)\tLoss (MSE) 6.863 (6.863)\n",
      "Epoch: [210][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0609)\tLoss (MSE) 6.484 (4.921)\n",
      "Epoch: [210][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0319)\tLoss (MSE) 4.996 (4.487)\n",
      "Epoch: [210][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0216)\tLoss (MSE) 6.373 (4.542)\n",
      "Epoch: [210][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 5.022 (4.650)\n",
      "Epoch: [210][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 5.774 (4.696)\n",
      "Epoch: [210][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.419 (4.732)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.174 (2.174)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 2.084\tL1 0.605\tG-Mean 0.265\n",
      " * Many: MSE 2.471\tL1 0.997\tG-Mean 0.832\n",
      " * Median: MSE 2.273\tL1 1.445\tG-Mean 1.392\n",
      " * Low: MSE 0.099\tL1 0.255\tG-Mean 0.240\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #210: Train loss [4.8092]; Val loss: MSE [2.0841], L1 [0.6051], G-Mean [0.2653]\n",
      "Epoch: [211][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 5.553 (5.553)\n",
      "Epoch: [211][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 3.986 (4.790)\n",
      "Epoch: [211][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 6.362 (4.488)\n",
      "Epoch: [211][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 5.639 (4.622)\n",
      "Epoch: [211][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 5.589 (4.734)\n",
      "Epoch: [211][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 3.038 (4.787)\n",
      "Epoch: [211][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.685 (4.790)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.913\tL1 0.594\tG-Mean 0.258\n",
      " * Many: MSE 2.295\tL1 1.010\tG-Mean 0.866\n",
      " * Median: MSE 2.213\tL1 1.422\tG-Mean 1.365\n",
      " * Low: MSE 0.077\tL1 0.216\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #211: Train loss [4.8560]; Val loss: MSE [1.9127], L1 [0.5940], G-Mean [0.2582]\n",
      "Epoch: [212][ 0/65]\tTime   0.55 (  0.55)\tData 0.5421 (0.5421)\tLoss (MSE) 3.154 (3.154)\n",
      "Epoch: [212][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 7.946 (5.211)\n",
      "Epoch: [212][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 4.080 (5.042)\n",
      "Epoch: [212][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 2.968 (4.664)\n",
      "Epoch: [212][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.323 (4.661)\n",
      "Epoch: [212][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 2.947 (4.728)\n",
      "Epoch: [212][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.571 (4.746)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.128 (2.128)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 2.143\tL1 0.606\tG-Mean 0.266\n",
      " * Many: MSE 2.547\tL1 1.001\tG-Mean 0.837\n",
      " * Median: MSE 2.268\tL1 1.442\tG-Mean 1.388\n",
      " * Low: MSE 0.114\tL1 0.248\tG-Mean 0.229\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #212: Train loss [4.7516]; Val loss: MSE [2.1425], L1 [0.6055], G-Mean [0.2656]\n",
      "Epoch: [213][ 0/65]\tTime   0.55 (  0.55)\tData 0.5430 (0.5430)\tLoss (MSE) 3.448 (3.448)\n",
      "Epoch: [213][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0504)\tLoss (MSE) 8.942 (5.181)\n",
      "Epoch: [213][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0264)\tLoss (MSE) 3.951 (4.692)\n",
      "Epoch: [213][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 6.408 (4.715)\n",
      "Epoch: [213][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 5.994 (4.846)\n",
      "Epoch: [213][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 4.934 (4.932)\n",
      "Epoch: [213][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 3.890 (4.908)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.061 (2.061)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 2.066\tL1 0.627\tG-Mean 0.282\n",
      " * Many: MSE 2.614\tL1 1.091\tG-Mean 0.941\n",
      " * Median: MSE 1.984\tL1 1.342\tG-Mean 1.285\n",
      " * Low: MSE 0.074\tL1 0.153\tG-Mean 0.129\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #213: Train loss [4.8903]; Val loss: MSE [2.0662], L1 [0.6269], G-Mean [0.2821]\n",
      "Epoch: [214][ 0/65]\tTime   0.61 (  0.61)\tData 0.5954 (0.5954)\tLoss (MSE) 5.394 (5.394)\n",
      "Epoch: [214][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0581)\tLoss (MSE) 8.144 (5.015)\n",
      "Epoch: [214][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.410 (4.628)\n",
      "Epoch: [214][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 7.179 (4.716)\n",
      "Epoch: [214][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.884 (4.663)\n",
      "Epoch: [214][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.326 (4.595)\n",
      "Epoch: [214][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.355 (4.558)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.005 (2.005)\tLoss (L1) 0.635 (0.635)\n",
      " * Overall: MSE 1.988\tL1 0.602\tG-Mean 0.259\n",
      " * Many: MSE 2.430\tL1 1.034\tG-Mean 0.885\n",
      " * Median: MSE 2.130\tL1 1.392\tG-Mean 1.328\n",
      " * Low: MSE 0.080\tL1 0.196\tG-Mean 0.177\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #214: Train loss [4.7277]; Val loss: MSE [1.9881], L1 [0.6023], G-Mean [0.2592]\n",
      "Epoch: [215][ 0/65]\tTime   0.55 (  0.55)\tData 0.5438 (0.5438)\tLoss (MSE) 3.368 (3.368)\n",
      "Epoch: [215][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 5.882 (4.051)\n",
      "Epoch: [215][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 7.160 (4.163)\n",
      "Epoch: [215][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 7.146 (4.575)\n",
      "Epoch: [215][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 7.434 (4.680)\n",
      "Epoch: [215][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.074 (4.667)\n",
      "Epoch: [215][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.332 (4.753)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 2.006\tL1 0.606\tG-Mean 0.262\n",
      " * Many: MSE 2.446\tL1 1.036\tG-Mean 0.885\n",
      " * Median: MSE 2.148\tL1 1.402\tG-Mean 1.348\n",
      " * Low: MSE 0.064\tL1 0.199\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #215: Train loss [4.6597]; Val loss: MSE [2.0057], L1 [0.6063], G-Mean [0.2618]\n",
      "Epoch: [216][ 0/65]\tTime   0.60 (  0.60)\tData 0.5814 (0.5814)\tLoss (MSE) 5.310 (5.310)\n",
      "Epoch: [216][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 5.967 (5.018)\n",
      "Epoch: [216][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 6.526 (4.680)\n",
      "Epoch: [216][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 5.226 (4.509)\n",
      "Epoch: [216][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.896 (4.420)\n",
      "Epoch: [216][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.684 (4.642)\n",
      "Epoch: [216][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.203 (4.712)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.097 (2.097)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.950\tL1 0.603\tG-Mean 0.260\n",
      " * Many: MSE 2.389\tL1 1.037\tG-Mean 0.890\n",
      " * Median: MSE 2.149\tL1 1.401\tG-Mean 1.346\n",
      " * Low: MSE 0.051\tL1 0.188\tG-Mean 0.175\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #216: Train loss [4.7802]; Val loss: MSE [1.9497], L1 [0.6028], G-Mean [0.2597]\n",
      "Epoch: [217][ 0/65]\tTime   0.55 (  0.55)\tData 0.5475 (0.5475)\tLoss (MSE) 4.770 (4.770)\n",
      "Epoch: [217][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0531)\tLoss (MSE) 3.133 (4.658)\n",
      "Epoch: [217][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 6.837 (5.278)\n",
      "Epoch: [217][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.058 (5.263)\n",
      "Epoch: [217][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 7.013 (5.178)\n",
      "Epoch: [217][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 2.808 (4.998)\n",
      "Epoch: [217][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.702 (4.877)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.159 (2.159)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 2.068\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.426\tL1 0.979\tG-Mean 0.817\n",
      " * Median: MSE 2.338\tL1 1.467\tG-Mean 1.415\n",
      " * Low: MSE 0.089\tL1 0.261\tG-Mean 0.248\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #217: Train loss [4.8287]; Val loss: MSE [2.0682], L1 [0.5967], G-Mean [0.2604]\n",
      "Epoch: [218][ 0/65]\tTime   0.62 (  0.62)\tData 0.6013 (0.6013)\tLoss (MSE) 2.805 (2.805)\n",
      "Epoch: [218][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 4.067 (4.309)\n",
      "Epoch: [218][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 3.466 (4.388)\n",
      "Epoch: [218][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.897 (4.700)\n",
      "Epoch: [218][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.477 (4.666)\n",
      "Epoch: [218][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.161 (4.710)\n",
      "Epoch: [218][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.267 (4.856)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.089 (2.089)\tLoss (L1) 0.637 (0.637)\n",
      " * Overall: MSE 2.033\tL1 0.592\tG-Mean 0.253\n",
      " * Many: MSE 2.336\tL1 0.951\tG-Mean 0.790\n",
      " * Median: MSE 2.405\tL1 1.491\tG-Mean 1.438\n",
      " * Low: MSE 0.109\tL1 0.288\tG-Mean 0.276\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #218: Train loss [4.9040]; Val loss: MSE [2.0330], L1 [0.5919], G-Mean [0.2532]\n",
      "Epoch: [219][ 0/65]\tTime   0.57 (  0.57)\tData 0.5614 (0.5614)\tLoss (MSE) 3.700 (3.700)\n",
      "Epoch: [219][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 6.813 (4.931)\n",
      "Epoch: [219][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.767 (4.761)\n",
      "Epoch: [219][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 5.203 (4.901)\n",
      "Epoch: [219][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.679 (4.871)\n",
      "Epoch: [219][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 4.849 (4.752)\n",
      "Epoch: [219][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.200 (4.860)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.071 (2.071)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 2.014\tL1 0.596\tG-Mean 0.264\n",
      " * Many: MSE 2.383\tL1 0.988\tG-Mean 0.831\n",
      " * Median: MSE 2.292\tL1 1.451\tG-Mean 1.396\n",
      " * Low: MSE 0.064\tL1 0.243\tG-Mean 0.237\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #219: Train loss [4.9049]; Val loss: MSE [2.0140], L1 [0.5964], G-Mean [0.2637]\n",
      "Epoch: [220][ 0/65]\tTime   0.55 (  0.55)\tData 0.5491 (0.5491)\tLoss (MSE) 4.487 (4.487)\n",
      "Epoch: [220][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 4.616 (4.554)\n",
      "Epoch: [220][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.297 (4.433)\n",
      "Epoch: [220][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.213 (4.396)\n",
      "Epoch: [220][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 7.785 (4.704)\n",
      "Epoch: [220][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 5.761 (4.637)\n",
      "Epoch: [220][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 9.870 (4.738)\n",
      "Val: [0/9]\tTime  0.572 ( 0.572)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.973\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.385\tL1 1.019\tG-Mean 0.870\n",
      " * Median: MSE 2.184\tL1 1.414\tG-Mean 1.356\n",
      " * Low: MSE 0.048\tL1 0.204\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #220: Train loss [4.7715]; Val loss: MSE [1.9729], L1 [0.5998], G-Mean [0.2598]\n",
      "Epoch: [221][ 0/65]\tTime   0.68 (  0.68)\tData 0.6717 (0.6717)\tLoss (MSE) 6.554 (6.554)\n",
      "Epoch: [221][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0651)\tLoss (MSE) 4.567 (4.673)\n",
      "Epoch: [221][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0341)\tLoss (MSE) 5.387 (4.722)\n",
      "Epoch: [221][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0231)\tLoss (MSE) 5.219 (4.760)\n",
      "Epoch: [221][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0175)\tLoss (MSE) 8.630 (5.011)\n",
      "Epoch: [221][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 4.316 (4.947)\n",
      "Epoch: [221][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.604 (4.887)\n",
      "Val: [0/9]\tTime  0.584 ( 0.584)\tLoss (MSE) 2.039 (2.039)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.987\tL1 0.591\tG-Mean 0.263\n",
      " * Many: MSE 2.335\tL1 0.978\tG-Mean 0.825\n",
      " * Median: MSE 2.326\tL1 1.459\tG-Mean 1.393\n",
      " * Low: MSE 0.064\tL1 0.245\tG-Mean 0.237\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #221: Train loss [4.9198]; Val loss: MSE [1.9874], L1 [0.5913], G-Mean [0.2630]\n",
      "Epoch: [222][ 0/65]\tTime   0.56 (  0.56)\tData 0.5490 (0.5490)\tLoss (MSE) 7.981 (7.981)\n",
      "Epoch: [222][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 3.231 (4.808)\n",
      "Epoch: [222][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.197 (4.734)\n",
      "Epoch: [222][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 10.035 (4.915)\n",
      "Epoch: [222][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.213 (4.925)\n",
      "Epoch: [222][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.404 (4.700)\n",
      "Epoch: [222][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 7.685 (4.684)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.004 (2.004)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 2.029\tL1 0.612\tG-Mean 0.264\n",
      " * Many: MSE 2.501\tL1 1.051\tG-Mean 0.898\n",
      " * Median: MSE 2.149\tL1 1.399\tG-Mean 1.339\n",
      " * Low: MSE 0.054\tL1 0.189\tG-Mean 0.175\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #222: Train loss [4.6796]; Val loss: MSE [2.0292], L1 [0.6124], G-Mean [0.2636]\n",
      "Epoch: [223][ 0/65]\tTime   0.55 (  0.55)\tData 0.5472 (0.5472)\tLoss (MSE) 6.409 (6.409)\n",
      "Epoch: [223][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0512)\tLoss (MSE) 4.036 (4.315)\n",
      "Epoch: [223][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.794 (4.733)\n",
      "Epoch: [223][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.997 (4.877)\n",
      "Epoch: [223][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 7.316 (5.156)\n",
      "Epoch: [223][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.028 (5.271)\n",
      "Epoch: [223][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.709 (4.996)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 1.994 (1.994)\tLoss (L1) 0.634 (0.634)\n",
      " * Overall: MSE 1.887\tL1 0.594\tG-Mean 0.258\n",
      " * Many: MSE 2.276\tL1 1.016\tG-Mean 0.875\n",
      " * Median: MSE 2.195\tL1 1.416\tG-Mean 1.359\n",
      " * Low: MSE 0.058\tL1 0.202\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #223: Train loss [4.9565]; Val loss: MSE [1.8872], L1 [0.5937], G-Mean [0.2583]\n",
      "Epoch: [224][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 3.641 (3.641)\n",
      "Epoch: [224][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 5.120 (3.737)\n",
      "Epoch: [224][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.254 (4.245)\n",
      "Epoch: [224][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 4.527 (4.402)\n",
      "Epoch: [224][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 9.785 (4.510)\n",
      "Epoch: [224][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.703 (4.561)\n",
      "Epoch: [224][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 6.956 (4.740)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.957\tL1 0.600\tG-Mean 0.258\n",
      " * Many: MSE 2.356\tL1 1.016\tG-Mean 0.866\n",
      " * Median: MSE 2.209\tL1 1.418\tG-Mean 1.338\n",
      " * Low: MSE 0.076\tL1 0.219\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #224: Train loss [4.7987]; Val loss: MSE [1.9573], L1 [0.5996], G-Mean [0.2581]\n",
      "Epoch: [225][ 0/65]\tTime   0.63 (  0.63)\tData 0.6193 (0.6193)\tLoss (MSE) 4.689 (4.689)\n",
      "Epoch: [225][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 4.968 (4.080)\n",
      "Epoch: [225][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 3.925 (4.103)\n",
      "Epoch: [225][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 4.934 (4.737)\n",
      "Epoch: [225][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.506 (4.735)\n",
      "Epoch: [225][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.165 (4.780)\n",
      "Epoch: [225][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.447 (4.737)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.226 (2.226)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 2.106\tL1 0.611\tG-Mean 0.260\n",
      " * Many: MSE 2.540\tL1 1.025\tG-Mean 0.862\n",
      " * Median: MSE 2.224\tL1 1.427\tG-Mean 1.371\n",
      " * Low: MSE 0.094\tL1 0.231\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #225: Train loss [4.7436]; Val loss: MSE [2.1057], L1 [0.6108], G-Mean [0.2603]\n",
      "Epoch: [226][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 5.965 (5.965)\n",
      "Epoch: [226][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 3.755 (4.738)\n",
      "Epoch: [226][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 3.826 (4.813)\n",
      "Epoch: [226][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.532 (4.668)\n",
      "Epoch: [226][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.655 (4.897)\n",
      "Epoch: [226][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.115 (4.856)\n",
      "Epoch: [226][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.257 (4.805)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.134 (2.134)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 2.015\tL1 0.592\tG-Mean 0.247\n",
      " * Many: MSE 2.291\tL1 0.940\tG-Mean 0.778\n",
      " * Median: MSE 2.478\tL1 1.514\tG-Mean 1.463\n",
      " * Low: MSE 0.092\tL1 0.297\tG-Mean 0.292\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #226: Train loss [4.8137]; Val loss: MSE [2.0151], L1 [0.5916], G-Mean [0.2466]\n",
      "Epoch: [227][ 0/65]\tTime   0.56 (  0.56)\tData 0.5567 (0.5567)\tLoss (MSE) 3.926 (3.926)\n",
      "Epoch: [227][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 5.798 (4.492)\n",
      "Epoch: [227][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0306)\tLoss (MSE) 3.612 (4.287)\n",
      "Epoch: [227][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 3.874 (4.537)\n",
      "Epoch: [227][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.044 (4.547)\n",
      "Epoch: [227][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.169 (4.567)\n",
      "Epoch: [227][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.924 (4.600)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.636 (0.636)\n",
      " * Overall: MSE 2.005\tL1 0.592\tG-Mean 0.254\n",
      " * Many: MSE 2.300\tL1 0.950\tG-Mean 0.790\n",
      " * Median: MSE 2.416\tL1 1.496\tG-Mean 1.446\n",
      " * Low: MSE 0.115\tL1 0.291\tG-Mean 0.276\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #227: Train loss [4.7001]; Val loss: MSE [2.0045], L1 [0.5922], G-Mean [0.2537]\n",
      "Epoch: [228][ 0/65]\tTime   0.56 (  0.56)\tData 0.5536 (0.5536)\tLoss (MSE) 6.133 (6.133)\n",
      "Epoch: [228][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 2.176 (4.881)\n",
      "Epoch: [228][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.485 (5.020)\n",
      "Epoch: [228][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.196 (5.161)\n",
      "Epoch: [228][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.211 (4.914)\n",
      "Epoch: [228][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.628 (5.016)\n",
      "Epoch: [228][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.743 (4.929)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.134 (2.134)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.989\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.329\tL1 0.977\tG-Mean 0.820\n",
      " * Median: MSE 2.320\tL1 1.457\tG-Mean 1.397\n",
      " * Low: MSE 0.098\tL1 0.267\tG-Mean 0.252\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #228: Train loss [4.9354]; Val loss: MSE [1.9890], L1 [0.5947], G-Mean [0.2641]\n",
      "Epoch: [229][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 6.720 (6.720)\n",
      "Epoch: [229][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0512)\tLoss (MSE) 7.131 (5.620)\n",
      "Epoch: [229][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.852 (5.061)\n",
      "Epoch: [229][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.998 (5.010)\n",
      "Epoch: [229][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.474 (4.786)\n",
      "Epoch: [229][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.482 (4.781)\n",
      "Epoch: [229][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.231 (4.788)\n",
      "Val: [0/9]\tTime  0.560 ( 0.560)\tLoss (MSE) 2.069 (2.069)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.939\tL1 0.593\tG-Mean 0.265\n",
      " * Many: MSE 2.268\tL1 0.974\tG-Mean 0.821\n",
      " * Median: MSE 2.339\tL1 1.469\tG-Mean 1.417\n",
      " * Low: MSE 0.083\tL1 0.260\tG-Mean 0.243\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #229: Train loss [4.7723]; Val loss: MSE [1.9390], L1 [0.5926], G-Mean [0.2651]\n",
      "Epoch: [230][ 0/65]\tTime   0.64 (  0.64)\tData 0.6344 (0.6344)\tLoss (MSE) 4.485 (4.485)\n",
      "Epoch: [230][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0587)\tLoss (MSE) 5.921 (5.337)\n",
      "Epoch: [230][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0308)\tLoss (MSE) 2.815 (5.159)\n",
      "Epoch: [230][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 5.493 (4.997)\n",
      "Epoch: [230][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 4.878 (5.117)\n",
      "Epoch: [230][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.814 (4.967)\n",
      "Epoch: [230][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.986 (4.969)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.031 (2.031)\tLoss (L1) 0.663 (0.663)\n",
      " * Overall: MSE 1.900\tL1 0.621\tG-Mean 0.288\n",
      " * Many: MSE 2.416\tL1 1.090\tG-Mean 0.950\n",
      " * Median: MSE 1.975\tL1 1.336\tG-Mean 1.273\n",
      " * Low: MSE 0.047\tL1 0.135\tG-Mean 0.117\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #230: Train loss [4.9335]; Val loss: MSE [1.9004], L1 [0.6206], G-Mean [0.2884]\n",
      "Epoch: [231][ 0/65]\tTime   0.56 (  0.56)\tData 0.5546 (0.5546)\tLoss (MSE) 4.477 (4.477)\n",
      "Epoch: [231][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0574)\tLoss (MSE) 3.323 (5.012)\n",
      "Epoch: [231][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 2.476 (5.135)\n",
      "Epoch: [231][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.629 (4.936)\n",
      "Epoch: [231][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.065 (4.743)\n",
      "Epoch: [231][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.767 (4.751)\n",
      "Epoch: [231][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.956 (4.742)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.035 (2.035)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.935\tL1 0.595\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.006\tG-Mean 0.857\n",
      " * Median: MSE 2.205\tL1 1.415\tG-Mean 1.332\n",
      " * Low: MSE 0.063\tL1 0.224\tG-Mean 0.213\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #231: Train loss [4.8479]; Val loss: MSE [1.9349], L1 [0.5951], G-Mean [0.2607]\n",
      "Epoch: [232][ 0/65]\tTime   0.60 (  0.60)\tData 0.5888 (0.5888)\tLoss (MSE) 4.947 (4.947)\n",
      "Epoch: [232][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 3.790 (4.694)\n",
      "Epoch: [232][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 5.460 (4.798)\n",
      "Epoch: [232][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.160 (4.939)\n",
      "Epoch: [232][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.019 (4.764)\n",
      "Epoch: [232][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.605 (4.854)\n",
      "Epoch: [232][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.136 (4.990)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.063 (2.063)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.921\tL1 0.591\tG-Mean 0.261\n",
      " * Many: MSE 2.259\tL1 0.982\tG-Mean 0.834\n",
      " * Median: MSE 2.316\tL1 1.458\tG-Mean 1.403\n",
      " * Low: MSE 0.074\tL1 0.245\tG-Mean 0.236\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #232: Train loss [4.9501]; Val loss: MSE [1.9213], L1 [0.5907], G-Mean [0.2610]\n",
      "Epoch: [233][ 0/65]\tTime   0.55 (  0.55)\tData 0.5443 (0.5443)\tLoss (MSE) 3.133 (3.133)\n",
      "Epoch: [233][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0560)\tLoss (MSE) 3.236 (3.950)\n",
      "Epoch: [233][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 3.770 (4.120)\n",
      "Epoch: [233][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 5.439 (4.343)\n",
      "Epoch: [233][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 7.815 (4.526)\n",
      "Epoch: [233][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.375 (4.765)\n",
      "Epoch: [233][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.103 (4.823)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.933\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.334\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.251\tL1 1.430\tG-Mean 1.372\n",
      " * Low: MSE 0.081\tL1 0.214\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #233: Train loss [4.8020]; Val loss: MSE [1.9326], L1 [0.5984], G-Mean [0.2613]\n",
      "Epoch: [234][ 0/65]\tTime   0.60 (  0.60)\tData 0.5854 (0.5854)\tLoss (MSE) 5.647 (5.647)\n",
      "Epoch: [234][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 4.376 (4.606)\n",
      "Epoch: [234][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 4.284 (4.373)\n",
      "Epoch: [234][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.856 (4.790)\n",
      "Epoch: [234][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.481 (4.703)\n",
      "Epoch: [234][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.995 (4.672)\n",
      "Epoch: [234][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.897 (4.675)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.086 (2.086)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.949\tL1 0.612\tG-Mean 0.268\n",
      " * Many: MSE 2.407\tL1 1.054\tG-Mean 0.907\n",
      " * Median: MSE 2.127\tL1 1.391\tG-Mean 1.333\n",
      " * Low: MSE 0.120\tL1 0.191\tG-Mean 0.163\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #234: Train loss [4.6670]; Val loss: MSE [1.9486], L1 [0.6117], G-Mean [0.2681]\n",
      "Epoch: [235][ 0/65]\tTime   0.62 (  0.62)\tData 0.6086 (0.6086)\tLoss (MSE) 4.321 (4.321)\n",
      "Epoch: [235][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 6.224 (3.763)\n",
      "Epoch: [235][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 6.626 (3.936)\n",
      "Epoch: [235][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 1.848 (4.247)\n",
      "Epoch: [235][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.469 (4.317)\n",
      "Epoch: [235][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.862 (4.526)\n",
      "Epoch: [235][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.858 (4.602)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.025 (2.025)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.981\tL1 0.627\tG-Mean 0.289\n",
      " * Many: MSE 2.513\tL1 1.096\tG-Mean 0.952\n",
      " * Median: MSE 1.995\tL1 1.346\tG-Mean 1.289\n",
      " * Low: MSE 0.093\tL1 0.148\tG-Mean 0.120\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #235: Train loss [4.6395]; Val loss: MSE [1.9810], L1 [0.6273], G-Mean [0.2895]\n",
      "Epoch: [236][ 0/65]\tTime   0.55 (  0.55)\tData 0.5489 (0.5489)\tLoss (MSE) 2.878 (2.878)\n",
      "Epoch: [236][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 4.709 (4.013)\n",
      "Epoch: [236][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 8.657 (4.504)\n",
      "Epoch: [236][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.186 (4.482)\n",
      "Epoch: [236][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.827 (4.752)\n",
      "Epoch: [236][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.240 (4.629)\n",
      "Epoch: [236][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.368 (4.593)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.090 (2.090)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 2.046\tL1 0.614\tG-Mean 0.261\n",
      " * Many: MSE 2.484\tL1 1.038\tG-Mean 0.882\n",
      " * Median: MSE 2.198\tL1 1.418\tG-Mean 1.363\n",
      " * Low: MSE 0.136\tL1 0.221\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #236: Train loss [4.5867]; Val loss: MSE [2.0462], L1 [0.6140], G-Mean [0.2612]\n",
      "Epoch: [237][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 2.691 (2.691)\n",
      "Epoch: [237][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 4.579 (4.031)\n",
      "Epoch: [237][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 6.192 (4.583)\n",
      "Epoch: [237][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 5.381 (4.550)\n",
      "Epoch: [237][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 2.895 (4.522)\n",
      "Epoch: [237][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.704 (4.796)\n",
      "Epoch: [237][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.180 (4.748)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 2.072\tL1 0.601\tG-Mean 0.255\n",
      " * Many: MSE 2.397\tL1 0.964\tG-Mean 0.798\n",
      " * Median: MSE 2.417\tL1 1.489\tG-Mean 1.425\n",
      " * Low: MSE 0.145\tL1 0.294\tG-Mean 0.273\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #237: Train loss [4.7303]; Val loss: MSE [2.0724], L1 [0.6006], G-Mean [0.2553]\n",
      "Epoch: [238][ 0/65]\tTime   0.56 (  0.56)\tData 0.5594 (0.5594)\tLoss (MSE) 2.848 (2.848)\n",
      "Epoch: [238][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0575)\tLoss (MSE) 2.980 (5.096)\n",
      "Epoch: [238][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 5.225 (4.812)\n",
      "Epoch: [238][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.890 (4.955)\n",
      "Epoch: [238][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.377 (4.844)\n",
      "Epoch: [238][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 6.204 (4.734)\n",
      "Epoch: [238][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.520 (4.684)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.128 (2.128)\tLoss (L1) 0.670 (0.670)\n",
      " * Overall: MSE 1.990\tL1 0.612\tG-Mean 0.266\n",
      " * Many: MSE 2.467\tL1 1.058\tG-Mean 0.910\n",
      " * Median: MSE 2.103\tL1 1.387\tG-Mean 1.334\n",
      " * Low: MSE 0.037\tL1 0.171\tG-Mean 0.158\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #238: Train loss [4.7610]; Val loss: MSE [1.9904], L1 [0.6123], G-Mean [0.2656]\n",
      "Epoch: [239][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 4.752 (4.752)\n",
      "Epoch: [239][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 3.688 (4.609)\n",
      "Epoch: [239][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.893 (4.678)\n",
      "Epoch: [239][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.226 (4.663)\n",
      "Epoch: [239][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.127 (4.974)\n",
      "Epoch: [239][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.972 (4.821)\n",
      "Epoch: [239][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.729 (4.785)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.177 (2.177)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.997\tL1 0.595\tG-Mean 0.263\n",
      " * Many: MSE 2.351\tL1 0.985\tG-Mean 0.830\n",
      " * Median: MSE 2.288\tL1 1.451\tG-Mean 1.399\n",
      " * Low: MSE 0.085\tL1 0.252\tG-Mean 0.236\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #239: Train loss [4.8238]; Val loss: MSE [1.9971], L1 [0.5946], G-Mean [0.2626]\n",
      "Epoch: [240][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 2.974 (2.974)\n",
      "Epoch: [240][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 3.871 (5.108)\n",
      "Epoch: [240][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.018 (5.153)\n",
      "Epoch: [240][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.374 (5.008)\n",
      "Epoch: [240][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.792 (4.985)\n",
      "Epoch: [240][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.802 (4.844)\n",
      "Epoch: [240][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.133 (4.793)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.666 (0.666)\n",
      " * Overall: MSE 1.981\tL1 0.611\tG-Mean 0.263\n",
      " * Many: MSE 2.422\tL1 1.044\tG-Mean 0.894\n",
      " * Median: MSE 2.150\tL1 1.402\tG-Mean 1.347\n",
      " * Low: MSE 0.159\tL1 0.211\tG-Mean 0.177\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #240: Train loss [4.7891]; Val loss: MSE [1.9807], L1 [0.6109], G-Mean [0.2631]\n",
      "Epoch: [241][ 0/65]\tTime   0.57 (  0.57)\tData 0.5578 (0.5578)\tLoss (MSE) 4.705 (4.705)\n",
      "Epoch: [241][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 2.714 (4.743)\n",
      "Epoch: [241][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 5.288 (5.120)\n",
      "Epoch: [241][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 6.191 (5.014)\n",
      "Epoch: [241][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 6.758 (4.953)\n",
      "Epoch: [241][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.544 (4.834)\n",
      "Epoch: [241][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.001 (4.735)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.120 (2.120)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.950\tL1 0.596\tG-Mean 0.265\n",
      " * Many: MSE 2.304\tL1 0.990\tG-Mean 0.838\n",
      " * Median: MSE 2.251\tL1 1.433\tG-Mean 1.361\n",
      " * Low: MSE 0.162\tL1 0.261\tG-Mean 0.233\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #241: Train loss [4.7376]; Val loss: MSE [1.9499], L1 [0.5960], G-Mean [0.2648]\n",
      "Epoch: [242][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 4.532 (4.532)\n",
      "Epoch: [242][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0574)\tLoss (MSE) 2.820 (4.172)\n",
      "Epoch: [242][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 5.520 (4.611)\n",
      "Epoch: [242][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 3.154 (4.358)\n",
      "Epoch: [242][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 6.302 (4.523)\n",
      "Epoch: [242][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 6.013 (4.614)\n",
      "Epoch: [242][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.130 (4.715)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.991\tL1 0.602\tG-Mean 0.267\n",
      " * Many: MSE 2.378\tL1 1.006\tG-Mean 0.852\n",
      " * Median: MSE 2.234\tL1 1.431\tG-Mean 1.374\n",
      " * Low: MSE 0.140\tL1 0.244\tG-Mean 0.217\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #242: Train loss [4.6753]; Val loss: MSE [1.9915], L1 [0.6020], G-Mean [0.2674]\n",
      "Epoch: [243][ 0/65]\tTime   0.55 (  0.55)\tData 0.5415 (0.5415)\tLoss (MSE) 3.656 (3.656)\n",
      "Epoch: [243][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 3.079 (4.152)\n",
      "Epoch: [243][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.256 (4.493)\n",
      "Epoch: [243][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 6.948 (4.657)\n",
      "Epoch: [243][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.519 (4.543)\n",
      "Epoch: [243][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.933 (4.686)\n",
      "Epoch: [243][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.270 (4.636)\n",
      "Val: [0/9]\tTime  0.534 ( 0.534)\tLoss (MSE) 2.071 (2.071)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 2.045\tL1 0.599\tG-Mean 0.264\n",
      " * Many: MSE 2.422\tL1 0.994\tG-Mean 0.837\n",
      " * Median: MSE 2.266\tL1 1.444\tG-Mean 1.392\n",
      " * Low: MSE 0.123\tL1 0.255\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #243: Train loss [4.6553]; Val loss: MSE [2.0451], L1 [0.5990], G-Mean [0.2641]\n",
      "Epoch: [244][ 0/65]\tTime   0.55 (  0.55)\tData 0.5434 (0.5434)\tLoss (MSE) 3.162 (3.162)\n",
      "Epoch: [244][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 4.950 (4.336)\n",
      "Epoch: [244][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 11.458 (4.415)\n",
      "Epoch: [244][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.622 (4.270)\n",
      "Epoch: [244][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.302 (4.279)\n",
      "Epoch: [244][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.463 (4.404)\n",
      "Epoch: [244][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.307 (4.596)\n",
      "Val: [0/9]\tTime  0.638 ( 0.638)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 2.002\tL1 0.603\tG-Mean 0.267\n",
      " * Many: MSE 2.382\tL1 1.003\tG-Mean 0.847\n",
      " * Median: MSE 2.248\tL1 1.436\tG-Mean 1.380\n",
      " * Low: MSE 0.146\tL1 0.249\tG-Mean 0.225\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #244: Train loss [4.5866]; Val loss: MSE [2.0023], L1 [0.6029], G-Mean [0.2669]\n",
      "Epoch: [245][ 0/65]\tTime   0.62 (  0.62)\tData 0.6127 (0.6127)\tLoss (MSE) 3.098 (3.098)\n",
      "Epoch: [245][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0627)\tLoss (MSE) 3.249 (4.119)\n",
      "Epoch: [245][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0328)\tLoss (MSE) 4.390 (4.325)\n",
      "Epoch: [245][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0223)\tLoss (MSE) 4.198 (4.453)\n",
      "Epoch: [245][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0168)\tLoss (MSE) 5.393 (4.577)\n",
      "Epoch: [245][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 4.570 (4.556)\n",
      "Epoch: [245][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.132 (4.483)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.062 (2.062)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.992\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.391\tL1 1.010\tG-Mean 0.856\n",
      " * Median: MSE 2.201\tL1 1.416\tG-Mean 1.355\n",
      " * Low: MSE 0.098\tL1 0.230\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #245: Train loss [4.5306]; Val loss: MSE [1.9919], L1 [0.6006], G-Mean [0.2622]\n",
      "Epoch: [246][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 5.153 (5.153)\n",
      "Epoch: [246][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 3.456 (4.163)\n",
      "Epoch: [246][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 4.196 (4.469)\n",
      "Epoch: [246][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.366 (4.412)\n",
      "Epoch: [246][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.099 (4.501)\n",
      "Epoch: [246][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.979 (4.658)\n",
      "Epoch: [246][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.179 (4.646)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.079 (2.079)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 2.007\tL1 0.611\tG-Mean 0.262\n",
      " * Many: MSE 2.475\tL1 1.051\tG-Mean 0.901\n",
      " * Median: MSE 2.100\tL1 1.379\tG-Mean 1.311\n",
      " * Low: MSE 0.097\tL1 0.195\tG-Mean 0.172\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #246: Train loss [4.6446]; Val loss: MSE [2.0073], L1 [0.6105], G-Mean [0.2619]\n",
      "Epoch: [247][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 9.028 (9.028)\n",
      "Epoch: [247][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 4.322 (4.544)\n",
      "Epoch: [247][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 7.370 (4.708)\n",
      "Epoch: [247][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 6.202 (4.641)\n",
      "Epoch: [247][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.370 (4.580)\n",
      "Epoch: [247][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.332 (4.690)\n",
      "Epoch: [247][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.556 (4.613)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.107 (2.107)\tLoss (L1) 0.657 (0.657)\n",
      " * Overall: MSE 1.987\tL1 0.610\tG-Mean 0.262\n",
      " * Many: MSE 2.450\tL1 1.048\tG-Mean 0.898\n",
      " * Median: MSE 2.125\tL1 1.393\tG-Mean 1.337\n",
      " * Low: MSE 0.105\tL1 0.202\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #247: Train loss [4.5833]; Val loss: MSE [1.9867], L1 [0.6097], G-Mean [0.2617]\n",
      "Epoch: [248][ 0/65]\tTime   0.56 (  0.56)\tData 0.5532 (0.5532)\tLoss (MSE) 4.043 (4.043)\n",
      "Epoch: [248][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0530)\tLoss (MSE) 4.151 (4.164)\n",
      "Epoch: [248][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.161 (4.383)\n",
      "Epoch: [248][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.063 (4.218)\n",
      "Epoch: [248][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.163 (4.285)\n",
      "Epoch: [248][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 4.328 (4.425)\n",
      "Epoch: [248][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.209 (4.382)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.195 (2.195)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 2.057\tL1 0.601\tG-Mean 0.264\n",
      " * Many: MSE 2.437\tL1 0.992\tG-Mean 0.831\n",
      " * Median: MSE 2.286\tL1 1.451\tG-Mean 1.399\n",
      " * Low: MSE 0.131\tL1 0.264\tG-Mean 0.241\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #248: Train loss [4.4299]; Val loss: MSE [2.0570], L1 [0.6013], G-Mean [0.2643]\n",
      "Epoch: [249][ 0/65]\tTime   0.55 (  0.55)\tData 0.5488 (0.5488)\tLoss (MSE) 4.000 (4.000)\n",
      "Epoch: [249][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 4.986 (4.268)\n",
      "Epoch: [249][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.739 (4.666)\n",
      "Epoch: [249][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.319 (4.690)\n",
      "Epoch: [249][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.392 (4.522)\n",
      "Epoch: [249][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.443 (4.688)\n",
      "Epoch: [249][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.889 (4.680)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.138 (2.138)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.993\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.397\tL1 1.014\tG-Mean 0.861\n",
      " * Median: MSE 2.183\tL1 1.412\tG-Mean 1.355\n",
      " * Low: MSE 0.124\tL1 0.234\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #249: Train loss [4.6388]; Val loss: MSE [1.9934], L1 [0.6014], G-Mean [0.2602]\n",
      "Epoch: [250][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 5.121 (5.121)\n",
      "Epoch: [250][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 5.034 (5.335)\n",
      "Epoch: [250][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 3.790 (5.233)\n",
      "Epoch: [250][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 3.102 (4.782)\n",
      "Epoch: [250][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.694 (4.592)\n",
      "Epoch: [250][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.290 (4.590)\n",
      "Epoch: [250][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 6.482 (4.559)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.248 (2.248)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 2.075\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.425\tL1 0.976\tG-Mean 0.812\n",
      " * Median: MSE 2.320\tL1 1.458\tG-Mean 1.398\n",
      " * Low: MSE 0.177\tL1 0.284\tG-Mean 0.258\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #250: Train loss [4.5399]; Val loss: MSE [2.0753], L1 [0.5996], G-Mean [0.2615]\n",
      "Epoch: [251][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 7.998 (7.998)\n",
      "Epoch: [251][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 3.097 (4.305)\n",
      "Epoch: [251][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 4.333 (4.440)\n",
      "Epoch: [251][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 2.093 (4.324)\n",
      "Epoch: [251][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 6.144 (4.323)\n",
      "Epoch: [251][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.809 (4.463)\n",
      "Epoch: [251][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.895 (4.451)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.089 (2.089)\tLoss (L1) 0.667 (0.667)\n",
      " * Overall: MSE 1.953\tL1 0.626\tG-Mean 0.289\n",
      " * Many: MSE 2.488\tL1 1.096\tG-Mean 0.953\n",
      " * Median: MSE 1.939\tL1 1.321\tG-Mean 1.249\n",
      " * Low: MSE 0.096\tL1 0.148\tG-Mean 0.117\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #251: Train loss [4.4814]; Val loss: MSE [1.9531], L1 [0.6259], G-Mean [0.2890]\n",
      "Epoch: [252][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 5.212 (5.212)\n",
      "Epoch: [252][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 4.102 (3.981)\n",
      "Epoch: [252][20/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.096 (4.084)\n",
      "Epoch: [252][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.846 (4.112)\n",
      "Epoch: [252][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.810 (4.164)\n",
      "Epoch: [252][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.570 (4.421)\n",
      "Epoch: [252][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.664 (4.544)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 2.018\tL1 0.593\tG-Mean 0.255\n",
      " * Many: MSE 2.314\tL1 0.954\tG-Mean 0.795\n",
      " * Median: MSE 2.402\tL1 1.487\tG-Mean 1.432\n",
      " * Low: MSE 0.207\tL1 0.302\tG-Mean 0.271\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #252: Train loss [4.6290]; Val loss: MSE [2.0180], L1 [0.5929], G-Mean [0.2553]\n",
      "Epoch: [253][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 3.333 (3.333)\n",
      "Epoch: [253][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0588)\tLoss (MSE) 3.835 (4.152)\n",
      "Epoch: [253][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 3.083 (4.302)\n",
      "Epoch: [253][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 2.602 (4.425)\n",
      "Epoch: [253][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 5.388 (4.473)\n",
      "Epoch: [253][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.194 (4.565)\n",
      "Epoch: [253][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0106)\tLoss (MSE) 3.427 (4.614)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.028 (2.028)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.910\tL1 0.611\tG-Mean 0.274\n",
      " * Many: MSE 2.379\tL1 1.065\tG-Mean 0.924\n",
      " * Median: MSE 2.058\tL1 1.367\tG-Mean 1.310\n",
      " * Low: MSE 0.106\tL1 0.167\tG-Mean 0.137\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #253: Train loss [4.6026]; Val loss: MSE [1.9096], L1 [0.6109], G-Mean [0.2737]\n",
      "Epoch: [254][ 0/65]\tTime   0.55 (  0.55)\tData 0.5459 (0.5459)\tLoss (MSE) 4.534 (4.534)\n",
      "Epoch: [254][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0545)\tLoss (MSE) 2.953 (5.059)\n",
      "Epoch: [254][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.266 (4.778)\n",
      "Epoch: [254][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 4.043 (4.984)\n",
      "Epoch: [254][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.110 (4.713)\n",
      "Epoch: [254][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 2.944 (4.612)\n",
      "Epoch: [254][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 5.055 (4.553)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.100 (2.100)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.980\tL1 0.589\tG-Mean 0.260\n",
      " * Many: MSE 2.283\tL1 0.956\tG-Mean 0.801\n",
      " * Median: MSE 2.375\tL1 1.478\tG-Mean 1.422\n",
      " * Low: MSE 0.128\tL1 0.285\tG-Mean 0.267\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #254: Train loss [4.5146]; Val loss: MSE [1.9804], L1 [0.5889], G-Mean [0.2600]\n",
      "Epoch: [255][ 0/65]\tTime   0.58 (  0.58)\tData 0.5706 (0.5706)\tLoss (MSE) 4.016 (4.016)\n",
      "Epoch: [255][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 4.392 (4.839)\n",
      "Epoch: [255][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 5.420 (4.582)\n",
      "Epoch: [255][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.751 (4.610)\n",
      "Epoch: [255][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 5.694 (4.642)\n",
      "Epoch: [255][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.149 (4.534)\n",
      "Epoch: [255][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.894 (4.523)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.073 (2.073)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 2.024\tL1 0.591\tG-Mean 0.260\n",
      " * Many: MSE 2.351\tL1 0.962\tG-Mean 0.804\n",
      " * Median: MSE 2.361\tL1 1.471\tG-Mean 1.402\n",
      " * Low: MSE 0.101\tL1 0.280\tG-Mean 0.268\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #255: Train loss [4.4940]; Val loss: MSE [2.0245], L1 [0.5909], G-Mean [0.2605]\n",
      "Epoch: [256][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 4.561 (4.561)\n",
      "Epoch: [256][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 3.301 (3.995)\n",
      "Epoch: [256][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 5.140 (4.061)\n",
      "Epoch: [256][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 6.616 (4.162)\n",
      "Epoch: [256][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 7.945 (4.470)\n",
      "Epoch: [256][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.224 (4.570)\n",
      "Epoch: [256][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.681 (4.691)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.003 (2.003)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.965\tL1 0.607\tG-Mean 0.266\n",
      " * Many: MSE 2.415\tL1 1.043\tG-Mean 0.896\n",
      " * Median: MSE 2.129\tL1 1.394\tG-Mean 1.339\n",
      " * Low: MSE 0.058\tL1 0.189\tG-Mean 0.170\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #256: Train loss [4.6628]; Val loss: MSE [1.9650], L1 [0.6069], G-Mean [0.2663]\n",
      "Epoch: [257][ 0/65]\tTime   0.56 (  0.56)\tData 0.5544 (0.5544)\tLoss (MSE) 3.211 (3.211)\n",
      "Epoch: [257][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 4.379 (4.417)\n",
      "Epoch: [257][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 7.381 (4.856)\n",
      "Epoch: [257][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 3.571 (4.951)\n",
      "Epoch: [257][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.804 (4.718)\n",
      "Epoch: [257][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.559 (4.594)\n",
      "Epoch: [257][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 7.007 (4.555)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.674 (0.674)\n",
      " * Overall: MSE 1.942\tL1 0.629\tG-Mean 0.296\n",
      " * Many: MSE 2.496\tL1 1.106\tG-Mean 0.964\n",
      " * Median: MSE 1.935\tL1 1.319\tG-Mean 1.254\n",
      " * Low: MSE 0.051\tL1 0.129\tG-Mean 0.101\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #257: Train loss [4.6158]; Val loss: MSE [1.9422], L1 [0.6291], G-Mean [0.2959]\n",
      "Epoch: [258][ 0/65]\tTime   0.56 (  0.56)\tData 0.5565 (0.5565)\tLoss (MSE) 2.307 (2.307)\n",
      "Epoch: [258][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0573)\tLoss (MSE) 5.404 (3.966)\n",
      "Epoch: [258][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 6.291 (4.188)\n",
      "Epoch: [258][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 3.684 (4.366)\n",
      "Epoch: [258][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.289 (4.508)\n",
      "Epoch: [258][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.112 (4.571)\n",
      "Epoch: [258][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.422 (4.550)\n",
      "Val: [0/9]\tTime  0.646 ( 0.646)\tLoss (MSE) 2.080 (2.080)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.982\tL1 0.609\tG-Mean 0.267\n",
      " * Many: MSE 2.443\tL1 1.046\tG-Mean 0.895\n",
      " * Median: MSE 2.104\tL1 1.382\tG-Mean 1.307\n",
      " * Low: MSE 0.065\tL1 0.191\tG-Mean 0.171\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #258: Train loss [4.5984]; Val loss: MSE [1.9823], L1 [0.6093], G-Mean [0.2668]\n",
      "Epoch: [259][ 0/65]\tTime   0.66 (  0.66)\tData 0.6497 (0.6497)\tLoss (MSE) 4.021 (4.021)\n",
      "Epoch: [259][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0606)\tLoss (MSE) 5.906 (4.135)\n",
      "Epoch: [259][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0318)\tLoss (MSE) 3.302 (4.305)\n",
      "Epoch: [259][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0215)\tLoss (MSE) 5.073 (4.158)\n",
      "Epoch: [259][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 4.826 (4.140)\n",
      "Epoch: [259][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 2.593 (4.314)\n",
      "Epoch: [259][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 5.957 (4.526)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.024 (2.024)\tLoss (L1) 0.675 (0.675)\n",
      " * Overall: MSE 1.886\tL1 0.638\tG-Mean 0.314\n",
      " * Many: MSE 2.477\tL1 1.133\tG-Mean 1.000\n",
      " * Median: MSE 1.855\tL1 1.292\tG-Mean 1.234\n",
      " * Low: MSE 0.033\tL1 0.089\tG-Mean 0.064\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #259: Train loss [4.6205]; Val loss: MSE [1.8857], L1 [0.6384], G-Mean [0.3140]\n",
      "Epoch: [260][ 0/65]\tTime   0.57 (  0.57)\tData 0.5645 (0.5645)\tLoss (MSE) 4.366 (4.366)\n",
      "Epoch: [260][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0611)\tLoss (MSE) 6.340 (4.843)\n",
      "Epoch: [260][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0320)\tLoss (MSE) 6.435 (4.468)\n",
      "Epoch: [260][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0217)\tLoss (MSE) 3.894 (4.560)\n",
      "Epoch: [260][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 3.552 (4.626)\n",
      "Epoch: [260][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 5.332 (4.483)\n",
      "Epoch: [260][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.160 (4.369)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.022 (2.022)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.915\tL1 0.622\tG-Mean 0.288\n",
      " * Many: MSE 2.435\tL1 1.090\tG-Mean 0.948\n",
      " * Median: MSE 1.980\tL1 1.341\tG-Mean 1.284\n",
      " * Low: MSE 0.057\tL1 0.145\tG-Mean 0.120\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #260: Train loss [4.5009]; Val loss: MSE [1.9152], L1 [0.6216], G-Mean [0.2884]\n",
      "Epoch: [261][ 0/65]\tTime   0.56 (  0.56)\tData 0.5492 (0.5492)\tLoss (MSE) 4.659 (4.659)\n",
      "Epoch: [261][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 2.739 (5.018)\n",
      "Epoch: [261][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.111 (4.418)\n",
      "Epoch: [261][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.230 (4.512)\n",
      "Epoch: [261][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 1.907 (4.468)\n",
      "Epoch: [261][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.807 (4.450)\n",
      "Epoch: [261][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.808 (4.467)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.113 (2.113)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.960\tL1 0.594\tG-Mean 0.263\n",
      " * Many: MSE 2.345\tL1 1.001\tG-Mean 0.849\n",
      " * Median: MSE 2.225\tL1 1.425\tG-Mean 1.361\n",
      " * Low: MSE 0.059\tL1 0.230\tG-Mean 0.221\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #261: Train loss [4.4325]; Val loss: MSE [1.9603], L1 [0.5943], G-Mean [0.2634]\n",
      "Epoch: [262][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 3.514 (3.514)\n",
      "Epoch: [262][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 4.770 (5.197)\n",
      "Epoch: [262][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0305)\tLoss (MSE) 4.191 (5.222)\n",
      "Epoch: [262][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 4.616 (4.950)\n",
      "Epoch: [262][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.708 (4.951)\n",
      "Epoch: [262][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.866 (4.987)\n",
      "Epoch: [262][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.577 (4.810)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.894\tL1 0.590\tG-Mean 0.266\n",
      " * Many: MSE 2.238\tL1 0.987\tG-Mean 0.840\n",
      " * Median: MSE 2.266\tL1 1.442\tG-Mean 1.388\n",
      " * Low: MSE 0.088\tL1 0.242\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #262: Train loss [4.7748]; Val loss: MSE [1.8944], L1 [0.5899], G-Mean [0.2655]\n",
      "Epoch: [263][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 3.652 (3.652)\n",
      "Epoch: [263][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0583)\tLoss (MSE) 3.092 (4.334)\n",
      "Epoch: [263][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.629 (4.391)\n",
      "Epoch: [263][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 3.547 (4.312)\n",
      "Epoch: [263][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.266 (4.476)\n",
      "Epoch: [263][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.928 (4.519)\n",
      "Epoch: [263][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.670 (4.437)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.146 (2.146)\tLoss (L1) 0.657 (0.657)\n",
      " * Overall: MSE 1.918\tL1 0.593\tG-Mean 0.267\n",
      " * Many: MSE 2.264\tL1 0.988\tG-Mean 0.838\n",
      " * Median: MSE 2.257\tL1 1.431\tG-Mean 1.329\n",
      " * Low: MSE 0.099\tL1 0.250\tG-Mean 0.230\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #263: Train loss [4.4158]; Val loss: MSE [1.9180], L1 [0.5927], G-Mean [0.2670]\n",
      "Epoch: [264][ 0/65]\tTime   0.56 (  0.56)\tData 0.5576 (0.5576)\tLoss (MSE) 5.171 (5.171)\n",
      "Epoch: [264][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.372 (4.422)\n",
      "Epoch: [264][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 6.195 (4.604)\n",
      "Epoch: [264][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 5.915 (4.476)\n",
      "Epoch: [264][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.171 (4.408)\n",
      "Epoch: [264][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 5.920 (4.395)\n",
      "Epoch: [264][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 6.169 (4.433)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.266\n",
      " * Many: MSE 2.303\tL1 1.007\tG-Mean 0.858\n",
      " * Median: MSE 2.252\tL1 1.437\tG-Mean 1.383\n",
      " * Low: MSE 0.096\tL1 0.232\tG-Mean 0.213\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #264: Train loss [4.4125]; Val loss: MSE [1.9247], L1 [0.5987], G-Mean [0.2660]\n",
      "Epoch: [265][ 0/65]\tTime   0.55 (  0.55)\tData 0.5476 (0.5476)\tLoss (MSE) 4.270 (4.270)\n",
      "Epoch: [265][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 4.690 (3.467)\n",
      "Epoch: [265][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 2.503 (3.998)\n",
      "Epoch: [265][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 5.221 (4.214)\n",
      "Epoch: [265][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 5.151 (4.389)\n",
      "Epoch: [265][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 8.519 (4.611)\n",
      "Epoch: [265][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.447 (4.804)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.091 (2.091)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.887\tL1 0.614\tG-Mean 0.281\n",
      " * Many: MSE 2.382\tL1 1.078\tG-Mean 0.940\n",
      " * Median: MSE 1.997\tL1 1.345\tG-Mean 1.285\n",
      " * Low: MSE 0.067\tL1 0.149\tG-Mean 0.127\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #265: Train loss [4.7614]; Val loss: MSE [1.8869], L1 [0.6144], G-Mean [0.2812]\n",
      "Epoch: [266][ 0/65]\tTime   0.57 (  0.57)\tData 0.5634 (0.5634)\tLoss (MSE) 5.034 (5.034)\n",
      "Epoch: [266][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 2.590 (3.926)\n",
      "Epoch: [266][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 3.235 (4.028)\n",
      "Epoch: [266][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.450 (4.020)\n",
      "Epoch: [266][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 8.244 (4.286)\n",
      "Epoch: [266][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.383 (4.390)\n",
      "Epoch: [266][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.464 (4.590)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.122 (2.122)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.931\tL1 0.592\tG-Mean 0.266\n",
      " * Many: MSE 2.273\tL1 0.986\tG-Mean 0.837\n",
      " * Median: MSE 2.282\tL1 1.448\tG-Mean 1.394\n",
      " * Low: MSE 0.119\tL1 0.258\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #266: Train loss [4.6728]; Val loss: MSE [1.9312], L1 [0.5916], G-Mean [0.2659]\n",
      "Epoch: [267][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 5.567 (5.567)\n",
      "Epoch: [267][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 6.130 (4.138)\n",
      "Epoch: [267][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 2.323 (4.402)\n",
      "Epoch: [267][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.270 (4.455)\n",
      "Epoch: [267][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.941 (4.372)\n",
      "Epoch: [267][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.463 (4.536)\n",
      "Epoch: [267][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.452 (4.593)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.119 (2.119)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.938\tL1 0.606\tG-Mean 0.263\n",
      " * Many: MSE 2.374\tL1 1.038\tG-Mean 0.890\n",
      " * Median: MSE 2.140\tL1 1.394\tG-Mean 1.329\n",
      " * Low: MSE 0.092\tL1 0.208\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #267: Train loss [4.5673]; Val loss: MSE [1.9382], L1 [0.6057], G-Mean [0.2628]\n",
      "Epoch: [268][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 3.613 (3.613)\n",
      "Epoch: [268][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0513)\tLoss (MSE) 4.479 (3.763)\n",
      "Epoch: [268][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.872 (3.991)\n",
      "Epoch: [268][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 6.218 (4.140)\n",
      "Epoch: [268][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.493 (4.284)\n",
      "Epoch: [268][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.392 (4.441)\n",
      "Epoch: [268][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.628 (4.338)\n",
      "Val: [0/9]\tTime  0.644 ( 0.644)\tLoss (MSE) 2.153 (2.153)\tLoss (L1) 0.668 (0.668)\n",
      " * Overall: MSE 1.907\tL1 0.621\tG-Mean 0.288\n",
      " * Many: MSE 2.429\tL1 1.090\tG-Mean 0.949\n",
      " * Median: MSE 1.957\tL1 1.326\tG-Mean 1.256\n",
      " * Low: MSE 0.073\tL1 0.151\tG-Mean 0.121\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #268: Train loss [4.4256]; Val loss: MSE [1.9069], L1 [0.6210], G-Mean [0.2880]\n",
      "Epoch: [269][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 3.150 (3.150)\n",
      "Epoch: [269][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 5.417 (4.092)\n",
      "Epoch: [269][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.083 (3.964)\n",
      "Epoch: [269][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.437 (4.094)\n",
      "Epoch: [269][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.065 (4.317)\n",
      "Epoch: [269][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 4.281 (4.465)\n",
      "Epoch: [269][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.665 (4.492)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.184 (2.184)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.913\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.353\tL1 1.042\tG-Mean 0.898\n",
      " * Median: MSE 2.099\tL1 1.378\tG-Mean 1.302\n",
      " * Low: MSE 0.044\tL1 0.185\tG-Mean 0.174\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #269: Train loss [4.5871]; Val loss: MSE [1.9126], L1 [0.6018], G-Mean [0.2609]\n",
      "Epoch: [270][ 0/65]\tTime   0.57 (  0.57)\tData 0.5589 (0.5589)\tLoss (MSE) 5.812 (5.812)\n",
      "Epoch: [270][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 5.659 (4.578)\n",
      "Epoch: [270][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.606 (4.493)\n",
      "Epoch: [270][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.874 (4.418)\n",
      "Epoch: [270][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 8.776 (4.452)\n",
      "Epoch: [270][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.197 (4.535)\n",
      "Epoch: [270][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.356 (4.589)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.131 (2.131)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.933\tL1 0.593\tG-Mean 0.265\n",
      " * Many: MSE 2.282\tL1 0.985\tG-Mean 0.832\n",
      " * Median: MSE 2.280\tL1 1.446\tG-Mean 1.390\n",
      " * Low: MSE 0.101\tL1 0.256\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #270: Train loss [4.4960]; Val loss: MSE [1.9327], L1 [0.5928], G-Mean [0.2649]\n",
      "Epoch: [271][ 0/65]\tTime   0.62 (  0.62)\tData 0.6052 (0.6052)\tLoss (MSE) 4.018 (4.018)\n",
      "Epoch: [271][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 6.909 (5.304)\n",
      "Epoch: [271][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 3.648 (4.826)\n",
      "Epoch: [271][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.099 (4.492)\n",
      "Epoch: [271][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 4.187 (4.386)\n",
      "Epoch: [271][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 5.932 (4.367)\n",
      "Epoch: [271][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.428 (4.391)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.163 (2.163)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.938\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.009\tG-Mean 0.858\n",
      " * Median: MSE 2.208\tL1 1.423\tG-Mean 1.370\n",
      " * Low: MSE 0.083\tL1 0.226\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #271: Train loss [4.3812]; Val loss: MSE [1.9382], L1 [0.5970], G-Mean [0.2605]\n",
      "Epoch: [272][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 2.618 (2.618)\n",
      "Epoch: [272][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0587)\tLoss (MSE) 5.279 (4.261)\n",
      "Epoch: [272][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 4.697 (4.169)\n",
      "Epoch: [272][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 5.315 (4.085)\n",
      "Epoch: [272][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 4.869 (4.049)\n",
      "Epoch: [272][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.537 (4.228)\n",
      "Epoch: [272][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.167 (4.353)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.945\tL1 0.607\tG-Mean 0.262\n",
      " * Many: MSE 2.400\tL1 1.046\tG-Mean 0.898\n",
      " * Median: MSE 2.090\tL1 1.375\tG-Mean 1.307\n",
      " * Low: MSE 0.093\tL1 0.202\tG-Mean 0.173\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #272: Train loss [4.3836]; Val loss: MSE [1.9446], L1 [0.6068], G-Mean [0.2622]\n",
      "Epoch: [273][ 0/65]\tTime   0.57 (  0.57)\tData 0.5654 (0.5654)\tLoss (MSE) 5.596 (5.596)\n",
      "Epoch: [273][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0596)\tLoss (MSE) 7.849 (4.353)\n",
      "Epoch: [273][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0312)\tLoss (MSE) 3.548 (4.406)\n",
      "Epoch: [273][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0212)\tLoss (MSE) 4.909 (4.567)\n",
      "Epoch: [273][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 6.130 (4.537)\n",
      "Epoch: [273][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 4.538 (4.384)\n",
      "Epoch: [273][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.147 (4.386)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.895\tL1 0.608\tG-Mean 0.269\n",
      " * Many: MSE 2.360\tL1 1.058\tG-Mean 0.917\n",
      " * Median: MSE 2.067\tL1 1.371\tG-Mean 1.313\n",
      " * Low: MSE 0.104\tL1 0.184\tG-Mean 0.155\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #273: Train loss [4.4003]; Val loss: MSE [1.8950], L1 [0.6083], G-Mean [0.2689]\n",
      "Epoch: [274][ 0/65]\tTime   0.56 (  0.56)\tData 0.5568 (0.5568)\tLoss (MSE) 6.458 (6.458)\n",
      "Epoch: [274][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 4.454 (4.573)\n",
      "Epoch: [274][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 4.748 (4.427)\n",
      "Epoch: [274][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.678 (4.348)\n",
      "Epoch: [274][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 4.879 (4.326)\n",
      "Epoch: [274][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.240 (4.384)\n",
      "Epoch: [274][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 5.593 (4.413)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.235 (2.235)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.970\tL1 0.598\tG-Mean 0.264\n",
      " * Many: MSE 2.303\tL1 0.975\tG-Mean 0.817\n",
      " * Median: MSE 2.343\tL1 1.468\tG-Mean 1.414\n",
      " * Low: MSE 0.176\tL1 0.290\tG-Mean 0.259\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #274: Train loss [4.4532]; Val loss: MSE [1.9698], L1 [0.5984], G-Mean [0.2641]\n",
      "Epoch: [275][ 0/65]\tTime   0.56 (  0.56)\tData 0.5509 (0.5509)\tLoss (MSE) 2.432 (2.432)\n",
      "Epoch: [275][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 4.463 (4.473)\n",
      "Epoch: [275][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 5.015 (4.262)\n",
      "Epoch: [275][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.568 (4.318)\n",
      "Epoch: [275][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.942 (4.203)\n",
      "Epoch: [275][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.293 (4.304)\n",
      "Epoch: [275][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.703 (4.418)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.146 (2.146)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.948\tL1 0.614\tG-Mean 0.271\n",
      " * Many: MSE 2.421\tL1 1.061\tG-Mean 0.913\n",
      " * Median: MSE 2.063\tL1 1.369\tG-Mean 1.310\n",
      " * Low: MSE 0.114\tL1 0.192\tG-Mean 0.159\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #275: Train loss [4.4661]; Val loss: MSE [1.9481], L1 [0.6140], G-Mean [0.2707]\n",
      "Epoch: [276][ 0/65]\tTime   0.62 (  0.62)\tData 0.6048 (0.6048)\tLoss (MSE) 3.631 (3.631)\n",
      "Epoch: [276][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0575)\tLoss (MSE) 4.392 (4.546)\n",
      "Epoch: [276][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 3.810 (4.404)\n",
      "Epoch: [276][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 7.303 (4.496)\n",
      "Epoch: [276][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 7.182 (4.555)\n",
      "Epoch: [276][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.128 (4.435)\n",
      "Epoch: [276][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.449 (4.411)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.189 (2.189)\tLoss (L1) 0.660 (0.660)\n",
      " * Overall: MSE 1.939\tL1 0.606\tG-Mean 0.263\n",
      " * Many: MSE 2.368\tL1 1.035\tG-Mean 0.885\n",
      " * Median: MSE 2.145\tL1 1.400\tG-Mean 1.344\n",
      " * Low: MSE 0.100\tL1 0.213\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #276: Train loss [4.4412]; Val loss: MSE [1.9391], L1 [0.6055], G-Mean [0.2627]\n",
      "Epoch: [277][ 0/65]\tTime   0.61 (  0.61)\tData 0.5882 (0.5882)\tLoss (MSE) 6.206 (6.206)\n",
      "Epoch: [277][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 6.270 (4.424)\n",
      "Epoch: [277][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0291)\tLoss (MSE) 4.392 (4.373)\n",
      "Epoch: [277][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0197)\tLoss (MSE) 6.066 (4.191)\n",
      "Epoch: [277][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 6.879 (4.274)\n",
      "Epoch: [277][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.333 (4.211)\n",
      "Epoch: [277][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.754 (4.254)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.217 (2.217)\tLoss (L1) 0.674 (0.674)\n",
      " * Overall: MSE 1.935\tL1 0.617\tG-Mean 0.275\n",
      " * Many: MSE 2.420\tL1 1.071\tG-Mean 0.926\n",
      " * Median: MSE 2.053\tL1 1.365\tG-Mean 1.303\n",
      " * Low: MSE 0.086\tL1 0.177\tG-Mean 0.150\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #277: Train loss [4.3170]; Val loss: MSE [1.9350], L1 [0.6171], G-Mean [0.2750]\n",
      "Epoch: [278][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 3.460 (3.460)\n",
      "Epoch: [278][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 6.079 (4.607)\n",
      "Epoch: [278][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.956 (4.443)\n",
      "Epoch: [278][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.437 (4.241)\n",
      "Epoch: [278][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 8.332 (4.481)\n",
      "Epoch: [278][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 8.056 (4.499)\n",
      "Epoch: [278][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.304 (4.441)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.172 (2.172)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.968\tL1 0.592\tG-Mean 0.256\n",
      " * Many: MSE 2.267\tL1 0.954\tG-Mean 0.795\n",
      " * Median: MSE 2.371\tL1 1.472\tG-Mean 1.403\n",
      " * Low: MSE 0.167\tL1 0.304\tG-Mean 0.277\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #278: Train loss [4.4558]; Val loss: MSE [1.9678], L1 [0.5916], G-Mean [0.2555]\n",
      "Epoch: [279][ 0/65]\tTime   0.55 (  0.55)\tData 0.5430 (0.5430)\tLoss (MSE) 9.849 (9.849)\n",
      "Epoch: [279][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0505)\tLoss (MSE) 10.846 (5.338)\n",
      "Epoch: [279][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0264)\tLoss (MSE) 3.350 (4.951)\n",
      "Epoch: [279][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 2.718 (4.554)\n",
      "Epoch: [279][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 6.189 (4.799)\n",
      "Epoch: [279][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 2.863 (4.807)\n",
      "Epoch: [279][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 3.133 (4.762)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.087 (2.087)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.885\tL1 0.587\tG-Mean 0.263\n",
      " * Many: MSE 2.228\tL1 0.985\tG-Mean 0.841\n",
      " * Median: MSE 2.271\tL1 1.446\tG-Mean 1.394\n",
      " * Low: MSE 0.066\tL1 0.237\tG-Mean 0.228\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #279: Train loss [4.7155]; Val loss: MSE [1.8851], L1 [0.5870], G-Mean [0.2629]\n",
      "Epoch: [280][ 0/65]\tTime   0.57 (  0.57)\tData 0.5698 (0.5698)\tLoss (MSE) 2.159 (2.159)\n",
      "Epoch: [280][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0604)\tLoss (MSE) 3.841 (4.181)\n",
      "Epoch: [280][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0317)\tLoss (MSE) 4.308 (4.688)\n",
      "Epoch: [280][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0215)\tLoss (MSE) 3.576 (4.593)\n",
      "Epoch: [280][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.675 (4.584)\n",
      "Epoch: [280][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 4.413 (4.515)\n",
      "Epoch: [280][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 6.908 (4.524)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.944\tL1 0.605\tG-Mean 0.260\n",
      " * Many: MSE 2.357\tL1 1.025\tG-Mean 0.872\n",
      " * Median: MSE 2.144\tL1 1.393\tG-Mean 1.314\n",
      " * Low: MSE 0.155\tL1 0.240\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #280: Train loss [4.5366]; Val loss: MSE [1.9438], L1 [0.6047], G-Mean [0.2598]\n",
      "Epoch: [281][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 3.371 (3.371)\n",
      "Epoch: [281][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 3.183 (3.624)\n",
      "Epoch: [281][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 4.108 (4.240)\n",
      "Epoch: [281][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.210 (4.094)\n",
      "Epoch: [281][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.969 (4.483)\n",
      "Epoch: [281][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 3.970 (4.328)\n",
      "Epoch: [281][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.657 (4.388)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 2.007\tL1 0.606\tG-Mean 0.264\n",
      " * Many: MSE 2.413\tL1 1.016\tG-Mean 0.859\n",
      " * Median: MSE 2.221\tL1 1.421\tG-Mean 1.355\n",
      " * Low: MSE 0.155\tL1 0.251\tG-Mean 0.220\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #281: Train loss [4.4219]; Val loss: MSE [2.0075], L1 [0.6065], G-Mean [0.2640]\n",
      "Epoch: [282][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 4.199 (4.199)\n",
      "Epoch: [282][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 2.656 (4.035)\n",
      "Epoch: [282][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 4.191 (4.261)\n",
      "Epoch: [282][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 2.739 (4.683)\n",
      "Epoch: [282][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.730 (4.426)\n",
      "Epoch: [282][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.251 (4.463)\n",
      "Epoch: [282][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 5.256 (4.371)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.022 (2.022)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.898\tL1 0.613\tG-Mean 0.272\n",
      " * Many: MSE 2.369\tL1 1.065\tG-Mean 0.922\n",
      " * Median: MSE 2.055\tL1 1.369\tG-Mean 1.315\n",
      " * Low: MSE 0.075\tL1 0.175\tG-Mean 0.153\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #282: Train loss [4.3719]; Val loss: MSE [1.8982], L1 [0.6131], G-Mean [0.2719]\n",
      "Epoch: [283][ 0/65]\tTime   0.60 (  0.60)\tData 0.5926 (0.5926)\tLoss (MSE) 4.319 (4.319)\n",
      "Epoch: [283][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 3.197 (4.471)\n",
      "Epoch: [283][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 2.044 (4.595)\n",
      "Epoch: [283][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.485 (4.912)\n",
      "Epoch: [283][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.389 (4.686)\n",
      "Epoch: [283][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 3.679 (4.667)\n",
      "Epoch: [283][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.959 (4.542)\n",
      "Val: [0/9]\tTime  0.561 ( 0.561)\tLoss (MSE) 2.089 (2.089)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.933\tL1 0.594\tG-Mean 0.266\n",
      " * Many: MSE 2.268\tL1 0.980\tG-Mean 0.828\n",
      " * Median: MSE 2.294\tL1 1.450\tG-Mean 1.382\n",
      " * Low: MSE 0.125\tL1 0.265\tG-Mean 0.241\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #283: Train loss [4.5236]; Val loss: MSE [1.9331], L1 [0.5936], G-Mean [0.2660]\n",
      "Epoch: [284][ 0/65]\tTime   0.55 (  0.55)\tData 0.5435 (0.5435)\tLoss (MSE) 4.296 (4.296)\n",
      "Epoch: [284][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 3.890 (4.898)\n",
      "Epoch: [284][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 4.804 (4.836)\n",
      "Epoch: [284][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.920 (4.613)\n",
      "Epoch: [284][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 5.887 (4.605)\n",
      "Epoch: [284][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 6.301 (4.492)\n",
      "Epoch: [284][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 5.182 (4.381)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.981\tL1 0.608\tG-Mean 0.265\n",
      " * Many: MSE 2.379\tL1 1.020\tG-Mean 0.865\n",
      " * Median: MSE 2.230\tL1 1.425\tG-Mean 1.360\n",
      " * Low: MSE 0.193\tL1 0.250\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #284: Train loss [4.3879]; Val loss: MSE [1.9806], L1 [0.6083], G-Mean [0.2655]\n",
      "Epoch: [285][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 4.807 (4.807)\n",
      "Epoch: [285][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 8.175 (4.419)\n",
      "Epoch: [285][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 6.168 (4.720)\n",
      "Epoch: [285][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 6.258 (4.741)\n",
      "Epoch: [285][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.396 (4.458)\n",
      "Epoch: [285][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.002 (4.539)\n",
      "Epoch: [285][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.107 (4.419)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.132 (2.132)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.986\tL1 0.600\tG-Mean 0.266\n",
      " * Many: MSE 2.352\tL1 0.997\tG-Mean 0.842\n",
      " * Median: MSE 2.244\tL1 1.432\tG-Mean 1.373\n",
      " * Low: MSE 0.202\tL1 0.266\tG-Mean 0.225\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #285: Train loss [4.4165]; Val loss: MSE [1.9859], L1 [0.5998], G-Mean [0.2661]\n",
      "Epoch: [286][ 0/65]\tTime   0.56 (  0.56)\tData 0.5540 (0.5540)\tLoss (MSE) 7.544 (7.544)\n",
      "Epoch: [286][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0577)\tLoss (MSE) 4.903 (5.265)\n",
      "Epoch: [286][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 5.955 (5.276)\n",
      "Epoch: [286][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 2.847 (4.979)\n",
      "Epoch: [286][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.376 (4.830)\n",
      "Epoch: [286][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.555 (4.584)\n",
      "Epoch: [286][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.671 (4.455)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.073 (2.073)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.976\tL1 0.602\tG-Mean 0.265\n",
      " * Many: MSE 2.353\tL1 1.003\tG-Mean 0.848\n",
      " * Median: MSE 2.236\tL1 1.432\tG-Mean 1.374\n",
      " * Low: MSE 0.158\tL1 0.256\tG-Mean 0.220\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #286: Train loss [4.4288]; Val loss: MSE [1.9761], L1 [0.6015], G-Mean [0.2653]\n",
      "Epoch: [287][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 4.859 (4.859)\n",
      "Epoch: [287][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 5.144 (4.681)\n",
      "Epoch: [287][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.643 (4.512)\n",
      "Epoch: [287][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.639 (4.331)\n",
      "Epoch: [287][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.103 (4.289)\n",
      "Epoch: [287][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.567 (4.331)\n",
      "Epoch: [287][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.134 (4.260)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.090 (2.090)\tLoss (L1) 0.638 (0.638)\n",
      " * Overall: MSE 2.002\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 0.964\tG-Mean 0.803\n",
      " * Median: MSE 2.353\tL1 1.471\tG-Mean 1.416\n",
      " * Low: MSE 0.138\tL1 0.291\tG-Mean 0.270\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #287: Train loss [4.3018]; Val loss: MSE [2.0020], L1 [0.5960], G-Mean [0.2603]\n",
      "Epoch: [288][ 0/65]\tTime   0.56 (  0.56)\tData 0.5535 (0.5535)\tLoss (MSE) 2.986 (2.986)\n",
      "Epoch: [288][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0565)\tLoss (MSE) 1.941 (3.665)\n",
      "Epoch: [288][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0296)\tLoss (MSE) 3.540 (3.919)\n",
      "Epoch: [288][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0201)\tLoss (MSE) 5.720 (3.964)\n",
      "Epoch: [288][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.594 (4.148)\n",
      "Epoch: [288][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.536 (4.166)\n",
      "Epoch: [288][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.204 (4.255)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.033 (2.033)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.915\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.350\tL1 1.040\tG-Mean 0.895\n",
      " * Median: MSE 2.110\tL1 1.384\tG-Mean 1.315\n",
      " * Low: MSE 0.067\tL1 0.194\tG-Mean 0.173\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #288: Train loss [4.2663]; Val loss: MSE [1.9149], L1 [0.6029], G-Mean [0.2621]\n",
      "Epoch: [289][ 0/65]\tTime   0.61 (  0.61)\tData 0.5931 (0.5931)\tLoss (MSE) 5.914 (5.914)\n",
      "Epoch: [289][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0573)\tLoss (MSE) 2.958 (4.617)\n",
      "Epoch: [289][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 4.973 (4.947)\n",
      "Epoch: [289][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 3.919 (4.696)\n",
      "Epoch: [289][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 5.322 (4.540)\n",
      "Epoch: [289][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.560 (4.511)\n",
      "Epoch: [289][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.934 (4.387)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.139 (2.139)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.975\tL1 0.599\tG-Mean 0.265\n",
      " * Many: MSE 2.349\tL1 0.999\tG-Mean 0.844\n",
      " * Median: MSE 2.227\tL1 1.425\tG-Mean 1.348\n",
      " * Low: MSE 0.126\tL1 0.255\tG-Mean 0.228\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #289: Train loss [4.3418]; Val loss: MSE [1.9754], L1 [0.5994], G-Mean [0.2653]\n",
      "Epoch: [290][ 0/65]\tTime   0.55 (  0.55)\tData 0.5487 (0.5487)\tLoss (MSE) 5.529 (5.529)\n",
      "Epoch: [290][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0583)\tLoss (MSE) 7.303 (4.671)\n",
      "Epoch: [290][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 5.524 (4.203)\n",
      "Epoch: [290][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 3.431 (4.218)\n",
      "Epoch: [290][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.017 (4.281)\n",
      "Epoch: [290][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.652 (4.370)\n",
      "Epoch: [290][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.969 (4.402)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.023 (2.023)\tLoss (L1) 0.659 (0.659)\n",
      " * Overall: MSE 1.925\tL1 0.617\tG-Mean 0.280\n",
      " * Many: MSE 2.423\tL1 1.078\tG-Mean 0.936\n",
      " * Median: MSE 1.995\tL1 1.344\tG-Mean 1.284\n",
      " * Low: MSE 0.085\tL1 0.166\tG-Mean 0.138\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #290: Train loss [4.3861]; Val loss: MSE [1.9249], L1 [0.6174], G-Mean [0.2800]\n",
      "Epoch: [291][ 0/65]\tTime   0.56 (  0.56)\tData 0.5521 (0.5521)\tLoss (MSE) 7.349 (7.349)\n",
      "Epoch: [291][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0513)\tLoss (MSE) 7.107 (4.800)\n",
      "Epoch: [291][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.935 (4.230)\n",
      "Epoch: [291][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.834 (4.337)\n",
      "Epoch: [291][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.909 (4.337)\n",
      "Epoch: [291][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.476 (4.307)\n",
      "Epoch: [291][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.366 (4.419)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.166 (2.166)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 2.007\tL1 0.599\tG-Mean 0.264\n",
      " * Many: MSE 2.369\tL1 0.990\tG-Mean 0.831\n",
      " * Median: MSE 2.252\tL1 1.427\tG-Mean 1.343\n",
      " * Low: MSE 0.136\tL1 0.267\tG-Mean 0.242\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #291: Train loss [4.4544]; Val loss: MSE [2.0074], L1 [0.5990], G-Mean [0.2644]\n",
      "Epoch: [292][ 0/65]\tTime   0.55 (  0.55)\tData 0.5487 (0.5487)\tLoss (MSE) 4.786 (4.786)\n",
      "Epoch: [292][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 4.397 (4.127)\n",
      "Epoch: [292][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 2.971 (4.135)\n",
      "Epoch: [292][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.409 (4.199)\n",
      "Epoch: [292][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.331 (4.237)\n",
      "Epoch: [292][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.744 (4.121)\n",
      "Epoch: [292][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.205 (4.209)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.665 (0.665)\n",
      " * Overall: MSE 1.978\tL1 0.630\tG-Mean 0.290\n",
      " * Many: MSE 2.523\tL1 1.102\tG-Mean 0.955\n",
      " * Median: MSE 1.929\tL1 1.314\tG-Mean 1.238\n",
      " * Low: MSE 0.094\tL1 0.155\tG-Mean 0.122\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #292: Train loss [4.3014]; Val loss: MSE [1.9783], L1 [0.6302], G-Mean [0.2900]\n",
      "Epoch: [293][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 3.446 (3.446)\n",
      "Epoch: [293][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 2.856 (4.060)\n",
      "Epoch: [293][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 4.944 (4.131)\n",
      "Epoch: [293][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.135 (4.172)\n",
      "Epoch: [293][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.514 (4.463)\n",
      "Epoch: [293][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.121 (4.254)\n",
      "Epoch: [293][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.321 (4.248)\n",
      "Val: [0/9]\tTime  0.667 ( 0.667)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.959\tL1 0.589\tG-Mean 0.256\n",
      " * Many: MSE 2.248\tL1 0.949\tG-Mean 0.792\n",
      " * Median: MSE 2.376\tL1 1.473\tG-Mean 1.390\n",
      " * Low: MSE 0.131\tL1 0.294\tG-Mean 0.276\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #293: Train loss [4.2548]; Val loss: MSE [1.9591], L1 [0.5885], G-Mean [0.2558]\n",
      "Epoch: [294][ 0/65]\tTime   0.62 (  0.62)\tData 0.6106 (0.6106)\tLoss (MSE) 5.422 (5.422)\n",
      "Epoch: [294][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 3.517 (4.511)\n",
      "Epoch: [294][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.247 (4.305)\n",
      "Epoch: [294][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 4.515 (4.185)\n",
      "Epoch: [294][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.162 (4.222)\n",
      "Epoch: [294][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.980 (4.348)\n",
      "Epoch: [294][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.424 (4.398)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 1.997 (1.997)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.879\tL1 0.605\tG-Mean 0.270\n",
      " * Many: MSE 2.335\tL1 1.056\tG-Mean 0.918\n",
      " * Median: MSE 2.032\tL1 1.353\tG-Mean 1.275\n",
      " * Low: MSE 0.073\tL1 0.170\tG-Mean 0.151\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #294: Train loss [4.3506]; Val loss: MSE [1.8786], L1 [0.6054], G-Mean [0.2695]\n",
      "Epoch: [295][ 0/65]\tTime   0.55 (  0.55)\tData 0.5464 (0.5464)\tLoss (MSE) 3.499 (3.499)\n",
      "Epoch: [295][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0527)\tLoss (MSE) 4.923 (3.852)\n",
      "Epoch: [295][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 2.336 (3.735)\n",
      "Epoch: [295][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.566 (4.025)\n",
      "Epoch: [295][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.450 (4.127)\n",
      "Epoch: [295][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.750 (4.337)\n",
      "Epoch: [295][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.483 (4.422)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.105 (2.105)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.907\tL1 0.587\tG-Mean 0.265\n",
      " * Many: MSE 2.240\tL1 0.981\tG-Mean 0.835\n",
      " * Median: MSE 2.257\tL1 1.440\tG-Mean 1.388\n",
      " * Low: MSE 0.097\tL1 0.248\tG-Mean 0.231\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #295: Train loss [4.4054]; Val loss: MSE [1.9071], L1 [0.5874], G-Mean [0.2649]\n",
      "Epoch: [296][ 0/65]\tTime   0.57 (  0.57)\tData 0.5633 (0.5633)\tLoss (MSE) 4.765 (4.765)\n",
      "Epoch: [296][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0585)\tLoss (MSE) 5.565 (4.792)\n",
      "Epoch: [296][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 2.069 (4.665)\n",
      "Epoch: [296][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 3.565 (4.650)\n",
      "Epoch: [296][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.813 (4.433)\n",
      "Epoch: [296][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.541 (4.411)\n",
      "Epoch: [296][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.582 (4.462)\n",
      "Val: [0/9]\tTime  0.560 ( 0.560)\tLoss (MSE) 2.175 (2.175)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.911\tL1 0.597\tG-Mean 0.258\n",
      " * Many: MSE 2.301\tL1 1.015\tG-Mean 0.869\n",
      " * Median: MSE 2.190\tL1 1.417\tG-Mean 1.362\n",
      " * Low: MSE 0.120\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #296: Train loss [4.5701]; Val loss: MSE [1.9112], L1 [0.5970], G-Mean [0.2580]\n",
      "Epoch: [297][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 4.395 (4.395)\n",
      "Epoch: [297][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0599)\tLoss (MSE) 3.669 (5.611)\n",
      "Epoch: [297][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 3.587 (4.846)\n",
      "Epoch: [297][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 3.689 (4.590)\n",
      "Epoch: [297][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 4.874 (4.549)\n",
      "Epoch: [297][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.327 (4.492)\n",
      "Epoch: [297][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 5.815 (4.548)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.092 (2.092)\tLoss (L1) 0.662 (0.662)\n",
      " * Overall: MSE 1.888\tL1 0.603\tG-Mean 0.264\n",
      " * Many: MSE 2.327\tL1 1.047\tG-Mean 0.908\n",
      " * Median: MSE 2.065\tL1 1.371\tG-Mean 1.315\n",
      " * Low: MSE 0.089\tL1 0.181\tG-Mean 0.161\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #297: Train loss [4.4955]; Val loss: MSE [1.8877], L1 [0.6029], G-Mean [0.2638]\n",
      "Epoch: [298][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 5.033 (5.033)\n",
      "Epoch: [298][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 2.898 (4.570)\n",
      "Epoch: [298][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.991 (4.743)\n",
      "Epoch: [298][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 4.022 (4.597)\n",
      "Epoch: [298][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 6.757 (4.477)\n",
      "Epoch: [298][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 2.686 (4.387)\n",
      "Epoch: [298][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.550 (4.429)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.166 (2.166)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.949\tL1 0.590\tG-Mean 0.266\n",
      " * Many: MSE 2.270\tL1 0.972\tG-Mean 0.819\n",
      " * Median: MSE 2.279\tL1 1.435\tG-Mean 1.333\n",
      " * Low: MSE 0.151\tL1 0.275\tG-Mean 0.255\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #298: Train loss [4.4603]; Val loss: MSE [1.9486], L1 [0.5902], G-Mean [0.2656]\n",
      "Epoch: [299][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 5.553 (5.553)\n",
      "Epoch: [299][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0528)\tLoss (MSE) 4.066 (4.523)\n",
      "Epoch: [299][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 5.830 (4.351)\n",
      "Epoch: [299][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.872 (4.359)\n",
      "Epoch: [299][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 6.074 (4.441)\n",
      "Epoch: [299][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 7.111 (4.460)\n",
      "Epoch: [299][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.973 (4.294)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.661 (0.661)\n",
      " * Overall: MSE 1.932\tL1 0.620\tG-Mean 0.282\n",
      " * Many: MSE 2.444\tL1 1.085\tG-Mean 0.942\n",
      " * Median: MSE 1.954\tL1 1.322\tG-Mean 1.248\n",
      " * Low: MSE 0.099\tL1 0.162\tG-Mean 0.131\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #299: Train loss [4.3115]; Val loss: MSE [1.9317], L1 [0.6202], G-Mean [0.2820]\n",
      "Epoch: [300][ 0/65]\tTime   0.57 (  0.57)\tData 0.5614 (0.5614)\tLoss (MSE) 5.187 (5.187)\n",
      "Epoch: [300][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0546)\tLoss (MSE) 2.459 (4.493)\n",
      "Epoch: [300][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.674 (4.201)\n",
      "Epoch: [300][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 5.773 (4.306)\n",
      "Epoch: [300][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.032 (4.363)\n",
      "Epoch: [300][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 2.743 (4.319)\n",
      "Epoch: [300][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.214 (4.249)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.104 (2.104)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.958\tL1 0.601\tG-Mean 0.263\n",
      " * Many: MSE 2.360\tL1 1.016\tG-Mean 0.865\n",
      " * Median: MSE 2.153\tL1 1.391\tG-Mean 1.301\n",
      " * Low: MSE 0.125\tL1 0.235\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #300: Train loss [4.2361]; Val loss: MSE [1.9582], L1 [0.6010], G-Mean [0.2632]\n",
      "Epoch: [301][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 7.400 (7.400)\n",
      "Epoch: [301][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0535)\tLoss (MSE) 6.949 (4.680)\n",
      "Epoch: [301][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 5.476 (4.200)\n",
      "Epoch: [301][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 1.955 (4.259)\n",
      "Epoch: [301][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.419 (4.265)\n",
      "Epoch: [301][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.577 (4.150)\n",
      "Epoch: [301][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.801 (4.163)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.107 (2.107)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.950\tL1 0.604\tG-Mean 0.264\n",
      " * Many: MSE 2.377\tL1 1.032\tG-Mean 0.883\n",
      " * Median: MSE 2.107\tL1 1.375\tG-Mean 1.280\n",
      " * Low: MSE 0.125\tL1 0.220\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #301: Train loss [4.1835]; Val loss: MSE [1.9502], L1 [0.6039], G-Mean [0.2644]\n",
      "Epoch: [302][ 0/65]\tTime   0.56 (  0.56)\tData 0.5579 (0.5579)\tLoss (MSE) 5.829 (5.829)\n",
      "Epoch: [302][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 4.349 (4.494)\n",
      "Epoch: [302][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 2.397 (4.368)\n",
      "Epoch: [302][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 6.242 (4.312)\n",
      "Epoch: [302][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.025 (4.106)\n",
      "Epoch: [302][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.880 (4.109)\n",
      "Epoch: [302][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.417 (4.152)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.952\tL1 0.606\tG-Mean 0.263\n",
      " * Many: MSE 2.391\tL1 1.039\tG-Mean 0.890\n",
      " * Median: MSE 2.087\tL1 1.369\tG-Mean 1.291\n",
      " * Low: MSE 0.127\tL1 0.214\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #302: Train loss [4.2180]; Val loss: MSE [1.9522], L1 [0.6059], G-Mean [0.2634]\n",
      "Epoch: [303][ 0/65]\tTime   0.58 (  0.58)\tData 0.5686 (0.5686)\tLoss (MSE) 4.006 (4.006)\n",
      "Epoch: [303][10/65]\tTime   0.00 (  0.07)\tData 0.0001 (0.0633)\tLoss (MSE) 3.770 (3.819)\n",
      "Epoch: [303][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0332)\tLoss (MSE) 3.669 (4.082)\n",
      "Epoch: [303][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0225)\tLoss (MSE) 3.215 (4.388)\n",
      "Epoch: [303][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0170)\tLoss (MSE) 8.116 (4.233)\n",
      "Epoch: [303][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.194 (4.153)\n",
      "Epoch: [303][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 2.551 (4.094)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.118 (2.118)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.948\tL1 0.606\tG-Mean 0.265\n",
      " * Many: MSE 2.390\tL1 1.041\tG-Mean 0.893\n",
      " * Median: MSE 2.078\tL1 1.363\tG-Mean 1.266\n",
      " * Low: MSE 0.123\tL1 0.211\tG-Mean 0.182\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #303: Train loss [4.1939]; Val loss: MSE [1.9476], L1 [0.6062], G-Mean [0.2646]\n",
      "Epoch: [304][ 0/65]\tTime   0.56 (  0.56)\tData 0.5546 (0.5546)\tLoss (MSE) 3.249 (3.249)\n",
      "Epoch: [304][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 3.592 (4.331)\n",
      "Epoch: [304][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 3.506 (4.208)\n",
      "Epoch: [304][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.312 (4.392)\n",
      "Epoch: [304][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.160 (4.325)\n",
      "Epoch: [304][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.002 (4.265)\n",
      "Epoch: [304][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.438 (4.186)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.105 (2.105)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.940\tL1 0.604\tG-Mean 0.264\n",
      " * Many: MSE 2.372\tL1 1.035\tG-Mean 0.888\n",
      " * Median: MSE 2.093\tL1 1.369\tG-Mean 1.273\n",
      " * Low: MSE 0.120\tL1 0.215\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #304: Train loss [4.2294]; Val loss: MSE [1.9403], L1 [0.6040], G-Mean [0.2637]\n",
      "Epoch: [305][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 5.648 (5.648)\n",
      "Epoch: [305][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0536)\tLoss (MSE) 5.526 (4.509)\n",
      "Epoch: [305][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 5.848 (4.486)\n",
      "Epoch: [305][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 5.334 (4.398)\n",
      "Epoch: [305][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.622 (4.529)\n",
      "Epoch: [305][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 2.495 (4.340)\n",
      "Epoch: [305][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.732 (4.256)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.129 (2.129)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.950\tL1 0.596\tG-Mean 0.266\n",
      " * Many: MSE 2.322\tL1 0.999\tG-Mean 0.847\n",
      " * Median: MSE 2.202\tL1 1.406\tG-Mean 1.297\n",
      " * Low: MSE 0.130\tL1 0.250\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #305: Train loss [4.1725]; Val loss: MSE [1.9500], L1 [0.5960], G-Mean [0.2662]\n",
      "Epoch: [306][ 0/65]\tTime   0.56 (  0.56)\tData 0.5494 (0.5494)\tLoss (MSE) 9.118 (9.118)\n",
      "Epoch: [306][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 3.700 (4.340)\n",
      "Epoch: [306][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 6.820 (4.430)\n",
      "Epoch: [306][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.644 (4.320)\n",
      "Epoch: [306][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.798 (4.031)\n",
      "Epoch: [306][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.033 (4.067)\n",
      "Epoch: [306][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.635 (4.115)\n",
      "Val: [0/9]\tTime  0.620 ( 0.620)\tLoss (MSE) 2.115 (2.115)\tLoss (L1) 0.658 (0.658)\n",
      " * Overall: MSE 1.939\tL1 0.610\tG-Mean 0.266\n",
      " * Many: MSE 2.407\tL1 1.057\tG-Mean 0.911\n",
      " * Median: MSE 2.032\tL1 1.345\tG-Mean 1.235\n",
      " * Low: MSE 0.109\tL1 0.192\tG-Mean 0.163\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #306: Train loss [4.1366]; Val loss: MSE [1.9391], L1 [0.6100], G-Mean [0.2659]\n",
      "Epoch: [307][ 0/65]\tTime   0.57 (  0.57)\tData 0.5626 (0.5626)\tLoss (MSE) 2.829 (2.829)\n",
      "Epoch: [307][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0533)\tLoss (MSE) 4.165 (3.806)\n",
      "Epoch: [307][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 4.860 (3.961)\n",
      "Epoch: [307][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.108 (4.010)\n",
      "Epoch: [307][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.280 (3.911)\n",
      "Epoch: [307][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.836 (3.967)\n",
      "Epoch: [307][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 5.017 (4.121)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.943\tL1 0.598\tG-Mean 0.263\n",
      " * Many: MSE 2.337\tL1 1.011\tG-Mean 0.861\n",
      " * Median: MSE 2.161\tL1 1.390\tG-Mean 1.221\n",
      " * Low: MSE 0.126\tL1 0.238\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #307: Train loss [4.1076]; Val loss: MSE [1.9434], L1 [0.5981], G-Mean [0.2632]\n",
      "Epoch: [308][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 5.945 (5.945)\n",
      "Epoch: [308][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 6.728 (4.567)\n",
      "Epoch: [308][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 5.176 (4.096)\n",
      "Epoch: [308][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.150 (4.250)\n",
      "Epoch: [308][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.774 (4.264)\n",
      "Epoch: [308][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 10.107 (4.280)\n",
      "Epoch: [308][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.285 (4.162)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.097 (2.097)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.937\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.347\tL1 1.021\tG-Mean 0.872\n",
      " * Median: MSE 2.132\tL1 1.382\tG-Mean 1.281\n",
      " * Low: MSE 0.113\tL1 0.226\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #308: Train loss [4.1419]; Val loss: MSE [1.9370], L1 [0.5995], G-Mean [0.2614]\n",
      "Epoch: [309][ 0/65]\tTime   0.55 (  0.55)\tData 0.5482 (0.5482)\tLoss (MSE) 4.858 (4.858)\n",
      "Epoch: [309][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0513)\tLoss (MSE) 2.222 (4.020)\n",
      "Epoch: [309][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.987 (4.208)\n",
      "Epoch: [309][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.612 (4.043)\n",
      "Epoch: [309][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.920 (4.247)\n",
      "Epoch: [309][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.756 (4.069)\n",
      "Epoch: [309][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.586 (4.061)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.938\tL1 0.601\tG-Mean 0.263\n",
      " * Many: MSE 2.355\tL1 1.025\tG-Mean 0.877\n",
      " * Median: MSE 2.120\tL1 1.379\tG-Mean 1.293\n",
      " * Low: MSE 0.105\tL1 0.219\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #309: Train loss [4.0608]; Val loss: MSE [1.9382], L1 [0.6009], G-Mean [0.2633]\n",
      "Epoch: [310][ 0/65]\tTime   0.57 (  0.57)\tData 0.5592 (0.5592)\tLoss (MSE) 3.980 (3.980)\n",
      "Epoch: [310][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0556)\tLoss (MSE) 7.215 (4.295)\n",
      "Epoch: [310][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 2.728 (4.187)\n",
      "Epoch: [310][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.410 (4.137)\n",
      "Epoch: [310][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 7.595 (4.248)\n",
      "Epoch: [310][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.287 (4.125)\n",
      "Epoch: [310][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.748 (4.133)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.097 (2.097)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.937\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.375\tL1 1.038\tG-Mean 0.891\n",
      " * Median: MSE 2.084\tL1 1.365\tG-Mean 1.261\n",
      " * Low: MSE 0.104\tL1 0.207\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #310: Train loss [4.1704]; Val loss: MSE [1.9374], L1 [0.6045], G-Mean [0.2626]\n",
      "Epoch: [311][ 0/65]\tTime   0.57 (  0.57)\tData 0.5600 (0.5600)\tLoss (MSE) 6.831 (6.831)\n",
      "Epoch: [311][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 5.301 (4.372)\n",
      "Epoch: [311][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 2.461 (4.109)\n",
      "Epoch: [311][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.922 (4.207)\n",
      "Epoch: [311][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.090 (4.146)\n",
      "Epoch: [311][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.569 (4.109)\n",
      "Epoch: [311][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.717 (4.109)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.116 (2.116)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.948\tL1 0.602\tG-Mean 0.262\n",
      " * Many: MSE 2.364\tL1 1.025\tG-Mean 0.875\n",
      " * Median: MSE 2.126\tL1 1.379\tG-Mean 1.274\n",
      " * Low: MSE 0.110\tL1 0.223\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #311: Train loss [4.0840]; Val loss: MSE [1.9481], L1 [0.6018], G-Mean [0.2621]\n",
      "Epoch: [312][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 3.153 (3.153)\n",
      "Epoch: [312][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 4.255 (3.743)\n",
      "Epoch: [312][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 3.390 (4.277)\n",
      "Epoch: [312][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.480 (4.081)\n",
      "Epoch: [312][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.435 (4.097)\n",
      "Epoch: [312][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.465 (4.011)\n",
      "Epoch: [312][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.856 (4.064)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.941\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.372\tL1 1.035\tG-Mean 0.886\n",
      " * Median: MSE 2.097\tL1 1.370\tG-Mean 1.246\n",
      " * Low: MSE 0.105\tL1 0.211\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #312: Train loss [4.0982]; Val loss: MSE [1.9415], L1 [0.6038], G-Mean [0.2621]\n",
      "Epoch: [313][ 0/65]\tTime   0.57 (  0.57)\tData 0.5641 (0.5641)\tLoss (MSE) 6.889 (6.889)\n",
      "Epoch: [313][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0596)\tLoss (MSE) 5.731 (4.472)\n",
      "Epoch: [313][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 6.809 (4.639)\n",
      "Epoch: [313][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 2.393 (4.223)\n",
      "Epoch: [313][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 2.402 (4.297)\n",
      "Epoch: [313][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 5.388 (4.162)\n",
      "Epoch: [313][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 4.991 (4.166)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.113 (2.113)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.941\tL1 0.602\tG-Mean 0.262\n",
      " * Many: MSE 2.360\tL1 1.028\tG-Mean 0.879\n",
      " * Median: MSE 2.114\tL1 1.376\tG-Mean 1.245\n",
      " * Low: MSE 0.103\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #313: Train loss [4.1511]; Val loss: MSE [1.9406], L1 [0.6015], G-Mean [0.2623]\n",
      "Epoch: [314][ 0/65]\tTime   0.55 (  0.55)\tData 0.5474 (0.5474)\tLoss (MSE) 4.012 (4.012)\n",
      "Epoch: [314][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 4.774 (4.137)\n",
      "Epoch: [314][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0295)\tLoss (MSE) 3.687 (4.069)\n",
      "Epoch: [314][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0200)\tLoss (MSE) 2.264 (3.810)\n",
      "Epoch: [314][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 6.868 (3.908)\n",
      "Epoch: [314][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 5.715 (3.991)\n",
      "Epoch: [314][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.838 (4.058)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.103 (2.103)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.935\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.373\tL1 1.039\tG-Mean 0.891\n",
      " * Median: MSE 2.081\tL1 1.364\tG-Mean 1.270\n",
      " * Low: MSE 0.098\tL1 0.204\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #314: Train loss [4.1172]; Val loss: MSE [1.9355], L1 [0.6039], G-Mean [0.2617]\n",
      "Epoch: [315][ 0/65]\tTime   0.56 (  0.56)\tData 0.5586 (0.5586)\tLoss (MSE) 1.667 (1.667)\n",
      "Epoch: [315][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0570)\tLoss (MSE) 3.677 (4.062)\n",
      "Epoch: [315][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 2.393 (3.790)\n",
      "Epoch: [315][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 3.712 (4.010)\n",
      "Epoch: [315][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.694 (3.950)\n",
      "Epoch: [315][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.363 (3.986)\n",
      "Epoch: [315][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.019 (3.966)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.105 (2.105)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.946\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.375\tL1 1.032\tG-Mean 0.883\n",
      " * Median: MSE 2.103\tL1 1.371\tG-Mean 1.248\n",
      " * Low: MSE 0.103\tL1 0.213\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #315: Train loss [4.0720]; Val loss: MSE [1.9462], L1 [0.6029], G-Mean [0.2619]\n",
      "Epoch: [316][ 0/65]\tTime   0.55 (  0.55)\tData 0.5485 (0.5485)\tLoss (MSE) 1.705 (1.705)\n",
      "Epoch: [316][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 3.542 (4.160)\n",
      "Epoch: [316][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.957 (4.133)\n",
      "Epoch: [316][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.313 (3.888)\n",
      "Epoch: [316][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.105 (3.980)\n",
      "Epoch: [316][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 9.113 (4.097)\n",
      "Epoch: [316][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.506 (4.116)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.110 (2.110)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.940\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.378\tL1 1.038\tG-Mean 0.891\n",
      " * Median: MSE 2.083\tL1 1.365\tG-Mean 1.276\n",
      " * Low: MSE 0.098\tL1 0.204\tG-Mean 0.180\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #316: Train loss [4.1821]; Val loss: MSE [1.9405], L1 [0.6042], G-Mean [0.2624]\n",
      "Epoch: [317][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 4.033 (4.033)\n",
      "Epoch: [317][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0551)\tLoss (MSE) 4.147 (4.009)\n",
      "Epoch: [317][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 5.215 (4.174)\n",
      "Epoch: [317][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.956 (4.292)\n",
      "Epoch: [317][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 5.359 (4.238)\n",
      "Epoch: [317][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.613 (4.219)\n",
      "Epoch: [317][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.019 (4.137)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.128 (2.128)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.949\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.363\tL1 1.024\tG-Mean 0.873\n",
      " * Median: MSE 2.129\tL1 1.380\tG-Mean 1.253\n",
      " * Low: MSE 0.108\tL1 0.222\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #317: Train loss [4.1011]; Val loss: MSE [1.9489], L1 [0.6014], G-Mean [0.2613]\n",
      "Epoch: [318][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 3.256 (3.256)\n",
      "Epoch: [318][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 3.474 (4.052)\n",
      "Epoch: [318][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 7.797 (4.380)\n",
      "Epoch: [318][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.996 (4.462)\n",
      "Epoch: [318][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.619 (4.149)\n",
      "Epoch: [318][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.152 (4.114)\n",
      "Epoch: [318][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.436 (4.133)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.943\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.358\tL1 1.024\tG-Mean 0.874\n",
      " * Median: MSE 2.125\tL1 1.380\tG-Mean 1.262\n",
      " * Low: MSE 0.108\tL1 0.220\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #318: Train loss [4.1131]; Val loss: MSE [1.9435], L1 [0.6008], G-Mean [0.2616]\n",
      "Epoch: [319][ 0/65]\tTime   0.57 (  0.57)\tData 0.5640 (0.5640)\tLoss (MSE) 1.897 (1.897)\n",
      "Epoch: [319][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 4.474 (4.350)\n",
      "Epoch: [319][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.623 (4.183)\n",
      "Epoch: [319][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.407 (4.371)\n",
      "Epoch: [319][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.252 (4.350)\n",
      "Epoch: [319][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.590 (4.138)\n",
      "Epoch: [319][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.530 (4.092)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.941\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.364\tL1 1.030\tG-Mean 0.881\n",
      " * Median: MSE 2.108\tL1 1.375\tG-Mean 1.280\n",
      " * Low: MSE 0.105\tL1 0.214\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #319: Train loss [4.1203]; Val loss: MSE [1.9408], L1 [0.6019], G-Mean [0.2612]\n",
      "Epoch: [320][ 0/65]\tTime   0.56 (  0.56)\tData 0.5530 (0.5530)\tLoss (MSE) 2.631 (2.631)\n",
      "Epoch: [320][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0614)\tLoss (MSE) 4.458 (4.101)\n",
      "Epoch: [320][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0322)\tLoss (MSE) 3.603 (4.105)\n",
      "Epoch: [320][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 3.874 (4.084)\n",
      "Epoch: [320][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 2.277 (3.914)\n",
      "Epoch: [320][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 7.752 (3.973)\n",
      "Epoch: [320][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.484 (4.031)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.116 (2.116)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.938\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.364\tL1 1.032\tG-Mean 0.883\n",
      " * Median: MSE 2.102\tL1 1.373\tG-Mean 1.281\n",
      " * Low: MSE 0.104\tL1 0.212\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #320: Train loss [4.0498]; Val loss: MSE [1.9381], L1 [0.6022], G-Mean [0.2607]\n",
      "Epoch: [321][ 0/65]\tTime   0.56 (  0.56)\tData 0.5554 (0.5554)\tLoss (MSE) 4.121 (4.121)\n",
      "Epoch: [321][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 3.403 (4.118)\n",
      "Epoch: [321][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 4.183 (3.958)\n",
      "Epoch: [321][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 3.939 (4.110)\n",
      "Epoch: [321][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 5.937 (4.136)\n",
      "Epoch: [321][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.404 (4.185)\n",
      "Epoch: [321][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.429 (4.099)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.926\tL1 0.606\tG-Mean 0.262\n",
      " * Many: MSE 2.376\tL1 1.048\tG-Mean 0.902\n",
      " * Median: MSE 2.053\tL1 1.353\tG-Mean 1.241\n",
      " * Low: MSE 0.094\tL1 0.193\tG-Mean 0.168\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #321: Train loss [4.1203]; Val loss: MSE [1.9256], L1 [0.6060], G-Mean [0.2619]\n",
      "Epoch: [322][ 0/65]\tTime   0.67 (  0.67)\tData 0.6678 (0.6678)\tLoss (MSE) 4.926 (4.926)\n",
      "Epoch: [322][10/65]\tTime   0.00 (  0.08)\tData 0.0000 (0.0692)\tLoss (MSE) 3.913 (4.130)\n",
      "Epoch: [322][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0362)\tLoss (MSE) 4.457 (4.433)\n",
      "Epoch: [322][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0246)\tLoss (MSE) 2.990 (4.462)\n",
      "Epoch: [322][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 4.500 (4.188)\n",
      "Epoch: [322][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 7.033 (4.150)\n",
      "Epoch: [322][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.987 (4.145)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.141 (2.141)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.947\tL1 0.593\tG-Mean 0.266\n",
      " * Many: MSE 2.298\tL1 0.987\tG-Mean 0.834\n",
      " * Median: MSE 2.234\tL1 1.419\tG-Mean 1.333\n",
      " * Low: MSE 0.115\tL1 0.256\tG-Mean 0.235\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #322: Train loss [4.1215]; Val loss: MSE [1.9470], L1 [0.5928], G-Mean [0.2665]\n",
      "Epoch: [323][ 0/65]\tTime   0.56 (  0.56)\tData 0.5511 (0.5511)\tLoss (MSE) 4.806 (4.806)\n",
      "Epoch: [323][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 2.490 (3.726)\n",
      "Epoch: [323][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 4.481 (4.003)\n",
      "Epoch: [323][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 2.325 (3.820)\n",
      "Epoch: [323][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.113 (3.921)\n",
      "Epoch: [323][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 3.670 (3.909)\n",
      "Epoch: [323][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.692 (4.043)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.131 (2.131)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.935\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.330\tL1 1.014\tG-Mean 0.864\n",
      " * Median: MSE 2.152\tL1 1.390\tG-Mean 1.294\n",
      " * Low: MSE 0.105\tL1 0.228\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #323: Train loss [4.0936]; Val loss: MSE [1.9350], L1 [0.5974], G-Mean [0.2621]\n",
      "Epoch: [324][ 0/65]\tTime   0.56 (  0.56)\tData 0.5511 (0.5511)\tLoss (MSE) 4.550 (4.550)\n",
      "Epoch: [324][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 2.703 (4.486)\n",
      "Epoch: [324][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.295 (4.099)\n",
      "Epoch: [324][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.330 (3.969)\n",
      "Epoch: [324][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 5.796 (4.068)\n",
      "Epoch: [324][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.454 (3.996)\n",
      "Epoch: [324][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.179 (3.975)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.117 (2.117)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.934\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.369\tL1 1.038\tG-Mean 0.890\n",
      " * Median: MSE 2.084\tL1 1.366\tG-Mean 1.260\n",
      " * Low: MSE 0.098\tL1 0.205\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #324: Train loss [4.0853]; Val loss: MSE [1.9343], L1 [0.6036], G-Mean [0.2618]\n",
      "Epoch: [325][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.024 (5.024)\n",
      "Epoch: [325][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 3.920 (3.779)\n",
      "Epoch: [325][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 6.827 (4.127)\n",
      "Epoch: [325][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.301 (4.084)\n",
      "Epoch: [325][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.853 (4.182)\n",
      "Epoch: [325][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.679 (4.029)\n",
      "Epoch: [325][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.675 (4.104)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.134 (2.134)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.941\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.353\tL1 1.024\tG-Mean 0.874\n",
      " * Median: MSE 2.127\tL1 1.382\tG-Mean 1.288\n",
      " * Low: MSE 0.105\tL1 0.220\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #325: Train loss [4.0256]; Val loss: MSE [1.9409], L1 [0.6005], G-Mean [0.2613]\n",
      "Epoch: [326][ 0/65]\tTime   0.56 (  0.56)\tData 0.5601 (0.5601)\tLoss (MSE) 4.365 (4.365)\n",
      "Epoch: [326][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 2.074 (4.121)\n",
      "Epoch: [326][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 2.984 (4.306)\n",
      "Epoch: [326][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.556 (4.210)\n",
      "Epoch: [326][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.861 (4.053)\n",
      "Epoch: [326][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.114 (4.287)\n",
      "Epoch: [326][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.461 (4.150)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.131 (2.131)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.940\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.369\tL1 1.034\tG-Mean 0.885\n",
      " * Median: MSE 2.097\tL1 1.370\tG-Mean 1.273\n",
      " * Low: MSE 0.099\tL1 0.210\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #326: Train loss [4.0689]; Val loss: MSE [1.9403], L1 [0.6032], G-Mean [0.2618]\n",
      "Epoch: [327][ 0/65]\tTime   0.56 (  0.56)\tData 0.5501 (0.5501)\tLoss (MSE) 2.831 (2.831)\n",
      "Epoch: [327][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 3.266 (3.233)\n",
      "Epoch: [327][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.085 (3.688)\n",
      "Epoch: [327][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.417 (3.842)\n",
      "Epoch: [327][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.056 (3.975)\n",
      "Epoch: [327][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.748 (3.891)\n",
      "Epoch: [327][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.731 (3.924)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.127 (2.127)\tLoss (L1) 0.657 (0.657)\n",
      " * Overall: MSE 1.941\tL1 0.606\tG-Mean 0.262\n",
      " * Many: MSE 2.383\tL1 1.042\tG-Mean 0.894\n",
      " * Median: MSE 2.077\tL1 1.366\tG-Mean 1.290\n",
      " * Low: MSE 0.099\tL1 0.203\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #327: Train loss [4.0786]; Val loss: MSE [1.9411], L1 [0.6056], G-Mean [0.2623]\n",
      "Epoch: [328][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 2.689 (2.689)\n",
      "Epoch: [328][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 8.928 (3.554)\n",
      "Epoch: [328][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 3.715 (3.681)\n",
      "Epoch: [328][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 3.707 (3.903)\n",
      "Epoch: [328][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.468 (4.048)\n",
      "Epoch: [328][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.903 (4.023)\n",
      "Epoch: [328][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.295 (3.987)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.131 (2.131)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.947\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.349\tL1 1.018\tG-Mean 0.867\n",
      " * Median: MSE 2.147\tL1 1.390\tG-Mean 1.309\n",
      " * Low: MSE 0.108\tL1 0.226\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #328: Train loss [3.9778]; Val loss: MSE [1.9466], L1 [0.5999], G-Mean [0.2623]\n",
      "Epoch: [329][ 0/65]\tTime   0.55 (  0.55)\tData 0.5407 (0.5407)\tLoss (MSE) 5.158 (5.158)\n",
      "Epoch: [329][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0502)\tLoss (MSE) 6.422 (3.787)\n",
      "Epoch: [329][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0263)\tLoss (MSE) 3.489 (3.653)\n",
      "Epoch: [329][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0178)\tLoss (MSE) 2.655 (4.055)\n",
      "Epoch: [329][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 3.429 (3.960)\n",
      "Epoch: [329][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.330 (3.982)\n",
      "Epoch: [329][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 4.287 (3.966)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.114 (2.114)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.946\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.356\tL1 1.023\tG-Mean 0.872\n",
      " * Median: MSE 2.133\tL1 1.385\tG-Mean 1.307\n",
      " * Low: MSE 0.106\tL1 0.222\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #329: Train loss [4.0343]; Val loss: MSE [1.9458], L1 [0.6009], G-Mean [0.2618]\n",
      "Epoch: [330][ 0/65]\tTime   0.55 (  0.55)\tData 0.5463 (0.5463)\tLoss (MSE) 5.400 (5.400)\n",
      "Epoch: [330][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 3.578 (4.177)\n",
      "Epoch: [330][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 5.579 (4.356)\n",
      "Epoch: [330][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.288 (4.246)\n",
      "Epoch: [330][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.243 (4.143)\n",
      "Epoch: [330][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.699 (4.209)\n",
      "Epoch: [330][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.638 (4.164)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.106 (2.106)\tLoss (L1) 0.655 (0.655)\n",
      " * Overall: MSE 1.934\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.376\tL1 1.042\tG-Mean 0.895\n",
      " * Median: MSE 2.072\tL1 1.362\tG-Mean 1.276\n",
      " * Low: MSE 0.095\tL1 0.201\tG-Mean 0.176\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #330: Train loss [4.1327]; Val loss: MSE [1.9345], L1 [0.6049], G-Mean [0.2625]\n",
      "Epoch: [331][ 0/65]\tTime   0.56 (  0.56)\tData 0.5532 (0.5532)\tLoss (MSE) 4.543 (4.543)\n",
      "Epoch: [331][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 5.110 (4.181)\n",
      "Epoch: [331][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 4.399 (4.239)\n",
      "Epoch: [331][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 2.152 (4.195)\n",
      "Epoch: [331][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.938 (4.228)\n",
      "Epoch: [331][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.018 (4.251)\n",
      "Epoch: [331][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.908 (4.195)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.102 (2.102)\tLoss (L1) 0.653 (0.653)\n",
      " * Overall: MSE 1.932\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.357\tL1 1.032\tG-Mean 0.884\n",
      " * Median: MSE 2.104\tL1 1.376\tG-Mean 1.294\n",
      " * Low: MSE 0.101\tL1 0.210\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #331: Train loss [4.1603]; Val loss: MSE [1.9323], L1 [0.6022], G-Mean [0.2610]\n",
      "Epoch: [332][ 0/65]\tTime   0.55 (  0.55)\tData 0.5504 (0.5504)\tLoss (MSE) 3.477 (3.477)\n",
      "Epoch: [332][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 3.486 (4.050)\n",
      "Epoch: [332][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.356 (4.102)\n",
      "Epoch: [332][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.076 (4.206)\n",
      "Epoch: [332][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.944 (4.277)\n",
      "Epoch: [332][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.273 (4.210)\n",
      "Epoch: [332][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.535 (4.107)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.129 (2.129)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.949\tL1 0.594\tG-Mean 0.266\n",
      " * Many: MSE 2.303\tL1 0.989\tG-Mean 0.836\n",
      " * Median: MSE 2.234\tL1 1.422\tG-Mean 1.343\n",
      " * Low: MSE 0.116\tL1 0.254\tG-Mean 0.235\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #332: Train loss [4.0785]; Val loss: MSE [1.9491], L1 [0.5938], G-Mean [0.2657]\n",
      "Epoch: [333][ 0/65]\tTime   0.57 (  0.57)\tData 0.5627 (0.5627)\tLoss (MSE) 4.197 (4.197)\n",
      "Epoch: [333][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 4.138 (4.210)\n",
      "Epoch: [333][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 2.619 (4.395)\n",
      "Epoch: [333][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 1.697 (4.248)\n",
      "Epoch: [333][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.114 (4.259)\n",
      "Epoch: [333][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 5.111 (4.206)\n",
      "Epoch: [333][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.893 (4.119)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.099 (2.099)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.930\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.335\tL1 1.020\tG-Mean 0.872\n",
      " * Median: MSE 2.138\tL1 1.390\tG-Mean 1.313\n",
      " * Low: MSE 0.099\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #333: Train loss [4.0542]; Val loss: MSE [1.9298], L1 [0.5991], G-Mean [0.2598]\n",
      "Epoch: [334][ 0/65]\tTime   0.57 (  0.57)\tData 0.5630 (0.5630)\tLoss (MSE) 2.184 (2.184)\n",
      "Epoch: [334][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 3.783 (3.596)\n",
      "Epoch: [334][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0306)\tLoss (MSE) 6.586 (3.826)\n",
      "Epoch: [334][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 3.261 (3.833)\n",
      "Epoch: [334][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 2.471 (3.894)\n",
      "Epoch: [334][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.186 (3.985)\n",
      "Epoch: [334][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.656 (4.054)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.103 (2.103)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.936\tL1 0.602\tG-Mean 0.263\n",
      " * Many: MSE 2.357\tL1 1.029\tG-Mean 0.881\n",
      " * Median: MSE 2.113\tL1 1.381\tG-Mean 1.312\n",
      " * Low: MSE 0.100\tL1 0.213\tG-Mean 0.188\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #334: Train loss [4.0190]; Val loss: MSE [1.9358], L1 [0.6023], G-Mean [0.2632]\n",
      "Epoch: [335][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 3.822 (3.822)\n",
      "Epoch: [335][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 5.751 (4.357)\n",
      "Epoch: [335][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.469 (4.235)\n",
      "Epoch: [335][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.660 (4.585)\n",
      "Epoch: [335][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.884 (4.337)\n",
      "Epoch: [335][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.047 (4.178)\n",
      "Epoch: [335][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.316 (4.151)\n",
      "Val: [0/9]\tTime  0.573 ( 0.573)\tLoss (MSE) 2.097 (2.097)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.934\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.347\tL1 1.026\tG-Mean 0.877\n",
      " * Median: MSE 2.123\tL1 1.383\tG-Mean 1.295\n",
      " * Low: MSE 0.100\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #335: Train loss [4.1435]; Val loss: MSE [1.9337], L1 [0.6012], G-Mean [0.2617]\n",
      "Epoch: [336][ 0/65]\tTime   0.68 (  0.68)\tData 0.6728 (0.6728)\tLoss (MSE) 3.609 (3.609)\n",
      "Epoch: [336][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0636)\tLoss (MSE) 2.935 (3.683)\n",
      "Epoch: [336][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0333)\tLoss (MSE) 5.958 (3.817)\n",
      "Epoch: [336][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0226)\tLoss (MSE) 5.204 (3.860)\n",
      "Epoch: [336][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0171)\tLoss (MSE) 6.045 (3.950)\n",
      "Epoch: [336][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.761 (4.073)\n",
      "Epoch: [336][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.390 (3.991)\n",
      "Val: [0/9]\tTime  0.595 ( 0.595)\tLoss (MSE) 2.100 (2.100)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.939\tL1 0.603\tG-Mean 0.263\n",
      " * Many: MSE 2.357\tL1 1.028\tG-Mean 0.879\n",
      " * Median: MSE 2.118\tL1 1.380\tG-Mean 1.277\n",
      " * Low: MSE 0.102\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #336: Train loss [4.0353]; Val loss: MSE [1.9387], L1 [0.6026], G-Mean [0.2631]\n",
      "Epoch: [337][ 0/65]\tTime   0.55 (  0.55)\tData 0.5446 (0.5446)\tLoss (MSE) 2.585 (2.585)\n",
      "Epoch: [337][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 2.934 (2.908)\n",
      "Epoch: [337][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 4.379 (3.388)\n",
      "Epoch: [337][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 6.062 (3.505)\n",
      "Epoch: [337][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.619 (3.669)\n",
      "Epoch: [337][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.747 (3.851)\n",
      "Epoch: [337][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.726 (3.857)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.109 (2.109)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.939\tL1 0.598\tG-Mean 0.264\n",
      " * Many: MSE 2.329\tL1 1.011\tG-Mean 0.860\n",
      " * Median: MSE 2.167\tL1 1.398\tG-Mean 1.311\n",
      " * Low: MSE 0.109\tL1 0.232\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #337: Train loss [3.9403]; Val loss: MSE [1.9392], L1 [0.5984], G-Mean [0.2643]\n",
      "Epoch: [338][ 0/65]\tTime   0.56 (  0.56)\tData 0.5544 (0.5544)\tLoss (MSE) 3.339 (3.339)\n",
      "Epoch: [338][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0569)\tLoss (MSE) 3.518 (4.817)\n",
      "Epoch: [338][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 6.168 (4.410)\n",
      "Epoch: [338][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 5.986 (4.238)\n",
      "Epoch: [338][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.882 (4.207)\n",
      "Epoch: [338][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.841 (4.189)\n",
      "Epoch: [338][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.829 (4.045)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.122 (2.122)\tLoss (L1) 0.651 (0.651)\n",
      " * Overall: MSE 1.940\tL1 0.597\tG-Mean 0.264\n",
      " * Many: MSE 2.324\tL1 1.007\tG-Mean 0.857\n",
      " * Median: MSE 2.176\tL1 1.403\tG-Mean 1.329\n",
      " * Low: MSE 0.108\tL1 0.235\tG-Mean 0.216\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #338: Train loss [4.0260]; Val loss: MSE [1.9399], L1 [0.5973], G-Mean [0.2643]\n",
      "Epoch: [339][ 0/65]\tTime   0.56 (  0.56)\tData 0.5589 (0.5589)\tLoss (MSE) 2.602 (2.602)\n",
      "Epoch: [339][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 3.107 (3.679)\n",
      "Epoch: [339][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 5.313 (3.958)\n",
      "Epoch: [339][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.629 (3.824)\n",
      "Epoch: [339][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.995 (3.965)\n",
      "Epoch: [339][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.299 (4.131)\n",
      "Epoch: [339][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.651 (4.090)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.112 (2.112)\tLoss (L1) 0.656 (0.656)\n",
      " * Overall: MSE 1.934\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.371\tL1 1.040\tG-Mean 0.893\n",
      " * Median: MSE 2.081\tL1 1.368\tG-Mean 1.284\n",
      " * Low: MSE 0.097\tL1 0.203\tG-Mean 0.180\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #339: Train loss [4.0607]; Val loss: MSE [1.9340], L1 [0.6050], G-Mean [0.2625]\n",
      "Epoch: [340][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 2.994 (2.994)\n",
      "Epoch: [340][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 5.646 (3.350)\n",
      "Epoch: [340][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.118 (4.063)\n",
      "Epoch: [340][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.298 (3.842)\n",
      "Epoch: [340][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.927 (3.870)\n",
      "Epoch: [340][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.461 (4.041)\n",
      "Epoch: [340][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.168 (4.021)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.116 (2.116)\tLoss (L1) 0.654 (0.654)\n",
      " * Overall: MSE 1.939\tL1 0.602\tG-Mean 0.263\n",
      " * Many: MSE 2.356\tL1 1.028\tG-Mean 0.879\n",
      " * Median: MSE 2.116\tL1 1.381\tG-Mean 1.307\n",
      " * Low: MSE 0.100\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #340: Train loss [4.0011]; Val loss: MSE [1.9385], L1 [0.6020], G-Mean [0.2634]\n",
      "Epoch: [341][ 0/65]\tTime   0.56 (  0.56)\tData 0.5555 (0.5555)\tLoss (MSE) 3.857 (3.857)\n",
      "Epoch: [341][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 4.575 (4.046)\n",
      "Epoch: [341][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.074 (3.981)\n",
      "Epoch: [341][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.927 (4.118)\n",
      "Epoch: [341][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.108 (4.093)\n",
      "Epoch: [341][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.305 (4.005)\n",
      "Epoch: [341][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.368 (4.102)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.097 (2.097)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.928\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.342\tL1 1.026\tG-Mean 0.878\n",
      " * Median: MSE 2.118\tL1 1.382\tG-Mean 1.303\n",
      " * Low: MSE 0.096\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #341: Train loss [4.0315]; Val loss: MSE [1.9279], L1 [0.6007], G-Mean [0.2624]\n",
      "Epoch: [342][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 4.648 (4.648)\n",
      "Epoch: [342][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 3.291 (4.112)\n",
      "Epoch: [342][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 7.001 (4.174)\n",
      "Epoch: [342][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.203 (4.257)\n",
      "Epoch: [342][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 1.839 (4.035)\n",
      "Epoch: [342][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.883 (4.142)\n",
      "Epoch: [342][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.368 (4.053)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.093 (2.093)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.927\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.020\tG-Mean 0.872\n",
      " * Median: MSE 2.140\tL1 1.393\tG-Mean 1.329\n",
      " * Low: MSE 0.100\tL1 0.220\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #342: Train loss [4.0696]; Val loss: MSE [1.9272], L1 [0.5993], G-Mean [0.2604]\n",
      "Epoch: [343][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 4.650 (4.650)\n",
      "Epoch: [343][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 2.306 (3.545)\n",
      "Epoch: [343][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.718 (4.147)\n",
      "Epoch: [343][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.247 (4.172)\n",
      "Epoch: [343][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.961 (4.089)\n",
      "Epoch: [343][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.540 (4.062)\n",
      "Epoch: [343][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.485 (4.016)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.924\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.342\tL1 1.029\tG-Mean 0.882\n",
      " * Median: MSE 2.113\tL1 1.383\tG-Mean 1.318\n",
      " * Low: MSE 0.099\tL1 0.211\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #343: Train loss [4.0571]; Val loss: MSE [1.9241], L1 [0.6011], G-Mean [0.2613]\n",
      "Epoch: [344][ 0/65]\tTime   0.63 (  0.63)\tData 0.6099 (0.6099)\tLoss (MSE) 3.863 (3.863)\n",
      "Epoch: [344][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0570)\tLoss (MSE) 4.625 (3.939)\n",
      "Epoch: [344][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.050 (4.019)\n",
      "Epoch: [344][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 5.974 (4.032)\n",
      "Epoch: [344][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 5.500 (4.068)\n",
      "Epoch: [344][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.351 (3.939)\n",
      "Epoch: [344][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.628 (4.003)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.094 (2.094)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.926\tL1 0.597\tG-Mean 0.263\n",
      " * Many: MSE 2.318\tL1 1.013\tG-Mean 0.865\n",
      " * Median: MSE 2.161\tL1 1.401\tG-Mean 1.335\n",
      " * Low: MSE 0.101\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #344: Train loss [4.0351]; Val loss: MSE [1.9258], L1 [0.5970], G-Mean [0.2634]\n",
      "Epoch: [345][ 0/65]\tTime   0.66 (  0.66)\tData 0.6545 (0.6545)\tLoss (MSE) 4.324 (4.324)\n",
      "Epoch: [345][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0603)\tLoss (MSE) 6.540 (3.953)\n",
      "Epoch: [345][20/65]\tTime   0.01 (  0.04)\tData 0.0000 (0.0316)\tLoss (MSE) 3.165 (4.192)\n",
      "Epoch: [345][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0214)\tLoss (MSE) 3.287 (4.115)\n",
      "Epoch: [345][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.270 (4.060)\n",
      "Epoch: [345][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 6.081 (4.118)\n",
      "Epoch: [345][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 3.804 (3.999)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.101 (2.101)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.929\tL1 0.597\tG-Mean 0.264\n",
      " * Many: MSE 2.320\tL1 1.012\tG-Mean 0.864\n",
      " * Median: MSE 2.165\tL1 1.401\tG-Mean 1.286\n",
      " * Low: MSE 0.101\tL1 0.227\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #345: Train loss [4.0159]; Val loss: MSE [1.9288], L1 [0.5973], G-Mean [0.2638]\n",
      "Epoch: [346][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 2.920 (2.920)\n",
      "Epoch: [346][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0615)\tLoss (MSE) 8.655 (4.251)\n",
      "Epoch: [346][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0322)\tLoss (MSE) 5.836 (3.948)\n",
      "Epoch: [346][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 4.105 (3.815)\n",
      "Epoch: [346][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 4.869 (3.908)\n",
      "Epoch: [346][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 5.025 (3.886)\n",
      "Epoch: [346][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.331 (4.028)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.090 (2.090)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.929\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.327\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.152\tL1 1.396\tG-Mean 1.321\n",
      " * Low: MSE 0.099\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #346: Train loss [4.0297]; Val loss: MSE [1.9289], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [347][ 0/65]\tTime   0.56 (  0.56)\tData 0.5593 (0.5593)\tLoss (MSE) 5.819 (5.819)\n",
      "Epoch: [347][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.941 (3.860)\n",
      "Epoch: [347][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.538 (3.836)\n",
      "Epoch: [347][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.151 (4.158)\n",
      "Epoch: [347][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.815 (3.975)\n",
      "Epoch: [347][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.160 (4.039)\n",
      "Epoch: [347][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.566 (3.952)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.072 (2.072)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.927\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.337\tL1 1.022\tG-Mean 0.874\n",
      " * Median: MSE 2.132\tL1 1.388\tG-Mean 1.311\n",
      " * Low: MSE 0.095\tL1 0.217\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #347: Train loss [3.9632]; Val loss: MSE [1.9275], L1 [0.5999], G-Mean [0.2598]\n",
      "Epoch: [348][ 0/65]\tTime   0.56 (  0.56)\tData 0.5540 (0.5540)\tLoss (MSE) 3.695 (3.695)\n",
      "Epoch: [348][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 4.956 (4.297)\n",
      "Epoch: [348][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.562 (4.150)\n",
      "Epoch: [348][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 5.993 (4.055)\n",
      "Epoch: [348][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.044 (4.077)\n",
      "Epoch: [348][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.784 (3.990)\n",
      "Epoch: [348][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 6.007 (4.060)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.071 (2.071)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.135\tL1 1.390\tG-Mean 1.317\n",
      " * Low: MSE 0.095\tL1 0.216\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #348: Train loss [4.0713]; Val loss: MSE [1.9217], L1 [0.5990], G-Mean [0.2610]\n",
      "Epoch: [349][ 0/65]\tTime   0.56 (  0.56)\tData 0.5548 (0.5548)\tLoss (MSE) 4.252 (4.252)\n",
      "Epoch: [349][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 5.503 (4.222)\n",
      "Epoch: [349][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 4.204 (3.957)\n",
      "Epoch: [349][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.853 (4.139)\n",
      "Epoch: [349][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.822 (4.134)\n",
      "Epoch: [349][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.579 (4.174)\n",
      "Epoch: [349][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.678 (4.162)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.076 (2.076)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.929\tL1 0.594\tG-Mean 0.266\n",
      " * Many: MSE 2.295\tL1 0.997\tG-Mean 0.848\n",
      " * Median: MSE 2.212\tL1 1.419\tG-Mean 1.353\n",
      " * Low: MSE 0.108\tL1 0.242\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #349: Train loss [4.0928]; Val loss: MSE [1.9291], L1 [0.5941], G-Mean [0.2655]\n",
      "Epoch: [350][ 0/65]\tTime   0.56 (  0.56)\tData 0.5495 (0.5495)\tLoss (MSE) 3.097 (3.097)\n",
      "Epoch: [350][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 5.265 (3.841)\n",
      "Epoch: [350][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.140 (3.822)\n",
      "Epoch: [350][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.702 (3.966)\n",
      "Epoch: [350][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.299 (3.827)\n",
      "Epoch: [350][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.801 (3.799)\n",
      "Epoch: [350][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.764 (3.862)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.071 (2.071)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.925\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.301\tL1 1.003\tG-Mean 0.855\n",
      " * Median: MSE 2.197\tL1 1.416\tG-Mean 1.357\n",
      " * Low: MSE 0.104\tL1 0.236\tG-Mean 0.217\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #350: Train loss [3.9318]; Val loss: MSE [1.9251], L1 [0.5951], G-Mean [0.2638]\n",
      "Epoch: [351][ 0/65]\tTime   0.57 (  0.57)\tData 0.5647 (0.5647)\tLoss (MSE) 3.215 (3.215)\n",
      "Epoch: [351][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0588)\tLoss (MSE) 3.480 (3.937)\n",
      "Epoch: [351][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 3.712 (3.944)\n",
      "Epoch: [351][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 4.282 (4.085)\n",
      "Epoch: [351][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 2.795 (3.915)\n",
      "Epoch: [351][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.433 (3.948)\n",
      "Epoch: [351][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.718 (4.036)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.075 (2.075)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.925\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.302\tL1 1.004\tG-Mean 0.856\n",
      " * Median: MSE 2.190\tL1 1.410\tG-Mean 1.336\n",
      " * Low: MSE 0.107\tL1 0.235\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #351: Train loss [4.0350]; Val loss: MSE [1.9246], L1 [0.5954], G-Mean [0.2642]\n",
      "Epoch: [352][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 2.771 (2.771)\n",
      "Epoch: [352][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 6.464 (3.379)\n",
      "Epoch: [352][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 4.256 (3.932)\n",
      "Epoch: [352][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.678 (3.835)\n",
      "Epoch: [352][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.921 (4.207)\n",
      "Epoch: [352][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.251 (4.088)\n",
      "Epoch: [352][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 6.432 (4.082)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.063 (2.063)\tLoss (L1) 0.650 (0.650)\n",
      " * Overall: MSE 1.915\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.359\tL1 1.044\tG-Mean 0.900\n",
      " * Median: MSE 2.068\tL1 1.368\tG-Mean 1.304\n",
      " * Low: MSE 0.091\tL1 0.194\tG-Mean 0.172\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #352: Train loss [4.0667]; Val loss: MSE [1.9155], L1 [0.6049], G-Mean [0.2635]\n",
      "Epoch: [353][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 3.025 (3.025)\n",
      "Epoch: [353][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0575)\tLoss (MSE) 4.533 (3.634)\n",
      "Epoch: [353][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 2.955 (3.578)\n",
      "Epoch: [353][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.572 (3.805)\n",
      "Epoch: [353][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.538 (3.925)\n",
      "Epoch: [353][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.176 (4.088)\n",
      "Epoch: [353][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.932 (4.007)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.079 (2.079)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.930\tL1 0.598\tG-Mean 0.264\n",
      " * Many: MSE 2.323\tL1 1.013\tG-Mean 0.864\n",
      " * Median: MSE 2.165\tL1 1.403\tG-Mean 1.340\n",
      " * Low: MSE 0.102\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #353: Train loss [3.9940]; Val loss: MSE [1.9297], L1 [0.5976], G-Mean [0.2636]\n",
      "Epoch: [354][ 0/65]\tTime   0.55 (  0.55)\tData 0.5475 (0.5475)\tLoss (MSE) 4.039 (4.039)\n",
      "Epoch: [354][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0577)\tLoss (MSE) 4.201 (4.537)\n",
      "Epoch: [354][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 4.610 (4.177)\n",
      "Epoch: [354][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 4.134 (4.050)\n",
      "Epoch: [354][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.576 (4.039)\n",
      "Epoch: [354][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.641 (4.118)\n",
      "Epoch: [354][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.544 (3.993)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.916\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.334\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.112\tL1 1.384\tG-Mean 1.322\n",
      " * Low: MSE 0.091\tL1 0.208\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #354: Train loss [3.9820]; Val loss: MSE [1.9162], L1 [0.6003], G-Mean [0.2619]\n",
      "Epoch: [355][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 2.819 (2.819)\n",
      "Epoch: [355][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 5.211 (3.925)\n",
      "Epoch: [355][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.321 (3.865)\n",
      "Epoch: [355][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.871 (4.242)\n",
      "Epoch: [355][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.751 (4.034)\n",
      "Epoch: [355][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.658 (3.998)\n",
      "Epoch: [355][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.425 (4.028)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.078 (2.078)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.930\tL1 0.596\tG-Mean 0.264\n",
      " * Many: MSE 2.315\tL1 1.007\tG-Mean 0.858\n",
      " * Median: MSE 2.174\tL1 1.404\tG-Mean 1.332\n",
      " * Low: MSE 0.096\tL1 0.232\tG-Mean 0.215\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #355: Train loss [4.0125]; Val loss: MSE [1.9301], L1 [0.5960], G-Mean [0.2639]\n",
      "Epoch: [356][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 2.791 (2.791)\n",
      "Epoch: [356][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 4.314 (4.302)\n",
      "Epoch: [356][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 1.871 (4.375)\n",
      "Epoch: [356][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 7.692 (4.321)\n",
      "Epoch: [356][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.617 (4.101)\n",
      "Epoch: [356][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 7.693 (4.126)\n",
      "Epoch: [356][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.203 (4.100)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.086 (2.086)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.929\tL1 0.594\tG-Mean 0.264\n",
      " * Many: MSE 2.301\tL1 1.000\tG-Mean 0.850\n",
      " * Median: MSE 2.193\tL1 1.411\tG-Mean 1.345\n",
      " * Low: MSE 0.100\tL1 0.239\tG-Mean 0.222\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #356: Train loss [4.0620]; Val loss: MSE [1.9291], L1 [0.5941], G-Mean [0.2643]\n",
      "Epoch: [357][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 4.218 (4.218)\n",
      "Epoch: [357][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0577)\tLoss (MSE) 3.451 (4.246)\n",
      "Epoch: [357][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 3.385 (4.439)\n",
      "Epoch: [357][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 2.982 (3.949)\n",
      "Epoch: [357][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.025 (3.958)\n",
      "Epoch: [357][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.859 (3.966)\n",
      "Epoch: [357][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 6.305 (4.061)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.088 (2.088)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.917\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.311\tL1 1.014\tG-Mean 0.867\n",
      " * Median: MSE 2.153\tL1 1.398\tG-Mean 1.332\n",
      " * Low: MSE 0.090\tL1 0.221\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #357: Train loss [4.0279]; Val loss: MSE [1.9171], L1 [0.5964], G-Mean [0.2604]\n",
      "Epoch: [358][ 0/65]\tTime   0.56 (  0.56)\tData 0.5514 (0.5514)\tLoss (MSE) 7.330 (7.330)\n",
      "Epoch: [358][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 5.964 (4.278)\n",
      "Epoch: [358][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 4.316 (3.722)\n",
      "Epoch: [358][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 2.892 (3.740)\n",
      "Epoch: [358][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 5.193 (3.855)\n",
      "Epoch: [358][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.271 (3.940)\n",
      "Epoch: [358][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.772 (3.929)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.911\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.341\tL1 1.036\tG-Mean 0.891\n",
      " * Median: MSE 2.091\tL1 1.377\tG-Mean 1.315\n",
      " * Low: MSE 0.083\tL1 0.199\tG-Mean 0.178\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #358: Train loss [3.9747]; Val loss: MSE [1.9112], L1 [0.6019], G-Mean [0.2608]\n",
      "Epoch: [359][ 0/65]\tTime   0.56 (  0.56)\tData 0.5510 (0.5510)\tLoss (MSE) 3.286 (3.286)\n",
      "Epoch: [359][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 2.624 (3.763)\n",
      "Epoch: [359][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 7.183 (4.186)\n",
      "Epoch: [359][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 6.019 (4.210)\n",
      "Epoch: [359][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.110 (4.256)\n",
      "Epoch: [359][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 5.001 (4.120)\n",
      "Epoch: [359][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.431 (4.012)\n",
      "Val: [0/9]\tTime  0.640 ( 0.640)\tLoss (MSE) 2.083 (2.083)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.926\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.018\tG-Mean 0.870\n",
      " * Median: MSE 2.148\tL1 1.396\tG-Mean 1.332\n",
      " * Low: MSE 0.090\tL1 0.220\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #359: Train loss [3.9769]; Val loss: MSE [1.9257], L1 [0.5984], G-Mean [0.2607]\n",
      "Epoch: [360][ 0/65]\tTime   0.66 (  0.66)\tData 0.6524 (0.6524)\tLoss (MSE) 3.406 (3.406)\n",
      "Epoch: [360][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0639)\tLoss (MSE) 2.578 (3.481)\n",
      "Epoch: [360][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0335)\tLoss (MSE) 3.647 (3.799)\n",
      "Epoch: [360][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0227)\tLoss (MSE) 3.019 (3.879)\n",
      "Epoch: [360][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0172)\tLoss (MSE) 5.306 (3.978)\n",
      "Epoch: [360][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.994 (4.055)\n",
      "Epoch: [360][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 7.333 (4.107)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.076 (2.076)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.324\tL1 1.019\tG-Mean 0.871\n",
      " * Median: MSE 2.144\tL1 1.394\tG-Mean 1.322\n",
      " * Low: MSE 0.088\tL1 0.218\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #360: Train loss [4.0836]; Val loss: MSE [1.9206], L1 [0.5980], G-Mean [0.2590]\n",
      "Epoch: [361][ 0/65]\tTime   0.55 (  0.55)\tData 0.5423 (0.5423)\tLoss (MSE) 2.334 (2.334)\n",
      "Epoch: [361][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0535)\tLoss (MSE) 4.237 (3.619)\n",
      "Epoch: [361][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 2.593 (3.576)\n",
      "Epoch: [361][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 4.151 (3.473)\n",
      "Epoch: [361][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.662 (3.622)\n",
      "Epoch: [361][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.134 (3.816)\n",
      "Epoch: [361][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.837 (3.821)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.078 (2.078)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.918\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.140\tL1 1.393\tG-Mean 1.321\n",
      " * Low: MSE 0.088\tL1 0.215\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #361: Train loss [3.8865]; Val loss: MSE [1.9181], L1 [0.5981], G-Mean [0.2609]\n",
      "Epoch: [362][ 0/65]\tTime   0.58 (  0.58)\tData 0.5725 (0.5725)\tLoss (MSE) 2.458 (2.458)\n",
      "Epoch: [362][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 5.931 (3.917)\n",
      "Epoch: [362][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.826 (3.957)\n",
      "Epoch: [362][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 2.280 (3.863)\n",
      "Epoch: [362][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 6.083 (4.126)\n",
      "Epoch: [362][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.436 (4.004)\n",
      "Epoch: [362][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.991 (3.938)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.095 (2.095)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.929\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.340\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.134\tL1 1.392\tG-Mean 1.327\n",
      " * Low: MSE 0.095\tL1 0.217\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #362: Train loss [3.9705]; Val loss: MSE [1.9288], L1 [0.6000], G-Mean [0.2622]\n",
      "Epoch: [363][ 0/65]\tTime   0.60 (  0.60)\tData 0.5835 (0.5835)\tLoss (MSE) 3.747 (3.747)\n",
      "Epoch: [363][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0556)\tLoss (MSE) 5.693 (3.693)\n",
      "Epoch: [363][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0291)\tLoss (MSE) 5.966 (4.355)\n",
      "Epoch: [363][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.711 (4.254)\n",
      "Epoch: [363][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 7.123 (4.275)\n",
      "Epoch: [363][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.100 (4.193)\n",
      "Epoch: [363][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.102 (4.104)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.108 (2.108)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.934\tL1 0.595\tG-Mean 0.266\n",
      " * Many: MSE 2.305\tL1 1.000\tG-Mean 0.850\n",
      " * Median: MSE 2.207\tL1 1.419\tG-Mean 1.357\n",
      " * Low: MSE 0.106\tL1 0.241\tG-Mean 0.219\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #363: Train loss [4.0320]; Val loss: MSE [1.9342], L1 [0.5950], G-Mean [0.2655]\n",
      "Epoch: [364][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 2.874 (2.874)\n",
      "Epoch: [364][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 4.210 (3.700)\n",
      "Epoch: [364][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 5.387 (3.742)\n",
      "Epoch: [364][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.374 (4.072)\n",
      "Epoch: [364][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.554 (4.135)\n",
      "Epoch: [364][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.431 (4.033)\n",
      "Epoch: [364][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.185 (4.012)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.094 (2.094)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.928\tL1 0.598\tG-Mean 0.262\n",
      " * Many: MSE 2.328\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.151\tL1 1.397\tG-Mean 1.328\n",
      " * Low: MSE 0.101\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #364: Train loss [3.9943]; Val loss: MSE [1.9280], L1 [0.5985], G-Mean [0.2618]\n",
      "Epoch: [365][ 0/65]\tTime   0.57 (  0.57)\tData 0.5593 (0.5593)\tLoss (MSE) 6.885 (6.885)\n",
      "Epoch: [365][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 2.459 (4.193)\n",
      "Epoch: [365][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 6.464 (4.104)\n",
      "Epoch: [365][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.277 (3.932)\n",
      "Epoch: [365][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.958 (3.978)\n",
      "Epoch: [365][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.706 (3.940)\n",
      "Epoch: [365][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.440 (3.936)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.085 (2.085)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.925\tL1 0.603\tG-Mean 0.261\n",
      " * Many: MSE 2.353\tL1 1.034\tG-Mean 0.887\n",
      " * Median: MSE 2.106\tL1 1.381\tG-Mean 1.310\n",
      " * Low: MSE 0.095\tL1 0.208\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #365: Train loss [3.9596]; Val loss: MSE [1.9250], L1 [0.6025], G-Mean [0.2610]\n",
      "Epoch: [366][ 0/65]\tTime   0.57 (  0.57)\tData 0.5639 (0.5639)\tLoss (MSE) 3.617 (3.617)\n",
      "Epoch: [366][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 4.111 (3.591)\n",
      "Epoch: [366][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 7.678 (3.948)\n",
      "Epoch: [366][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 7.462 (4.223)\n",
      "Epoch: [366][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.961 (4.075)\n",
      "Epoch: [366][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.814 (4.149)\n",
      "Epoch: [366][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.616 (4.095)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.088 (2.088)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.931\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.342\tL1 1.023\tG-Mean 0.874\n",
      " * Median: MSE 2.137\tL1 1.393\tG-Mean 1.327\n",
      " * Low: MSE 0.097\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #366: Train loss [4.0798]; Val loss: MSE [1.9312], L1 [0.5998], G-Mean [0.2614]\n",
      "Epoch: [367][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 3.761 (3.761)\n",
      "Epoch: [367][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 5.206 (3.694)\n",
      "Epoch: [367][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.264 (3.907)\n",
      "Epoch: [367][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 6.224 (4.114)\n",
      "Epoch: [367][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.613 (4.031)\n",
      "Epoch: [367][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.281 (3.897)\n",
      "Epoch: [367][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.682 (3.841)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.933\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.357\tL1 1.031\tG-Mean 0.882\n",
      " * Median: MSE 2.112\tL1 1.384\tG-Mean 1.320\n",
      " * Low: MSE 0.093\tL1 0.211\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #367: Train loss [3.8727]; Val loss: MSE [1.9326], L1 [0.6019], G-Mean [0.2607]\n",
      "Epoch: [368][ 0/65]\tTime   0.56 (  0.56)\tData 0.5481 (0.5481)\tLoss (MSE) 5.541 (5.541)\n",
      "Epoch: [368][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0545)\tLoss (MSE) 4.601 (4.126)\n",
      "Epoch: [368][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 4.918 (3.963)\n",
      "Epoch: [368][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 8.241 (3.989)\n",
      "Epoch: [368][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.911 (3.948)\n",
      "Epoch: [368][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.444 (3.948)\n",
      "Epoch: [368][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.296 (3.914)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.064 (2.064)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.927\tL1 0.606\tG-Mean 0.262\n",
      " * Many: MSE 2.376\tL1 1.046\tG-Mean 0.899\n",
      " * Median: MSE 2.066\tL1 1.365\tG-Mean 1.280\n",
      " * Low: MSE 0.089\tL1 0.195\tG-Mean 0.172\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #368: Train loss [3.9636]; Val loss: MSE [1.9265], L1 [0.6058], G-Mean [0.2623]\n",
      "Epoch: [369][ 0/65]\tTime   0.56 (  0.56)\tData 0.5525 (0.5525)\tLoss (MSE) 4.211 (4.211)\n",
      "Epoch: [369][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0543)\tLoss (MSE) 3.463 (3.580)\n",
      "Epoch: [369][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 2.262 (3.981)\n",
      "Epoch: [369][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.880 (3.800)\n",
      "Epoch: [369][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 4.857 (3.796)\n",
      "Epoch: [369][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0117)\tLoss (MSE) 8.141 (3.972)\n",
      "Epoch: [369][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.320 (4.011)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.927\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.361\tL1 1.036\tG-Mean 0.888\n",
      " * Median: MSE 2.091\tL1 1.374\tG-Mean 1.290\n",
      " * Low: MSE 0.095\tL1 0.205\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #369: Train loss [4.0122]; Val loss: MSE [1.9272], L1 [0.6033], G-Mean [0.2615]\n",
      "Epoch: [370][ 0/65]\tTime   0.63 (  0.63)\tData 0.6090 (0.6090)\tLoss (MSE) 2.146 (2.146)\n",
      "Epoch: [370][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0578)\tLoss (MSE) 3.536 (3.870)\n",
      "Epoch: [370][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 4.567 (3.965)\n",
      "Epoch: [370][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 4.287 (4.031)\n",
      "Epoch: [370][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.372 (3.977)\n",
      "Epoch: [370][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.858 (4.028)\n",
      "Epoch: [370][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.530 (4.024)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.019\tG-Mean 0.871\n",
      " * Median: MSE 2.141\tL1 1.392\tG-Mean 1.305\n",
      " * Low: MSE 0.098\tL1 0.220\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #370: Train loss [4.0092]; Val loss: MSE [1.9212], L1 [0.5983], G-Mean [0.2609]\n",
      "Epoch: [371][ 0/65]\tTime   0.57 (  0.57)\tData 0.5595 (0.5595)\tLoss (MSE) 4.102 (4.102)\n",
      "Epoch: [371][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 2.207 (4.481)\n",
      "Epoch: [371][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.336 (4.394)\n",
      "Epoch: [371][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 5.460 (4.204)\n",
      "Epoch: [371][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.963 (4.057)\n",
      "Epoch: [371][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.977 (3.997)\n",
      "Epoch: [371][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.106 (3.944)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.074 (2.074)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.921\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.317\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.151\tL1 1.394\tG-Mean 1.319\n",
      " * Low: MSE 0.098\tL1 0.224\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #371: Train loss [3.9665]; Val loss: MSE [1.9211], L1 [0.5971], G-Mean [0.2620]\n",
      "Epoch: [372][ 0/65]\tTime   0.56 (  0.56)\tData 0.5596 (0.5596)\tLoss (MSE) 5.226 (5.226)\n",
      "Epoch: [372][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 2.566 (3.783)\n",
      "Epoch: [372][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.924 (3.781)\n",
      "Epoch: [372][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 4.657 (3.898)\n",
      "Epoch: [372][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 7.400 (3.897)\n",
      "Epoch: [372][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.913 (3.942)\n",
      "Epoch: [372][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 8.938 (4.036)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.916\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.313\tL1 1.015\tG-Mean 0.868\n",
      " * Median: MSE 2.146\tL1 1.393\tG-Mean 1.320\n",
      " * Low: MSE 0.099\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #372: Train loss [4.0080]; Val loss: MSE [1.9162], L1 [0.5969], G-Mean [0.2610]\n",
      "Epoch: [373][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 4.075 (4.075)\n",
      "Epoch: [373][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 5.206 (4.099)\n",
      "Epoch: [373][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 4.461 (4.474)\n",
      "Epoch: [373][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 4.889 (4.198)\n",
      "Epoch: [373][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.774 (4.097)\n",
      "Epoch: [373][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.861 (4.088)\n",
      "Epoch: [373][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.636 (4.082)\n",
      "Val: [0/9]\tTime  0.593 ( 0.593)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.907\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.316\tL1 1.024\tG-Mean 0.879\n",
      " * Median: MSE 2.118\tL1 1.382\tG-Mean 1.290\n",
      " * Low: MSE 0.093\tL1 0.212\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #373: Train loss [4.0754]; Val loss: MSE [1.9072], L1 [0.5979], G-Mean [0.2614]\n",
      "Epoch: [374][ 0/65]\tTime   0.67 (  0.67)\tData 0.6670 (0.6670)\tLoss (MSE) 5.558 (5.558)\n",
      "Epoch: [374][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0617)\tLoss (MSE) 6.462 (4.118)\n",
      "Epoch: [374][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0323)\tLoss (MSE) 4.058 (3.708)\n",
      "Epoch: [374][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0219)\tLoss (MSE) 2.484 (3.887)\n",
      "Epoch: [374][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0166)\tLoss (MSE) 4.514 (3.985)\n",
      "Epoch: [374][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 5.040 (4.017)\n",
      "Epoch: [374][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.809 (3.884)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.911\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.337\tL1 1.033\tG-Mean 0.888\n",
      " * Median: MSE 2.088\tL1 1.370\tG-Mean 1.288\n",
      " * Low: MSE 0.090\tL1 0.204\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #374: Train loss [3.9474]; Val loss: MSE [1.9114], L1 [0.6008], G-Mean [0.2618]\n",
      "Epoch: [375][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 4.351 (4.351)\n",
      "Epoch: [375][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0592)\tLoss (MSE) 4.107 (3.791)\n",
      "Epoch: [375][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 2.372 (4.030)\n",
      "Epoch: [375][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 3.585 (4.004)\n",
      "Epoch: [375][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 5.932 (3.986)\n",
      "Epoch: [375][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 6.488 (3.990)\n",
      "Epoch: [375][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 4.316 (4.032)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.909\tL1 0.602\tG-Mean 0.263\n",
      " * Many: MSE 2.343\tL1 1.038\tG-Mean 0.894\n",
      " * Median: MSE 2.075\tL1 1.367\tG-Mean 1.295\n",
      " * Low: MSE 0.090\tL1 0.199\tG-Mean 0.178\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #375: Train loss [4.0063]; Val loss: MSE [1.9093], L1 [0.6019], G-Mean [0.2626]\n",
      "Epoch: [376][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 6.394 (6.394)\n",
      "Epoch: [376][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 3.404 (3.745)\n",
      "Epoch: [376][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 8.421 (4.157)\n",
      "Epoch: [376][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 4.927 (4.269)\n",
      "Epoch: [376][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.292 (4.100)\n",
      "Epoch: [376][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.403 (3.930)\n",
      "Epoch: [376][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.098 (3.901)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.082 (2.082)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.592\tG-Mean 0.265\n",
      " * Many: MSE 2.281\tL1 0.994\tG-Mean 0.845\n",
      " * Median: MSE 2.210\tL1 1.418\tG-Mean 1.352\n",
      " * Low: MSE 0.106\tL1 0.244\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #376: Train loss [3.9580]; Val loss: MSE [1.9202], L1 [0.5919], G-Mean [0.2648]\n",
      "Epoch: [377][ 0/65]\tTime   0.56 (  0.56)\tData 0.5491 (0.5491)\tLoss (MSE) 4.700 (4.700)\n",
      "Epoch: [377][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 3.528 (3.685)\n",
      "Epoch: [377][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.510 (3.620)\n",
      "Epoch: [377][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.852 (3.572)\n",
      "Epoch: [377][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.856 (3.663)\n",
      "Epoch: [377][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.369 (3.831)\n",
      "Epoch: [377][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.472 (3.872)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.077 (2.077)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.919\tL1 0.596\tG-Mean 0.261\n",
      " * Many: MSE 2.315\tL1 1.015\tG-Mean 0.867\n",
      " * Median: MSE 2.149\tL1 1.395\tG-Mean 1.314\n",
      " * Low: MSE 0.094\tL1 0.223\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #377: Train loss [3.8658]; Val loss: MSE [1.9188], L1 [0.5965], G-Mean [0.2609]\n",
      "Epoch: [378][ 0/65]\tTime   0.65 (  0.65)\tData 0.6375 (0.6375)\tLoss (MSE) 2.422 (2.422)\n",
      "Epoch: [378][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 2.959 (3.555)\n",
      "Epoch: [378][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0305)\tLoss (MSE) 2.926 (3.960)\n",
      "Epoch: [378][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 6.425 (4.168)\n",
      "Epoch: [378][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.228 (3.959)\n",
      "Epoch: [378][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.126 (3.960)\n",
      "Epoch: [378][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.745 (4.051)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.061 (2.061)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.911\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.029\tG-Mean 0.884\n",
      " * Median: MSE 2.109\tL1 1.382\tG-Mean 1.314\n",
      " * Low: MSE 0.090\tL1 0.208\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #378: Train loss [4.0336]; Val loss: MSE [1.9115], L1 [0.5996], G-Mean [0.2606]\n",
      "Epoch: [379][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 7.524 (7.524)\n",
      "Epoch: [379][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0543)\tLoss (MSE) 2.998 (4.118)\n",
      "Epoch: [379][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 3.925 (3.872)\n",
      "Epoch: [379][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.473 (3.944)\n",
      "Epoch: [379][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 4.160 (4.070)\n",
      "Epoch: [379][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.797 (4.012)\n",
      "Epoch: [379][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.116 (4.005)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.082 (2.082)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.592\tG-Mean 0.266\n",
      " * Many: MSE 2.281\tL1 0.990\tG-Mean 0.841\n",
      " * Median: MSE 2.226\tL1 1.424\tG-Mean 1.356\n",
      " * Low: MSE 0.107\tL1 0.250\tG-Mean 0.232\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #379: Train loss [3.9297]; Val loss: MSE [1.9253], L1 [0.5918], G-Mean [0.2655]\n",
      "Epoch: [380][ 0/65]\tTime   0.56 (  0.56)\tData 0.5551 (0.5551)\tLoss (MSE) 4.017 (4.017)\n",
      "Epoch: [380][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0583)\tLoss (MSE) 4.400 (4.051)\n",
      "Epoch: [380][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0306)\tLoss (MSE) 2.845 (4.077)\n",
      "Epoch: [380][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 4.929 (4.119)\n",
      "Epoch: [380][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.436 (4.059)\n",
      "Epoch: [380][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 1.937 (4.024)\n",
      "Epoch: [380][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.188 (3.989)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.074 (2.074)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.326\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.146\tL1 1.395\tG-Mean 1.281\n",
      " * Low: MSE 0.098\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #380: Train loss [3.9262]; Val loss: MSE [1.9231], L1 [0.5979], G-Mean [0.2588]\n",
      "Epoch: [381][ 0/65]\tTime   0.61 (  0.61)\tData 0.5934 (0.5934)\tLoss (MSE) 3.730 (3.730)\n",
      "Epoch: [381][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0555)\tLoss (MSE) 5.900 (3.903)\n",
      "Epoch: [381][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0291)\tLoss (MSE) 2.764 (3.746)\n",
      "Epoch: [381][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.743 (3.939)\n",
      "Epoch: [381][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.979 (3.965)\n",
      "Epoch: [381][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.762 (4.060)\n",
      "Epoch: [381][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.893 (4.007)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.081 (2.081)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.929\tL1 0.599\tG-Mean 0.263\n",
      " * Many: MSE 2.340\tL1 1.022\tG-Mean 0.874\n",
      " * Median: MSE 2.132\tL1 1.390\tG-Mean 1.318\n",
      " * Low: MSE 0.097\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #381: Train loss [3.9577]; Val loss: MSE [1.9294], L1 [0.5992], G-Mean [0.2627]\n",
      "Epoch: [382][ 0/65]\tTime   0.56 (  0.56)\tData 0.5498 (0.5498)\tLoss (MSE) 4.214 (4.214)\n",
      "Epoch: [382][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 5.104 (4.725)\n",
      "Epoch: [382][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.638 (4.280)\n",
      "Epoch: [382][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.757 (4.079)\n",
      "Epoch: [382][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.076 (4.081)\n",
      "Epoch: [382][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.478 (4.112)\n",
      "Epoch: [382][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.366 (4.023)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.925\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.350\tL1 1.031\tG-Mean 0.884\n",
      " * Median: MSE 2.106\tL1 1.381\tG-Mean 1.315\n",
      " * Low: MSE 0.089\tL1 0.210\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #382: Train loss [3.9766]; Val loss: MSE [1.9252], L1 [0.6009], G-Mean [0.2609]\n",
      "Epoch: [383][ 0/65]\tTime   0.58 (  0.58)\tData 0.5764 (0.5764)\tLoss (MSE) 4.009 (4.009)\n",
      "Epoch: [383][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 3.894 (3.941)\n",
      "Epoch: [383][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.227 (3.825)\n",
      "Epoch: [383][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.573 (3.792)\n",
      "Epoch: [383][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.900 (3.742)\n",
      "Epoch: [383][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.153 (3.750)\n",
      "Epoch: [383][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.320 (3.817)\n",
      "Val: [0/9]\tTime  0.602 ( 0.602)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.923\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.349\tL1 1.032\tG-Mean 0.885\n",
      " * Median: MSE 2.102\tL1 1.379\tG-Mean 1.308\n",
      " * Low: MSE 0.086\tL1 0.207\tG-Mean 0.188\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #383: Train loss [3.8931]; Val loss: MSE [1.9232], L1 [0.6006], G-Mean [0.2596]\n",
      "Epoch: [384][ 0/65]\tTime   0.55 (  0.55)\tData 0.5462 (0.5462)\tLoss (MSE) 5.841 (5.841)\n",
      "Epoch: [384][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 3.371 (4.197)\n",
      "Epoch: [384][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 3.751 (4.305)\n",
      "Epoch: [384][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.384 (4.024)\n",
      "Epoch: [384][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.042 (3.994)\n",
      "Epoch: [384][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.400 (3.954)\n",
      "Epoch: [384][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.014 (3.991)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.926\tL1 0.595\tG-Mean 0.262\n",
      " * Many: MSE 2.311\tL1 1.007\tG-Mean 0.858\n",
      " * Median: MSE 2.176\tL1 1.405\tG-Mean 1.329\n",
      " * Low: MSE 0.095\tL1 0.232\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #384: Train loss [3.9590]; Val loss: MSE [1.9260], L1 [0.5948], G-Mean [0.2620]\n",
      "Epoch: [385][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 2.224 (2.224)\n",
      "Epoch: [385][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 3.869 (3.883)\n",
      "Epoch: [385][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 2.932 (3.900)\n",
      "Epoch: [385][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 7.435 (4.149)\n",
      "Epoch: [385][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 3.489 (4.109)\n",
      "Epoch: [385][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.824 (4.060)\n",
      "Epoch: [385][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.647 (4.033)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.597\tG-Mean 0.259\n",
      " * Many: MSE 2.323\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.138\tL1 1.391\tG-Mean 1.314\n",
      " * Low: MSE 0.091\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #385: Train loss [3.9978]; Val loss: MSE [1.9196], L1 [0.5971], G-Mean [0.2589]\n",
      "Epoch: [386][ 0/65]\tTime   0.56 (  0.56)\tData 0.5514 (0.5514)\tLoss (MSE) 2.564 (2.564)\n",
      "Epoch: [386][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 3.682 (4.136)\n",
      "Epoch: [386][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.852 (4.022)\n",
      "Epoch: [386][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 6.393 (3.936)\n",
      "Epoch: [386][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.130 (4.041)\n",
      "Epoch: [386][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.647 (4.020)\n",
      "Epoch: [386][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.482 (3.960)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.916\tL1 0.602\tG-Mean 0.262\n",
      " * Many: MSE 2.346\tL1 1.036\tG-Mean 0.890\n",
      " * Median: MSE 2.090\tL1 1.374\tG-Mean 1.267\n",
      " * Low: MSE 0.087\tL1 0.204\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #386: Train loss [3.9710]; Val loss: MSE [1.9156], L1 [0.6019], G-Mean [0.2623]\n",
      "Epoch: [387][ 0/65]\tTime   0.56 (  0.56)\tData 0.5555 (0.5555)\tLoss (MSE) 3.228 (3.228)\n",
      "Epoch: [387][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0523)\tLoss (MSE) 5.487 (3.783)\n",
      "Epoch: [387][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.434 (3.605)\n",
      "Epoch: [387][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 4.798 (3.594)\n",
      "Epoch: [387][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 7.080 (3.953)\n",
      "Epoch: [387][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.542 (3.949)\n",
      "Epoch: [387][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.954 (3.946)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.929\tL1 0.597\tG-Mean 0.263\n",
      " * Many: MSE 2.322\tL1 1.013\tG-Mean 0.864\n",
      " * Median: MSE 2.162\tL1 1.400\tG-Mean 1.322\n",
      " * Low: MSE 0.100\tL1 0.229\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #387: Train loss [3.9300]; Val loss: MSE [1.9290], L1 [0.5970], G-Mean [0.2627]\n",
      "Epoch: [388][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 6.260 (6.260)\n",
      "Epoch: [388][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 3.430 (3.966)\n",
      "Epoch: [388][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 4.065 (3.938)\n",
      "Epoch: [388][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.215 (4.009)\n",
      "Epoch: [388][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.233 (3.939)\n",
      "Epoch: [388][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.774 (3.974)\n",
      "Epoch: [388][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.657 (3.967)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.925\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.012\tG-Mean 0.864\n",
      " * Median: MSE 2.162\tL1 1.400\tG-Mean 1.313\n",
      " * Low: MSE 0.100\tL1 0.229\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #388: Train loss [3.9641]; Val loss: MSE [1.9249], L1 [0.5965], G-Mean [0.2605]\n",
      "Epoch: [389][ 0/65]\tTime   0.65 (  0.65)\tData 0.6344 (0.6344)\tLoss (MSE) 3.623 (3.623)\n",
      "Epoch: [389][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 2.780 (4.206)\n",
      "Epoch: [389][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 3.611 (4.047)\n",
      "Epoch: [389][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 2.742 (3.969)\n",
      "Epoch: [389][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.130 (3.932)\n",
      "Epoch: [389][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.305 (3.894)\n",
      "Epoch: [389][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.900 (3.925)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.075 (2.075)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.931\tL1 0.594\tG-Mean 0.264\n",
      " * Many: MSE 2.305\tL1 1.000\tG-Mean 0.851\n",
      " * Median: MSE 2.196\tL1 1.413\tG-Mean 1.344\n",
      " * Low: MSE 0.104\tL1 0.242\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #389: Train loss [3.9338]; Val loss: MSE [1.9315], L1 [0.5944], G-Mean [0.2640]\n",
      "Epoch: [390][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 4.009 (4.009)\n",
      "Epoch: [390][10/65]\tTime   0.00 (  0.07)\tData 0.0001 (0.0595)\tLoss (MSE) 3.725 (3.971)\n",
      "Epoch: [390][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 3.080 (4.019)\n",
      "Epoch: [390][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 2.802 (4.080)\n",
      "Epoch: [390][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 1.892 (3.870)\n",
      "Epoch: [390][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.280 (3.955)\n",
      "Epoch: [390][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.505 (3.957)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.927\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.348\tL1 1.029\tG-Mean 0.882\n",
      " * Median: MSE 2.111\tL1 1.382\tG-Mean 1.307\n",
      " * Low: MSE 0.097\tL1 0.214\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #390: Train loss [3.9757]; Val loss: MSE [1.9266], L1 [0.6004], G-Mean [0.2594]\n",
      "Epoch: [391][ 0/65]\tTime   0.56 (  0.56)\tData 0.5514 (0.5514)\tLoss (MSE) 3.077 (3.077)\n",
      "Epoch: [391][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 6.356 (4.038)\n",
      "Epoch: [391][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0290)\tLoss (MSE) 3.877 (4.013)\n",
      "Epoch: [391][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.344 (3.852)\n",
      "Epoch: [391][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.305 (3.832)\n",
      "Epoch: [391][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 8.813 (3.843)\n",
      "Epoch: [391][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.050 (3.894)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.088 (2.088)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.942\tL1 0.593\tG-Mean 0.266\n",
      " * Many: MSE 2.297\tL1 0.988\tG-Mean 0.836\n",
      " * Median: MSE 2.234\tL1 1.425\tG-Mean 1.345\n",
      " * Low: MSE 0.113\tL1 0.257\tG-Mean 0.237\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #391: Train loss [3.9368]; Val loss: MSE [1.9420], L1 [0.5927], G-Mean [0.2663]\n",
      "Epoch: [392][ 0/65]\tTime   0.61 (  0.61)\tData 0.5937 (0.5937)\tLoss (MSE) 3.684 (3.684)\n",
      "Epoch: [392][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 2.853 (3.741)\n",
      "Epoch: [392][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 4.924 (3.937)\n",
      "Epoch: [392][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.498 (4.004)\n",
      "Epoch: [392][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 2.422 (3.799)\n",
      "Epoch: [392][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.887 (3.788)\n",
      "Epoch: [392][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.932 (3.955)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.074 (2.074)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.930\tL1 0.593\tG-Mean 0.265\n",
      " * Many: MSE 2.296\tL1 0.995\tG-Mean 0.845\n",
      " * Median: MSE 2.210\tL1 1.418\tG-Mean 1.353\n",
      " * Low: MSE 0.100\tL1 0.246\tG-Mean 0.228\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #392: Train loss [3.9697]; Val loss: MSE [1.9302], L1 [0.5932], G-Mean [0.2653]\n",
      "Epoch: [393][ 0/65]\tTime   0.57 (  0.57)\tData 0.5582 (0.5582)\tLoss (MSE) 4.605 (4.605)\n",
      "Epoch: [393][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0523)\tLoss (MSE) 3.510 (3.819)\n",
      "Epoch: [393][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.079 (3.710)\n",
      "Epoch: [393][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.830 (3.496)\n",
      "Epoch: [393][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 6.321 (3.799)\n",
      "Epoch: [393][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 5.534 (3.841)\n",
      "Epoch: [393][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 6.576 (3.915)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.934\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.349\tL1 1.025\tG-Mean 0.876\n",
      " * Median: MSE 2.122\tL1 1.384\tG-Mean 1.286\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #393: Train loss [3.9629]; Val loss: MSE [1.9336], L1 [0.6000], G-Mean [0.2594]\n",
      "Epoch: [394][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 2.621 (2.621)\n",
      "Epoch: [394][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 2.995 (4.482)\n",
      "Epoch: [394][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 6.135 (4.381)\n",
      "Epoch: [394][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.852 (4.237)\n",
      "Epoch: [394][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.858 (4.093)\n",
      "Epoch: [394][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.313 (3.975)\n",
      "Epoch: [394][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.653 (3.964)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.921\tL1 0.606\tG-Mean 0.264\n",
      " * Many: MSE 2.373\tL1 1.048\tG-Mean 0.903\n",
      " * Median: MSE 2.050\tL1 1.359\tG-Mean 1.289\n",
      " * Low: MSE 0.092\tL1 0.196\tG-Mean 0.171\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #394: Train loss [4.0412]; Val loss: MSE [1.9213], L1 [0.6061], G-Mean [0.2637]\n",
      "Epoch: [395][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 4.800 (4.800)\n",
      "Epoch: [395][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 2.026 (3.446)\n",
      "Epoch: [395][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.757 (3.362)\n",
      "Epoch: [395][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 2.704 (3.788)\n",
      "Epoch: [395][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.545 (3.843)\n",
      "Epoch: [395][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.225 (4.037)\n",
      "Epoch: [395][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.664 (4.030)\n",
      "Val: [0/9]\tTime  0.533 ( 0.533)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.922\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.361\tL1 1.041\tG-Mean 0.896\n",
      " * Median: MSE 2.070\tL1 1.366\tG-Mean 1.293\n",
      " * Low: MSE 0.097\tL1 0.204\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #395: Train loss [3.9886]; Val loss: MSE [1.9217], L1 [0.6037], G-Mean [0.2616]\n",
      "Epoch: [396][ 0/65]\tTime   0.56 (  0.56)\tData 0.5500 (0.5500)\tLoss (MSE) 3.798 (3.798)\n",
      "Epoch: [396][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 7.084 (4.231)\n",
      "Epoch: [396][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 3.334 (4.004)\n",
      "Epoch: [396][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 5.050 (3.922)\n",
      "Epoch: [396][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 1.833 (3.842)\n",
      "Epoch: [396][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 5.089 (3.858)\n",
      "Epoch: [396][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.177 (3.907)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.074 (2.074)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.934\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.153\tL1 1.396\tG-Mean 1.322\n",
      " * Low: MSE 0.107\tL1 0.232\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #396: Train loss [3.9473]; Val loss: MSE [1.9344], L1 [0.5976], G-Mean [0.2604]\n",
      "Epoch: [397][ 0/65]\tTime   0.55 (  0.55)\tData 0.5483 (0.5483)\tLoss (MSE) 3.925 (3.925)\n",
      "Epoch: [397][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 4.311 (3.843)\n",
      "Epoch: [397][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 2.363 (4.138)\n",
      "Epoch: [397][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.785 (3.940)\n",
      "Epoch: [397][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 5.136 (3.793)\n",
      "Epoch: [397][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.366 (3.947)\n",
      "Epoch: [397][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.783 (4.104)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.926\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.337\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.131\tL1 1.392\tG-Mean 1.332\n",
      " * Low: MSE 0.096\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #397: Train loss [4.1243]; Val loss: MSE [1.9262], L1 [0.5988], G-Mean [0.2604]\n",
      "Epoch: [398][ 0/65]\tTime   0.61 (  0.61)\tData 0.6000 (0.6000)\tLoss (MSE) 2.818 (2.818)\n",
      "Epoch: [398][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 2.597 (3.301)\n",
      "Epoch: [398][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.649 (3.899)\n",
      "Epoch: [398][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 6.028 (3.941)\n",
      "Epoch: [398][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 1.985 (3.835)\n",
      "Epoch: [398][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.085 (3.760)\n",
      "Epoch: [398][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.636 (3.860)\n",
      "Val: [0/9]\tTime  0.644 ( 0.644)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.921\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.349\tL1 1.034\tG-Mean 0.888\n",
      " * Median: MSE 2.094\tL1 1.376\tG-Mean 1.307\n",
      " * Low: MSE 0.095\tL1 0.208\tG-Mean 0.185\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #398: Train loss [3.9450]; Val loss: MSE [1.9211], L1 [0.6012], G-Mean [0.2609]\n",
      "Epoch: [399][ 0/65]\tTime   0.57 (  0.57)\tData 0.5649 (0.5649)\tLoss (MSE) 4.227 (4.227)\n",
      "Epoch: [399][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.974 (4.876)\n",
      "Epoch: [399][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.094 (4.445)\n",
      "Epoch: [399][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.787 (4.396)\n",
      "Epoch: [399][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.789 (4.121)\n",
      "Epoch: [399][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.020 (3.973)\n",
      "Epoch: [399][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.276 (3.946)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.919\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.349\tL1 1.035\tG-Mean 0.890\n",
      " * Median: MSE 2.090\tL1 1.375\tG-Mean 1.296\n",
      " * Low: MSE 0.095\tL1 0.207\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #399: Train loss [3.9667]; Val loss: MSE [1.9186], L1 [0.6015], G-Mean [0.2620]\n",
      "Epoch: [400][ 0/65]\tTime   0.56 (  0.56)\tData 0.5553 (0.5553)\tLoss (MSE) 3.635 (3.635)\n",
      "Epoch: [400][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 2.575 (3.831)\n",
      "Epoch: [400][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 3.068 (3.827)\n",
      "Epoch: [400][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.576 (3.665)\n",
      "Epoch: [400][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.083 (3.590)\n",
      "Epoch: [400][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.677 (3.818)\n",
      "Epoch: [400][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.855 (3.899)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.063 (2.063)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.930\tL1 0.593\tG-Mean 0.264\n",
      " * Many: MSE 2.294\tL1 0.995\tG-Mean 0.846\n",
      " * Median: MSE 2.212\tL1 1.421\tG-Mean 1.360\n",
      " * Low: MSE 0.106\tL1 0.246\tG-Mean 0.226\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #400: Train loss [3.9060]; Val loss: MSE [1.9298], L1 [0.5928], G-Mean [0.2641]\n",
      "Epoch: [401][ 0/65]\tTime   0.56 (  0.56)\tData 0.5545 (0.5545)\tLoss (MSE) 3.498 (3.498)\n",
      "Epoch: [401][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0570)\tLoss (MSE) 4.852 (4.219)\n",
      "Epoch: [401][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.725 (4.429)\n",
      "Epoch: [401][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.542 (4.202)\n",
      "Epoch: [401][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 2.129 (4.043)\n",
      "Epoch: [401][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.784 (4.000)\n",
      "Epoch: [401][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.988 (3.910)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.317\tL1 1.013\tG-Mean 0.866\n",
      " * Median: MSE 2.157\tL1 1.400\tG-Mean 1.328\n",
      " * Low: MSE 0.096\tL1 0.227\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #401: Train loss [3.9259]; Val loss: MSE [1.9225], L1 [0.5961], G-Mean [0.2603]\n",
      "Epoch: [402][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 2.997 (2.997)\n",
      "Epoch: [402][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0543)\tLoss (MSE) 3.860 (3.981)\n",
      "Epoch: [402][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.706 (4.105)\n",
      "Epoch: [402][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.113 (4.001)\n",
      "Epoch: [402][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 1.973 (3.810)\n",
      "Epoch: [402][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 8.301 (3.952)\n",
      "Epoch: [402][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.680 (3.966)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.317\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.150\tL1 1.398\tG-Mean 1.327\n",
      " * Low: MSE 0.097\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #402: Train loss [3.9756]; Val loss: MSE [1.9193], L1 [0.5968], G-Mean [0.2602]\n",
      "Epoch: [403][ 0/65]\tTime   0.56 (  0.56)\tData 0.5493 (0.5493)\tLoss (MSE) 3.764 (3.764)\n",
      "Epoch: [403][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0529)\tLoss (MSE) 3.731 (3.937)\n",
      "Epoch: [403][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.493 (3.597)\n",
      "Epoch: [403][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 7.995 (3.942)\n",
      "Epoch: [403][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.942 (3.832)\n",
      "Epoch: [403][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.389 (3.848)\n",
      "Epoch: [403][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.631 (3.811)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.915\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.134\tL1 1.391\tG-Mean 1.313\n",
      " * Low: MSE 0.096\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #403: Train loss [3.8619]; Val loss: MSE [1.9149], L1 [0.5977], G-Mean [0.2610]\n",
      "Epoch: [404][ 0/65]\tTime   0.56 (  0.56)\tData 0.5535 (0.5535)\tLoss (MSE) 9.559 (9.559)\n",
      "Epoch: [404][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 2.639 (4.795)\n",
      "Epoch: [404][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 3.051 (4.008)\n",
      "Epoch: [404][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 7.839 (4.058)\n",
      "Epoch: [404][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.983 (3.920)\n",
      "Epoch: [404][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.891 (4.013)\n",
      "Epoch: [404][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.536 (3.920)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.912\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.351\tL1 1.041\tG-Mean 0.897\n",
      " * Median: MSE 2.074\tL1 1.370\tG-Mean 1.304\n",
      " * Low: MSE 0.095\tL1 0.200\tG-Mean 0.176\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #404: Train loss [3.9450]; Val loss: MSE [1.9123], L1 [0.6031], G-Mean [0.2619]\n",
      "Epoch: [405][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 4.817 (4.817)\n",
      "Epoch: [405][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 6.027 (3.816)\n",
      "Epoch: [405][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 4.641 (4.147)\n",
      "Epoch: [405][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 2.504 (4.340)\n",
      "Epoch: [405][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.531 (4.175)\n",
      "Epoch: [405][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.136 (3.989)\n",
      "Epoch: [405][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.802 (3.963)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.307\tL1 1.009\tG-Mean 0.861\n",
      " * Median: MSE 2.170\tL1 1.404\tG-Mean 1.336\n",
      " * Low: MSE 0.104\tL1 0.232\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #405: Train loss [3.9191]; Val loss: MSE [1.9211], L1 [0.5952], G-Mean [0.2636]\n",
      "Epoch: [406][ 0/65]\tTime   0.57 (  0.57)\tData 0.5623 (0.5623)\tLoss (MSE) 3.505 (3.505)\n",
      "Epoch: [406][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 2.741 (3.835)\n",
      "Epoch: [406][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.523 (4.009)\n",
      "Epoch: [406][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 2.093 (4.033)\n",
      "Epoch: [406][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.430 (3.941)\n",
      "Epoch: [406][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.356 (3.846)\n",
      "Epoch: [406][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.168 (3.882)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.132\tL1 1.389\tG-Mean 1.276\n",
      " * Low: MSE 0.106\tL1 0.222\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #406: Train loss [3.9021]; Val loss: MSE [1.9177], L1 [0.5982], G-Mean [0.2607]\n",
      "Epoch: [407][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 2.602 (2.602)\n",
      "Epoch: [407][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 3.532 (4.618)\n",
      "Epoch: [407][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 3.558 (4.174)\n",
      "Epoch: [407][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 2.693 (4.210)\n",
      "Epoch: [407][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.173 (3.962)\n",
      "Epoch: [407][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 2.435 (3.928)\n",
      "Epoch: [407][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.338 (3.911)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.069 (2.069)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.928\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.304\tL1 1.003\tG-Mean 0.854\n",
      " * Median: MSE 2.187\tL1 1.409\tG-Mean 1.320\n",
      " * Low: MSE 0.114\tL1 0.240\tG-Mean 0.219\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #407: Train loss [3.9363]; Val loss: MSE [1.9277], L1 [0.5947], G-Mean [0.2644]\n",
      "Epoch: [408][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 6.750 (6.750)\n",
      "Epoch: [408][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 5.477 (3.533)\n",
      "Epoch: [408][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 5.931 (3.531)\n",
      "Epoch: [408][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.711 (3.709)\n",
      "Epoch: [408][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 7.031 (4.087)\n",
      "Epoch: [408][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.050 (4.052)\n",
      "Epoch: [408][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.790 (3.985)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.069 (2.069)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.920\tL1 0.592\tG-Mean 0.264\n",
      " * Many: MSE 2.285\tL1 0.996\tG-Mean 0.848\n",
      " * Median: MSE 2.204\tL1 1.417\tG-Mean 1.356\n",
      " * Low: MSE 0.108\tL1 0.242\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #408: Train loss [3.9436]; Val loss: MSE [1.9204], L1 [0.5922], G-Mean [0.2643]\n",
      "Epoch: [409][ 0/65]\tTime   0.59 (  0.59)\tData 0.5795 (0.5795)\tLoss (MSE) 5.020 (5.020)\n",
      "Epoch: [409][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 3.320 (4.060)\n",
      "Epoch: [409][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.015 (4.506)\n",
      "Epoch: [409][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.167 (4.420)\n",
      "Epoch: [409][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.817 (4.131)\n",
      "Epoch: [409][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.113 (4.030)\n",
      "Epoch: [409][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.930 (4.003)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.081 (2.081)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.927\tL1 0.596\tG-Mean 0.264\n",
      " * Many: MSE 2.314\tL1 1.010\tG-Mean 0.862\n",
      " * Median: MSE 2.167\tL1 1.404\tG-Mean 1.342\n",
      " * Low: MSE 0.105\tL1 0.232\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #409: Train loss [4.0189]; Val loss: MSE [1.9265], L1 [0.5961], G-Mean [0.2637]\n",
      "Epoch: [410][ 0/65]\tTime   0.56 (  0.56)\tData 0.5536 (0.5536)\tLoss (MSE) 3.474 (3.474)\n",
      "Epoch: [410][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0588)\tLoss (MSE) 2.921 (3.665)\n",
      "Epoch: [410][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 3.658 (4.142)\n",
      "Epoch: [410][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 2.291 (4.052)\n",
      "Epoch: [410][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.929 (3.905)\n",
      "Epoch: [410][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.520 (3.805)\n",
      "Epoch: [410][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.909 (3.818)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.087 (2.087)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.940\tL1 0.592\tG-Mean 0.267\n",
      " * Many: MSE 2.289\tL1 0.985\tG-Mean 0.834\n",
      " * Median: MSE 2.242\tL1 1.431\tG-Mean 1.371\n",
      " * Low: MSE 0.118\tL1 0.259\tG-Mean 0.238\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #410: Train loss [3.8476]; Val loss: MSE [1.9403], L1 [0.5918], G-Mean [0.2673]\n",
      "Epoch: [411][ 0/65]\tTime   0.57 (  0.57)\tData 0.5678 (0.5678)\tLoss (MSE) 3.378 (3.378)\n",
      "Epoch: [411][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0596)\tLoss (MSE) 3.176 (3.615)\n",
      "Epoch: [411][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.920 (3.943)\n",
      "Epoch: [411][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 3.170 (3.939)\n",
      "Epoch: [411][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 4.003 (3.928)\n",
      "Epoch: [411][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.427 (3.881)\n",
      "Epoch: [411][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.861 (3.825)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.926\tL1 0.604\tG-Mean 0.261\n",
      " * Many: MSE 2.364\tL1 1.040\tG-Mean 0.894\n",
      " * Median: MSE 2.077\tL1 1.370\tG-Mean 1.303\n",
      " * Low: MSE 0.096\tL1 0.203\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #411: Train loss [3.8805]; Val loss: MSE [1.9257], L1 [0.6036], G-Mean [0.2610]\n",
      "Epoch: [412][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 3.430 (3.430)\n",
      "Epoch: [412][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0550)\tLoss (MSE) 2.628 (3.403)\n",
      "Epoch: [412][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.071 (3.706)\n",
      "Epoch: [412][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 9.883 (4.054)\n",
      "Epoch: [412][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.636 (4.049)\n",
      "Epoch: [412][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.176 (3.973)\n",
      "Epoch: [412][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.666 (3.931)\n",
      "Val: [0/9]\tTime  0.627 ( 0.627)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.918\tL1 0.605\tG-Mean 0.264\n",
      " * Many: MSE 2.367\tL1 1.048\tG-Mean 0.904\n",
      " * Median: MSE 2.056\tL1 1.363\tG-Mean 1.298\n",
      " * Low: MSE 0.089\tL1 0.191\tG-Mean 0.169\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #412: Train loss [3.9485]; Val loss: MSE [1.9178], L1 [0.6052], G-Mean [0.2636]\n",
      "Epoch: [413][ 0/65]\tTime   0.67 (  0.67)\tData 0.6592 (0.6592)\tLoss (MSE) 3.362 (3.362)\n",
      "Epoch: [413][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0613)\tLoss (MSE) 5.608 (4.464)\n",
      "Epoch: [413][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0321)\tLoss (MSE) 5.159 (3.987)\n",
      "Epoch: [413][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 3.121 (3.970)\n",
      "Epoch: [413][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 2.303 (3.952)\n",
      "Epoch: [413][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 5.577 (3.963)\n",
      "Epoch: [413][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.051 (3.907)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.926\tL1 0.595\tG-Mean 0.263\n",
      " * Many: MSE 2.304\tL1 1.005\tG-Mean 0.857\n",
      " * Median: MSE 2.182\tL1 1.410\tG-Mean 1.349\n",
      " * Low: MSE 0.105\tL1 0.235\tG-Mean 0.216\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #413: Train loss [3.8692]; Val loss: MSE [1.9257], L1 [0.5946], G-Mean [0.2632]\n",
      "Epoch: [414][ 0/65]\tTime   0.55 (  0.55)\tData 0.5443 (0.5443)\tLoss (MSE) 3.920 (3.920)\n",
      "Epoch: [414][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 3.359 (4.065)\n",
      "Epoch: [414][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.937 (4.062)\n",
      "Epoch: [414][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 4.623 (3.968)\n",
      "Epoch: [414][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.678 (3.776)\n",
      "Epoch: [414][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 2.807 (3.818)\n",
      "Epoch: [414][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 5.298 (3.891)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.067 (2.067)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.926\tL1 0.594\tG-Mean 0.263\n",
      " * Many: MSE 2.303\tL1 1.004\tG-Mean 0.855\n",
      " * Median: MSE 2.185\tL1 1.410\tG-Mean 1.349\n",
      " * Low: MSE 0.101\tL1 0.235\tG-Mean 0.216\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #414: Train loss [3.8911]; Val loss: MSE [1.9258], L1 [0.5942], G-Mean [0.2628]\n",
      "Epoch: [415][ 0/65]\tTime   0.60 (  0.60)\tData 0.5903 (0.5903)\tLoss (MSE) 4.262 (4.262)\n",
      "Epoch: [415][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0571)\tLoss (MSE) 1.802 (3.711)\n",
      "Epoch: [415][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 3.908 (4.118)\n",
      "Epoch: [415][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 5.790 (4.026)\n",
      "Epoch: [415][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 2.726 (3.939)\n",
      "Epoch: [415][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.862 (4.037)\n",
      "Epoch: [415][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.169 (3.948)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.327\tL1 1.018\tG-Mean 0.870\n",
      " * Median: MSE 2.141\tL1 1.394\tG-Mean 1.329\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #415: Train loss [3.9333]; Val loss: MSE [1.9254], L1 [0.5975], G-Mean [0.2596]\n",
      "Epoch: [416][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 3.388 (3.388)\n",
      "Epoch: [416][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 4.102 (3.644)\n",
      "Epoch: [416][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.116 (4.261)\n",
      "Epoch: [416][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.726 (4.188)\n",
      "Epoch: [416][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 5.390 (4.118)\n",
      "Epoch: [416][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.185 (4.095)\n",
      "Epoch: [416][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 1.591 (3.963)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.062 (2.062)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.927\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.341\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.119\tL1 1.384\tG-Mean 1.315\n",
      " * Low: MSE 0.098\tL1 0.218\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #416: Train loss [3.9818]; Val loss: MSE [1.9266], L1 [0.6001], G-Mean [0.2613]\n",
      "Epoch: [417][ 0/65]\tTime   0.57 (  0.57)\tData 0.5607 (0.5607)\tLoss (MSE) 2.753 (2.753)\n",
      "Epoch: [417][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 5.901 (3.443)\n",
      "Epoch: [417][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 2.873 (3.598)\n",
      "Epoch: [417][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.169 (3.605)\n",
      "Epoch: [417][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.068 (3.725)\n",
      "Epoch: [417][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 6.165 (3.823)\n",
      "Epoch: [417][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 5.274 (3.951)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.913\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.032\tG-Mean 0.886\n",
      " * Median: MSE 2.100\tL1 1.378\tG-Mean 1.309\n",
      " * Low: MSE 0.093\tL1 0.209\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #417: Train loss [3.9700]; Val loss: MSE [1.9125], L1 [0.6008], G-Mean [0.2598]\n",
      "Epoch: [418][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 3.728 (3.728)\n",
      "Epoch: [418][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 4.344 (3.957)\n",
      "Epoch: [418][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.308 (3.876)\n",
      "Epoch: [418][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.985 (3.778)\n",
      "Epoch: [418][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 7.456 (3.762)\n",
      "Epoch: [418][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.148 (3.831)\n",
      "Epoch: [418][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.593 (3.932)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.318\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.142\tL1 1.393\tG-Mean 1.324\n",
      " * Low: MSE 0.106\tL1 0.227\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #418: Train loss [3.9702]; Val loss: MSE [1.9207], L1 [0.5977], G-Mean [0.2588]\n",
      "Epoch: [419][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 3.945 (3.945)\n",
      "Epoch: [419][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0587)\tLoss (MSE) 3.179 (3.737)\n",
      "Epoch: [419][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 2.440 (3.703)\n",
      "Epoch: [419][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 3.424 (3.702)\n",
      "Epoch: [419][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.577 (3.766)\n",
      "Epoch: [419][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.515 (3.859)\n",
      "Epoch: [419][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.435 (3.878)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.915\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.335\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.102\tL1 1.380\tG-Mean 1.317\n",
      " * Low: MSE 0.104\tL1 0.213\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #419: Train loss [3.8972]; Val loss: MSE [1.9152], L1 [0.6011], G-Mean [0.2608]\n",
      "Epoch: [420][ 0/65]\tTime   0.55 (  0.55)\tData 0.5491 (0.5491)\tLoss (MSE) 7.709 (7.709)\n",
      "Epoch: [420][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 2.465 (4.035)\n",
      "Epoch: [420][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 2.853 (3.768)\n",
      "Epoch: [420][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 4.419 (3.792)\n",
      "Epoch: [420][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 4.988 (3.840)\n",
      "Epoch: [420][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 11.294 (4.044)\n",
      "Epoch: [420][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.268 (3.964)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.918\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.313\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.149\tL1 1.399\tG-Mean 1.340\n",
      " * Low: MSE 0.106\tL1 0.226\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #420: Train loss [3.8949]; Val loss: MSE [1.9183], L1 [0.5974], G-Mean [0.2597]\n",
      "Epoch: [421][ 0/65]\tTime   0.55 (  0.55)\tData 0.5461 (0.5461)\tLoss (MSE) 3.162 (3.162)\n",
      "Epoch: [421][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0573)\tLoss (MSE) 2.608 (3.900)\n",
      "Epoch: [421][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 2.161 (3.737)\n",
      "Epoch: [421][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 6.380 (3.928)\n",
      "Epoch: [421][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.673 (3.850)\n",
      "Epoch: [421][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.817 (3.863)\n",
      "Epoch: [421][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.483 (3.873)\n",
      "Val: [0/9]\tTime  0.578 ( 0.578)\tLoss (MSE) 2.080 (2.080)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.932\tL1 0.593\tG-Mean 0.264\n",
      " * Many: MSE 2.286\tL1 0.991\tG-Mean 0.841\n",
      " * Median: MSE 2.227\tL1 1.426\tG-Mean 1.368\n",
      " * Low: MSE 0.115\tL1 0.252\tG-Mean 0.233\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #421: Train loss [3.9353]; Val loss: MSE [1.9323], L1 [0.5928], G-Mean [0.2643]\n",
      "Epoch: [422][ 0/65]\tTime   0.63 (  0.63)\tData 0.6276 (0.6276)\tLoss (MSE) 2.905 (2.905)\n",
      "Epoch: [422][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0615)\tLoss (MSE) 3.786 (3.110)\n",
      "Epoch: [422][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0323)\tLoss (MSE) 3.713 (3.627)\n",
      "Epoch: [422][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0219)\tLoss (MSE) 3.445 (3.639)\n",
      "Epoch: [422][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 5.270 (3.744)\n",
      "Epoch: [422][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 2.753 (3.990)\n",
      "Epoch: [422][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.641 (3.948)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.076 (2.076)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.930\tL1 0.593\tG-Mean 0.265\n",
      " * Many: MSE 2.286\tL1 0.992\tG-Mean 0.843\n",
      " * Median: MSE 2.225\tL1 1.426\tG-Mean 1.368\n",
      " * Low: MSE 0.118\tL1 0.250\tG-Mean 0.230\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #422: Train loss [3.9662]; Val loss: MSE [1.9303], L1 [0.5931], G-Mean [0.2654]\n",
      "Epoch: [423][ 0/65]\tTime   0.56 (  0.56)\tData 0.5573 (0.5573)\tLoss (MSE) 6.868 (6.868)\n",
      "Epoch: [423][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0611)\tLoss (MSE) 4.175 (4.260)\n",
      "Epoch: [423][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0321)\tLoss (MSE) 2.758 (3.786)\n",
      "Epoch: [423][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0217)\tLoss (MSE) 4.789 (3.870)\n",
      "Epoch: [423][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 7.172 (3.871)\n",
      "Epoch: [423][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 3.587 (4.012)\n",
      "Epoch: [423][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.264 (3.963)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.084 (2.084)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.937\tL1 0.595\tG-Mean 0.265\n",
      " * Many: MSE 2.307\tL1 1.001\tG-Mean 0.851\n",
      " * Median: MSE 2.201\tL1 1.417\tG-Mean 1.359\n",
      " * Low: MSE 0.115\tL1 0.244\tG-Mean 0.223\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #423: Train loss [3.9412]; Val loss: MSE [1.9366], L1 [0.5955], G-Mean [0.2652]\n",
      "Epoch: [424][ 0/65]\tTime   0.56 (  0.56)\tData 0.5586 (0.5586)\tLoss (MSE) 2.763 (2.763)\n",
      "Epoch: [424][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0526)\tLoss (MSE) 2.597 (3.980)\n",
      "Epoch: [424][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 4.264 (3.940)\n",
      "Epoch: [424][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.763 (3.817)\n",
      "Epoch: [424][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.891 (3.872)\n",
      "Epoch: [424][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 4.774 (3.994)\n",
      "Epoch: [424][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.080 (3.962)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.927\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.339\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.125\tL1 1.390\tG-Mean 1.332\n",
      " * Low: MSE 0.105\tL1 0.217\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #424: Train loss [3.9597]; Val loss: MSE [1.9269], L1 [0.6006], G-Mean [0.2618]\n",
      "Epoch: [425][ 0/65]\tTime   0.55 (  0.55)\tData 0.5429 (0.5429)\tLoss (MSE) 2.714 (2.714)\n",
      "Epoch: [425][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 2.149 (3.754)\n",
      "Epoch: [425][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.721 (3.994)\n",
      "Epoch: [425][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.575 (4.230)\n",
      "Epoch: [425][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.557 (4.095)\n",
      "Epoch: [425][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 4.077 (4.003)\n",
      "Epoch: [425][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.683 (3.945)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.061 (2.061)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.928\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.365\tL1 1.041\tG-Mean 0.896\n",
      " * Median: MSE 2.079\tL1 1.372\tG-Mean 1.309\n",
      " * Low: MSE 0.102\tL1 0.204\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #425: Train loss [4.0417]; Val loss: MSE [1.9278], L1 [0.6047], G-Mean [0.2630]\n",
      "Epoch: [426][ 0/65]\tTime   0.57 (  0.57)\tData 0.5609 (0.5609)\tLoss (MSE) 3.642 (3.642)\n",
      "Epoch: [426][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 3.560 (3.491)\n",
      "Epoch: [426][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.701 (3.873)\n",
      "Epoch: [426][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.346 (3.784)\n",
      "Epoch: [426][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.904 (3.912)\n",
      "Epoch: [426][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 1.796 (3.753)\n",
      "Epoch: [426][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.385 (3.755)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.937\tL1 0.604\tG-Mean 0.263\n",
      " * Many: MSE 2.366\tL1 1.035\tG-Mean 0.888\n",
      " * Median: MSE 2.097\tL1 1.378\tG-Mean 1.314\n",
      " * Low: MSE 0.104\tL1 0.212\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #426: Train loss [3.8567]; Val loss: MSE [1.9370], L1 [0.6037], G-Mean [0.2632]\n",
      "Epoch: [427][ 0/65]\tTime   0.57 (  0.57)\tData 0.5580 (0.5580)\tLoss (MSE) 2.804 (2.804)\n",
      "Epoch: [427][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.917 (4.484)\n",
      "Epoch: [427][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.527 (4.311)\n",
      "Epoch: [427][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.093 (4.126)\n",
      "Epoch: [427][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.295 (4.122)\n",
      "Epoch: [427][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.935 (3.996)\n",
      "Epoch: [427][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.470 (4.041)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.095 (2.095)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.945\tL1 0.594\tG-Mean 0.266\n",
      " * Many: MSE 2.302\tL1 0.991\tG-Mean 0.840\n",
      " * Median: MSE 2.227\tL1 1.425\tG-Mean 1.365\n",
      " * Low: MSE 0.114\tL1 0.253\tG-Mean 0.234\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #427: Train loss [3.9848]; Val loss: MSE [1.9454], L1 [0.5940], G-Mean [0.2655]\n",
      "Epoch: [428][ 0/65]\tTime   0.56 (  0.56)\tData 0.5508 (0.5508)\tLoss (MSE) 2.918 (2.918)\n",
      "Epoch: [428][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 2.323 (3.524)\n",
      "Epoch: [428][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 7.709 (3.885)\n",
      "Epoch: [428][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.551 (3.866)\n",
      "Epoch: [428][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.686 (3.924)\n",
      "Epoch: [428][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.227 (3.832)\n",
      "Epoch: [428][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.020 (3.908)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.092 (2.092)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.939\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.348\tL1 1.024\tG-Mean 0.875\n",
      " * Median: MSE 2.136\tL1 1.393\tG-Mean 1.331\n",
      " * Low: MSE 0.105\tL1 0.222\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #428: Train loss [3.9110]; Val loss: MSE [1.9386], L1 [0.6010], G-Mean [0.2608]\n",
      "Epoch: [429][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 5.405 (5.405)\n",
      "Epoch: [429][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 3.678 (4.120)\n",
      "Epoch: [429][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.741 (4.052)\n",
      "Epoch: [429][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.150 (3.897)\n",
      "Epoch: [429][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.497 (3.905)\n",
      "Epoch: [429][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.768 (3.958)\n",
      "Epoch: [429][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.619 (3.956)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.080 (2.080)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.924\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.344\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.108\tL1 1.384\tG-Mean 1.324\n",
      " * Low: MSE 0.102\tL1 0.212\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #429: Train loss [3.9511]; Val loss: MSE [1.9235], L1 [0.6016], G-Mean [0.2611]\n",
      "Epoch: [430][ 0/65]\tTime   0.57 (  0.57)\tData 0.5673 (0.5673)\tLoss (MSE) 3.538 (3.538)\n",
      "Epoch: [430][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0539)\tLoss (MSE) 2.896 (4.022)\n",
      "Epoch: [430][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 4.597 (3.771)\n",
      "Epoch: [430][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 6.468 (4.027)\n",
      "Epoch: [430][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 5.490 (3.989)\n",
      "Epoch: [430][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.668 (3.986)\n",
      "Epoch: [430][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.866 (4.035)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.079 (2.079)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.928\tL1 0.595\tG-Mean 0.264\n",
      " * Many: MSE 2.300\tL1 1.001\tG-Mean 0.853\n",
      " * Median: MSE 2.196\tL1 1.416\tG-Mean 1.358\n",
      " * Low: MSE 0.109\tL1 0.240\tG-Mean 0.221\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #430: Train loss [3.9762]; Val loss: MSE [1.9283], L1 [0.5948], G-Mean [0.2641]\n",
      "Epoch: [431][ 0/65]\tTime   0.55 (  0.55)\tData 0.5412 (0.5412)\tLoss (MSE) 3.426 (3.426)\n",
      "Epoch: [431][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 2.735 (3.449)\n",
      "Epoch: [431][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 5.323 (3.513)\n",
      "Epoch: [431][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 2.942 (3.494)\n",
      "Epoch: [431][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.419 (3.776)\n",
      "Epoch: [431][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 4.838 (3.822)\n",
      "Epoch: [431][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.098 (3.829)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.081 (2.081)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.931\tL1 0.595\tG-Mean 0.265\n",
      " * Many: MSE 2.304\tL1 1.002\tG-Mean 0.852\n",
      " * Median: MSE 2.194\tL1 1.415\tG-Mean 1.356\n",
      " * Low: MSE 0.106\tL1 0.240\tG-Mean 0.221\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #431: Train loss [3.8729]; Val loss: MSE [1.9315], L1 [0.5953], G-Mean [0.2646]\n",
      "Epoch: [432][ 0/65]\tTime   0.56 (  0.56)\tData 0.5556 (0.5556)\tLoss (MSE) 2.627 (2.627)\n",
      "Epoch: [432][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0597)\tLoss (MSE) 2.616 (4.114)\n",
      "Epoch: [432][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.680 (4.101)\n",
      "Epoch: [432][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 1.894 (3.881)\n",
      "Epoch: [432][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 4.179 (3.821)\n",
      "Epoch: [432][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.670 (3.836)\n",
      "Epoch: [432][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 4.339 (4.052)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.914\tL1 0.599\tG-Mean 0.262\n",
      " * Many: MSE 2.321\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.124\tL1 1.388\tG-Mean 1.325\n",
      " * Low: MSE 0.100\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #432: Train loss [4.0150]; Val loss: MSE [1.9140], L1 [0.5986], G-Mean [0.2615]\n",
      "Epoch: [433][ 0/65]\tTime   0.57 (  0.57)\tData 0.5605 (0.5605)\tLoss (MSE) 7.515 (7.515)\n",
      "Epoch: [433][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0600)\tLoss (MSE) 4.006 (3.925)\n",
      "Epoch: [433][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0315)\tLoss (MSE) 5.398 (3.835)\n",
      "Epoch: [433][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 3.218 (3.965)\n",
      "Epoch: [433][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 2.374 (4.019)\n",
      "Epoch: [433][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 3.412 (3.961)\n",
      "Epoch: [433][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.685 (3.922)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.908\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.029\tG-Mean 0.885\n",
      " * Median: MSE 2.105\tL1 1.382\tG-Mean 1.321\n",
      " * Low: MSE 0.097\tL1 0.211\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #433: Train loss [3.8847]; Val loss: MSE [1.9080], L1 [0.5998], G-Mean [0.2609]\n",
      "Epoch: [434][ 0/65]\tTime   0.57 (  0.57)\tData 0.5613 (0.5613)\tLoss (MSE) 3.261 (3.261)\n",
      "Epoch: [434][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 2.481 (4.340)\n",
      "Epoch: [434][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 2.854 (3.739)\n",
      "Epoch: [434][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.845 (3.726)\n",
      "Epoch: [434][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.424 (3.785)\n",
      "Epoch: [434][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.349 (3.797)\n",
      "Epoch: [434][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.398 (3.747)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.916\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.308\tL1 1.014\tG-Mean 0.868\n",
      " * Median: MSE 2.155\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.102\tL1 0.227\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #434: Train loss [3.8117]; Val loss: MSE [1.9157], L1 [0.5964], G-Mean [0.2598]\n",
      "Epoch: [435][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 3.009 (3.009)\n",
      "Epoch: [435][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 5.355 (3.976)\n",
      "Epoch: [435][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 2.783 (3.900)\n",
      "Epoch: [435][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 2.699 (3.752)\n",
      "Epoch: [435][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.553 (3.710)\n",
      "Epoch: [435][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 6.193 (3.722)\n",
      "Epoch: [435][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.845 (3.856)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.912\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.330\tL1 1.029\tG-Mean 0.885\n",
      " * Median: MSE 2.115\tL1 1.388\tG-Mean 1.331\n",
      " * Low: MSE 0.099\tL1 0.211\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #435: Train loss [3.8601]; Val loss: MSE [1.9122], L1 [0.6000], G-Mean [0.2598]\n",
      "Epoch: [436][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 5.299 (5.299)\n",
      "Epoch: [436][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0519)\tLoss (MSE) 2.575 (3.648)\n",
      "Epoch: [436][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.370 (3.678)\n",
      "Epoch: [436][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.824 (3.567)\n",
      "Epoch: [436][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.652 (3.777)\n",
      "Epoch: [436][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.021 (3.725)\n",
      "Epoch: [436][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.603 (3.868)\n",
      "Val: [0/9]\tTime  0.646 ( 0.646)\tLoss (MSE) 2.040 (2.040)\tLoss (L1) 0.649 (0.649)\n",
      " * Overall: MSE 1.907\tL1 0.608\tG-Mean 0.267\n",
      " * Many: MSE 2.368\tL1 1.056\tG-Mean 0.914\n",
      " * Median: MSE 2.037\tL1 1.360\tG-Mean 1.301\n",
      " * Low: MSE 0.090\tL1 0.184\tG-Mean 0.159\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #436: Train loss [3.9616]; Val loss: MSE [1.9072], L1 [0.6079], G-Mean [0.2672]\n",
      "Epoch: [437][ 0/65]\tTime   0.66 (  0.66)\tData 0.6487 (0.6487)\tLoss (MSE) 3.493 (3.493)\n",
      "Epoch: [437][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0601)\tLoss (MSE) 6.409 (3.818)\n",
      "Epoch: [437][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0315)\tLoss (MSE) 2.842 (4.050)\n",
      "Epoch: [437][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 2.917 (4.049)\n",
      "Epoch: [437][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 2.934 (3.848)\n",
      "Epoch: [437][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 4.808 (3.942)\n",
      "Epoch: [437][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.523 (3.793)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.916\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.349\tL1 1.038\tG-Mean 0.893\n",
      " * Median: MSE 2.089\tL1 1.377\tG-Mean 1.317\n",
      " * Low: MSE 0.103\tL1 0.205\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #437: Train loss [3.8938]; Val loss: MSE [1.9161], L1 [0.6032], G-Mean [0.2620]\n",
      "Epoch: [438][ 0/65]\tTime   0.56 (  0.56)\tData 0.5494 (0.5494)\tLoss (MSE) 2.677 (2.677)\n",
      "Epoch: [438][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 5.271 (3.146)\n",
      "Epoch: [438][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.639 (3.730)\n",
      "Epoch: [438][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 6.286 (4.007)\n",
      "Epoch: [438][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.780 (3.980)\n",
      "Epoch: [438][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.768 (3.885)\n",
      "Epoch: [438][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.733 (3.885)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.326\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.137\tL1 1.395\tG-Mean 1.337\n",
      " * Low: MSE 0.108\tL1 0.219\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #438: Train loss [3.9052]; Val loss: MSE [1.9167], L1 [0.5993], G-Mean [0.2606]\n",
      "Epoch: [439][ 0/65]\tTime   0.56 (  0.56)\tData 0.5521 (0.5521)\tLoss (MSE) 5.554 (5.554)\n",
      "Epoch: [439][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0592)\tLoss (MSE) 3.768 (3.769)\n",
      "Epoch: [439][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 3.239 (3.944)\n",
      "Epoch: [439][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 2.707 (4.040)\n",
      "Epoch: [439][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.378 (3.956)\n",
      "Epoch: [439][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 2.821 (4.019)\n",
      "Epoch: [439][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.223 (4.019)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.913\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.021\tG-Mean 0.876\n",
      " * Median: MSE 2.141\tL1 1.397\tG-Mean 1.338\n",
      " * Low: MSE 0.105\tL1 0.220\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #439: Train loss [4.0127]; Val loss: MSE [1.9134], L1 [0.5982], G-Mean [0.2604]\n",
      "Epoch: [440][ 0/65]\tTime   0.55 (  0.55)\tData 0.5478 (0.5478)\tLoss (MSE) 2.769 (2.769)\n",
      "Epoch: [440][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0559)\tLoss (MSE) 3.824 (3.848)\n",
      "Epoch: [440][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0293)\tLoss (MSE) 2.896 (3.823)\n",
      "Epoch: [440][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0199)\tLoss (MSE) 2.167 (3.621)\n",
      "Epoch: [440][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 2.683 (3.755)\n",
      "Epoch: [440][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.796 (3.857)\n",
      "Epoch: [440][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.103 (3.820)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.915\tL1 0.597\tG-Mean 0.260\n",
      " * Many: MSE 2.308\tL1 1.015\tG-Mean 0.868\n",
      " * Median: MSE 2.161\tL1 1.404\tG-Mean 1.347\n",
      " * Low: MSE 0.110\tL1 0.228\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #440: Train loss [3.8017]; Val loss: MSE [1.9147], L1 [0.5972], G-Mean [0.2596]\n",
      "Epoch: [441][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 3.476 (3.476)\n",
      "Epoch: [441][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 6.371 (3.942)\n",
      "Epoch: [441][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 3.879 (4.221)\n",
      "Epoch: [441][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.830 (4.101)\n",
      "Epoch: [441][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.259 (3.925)\n",
      "Epoch: [441][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.516 (3.957)\n",
      "Epoch: [441][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.669 (3.872)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.915\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.336\tL1 1.032\tG-Mean 0.886\n",
      " * Median: MSE 2.113\tL1 1.387\tG-Mean 1.329\n",
      " * Low: MSE 0.103\tL1 0.211\tG-Mean 0.187\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #441: Train loss [3.8712]; Val loss: MSE [1.9153], L1 [0.6014], G-Mean [0.2611]\n",
      "Epoch: [442][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 3.566 (3.566)\n",
      "Epoch: [442][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 2.293 (3.314)\n",
      "Epoch: [442][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.711 (3.655)\n",
      "Epoch: [442][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.539 (3.615)\n",
      "Epoch: [442][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.767 (3.636)\n",
      "Epoch: [442][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.339 (3.834)\n",
      "Epoch: [442][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.746 (3.886)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.923\tL1 0.593\tG-Mean 0.264\n",
      " * Many: MSE 2.281\tL1 0.994\tG-Mean 0.845\n",
      " * Median: MSE 2.231\tL1 1.429\tG-Mean 1.374\n",
      " * Low: MSE 0.113\tL1 0.248\tG-Mean 0.228\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #442: Train loss [3.8963]; Val loss: MSE [1.9234], L1 [0.5931], G-Mean [0.2643]\n",
      "Epoch: [443][ 0/65]\tTime   0.57 (  0.57)\tData 0.5622 (0.5622)\tLoss (MSE) 2.497 (2.497)\n",
      "Epoch: [443][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 6.321 (3.936)\n",
      "Epoch: [443][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.412 (3.637)\n",
      "Epoch: [443][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.599 (3.665)\n",
      "Epoch: [443][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.275 (3.586)\n",
      "Epoch: [443][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.772 (3.671)\n",
      "Epoch: [443][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.873 (3.756)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.041 (2.041)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.913\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.326\tL1 1.027\tG-Mean 0.882\n",
      " * Median: MSE 2.127\tL1 1.392\tG-Mean 1.334\n",
      " * Low: MSE 0.102\tL1 0.215\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #443: Train loss [3.8427]; Val loss: MSE [1.9131], L1 [0.5999], G-Mean [0.2618]\n",
      "Epoch: [444][ 0/65]\tTime   0.55 (  0.55)\tData 0.5467 (0.5467)\tLoss (MSE) 3.798 (3.798)\n",
      "Epoch: [444][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 5.883 (3.903)\n",
      "Epoch: [444][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.612 (4.025)\n",
      "Epoch: [444][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.103 (3.916)\n",
      "Epoch: [444][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.242 (3.863)\n",
      "Epoch: [444][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.236 (3.857)\n",
      "Epoch: [444][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.746 (3.753)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.040 (2.040)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.908\tL1 0.600\tG-Mean 0.262\n",
      " * Many: MSE 2.320\tL1 1.027\tG-Mean 0.882\n",
      " * Median: MSE 2.124\tL1 1.390\tG-Mean 1.331\n",
      " * Low: MSE 0.103\tL1 0.214\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #444: Train loss [3.8319]; Val loss: MSE [1.9077], L1 [0.5996], G-Mean [0.2616]\n",
      "Epoch: [445][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 3.727 (3.727)\n",
      "Epoch: [445][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 6.178 (4.282)\n",
      "Epoch: [445][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.593 (4.169)\n",
      "Epoch: [445][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.984 (3.945)\n",
      "Epoch: [445][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.064 (3.938)\n",
      "Epoch: [445][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.806 (3.887)\n",
      "Epoch: [445][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.112 (3.864)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.038 (2.038)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.912\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.349\tL1 1.041\tG-Mean 0.896\n",
      " * Median: MSE 2.088\tL1 1.378\tG-Mean 1.318\n",
      " * Low: MSE 0.100\tL1 0.202\tG-Mean 0.177\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #445: Train loss [3.8923]; Val loss: MSE [1.9123], L1 [0.6039], G-Mean [0.2619]\n",
      "Epoch: [446][ 0/65]\tTime   0.58 (  0.58)\tData 0.5706 (0.5706)\tLoss (MSE) 5.584 (5.584)\n",
      "Epoch: [446][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 3.532 (3.953)\n",
      "Epoch: [446][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.181 (3.998)\n",
      "Epoch: [446][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 5.583 (4.074)\n",
      "Epoch: [446][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.368 (3.930)\n",
      "Epoch: [446][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.814 (3.856)\n",
      "Epoch: [446][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.516 (3.883)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.029 (2.029)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.607\tG-Mean 0.265\n",
      " * Many: MSE 2.369\tL1 1.050\tG-Mean 0.904\n",
      " * Median: MSE 2.062\tL1 1.367\tG-Mean 1.305\n",
      " * Low: MSE 0.100\tL1 0.194\tG-Mean 0.168\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #446: Train loss [3.8920]; Val loss: MSE [1.9167], L1 [0.6070], G-Mean [0.2647]\n",
      "Epoch: [447][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 2.706 (2.706)\n",
      "Epoch: [447][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 4.973 (3.988)\n",
      "Epoch: [447][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 5.229 (4.053)\n",
      "Epoch: [447][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.918 (3.934)\n",
      "Epoch: [447][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.961 (3.910)\n",
      "Epoch: [447][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.802 (3.816)\n",
      "Epoch: [447][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.240 (3.802)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.027 (2.027)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.607\tG-Mean 0.265\n",
      " * Many: MSE 2.374\tL1 1.050\tG-Mean 0.904\n",
      " * Median: MSE 2.058\tL1 1.365\tG-Mean 1.300\n",
      " * Low: MSE 0.099\tL1 0.194\tG-Mean 0.167\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #447: Train loss [3.8574]; Val loss: MSE [1.9203], L1 [0.6072], G-Mean [0.2649]\n",
      "Epoch: [448][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 3.503 (3.503)\n",
      "Epoch: [448][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.647 (3.804)\n",
      "Epoch: [448][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.710 (3.918)\n",
      "Epoch: [448][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.822 (3.741)\n",
      "Epoch: [448][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.464 (3.835)\n",
      "Epoch: [448][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.994 (3.860)\n",
      "Epoch: [448][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.075 (3.887)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.042 (2.042)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.929\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.355\tL1 1.033\tG-Mean 0.884\n",
      " * Median: MSE 2.107\tL1 1.382\tG-Mean 1.316\n",
      " * Low: MSE 0.105\tL1 0.213\tG-Mean 0.188\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #448: Train loss [3.9085]; Val loss: MSE [1.9287], L1 [0.6025], G-Mean [0.2611]\n",
      "Epoch: [449][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 3.026 (3.026)\n",
      "Epoch: [449][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.125 (3.210)\n",
      "Epoch: [449][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.805 (3.711)\n",
      "Epoch: [449][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.061 (3.822)\n",
      "Epoch: [449][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.398 (3.962)\n",
      "Epoch: [449][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.670 (3.956)\n",
      "Epoch: [449][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.733 (3.923)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.638 (0.638)\n",
      " * Overall: MSE 1.935\tL1 0.596\tG-Mean 0.264\n",
      " * Many: MSE 2.315\tL1 1.005\tG-Mean 0.855\n",
      " * Median: MSE 2.190\tL1 1.413\tG-Mean 1.351\n",
      " * Low: MSE 0.115\tL1 0.241\tG-Mean 0.217\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #449: Train loss [4.0043]; Val loss: MSE [1.9348], L1 [0.5960], G-Mean [0.2636]\n",
      "Epoch: [450][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 6.079 (6.079)\n",
      "Epoch: [450][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 3.298 (3.899)\n",
      "Epoch: [450][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 2.518 (3.926)\n",
      "Epoch: [450][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.266 (3.951)\n",
      "Epoch: [450][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 2.982 (3.835)\n",
      "Epoch: [450][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.525 (3.854)\n",
      "Epoch: [450][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.335 (3.868)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.637 (0.637)\n",
      " * Overall: MSE 1.933\tL1 0.596\tG-Mean 0.263\n",
      " * Many: MSE 2.311\tL1 1.004\tG-Mean 0.853\n",
      " * Median: MSE 2.196\tL1 1.415\tG-Mean 1.353\n",
      " * Low: MSE 0.117\tL1 0.243\tG-Mean 0.220\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #450: Train loss [3.8572]; Val loss: MSE [1.9332], L1 [0.5956], G-Mean [0.2634]\n",
      "Epoch: [451][ 0/65]\tTime   0.60 (  0.60)\tData 0.5916 (0.5916)\tLoss (MSE) 5.592 (5.592)\n",
      "Epoch: [451][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.128 (3.901)\n",
      "Epoch: [451][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.000 (3.912)\n",
      "Epoch: [451][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.882 (3.699)\n",
      "Epoch: [451][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 2.697 (3.988)\n",
      "Epoch: [451][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.485 (3.882)\n",
      "Epoch: [451][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.794 (3.829)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.936\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.342\tL1 1.021\tG-Mean 0.872\n",
      " * Median: MSE 2.143\tL1 1.395\tG-Mean 1.328\n",
      " * Low: MSE 0.115\tL1 0.227\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #451: Train loss [3.8611]; Val loss: MSE [1.9356], L1 [0.5999], G-Mean [0.2598]\n",
      "Epoch: [452][ 0/65]\tTime   0.55 (  0.55)\tData 0.5486 (0.5486)\tLoss (MSE) 3.705 (3.705)\n",
      "Epoch: [452][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0513)\tLoss (MSE) 5.465 (3.503)\n",
      "Epoch: [452][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 4.744 (3.410)\n",
      "Epoch: [452][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.695 (3.565)\n",
      "Epoch: [452][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.105 (3.673)\n",
      "Epoch: [452][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.298 (3.763)\n",
      "Epoch: [452][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.694 (3.759)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.936\tL1 0.598\tG-Mean 0.263\n",
      " * Many: MSE 2.326\tL1 1.011\tG-Mean 0.861\n",
      " * Median: MSE 2.172\tL1 1.404\tG-Mean 1.337\n",
      " * Low: MSE 0.119\tL1 0.237\tG-Mean 0.213\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #452: Train loss [3.8351]; Val loss: MSE [1.9364], L1 [0.5981], G-Mean [0.2627]\n",
      "Epoch: [453][ 0/65]\tTime   0.56 (  0.56)\tData 0.5509 (0.5509)\tLoss (MSE) 5.077 (5.077)\n",
      "Epoch: [453][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 2.692 (3.656)\n",
      "Epoch: [453][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 4.250 (3.843)\n",
      "Epoch: [453][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.962 (3.943)\n",
      "Epoch: [453][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 2.362 (3.900)\n",
      "Epoch: [453][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.850 (3.834)\n",
      "Epoch: [453][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.561 (3.848)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.041 (2.041)\tLoss (L1) 0.637 (0.637)\n",
      " * Overall: MSE 1.925\tL1 0.596\tG-Mean 0.261\n",
      " * Many: MSE 2.311\tL1 1.010\tG-Mean 0.860\n",
      " * Median: MSE 2.178\tL1 1.407\tG-Mean 1.343\n",
      " * Low: MSE 0.114\tL1 0.235\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #453: Train loss [3.8569]; Val loss: MSE [1.9247], L1 [0.5965], G-Mean [0.2613]\n",
      "Epoch: [454][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 7.936 (7.936)\n",
      "Epoch: [454][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0603)\tLoss (MSE) 2.498 (4.378)\n",
      "Epoch: [454][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0316)\tLoss (MSE) 4.014 (4.138)\n",
      "Epoch: [454][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0214)\tLoss (MSE) 4.561 (3.910)\n",
      "Epoch: [454][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.756 (3.980)\n",
      "Epoch: [454][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 3.600 (3.835)\n",
      "Epoch: [454][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 2.840 (3.831)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.026 (2.026)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.912\tL1 0.607\tG-Mean 0.264\n",
      " * Many: MSE 2.366\tL1 1.051\tG-Mean 0.907\n",
      " * Median: MSE 2.054\tL1 1.362\tG-Mean 1.293\n",
      " * Low: MSE 0.107\tL1 0.194\tG-Mean 0.167\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #454: Train loss [3.8216]; Val loss: MSE [1.9124], L1 [0.6073], G-Mean [0.2643]\n",
      "Epoch: [455][ 0/65]\tTime   0.56 (  0.56)\tData 0.5554 (0.5554)\tLoss (MSE) 5.583 (5.583)\n",
      "Epoch: [455][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 4.061 (4.231)\n",
      "Epoch: [455][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.868 (3.884)\n",
      "Epoch: [455][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 4.065 (3.860)\n",
      "Epoch: [455][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.795 (3.878)\n",
      "Epoch: [455][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.284 (4.098)\n",
      "Epoch: [455][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.056 (4.033)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.033 (2.033)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.913\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.128\tL1 1.390\tG-Mean 1.327\n",
      " * Low: MSE 0.111\tL1 0.217\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #455: Train loss [4.0386]; Val loss: MSE [1.9133], L1 [0.5995], G-Mean [0.2599]\n",
      "Epoch: [456][ 0/65]\tTime   0.56 (  0.56)\tData 0.5555 (0.5555)\tLoss (MSE) 3.277 (3.277)\n",
      "Epoch: [456][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0566)\tLoss (MSE) 2.280 (3.963)\n",
      "Epoch: [456][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 2.584 (3.864)\n",
      "Epoch: [456][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 2.543 (4.054)\n",
      "Epoch: [456][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.586 (4.008)\n",
      "Epoch: [456][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.094 (3.927)\n",
      "Epoch: [456][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.110 (3.901)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.918\tL1 0.595\tG-Mean 0.261\n",
      " * Many: MSE 2.300\tL1 1.008\tG-Mean 0.861\n",
      " * Median: MSE 2.184\tL1 1.411\tG-Mean 1.350\n",
      " * Low: MSE 0.112\tL1 0.235\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #456: Train loss [3.9334]; Val loss: MSE [1.9181], L1 [0.5952], G-Mean [0.2614]\n",
      "Epoch: [457][ 0/65]\tTime   0.55 (  0.55)\tData 0.5444 (0.5444)\tLoss (MSE) 4.689 (4.689)\n",
      "Epoch: [457][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 2.521 (4.062)\n",
      "Epoch: [457][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 2.034 (3.742)\n",
      "Epoch: [457][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.309 (3.652)\n",
      "Epoch: [457][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 6.143 (3.789)\n",
      "Epoch: [457][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.379 (4.017)\n",
      "Epoch: [457][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.819 (3.885)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.913\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.332\tL1 1.030\tG-Mean 0.885\n",
      " * Median: MSE 2.116\tL1 1.385\tG-Mean 1.320\n",
      " * Low: MSE 0.107\tL1 0.212\tG-Mean 0.188\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #457: Train loss [3.8710]; Val loss: MSE [1.9128], L1 [0.6007], G-Mean [0.2619]\n",
      "Epoch: [458][ 0/65]\tTime   0.55 (  0.55)\tData 0.5413 (0.5413)\tLoss (MSE) 3.336 (3.336)\n",
      "Epoch: [458][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 4.910 (4.401)\n",
      "Epoch: [458][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 4.422 (3.982)\n",
      "Epoch: [458][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 2.488 (3.977)\n",
      "Epoch: [458][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.498 (4.019)\n",
      "Epoch: [458][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 2.223 (3.930)\n",
      "Epoch: [458][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.619 (3.831)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.913\tL1 0.603\tG-Mean 0.261\n",
      " * Many: MSE 2.348\tL1 1.040\tG-Mean 0.895\n",
      " * Median: MSE 2.086\tL1 1.374\tG-Mean 1.307\n",
      " * Low: MSE 0.107\tL1 0.204\tG-Mean 0.179\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #458: Train loss [3.8207]; Val loss: MSE [1.9130], L1 [0.6033], G-Mean [0.2613]\n",
      "Epoch: [459][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 5.242 (5.242)\n",
      "Epoch: [459][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 4.913 (4.067)\n",
      "Epoch: [459][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.516 (4.149)\n",
      "Epoch: [459][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.508 (3.853)\n",
      "Epoch: [459][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.611 (3.828)\n",
      "Epoch: [459][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.142 (3.891)\n",
      "Epoch: [459][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.929 (3.915)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.076 (2.076)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.933\tL1 0.596\tG-Mean 0.264\n",
      " * Many: MSE 2.308\tL1 1.002\tG-Mean 0.852\n",
      " * Median: MSE 2.196\tL1 1.413\tG-Mean 1.346\n",
      " * Low: MSE 0.123\tL1 0.246\tG-Mean 0.222\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #459: Train loss [3.8443]; Val loss: MSE [1.9335], L1 [0.5956], G-Mean [0.2641]\n",
      "Epoch: [460][ 0/65]\tTime   0.59 (  0.59)\tData 0.5844 (0.5844)\tLoss (MSE) 2.560 (2.560)\n",
      "Epoch: [460][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 3.096 (3.634)\n",
      "Epoch: [460][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 2.939 (3.665)\n",
      "Epoch: [460][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 4.615 (3.767)\n",
      "Epoch: [460][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 5.141 (3.740)\n",
      "Epoch: [460][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.508 (3.752)\n",
      "Epoch: [460][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.321 (3.769)\n",
      "Val: [0/9]\tTime  0.590 ( 0.590)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.925\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.356\tL1 1.037\tG-Mean 0.891\n",
      " * Median: MSE 2.097\tL1 1.379\tG-Mean 1.315\n",
      " * Low: MSE 0.111\tL1 0.210\tG-Mean 0.183\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #460: Train loss [3.7990]; Val loss: MSE [1.9247], L1 [0.6036], G-Mean [0.2615]\n",
      "Epoch: [461][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 3.342 (3.342)\n",
      "Epoch: [461][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 5.930 (3.676)\n",
      "Epoch: [461][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 2.629 (3.720)\n",
      "Epoch: [461][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.756 (3.896)\n",
      "Epoch: [461][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.626 (3.813)\n",
      "Epoch: [461][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 6.015 (3.923)\n",
      "Epoch: [461][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.054 (3.908)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.079 (2.079)\tLoss (L1) 0.638 (0.638)\n",
      " * Overall: MSE 1.950\tL1 0.594\tG-Mean 0.267\n",
      " * Many: MSE 2.299\tL1 0.986\tG-Mean 0.833\n",
      " * Median: MSE 2.253\tL1 1.434\tG-Mean 1.371\n",
      " * Low: MSE 0.131\tL1 0.263\tG-Mean 0.240\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #461: Train loss [3.8272]; Val loss: MSE [1.9498], L1 [0.5942], G-Mean [0.2671]\n",
      "Epoch: [462][ 0/65]\tTime   0.57 (  0.57)\tData 0.5589 (0.5589)\tLoss (MSE) 4.300 (4.300)\n",
      "Epoch: [462][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 3.419 (3.734)\n",
      "Epoch: [462][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.671 (3.801)\n",
      "Epoch: [462][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 5.281 (3.739)\n",
      "Epoch: [462][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.175 (3.775)\n",
      "Epoch: [462][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.085 (3.671)\n",
      "Epoch: [462][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.882 (3.854)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.933\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.334\tL1 1.017\tG-Mean 0.868\n",
      " * Median: MSE 2.156\tL1 1.400\tG-Mean 1.337\n",
      " * Low: MSE 0.114\tL1 0.229\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #462: Train loss [3.8670]; Val loss: MSE [1.9334], L1 [0.5990], G-Mean [0.2598]\n",
      "Epoch: [463][ 0/65]\tTime   0.55 (  0.55)\tData 0.5462 (0.5462)\tLoss (MSE) 4.577 (4.577)\n",
      "Epoch: [463][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 5.216 (4.613)\n",
      "Epoch: [463][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 2.976 (4.258)\n",
      "Epoch: [463][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.544 (4.105)\n",
      "Epoch: [463][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.291 (3.941)\n",
      "Epoch: [463][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.132 (3.960)\n",
      "Epoch: [463][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.867 (3.872)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.144\tL1 1.397\tG-Mean 1.335\n",
      " * Low: MSE 0.113\tL1 0.224\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #463: Train loss [3.8590]; Val loss: MSE [1.9190], L1 [0.5988], G-Mean [0.2614]\n",
      "Epoch: [464][ 0/65]\tTime   0.56 (  0.56)\tData 0.5570 (0.5570)\tLoss (MSE) 2.925 (2.925)\n",
      "Epoch: [464][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0518)\tLoss (MSE) 4.676 (3.537)\n",
      "Epoch: [464][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.059 (3.887)\n",
      "Epoch: [464][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.560 (3.724)\n",
      "Epoch: [464][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.745 (3.815)\n",
      "Epoch: [464][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.472 (3.818)\n",
      "Epoch: [464][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.882 (3.849)\n",
      "Val: [0/9]\tTime  0.562 ( 0.562)\tLoss (MSE) 2.058 (2.058)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.916\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.137\tL1 1.394\tG-Mean 1.334\n",
      " * Low: MSE 0.112\tL1 0.221\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #464: Train loss [3.8520]; Val loss: MSE [1.9163], L1 [0.5993], G-Mean [0.2612]\n",
      "Epoch: [465][ 0/65]\tTime   0.55 (  0.55)\tData 0.5428 (0.5428)\tLoss (MSE) 2.334 (2.334)\n",
      "Epoch: [465][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0550)\tLoss (MSE) 4.590 (3.255)\n",
      "Epoch: [465][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 4.083 (3.448)\n",
      "Epoch: [465][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 5.761 (3.507)\n",
      "Epoch: [465][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.193 (3.624)\n",
      "Epoch: [465][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.049 (3.732)\n",
      "Epoch: [465][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.461 (3.852)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.603\tG-Mean 0.263\n",
      " * Many: MSE 2.352\tL1 1.038\tG-Mean 0.893\n",
      " * Median: MSE 2.095\tL1 1.378\tG-Mean 1.315\n",
      " * Low: MSE 0.109\tL1 0.207\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #465: Train loss [3.8396]; Val loss: MSE [1.9196], L1 [0.6034], G-Mean [0.2627]\n",
      "Epoch: [466][ 0/65]\tTime   0.56 (  0.56)\tData 0.5502 (0.5502)\tLoss (MSE) 5.887 (5.887)\n",
      "Epoch: [466][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 3.414 (3.764)\n",
      "Epoch: [466][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 5.461 (3.979)\n",
      "Epoch: [466][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 3.571 (3.959)\n",
      "Epoch: [466][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 2.178 (3.842)\n",
      "Epoch: [466][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.953 (3.821)\n",
      "Epoch: [466][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.863 (3.785)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.332\tL1 1.024\tG-Mean 0.877\n",
      " * Median: MSE 2.141\tL1 1.396\tG-Mean 1.337\n",
      " * Low: MSE 0.111\tL1 0.220\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #466: Train loss [3.8364]; Val loss: MSE [1.9224], L1 [0.5992], G-Mean [0.2596]\n",
      "Epoch: [467][ 0/65]\tTime   0.58 (  0.58)\tData 0.5725 (0.5725)\tLoss (MSE) 4.043 (4.043)\n",
      "Epoch: [467][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0526)\tLoss (MSE) 6.090 (4.075)\n",
      "Epoch: [467][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.488 (4.200)\n",
      "Epoch: [467][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 3.765 (4.176)\n",
      "Epoch: [467][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.815 (4.076)\n",
      "Epoch: [467][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.098 (3.921)\n",
      "Epoch: [467][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.121 (3.845)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.917\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.142\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.099\tL1 0.220\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #467: Train loss [3.8761]; Val loss: MSE [1.9171], L1 [0.5987], G-Mean [0.2613]\n",
      "Epoch: [468][ 0/65]\tTime   0.62 (  0.62)\tData 0.6008 (0.6008)\tLoss (MSE) 2.665 (2.665)\n",
      "Epoch: [468][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0570)\tLoss (MSE) 2.124 (3.393)\n",
      "Epoch: [468][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 4.253 (3.531)\n",
      "Epoch: [468][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0202)\tLoss (MSE) 4.826 (3.659)\n",
      "Epoch: [468][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 2.617 (4.051)\n",
      "Epoch: [468][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.740 (3.947)\n",
      "Epoch: [468][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.435 (3.891)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.912\tL1 0.596\tG-Mean 0.260\n",
      " * Many: MSE 2.300\tL1 1.011\tG-Mean 0.865\n",
      " * Median: MSE 2.171\tL1 1.408\tG-Mean 1.351\n",
      " * Low: MSE 0.102\tL1 0.229\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #468: Train loss [3.8486]; Val loss: MSE [1.9117], L1 [0.5957], G-Mean [0.2604]\n",
      "Epoch: [469][ 0/65]\tTime   0.57 (  0.57)\tData 0.5610 (0.5610)\tLoss (MSE) 3.833 (3.833)\n",
      "Epoch: [469][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0593)\tLoss (MSE) 1.479 (3.762)\n",
      "Epoch: [469][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 4.949 (3.758)\n",
      "Epoch: [469][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0210)\tLoss (MSE) 2.481 (3.907)\n",
      "Epoch: [469][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.001 (3.811)\n",
      "Epoch: [469][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 5.072 (3.923)\n",
      "Epoch: [469][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.515 (3.827)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.913\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.136\tL1 1.395\tG-Mean 1.338\n",
      " * Low: MSE 0.103\tL1 0.219\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #469: Train loss [3.9082]; Val loss: MSE [1.9134], L1 [0.5987], G-Mean [0.2597]\n",
      "Epoch: [470][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 2.517 (2.517)\n",
      "Epoch: [470][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0567)\tLoss (MSE) 2.571 (3.460)\n",
      "Epoch: [470][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 2.456 (3.341)\n",
      "Epoch: [470][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 4.977 (3.471)\n",
      "Epoch: [470][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 6.483 (3.730)\n",
      "Epoch: [470][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 5.071 (3.731)\n",
      "Epoch: [470][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.680 (3.761)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.041 (2.041)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.913\tL1 0.603\tG-Mean 0.262\n",
      " * Many: MSE 2.344\tL1 1.037\tG-Mean 0.892\n",
      " * Median: MSE 2.091\tL1 1.379\tG-Mean 1.319\n",
      " * Low: MSE 0.101\tL1 0.206\tG-Mean 0.181\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #470: Train loss [3.8242]; Val loss: MSE [1.9134], L1 [0.6026], G-Mean [0.2623]\n",
      "Epoch: [471][ 0/65]\tTime   0.56 (  0.56)\tData 0.5544 (0.5544)\tLoss (MSE) 3.105 (3.105)\n",
      "Epoch: [471][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0591)\tLoss (MSE) 3.880 (4.448)\n",
      "Epoch: [471][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 6.197 (4.239)\n",
      "Epoch: [471][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 1.811 (4.054)\n",
      "Epoch: [471][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.473 (4.050)\n",
      "Epoch: [471][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 2.307 (3.935)\n",
      "Epoch: [471][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.618 (3.851)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.336\tL1 1.025\tG-Mean 0.879\n",
      " * Median: MSE 2.130\tL1 1.394\tG-Mean 1.338\n",
      " * Low: MSE 0.099\tL1 0.218\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #471: Train loss [3.8492]; Val loss: MSE [1.9227], L1 [0.6000], G-Mean [0.2601]\n",
      "Epoch: [472][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 2.664 (2.664)\n",
      "Epoch: [472][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 4.050 (3.626)\n",
      "Epoch: [472][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 4.965 (3.957)\n",
      "Epoch: [472][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.818 (3.813)\n",
      "Epoch: [472][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 4.780 (3.799)\n",
      "Epoch: [472][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.605 (3.710)\n",
      "Epoch: [472][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 1.817 (3.815)\n",
      "Val: [0/9]\tTime  0.533 ( 0.533)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.922\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.343\tL1 1.030\tG-Mean 0.884\n",
      " * Median: MSE 2.119\tL1 1.390\tG-Mean 1.333\n",
      " * Low: MSE 0.104\tL1 0.214\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #472: Train loss [3.8477]; Val loss: MSE [1.9225], L1 [0.6014], G-Mean [0.2597]\n",
      "Epoch: [473][ 0/65]\tTime   0.57 (  0.57)\tData 0.5610 (0.5610)\tLoss (MSE) 3.646 (3.646)\n",
      "Epoch: [473][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 4.922 (4.226)\n",
      "Epoch: [473][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.547 (4.083)\n",
      "Epoch: [473][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.534 (3.875)\n",
      "Epoch: [473][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.280 (3.998)\n",
      "Epoch: [473][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 1.865 (3.974)\n",
      "Epoch: [473][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.275 (3.947)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.060 (2.060)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.916\tL1 0.597\tG-Mean 0.259\n",
      " * Many: MSE 2.310\tL1 1.016\tG-Mean 0.870\n",
      " * Median: MSE 2.163\tL1 1.406\tG-Mean 1.351\n",
      " * Low: MSE 0.107\tL1 0.227\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #473: Train loss [3.8804]; Val loss: MSE [1.9159], L1 [0.5974], G-Mean [0.2587]\n",
      "Epoch: [474][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 2.945 (2.945)\n",
      "Epoch: [474][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.596 (3.833)\n",
      "Epoch: [474][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 1.924 (3.864)\n",
      "Epoch: [474][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.656 (3.756)\n",
      "Epoch: [474][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.874 (3.784)\n",
      "Epoch: [474][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 2.576 (3.897)\n",
      "Epoch: [474][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.781 (3.887)\n",
      "Val: [0/9]\tTime  0.611 ( 0.611)\tLoss (MSE) 2.083 (2.083)\tLoss (L1) 0.639 (0.639)\n",
      " * Overall: MSE 1.935\tL1 0.591\tG-Mean 0.264\n",
      " * Many: MSE 2.273\tL1 0.980\tG-Mean 0.829\n",
      " * Median: MSE 2.272\tL1 1.444\tG-Mean 1.390\n",
      " * Low: MSE 0.120\tL1 0.264\tG-Mean 0.245\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #474: Train loss [3.8887]; Val loss: MSE [1.9346], L1 [0.5914], G-Mean [0.2639]\n",
      "Epoch: [475][ 0/65]\tTime   0.66 (  0.66)\tData 0.6491 (0.6491)\tLoss (MSE) 3.074 (3.074)\n",
      "Epoch: [475][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0602)\tLoss (MSE) 3.222 (3.344)\n",
      "Epoch: [475][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0315)\tLoss (MSE) 2.684 (3.737)\n",
      "Epoch: [475][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0214)\tLoss (MSE) 6.266 (3.840)\n",
      "Epoch: [475][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.466 (3.846)\n",
      "Epoch: [475][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 4.664 (3.794)\n",
      "Epoch: [475][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 3.905 (3.898)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.080 (2.080)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.315\tL1 1.012\tG-Mean 0.863\n",
      " * Median: MSE 2.174\tL1 1.410\tG-Mean 1.354\n",
      " * Low: MSE 0.103\tL1 0.231\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #475: Train loss [3.8769]; Val loss: MSE [1.9248], L1 [0.5969], G-Mean [0.2616]\n",
      "Epoch: [476][ 0/65]\tTime   0.57 (  0.57)\tData 0.5613 (0.5613)\tLoss (MSE) 3.581 (3.581)\n",
      "Epoch: [476][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0573)\tLoss (MSE) 3.745 (3.943)\n",
      "Epoch: [476][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.561 (3.929)\n",
      "Epoch: [476][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 2.992 (3.945)\n",
      "Epoch: [476][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.139 (3.828)\n",
      "Epoch: [476][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 9.173 (3.915)\n",
      "Epoch: [476][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.497 (3.902)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.079 (2.079)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.926\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.316\tL1 1.011\tG-Mean 0.862\n",
      " * Median: MSE 2.176\tL1 1.410\tG-Mean 1.354\n",
      " * Low: MSE 0.106\tL1 0.232\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #476: Train loss [3.8801]; Val loss: MSE [1.9260], L1 [0.5968], G-Mean [0.2618]\n",
      "Epoch: [477][ 0/65]\tTime   0.56 (  0.56)\tData 0.5567 (0.5567)\tLoss (MSE) 5.521 (5.521)\n",
      "Epoch: [477][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 3.567 (3.798)\n",
      "Epoch: [477][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 4.527 (3.802)\n",
      "Epoch: [477][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 4.524 (4.061)\n",
      "Epoch: [477][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 4.736 (4.016)\n",
      "Epoch: [477][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.089 (3.905)\n",
      "Epoch: [477][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.542 (3.799)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.067 (2.067)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.922\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.360\tL1 1.041\tG-Mean 0.896\n",
      " * Median: MSE 2.090\tL1 1.380\tG-Mean 1.323\n",
      " * Low: MSE 0.100\tL1 0.203\tG-Mean 0.178\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #477: Train loss [3.9005]; Val loss: MSE [1.9215], L1 [0.6045], G-Mean [0.2621]\n",
      "Epoch: [478][ 0/65]\tTime   0.56 (  0.56)\tData 0.5556 (0.5556)\tLoss (MSE) 3.595 (3.595)\n",
      "Epoch: [478][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0509)\tLoss (MSE) 10.016 (4.418)\n",
      "Epoch: [478][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.507 (4.007)\n",
      "Epoch: [478][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 1.851 (3.814)\n",
      "Epoch: [478][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.187 (4.082)\n",
      "Epoch: [478][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.753 (4.058)\n",
      "Epoch: [478][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.285 (3.937)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.065 (2.065)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.342\tL1 1.029\tG-Mean 0.882\n",
      " * Median: MSE 2.126\tL1 1.393\tG-Mean 1.337\n",
      " * Low: MSE 0.104\tL1 0.215\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #478: Train loss [3.9712]; Val loss: MSE [1.9222], L1 [0.6009], G-Mean [0.2608]\n",
      "Epoch: [479][ 0/65]\tTime   0.55 (  0.55)\tData 0.5447 (0.5447)\tLoss (MSE) 2.341 (2.341)\n",
      "Epoch: [479][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 4.713 (3.274)\n",
      "Epoch: [479][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 5.908 (3.432)\n",
      "Epoch: [479][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.178 (3.722)\n",
      "Epoch: [479][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 7.619 (3.892)\n",
      "Epoch: [479][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.416 (4.027)\n",
      "Epoch: [479][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.549 (3.915)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.074 (2.074)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.934\tL1 0.599\tG-Mean 0.259\n",
      " * Many: MSE 2.335\tL1 1.018\tG-Mean 0.869\n",
      " * Median: MSE 2.162\tL1 1.406\tG-Mean 1.350\n",
      " * Low: MSE 0.107\tL1 0.227\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #479: Train loss [3.9463]; Val loss: MSE [1.9336], L1 [0.5991], G-Mean [0.2591]\n",
      "Epoch: [480][ 0/65]\tTime   0.56 (  0.56)\tData 0.5528 (0.5528)\tLoss (MSE) 5.367 (5.367)\n",
      "Epoch: [480][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0582)\tLoss (MSE) 3.349 (3.879)\n",
      "Epoch: [480][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 5.481 (3.758)\n",
      "Epoch: [480][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 3.203 (3.766)\n",
      "Epoch: [480][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.543 (3.903)\n",
      "Epoch: [480][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 1.908 (3.968)\n",
      "Epoch: [480][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.987 (3.886)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.070 (2.070)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.925\tL1 0.596\tG-Mean 0.261\n",
      " * Many: MSE 2.314\tL1 1.011\tG-Mean 0.863\n",
      " * Median: MSE 2.184\tL1 1.414\tG-Mean 1.360\n",
      " * Low: MSE 0.101\tL1 0.230\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #480: Train loss [3.9121]; Val loss: MSE [1.9250], L1 [0.5960], G-Mean [0.2612]\n",
      "Epoch: [481][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 2.818 (2.818)\n",
      "Epoch: [481][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 3.177 (3.793)\n",
      "Epoch: [481][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 2.160 (3.714)\n",
      "Epoch: [481][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 3.969 (3.701)\n",
      "Epoch: [481][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.612 (3.810)\n",
      "Epoch: [481][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.056 (3.772)\n",
      "Epoch: [481][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.137 (3.761)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.646 (0.646)\n",
      " * Overall: MSE 1.916\tL1 0.605\tG-Mean 0.263\n",
      " * Many: MSE 2.355\tL1 1.041\tG-Mean 0.896\n",
      " * Median: MSE 2.090\tL1 1.380\tG-Mean 1.323\n",
      " * Low: MSE 0.099\tL1 0.203\tG-Mean 0.177\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #481: Train loss [3.7747]; Val loss: MSE [1.9162], L1 [0.6046], G-Mean [0.2627]\n",
      "Epoch: [482][ 0/65]\tTime   0.56 (  0.56)\tData 0.5508 (0.5508)\tLoss (MSE) 2.039 (2.039)\n",
      "Epoch: [482][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 3.390 (3.522)\n",
      "Epoch: [482][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 4.195 (3.657)\n",
      "Epoch: [482][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 4.441 (3.979)\n",
      "Epoch: [482][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.070 (3.793)\n",
      "Epoch: [482][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 5.132 (3.823)\n",
      "Epoch: [482][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.695 (3.897)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.059 (2.059)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.917\tL1 0.603\tG-Mean 0.263\n",
      " * Many: MSE 2.348\tL1 1.037\tG-Mean 0.891\n",
      " * Median: MSE 2.103\tL1 1.385\tG-Mean 1.329\n",
      " * Low: MSE 0.104\tL1 0.207\tG-Mean 0.182\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #482: Train loss [3.8273]; Val loss: MSE [1.9165], L1 [0.6034], G-Mean [0.2627]\n",
      "Epoch: [483][ 0/65]\tTime   0.57 (  0.57)\tData 0.5591 (0.5591)\tLoss (MSE) 2.015 (2.015)\n",
      "Epoch: [483][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0527)\tLoss (MSE) 4.209 (3.644)\n",
      "Epoch: [483][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.886 (4.109)\n",
      "Epoch: [483][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.223 (3.979)\n",
      "Epoch: [483][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 6.963 (4.022)\n",
      "Epoch: [483][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.641 (3.963)\n",
      "Epoch: [483][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.833 (3.887)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.596\tG-Mean 0.263\n",
      " * Many: MSE 2.305\tL1 1.007\tG-Mean 0.859\n",
      " * Median: MSE 2.191\tL1 1.416\tG-Mean 1.361\n",
      " * Low: MSE 0.103\tL1 0.234\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #483: Train loss [3.8839]; Val loss: MSE [1.9223], L1 [0.5960], G-Mean [0.2629]\n",
      "Epoch: [484][ 0/65]\tTime   0.56 (  0.56)\tData 0.5492 (0.5492)\tLoss (MSE) 2.316 (2.316)\n",
      "Epoch: [484][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0543)\tLoss (MSE) 2.580 (3.797)\n",
      "Epoch: [484][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 4.932 (3.830)\n",
      "Epoch: [484][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 5.979 (3.813)\n",
      "Epoch: [484][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.232 (3.821)\n",
      "Epoch: [484][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0117)\tLoss (MSE) 4.856 (3.795)\n",
      "Epoch: [484][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.885 (3.819)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.039 (2.039)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.909\tL1 0.604\tG-Mean 0.262\n",
      " * Many: MSE 2.349\tL1 1.042\tG-Mean 0.898\n",
      " * Median: MSE 2.086\tL1 1.378\tG-Mean 1.320\n",
      " * Low: MSE 0.090\tL1 0.199\tG-Mean 0.176\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #484: Train loss [3.8700]; Val loss: MSE [1.9095], L1 [0.6040], G-Mean [0.2621]\n",
      "Epoch: [485][ 0/65]\tTime   0.55 (  0.55)\tData 0.5432 (0.5432)\tLoss (MSE) 2.124 (2.124)\n",
      "Epoch: [485][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0505)\tLoss (MSE) 2.885 (2.897)\n",
      "Epoch: [485][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0264)\tLoss (MSE) 3.158 (3.496)\n",
      "Epoch: [485][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 3.558 (3.701)\n",
      "Epoch: [485][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.100 (3.803)\n",
      "Epoch: [485][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 4.103 (3.789)\n",
      "Epoch: [485][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 3.968 (3.845)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.061 (2.061)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.927\tL1 0.596\tG-Mean 0.263\n",
      " * Many: MSE 2.311\tL1 1.008\tG-Mean 0.860\n",
      " * Median: MSE 2.187\tL1 1.413\tG-Mean 1.356\n",
      " * Low: MSE 0.108\tL1 0.236\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #485: Train loss [3.8047]; Val loss: MSE [1.9266], L1 [0.5965], G-Mean [0.2629]\n",
      "Epoch: [486][ 0/65]\tTime   0.56 (  0.56)\tData 0.5503 (0.5503)\tLoss (MSE) 2.920 (2.920)\n",
      "Epoch: [486][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 3.273 (3.865)\n",
      "Epoch: [486][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 1.854 (4.117)\n",
      "Epoch: [486][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.054 (4.045)\n",
      "Epoch: [486][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.814 (3.898)\n",
      "Epoch: [486][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.103 (3.892)\n",
      "Epoch: [486][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.940 (3.849)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.916\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.105\tL1 0.221\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #486: Train loss [3.8701]; Val loss: MSE [1.9160], L1 [0.5991], G-Mean [0.2603]\n",
      "Epoch: [487][ 0/65]\tTime   0.57 (  0.57)\tData 0.5650 (0.5650)\tLoss (MSE) 2.315 (2.315)\n",
      "Epoch: [487][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 4.626 (4.021)\n",
      "Epoch: [487][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 2.279 (4.143)\n",
      "Epoch: [487][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 2.323 (3.878)\n",
      "Epoch: [487][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.720 (3.904)\n",
      "Epoch: [487][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.630 (3.881)\n",
      "Epoch: [487][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 6.636 (3.962)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.914\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.339\tL1 1.033\tG-Mean 0.888\n",
      " * Median: MSE 2.111\tL1 1.387\tG-Mean 1.329\n",
      " * Low: MSE 0.096\tL1 0.209\tG-Mean 0.186\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #487: Train loss [3.8764]; Val loss: MSE [1.9138], L1 [0.6019], G-Mean [0.2611]\n",
      "Epoch: [488][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 2.866 (2.866)\n",
      "Epoch: [488][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0543)\tLoss (MSE) 9.279 (4.336)\n",
      "Epoch: [488][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.463 (4.016)\n",
      "Epoch: [488][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.526 (3.843)\n",
      "Epoch: [488][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 5.070 (3.693)\n",
      "Epoch: [488][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.381 (3.597)\n",
      "Epoch: [488][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 7.215 (3.624)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.018\tG-Mean 0.870\n",
      " * Median: MSE 2.158\tL1 1.404\tG-Mean 1.347\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #488: Train loss [3.7966]; Val loss: MSE [1.9214], L1 [0.5984], G-Mean [0.2605]\n",
      "Epoch: [489][ 0/65]\tTime   0.61 (  0.61)\tData 0.6057 (0.6057)\tLoss (MSE) 5.447 (5.447)\n",
      "Epoch: [489][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0589)\tLoss (MSE) 3.132 (3.998)\n",
      "Epoch: [489][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0309)\tLoss (MSE) 3.398 (3.905)\n",
      "Epoch: [489][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 5.130 (3.810)\n",
      "Epoch: [489][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 5.731 (3.803)\n",
      "Epoch: [489][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 3.109 (3.718)\n",
      "Epoch: [489][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.562 (3.917)\n",
      "Val: [0/9]\tTime  0.647 ( 0.647)\tLoss (MSE) 2.062 (2.062)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.925\tL1 0.595\tG-Mean 0.262\n",
      " * Many: MSE 2.299\tL1 1.002\tG-Mean 0.853\n",
      " * Median: MSE 2.208\tL1 1.421\tG-Mean 1.365\n",
      " * Low: MSE 0.098\tL1 0.240\tG-Mean 0.221\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #489: Train loss [3.9294]; Val loss: MSE [1.9249], L1 [0.5952], G-Mean [0.2623]\n",
      "Epoch: [490][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 5.920 (5.920)\n",
      "Epoch: [490][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 3.799 (3.580)\n",
      "Epoch: [490][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 2.079 (3.334)\n",
      "Epoch: [490][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 4.127 (3.542)\n",
      "Epoch: [490][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.981 (3.681)\n",
      "Epoch: [490][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.596 (3.745)\n",
      "Epoch: [490][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.017 (3.812)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.068 (2.068)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.937\tL1 0.597\tG-Mean 0.264\n",
      " * Many: MSE 2.314\tL1 1.004\tG-Mean 0.853\n",
      " * Median: MSE 2.202\tL1 1.417\tG-Mean 1.357\n",
      " * Low: MSE 0.109\tL1 0.243\tG-Mean 0.221\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #490: Train loss [3.7942]; Val loss: MSE [1.9370], L1 [0.5965], G-Mean [0.2637]\n",
      "Epoch: [491][ 0/65]\tTime   0.57 (  0.57)\tData 0.5589 (0.5589)\tLoss (MSE) 4.152 (4.152)\n",
      "Epoch: [491][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 4.402 (3.887)\n",
      "Epoch: [491][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.948 (3.598)\n",
      "Epoch: [491][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 6.115 (3.697)\n",
      "Epoch: [491][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 7.399 (3.977)\n",
      "Epoch: [491][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.895 (3.935)\n",
      "Epoch: [491][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.696 (3.843)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.648 (0.648)\n",
      " * Overall: MSE 1.917\tL1 0.606\tG-Mean 0.263\n",
      " * Many: MSE 2.366\tL1 1.048\tG-Mean 0.903\n",
      " * Median: MSE 2.070\tL1 1.371\tG-Mean 1.311\n",
      " * Low: MSE 0.089\tL1 0.195\tG-Mean 0.170\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #491: Train loss [3.8723]; Val loss: MSE [1.9171], L1 [0.6063], G-Mean [0.2628]\n",
      "Epoch: [492][ 0/65]\tTime   0.55 (  0.55)\tData 0.5479 (0.5479)\tLoss (MSE) 4.498 (4.498)\n",
      "Epoch: [492][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0541)\tLoss (MSE) 3.618 (4.364)\n",
      "Epoch: [492][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 2.630 (4.114)\n",
      "Epoch: [492][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 3.864 (3.999)\n",
      "Epoch: [492][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.132 (3.856)\n",
      "Epoch: [492][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.903 (3.761)\n",
      "Epoch: [492][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.042 (3.830)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.916\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.342\tL1 1.035\tG-Mean 0.890\n",
      " * Median: MSE 2.107\tL1 1.384\tG-Mean 1.325\n",
      " * Low: MSE 0.096\tL1 0.207\tG-Mean 0.184\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #492: Train loss [3.8630]; Val loss: MSE [1.9157], L1 [0.6020], G-Mean [0.2606]\n",
      "Epoch: [493][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 4.182 (4.182)\n",
      "Epoch: [493][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0590)\tLoss (MSE) 4.078 (3.753)\n",
      "Epoch: [493][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0309)\tLoss (MSE) 3.700 (3.739)\n",
      "Epoch: [493][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 2.781 (3.570)\n",
      "Epoch: [493][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 1.811 (3.807)\n",
      "Epoch: [493][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.215 (3.877)\n",
      "Epoch: [493][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0107)\tLoss (MSE) 2.860 (3.750)\n",
      "Val: [0/9]\tTime  0.532 ( 0.532)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.596\tG-Mean 0.263\n",
      " * Many: MSE 2.300\tL1 1.007\tG-Mean 0.859\n",
      " * Median: MSE 2.189\tL1 1.414\tG-Mean 1.357\n",
      " * Low: MSE 0.106\tL1 0.235\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #493: Train loss [3.7859]; Val loss: MSE [1.9193], L1 [0.5957], G-Mean [0.2627]\n",
      "Epoch: [494][ 0/65]\tTime   0.63 (  0.63)\tData 0.6070 (0.6070)\tLoss (MSE) 4.009 (4.009)\n",
      "Epoch: [494][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 2.646 (3.371)\n",
      "Epoch: [494][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 3.284 (3.720)\n",
      "Epoch: [494][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 3.736 (3.844)\n",
      "Epoch: [494][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.926 (3.803)\n",
      "Epoch: [494][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.053 (3.835)\n",
      "Epoch: [494][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.975 (3.890)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.072 (2.072)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.929\tL1 0.595\tG-Mean 0.263\n",
      " * Many: MSE 2.299\tL1 1.001\tG-Mean 0.852\n",
      " * Median: MSE 2.210\tL1 1.421\tG-Mean 1.364\n",
      " * Low: MSE 0.108\tL1 0.243\tG-Mean 0.222\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #494: Train loss [3.9276]; Val loss: MSE [1.9286], L1 [0.5946], G-Mean [0.2631]\n",
      "Epoch: [495][ 0/65]\tTime   0.55 (  0.55)\tData 0.5454 (0.5454)\tLoss (MSE) 6.051 (6.051)\n",
      "Epoch: [495][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0571)\tLoss (MSE) 2.483 (3.544)\n",
      "Epoch: [495][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 5.928 (3.756)\n",
      "Epoch: [495][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 2.267 (3.805)\n",
      "Epoch: [495][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 5.406 (3.929)\n",
      "Epoch: [495][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 7.986 (3.933)\n",
      "Epoch: [495][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 1.658 (3.807)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.066 (2.066)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.926\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.327\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.343\n",
      " * Low: MSE 0.103\tL1 0.225\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #495: Train loss [3.8267]; Val loss: MSE [1.9255], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [496][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 4.709 (4.709)\n",
      "Epoch: [496][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0565)\tLoss (MSE) 2.814 (3.791)\n",
      "Epoch: [496][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0296)\tLoss (MSE) 2.635 (3.866)\n",
      "Epoch: [496][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0201)\tLoss (MSE) 3.639 (3.788)\n",
      "Epoch: [496][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.831 (3.740)\n",
      "Epoch: [496][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.432 (3.745)\n",
      "Epoch: [496][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.866 (3.842)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.072 (2.072)\tLoss (L1) 0.647 (0.647)\n",
      " * Overall: MSE 1.929\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.165\tL1 1.405\tG-Mean 1.346\n",
      " * Low: MSE 0.095\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #496: Train loss [3.7795]; Val loss: MSE [1.9290], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [497][ 0/65]\tTime   0.55 (  0.55)\tData 0.5443 (0.5443)\tLoss (MSE) 4.359 (4.359)\n",
      "Epoch: [497][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0556)\tLoss (MSE) 5.058 (3.965)\n",
      "Epoch: [497][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 8.264 (4.095)\n",
      "Epoch: [497][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.555 (4.033)\n",
      "Epoch: [497][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.664 (3.988)\n",
      "Epoch: [497][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.641 (3.879)\n",
      "Epoch: [497][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.661 (3.865)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.072 (2.072)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.927\tL1 0.595\tG-Mean 0.263\n",
      " * Many: MSE 2.302\tL1 1.004\tG-Mean 0.855\n",
      " * Median: MSE 2.201\tL1 1.417\tG-Mean 1.357\n",
      " * Low: MSE 0.107\tL1 0.239\tG-Mean 0.218\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #497: Train loss [3.8189]; Val loss: MSE [1.9268], L1 [0.5954], G-Mean [0.2627]\n",
      "Epoch: [498][ 0/65]\tTime   0.56 (  0.56)\tData 0.5501 (0.5501)\tLoss (MSE) 3.395 (3.395)\n",
      "Epoch: [498][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0505)\tLoss (MSE) 2.214 (3.363)\n",
      "Epoch: [498][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 3.234 (3.580)\n",
      "Epoch: [498][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 2.705 (3.689)\n",
      "Epoch: [498][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.167 (3.773)\n",
      "Epoch: [498][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 3.494 (3.822)\n",
      "Epoch: [498][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 4.750 (3.804)\n",
      "Val: [0/9]\tTime  0.642 ( 0.642)\tLoss (MSE) 2.039 (2.039)\tLoss (L1) 0.652 (0.652)\n",
      " * Overall: MSE 1.906\tL1 0.609\tG-Mean 0.267\n",
      " * Many: MSE 2.367\tL1 1.057\tG-Mean 0.915\n",
      " * Median: MSE 2.044\tL1 1.361\tG-Mean 1.299\n",
      " * Low: MSE 0.078\tL1 0.182\tG-Mean 0.159\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #498: Train loss [3.8622]; Val loss: MSE [1.9061], L1 [0.6085], G-Mean [0.2673]\n",
      "Epoch: [499][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 4.783 (4.783)\n",
      "Epoch: [499][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 4.999 (4.099)\n",
      "Epoch: [499][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 3.401 (3.767)\n",
      "Epoch: [499][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.836 (3.955)\n",
      "Epoch: [499][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.127 (4.166)\n",
      "Epoch: [499][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.820 (4.024)\n",
      "Epoch: [499][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.342 (3.826)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.923\tL1 0.602\tG-Mean 0.260\n",
      " * Many: MSE 2.344\tL1 1.031\tG-Mean 0.884\n",
      " * Median: MSE 2.124\tL1 1.390\tG-Mean 1.330\n",
      " * Low: MSE 0.084\tL1 0.210\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #499: Train loss [3.8616]; Val loss: MSE [1.9232], L1 [0.6016], G-Mean [0.2598]\n",
      "Epoch: [500][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 4.483 (4.483)\n",
      "Epoch: [500][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 3.536 (4.088)\n",
      "Epoch: [500][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 3.437 (3.843)\n",
      "Epoch: [500][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.223 (3.719)\n",
      "Epoch: [500][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.526 (3.789)\n",
      "Epoch: [500][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.454 (3.904)\n",
      "Epoch: [500][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.047 (3.866)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.334\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.140\tL1 1.396\tG-Mean 1.336\n",
      " * Low: MSE 0.086\tL1 0.216\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #500: Train loss [3.8726]; Val loss: MSE [1.9233], L1 [0.6000], G-Mean [0.2600]\n",
      "Epoch: [501][ 0/65]\tTime   0.55 (  0.55)\tData 0.5474 (0.5474)\tLoss (MSE) 2.756 (2.756)\n",
      "Epoch: [501][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 4.069 (3.236)\n",
      "Epoch: [501][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.558 (3.415)\n",
      "Epoch: [501][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 5.701 (3.533)\n",
      "Epoch: [501][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.130 (3.616)\n",
      "Epoch: [501][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.553 (3.682)\n",
      "Epoch: [501][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.584 (3.758)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.152\tL1 1.400\tG-Mean 1.341\n",
      " * Low: MSE 0.088\tL1 0.220\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #501: Train loss [3.7774]; Val loss: MSE [1.9242], L1 [0.5991], G-Mean [0.2606]\n",
      "Epoch: [502][ 0/65]\tTime   0.56 (  0.56)\tData 0.5577 (0.5577)\tLoss (MSE) 2.268 (2.268)\n",
      "Epoch: [502][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 4.562 (3.440)\n",
      "Epoch: [502][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 5.799 (3.996)\n",
      "Epoch: [502][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.216 (3.868)\n",
      "Epoch: [502][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.645 (3.698)\n",
      "Epoch: [502][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.462 (3.680)\n",
      "Epoch: [502][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.635 (3.802)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.166\tL1 1.405\tG-Mean 1.346\n",
      " * Low: MSE 0.091\tL1 0.225\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #502: Train loss [3.8150]; Val loss: MSE [1.9255], L1 [0.5980], G-Mean [0.2605]\n",
      "Epoch: [503][ 0/65]\tTime   0.62 (  0.62)\tData 0.6016 (0.6016)\tLoss (MSE) 3.889 (3.889)\n",
      "Epoch: [503][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 5.971 (3.905)\n",
      "Epoch: [503][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.732 (3.832)\n",
      "Epoch: [503][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 5.521 (3.941)\n",
      "Epoch: [503][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.224 (3.805)\n",
      "Epoch: [503][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.118 (3.919)\n",
      "Epoch: [503][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.553 (3.889)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.154\tL1 1.401\tG-Mean 1.341\n",
      " * Low: MSE 0.090\tL1 0.221\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #503: Train loss [3.8368]; Val loss: MSE [1.9246], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [504][ 0/65]\tTime   0.55 (  0.55)\tData 0.5467 (0.5467)\tLoss (MSE) 4.301 (4.301)\n",
      "Epoch: [504][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 2.209 (3.505)\n",
      "Epoch: [504][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.045 (3.580)\n",
      "Epoch: [504][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.122 (3.613)\n",
      "Epoch: [504][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.007 (3.565)\n",
      "Epoch: [504][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 6.277 (3.717)\n",
      "Epoch: [504][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 9.187 (3.832)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.922\tL1 0.601\tG-Mean 0.259\n",
      " * Many: MSE 2.339\tL1 1.028\tG-Mean 0.882\n",
      " * Median: MSE 2.129\tL1 1.392\tG-Mean 1.332\n",
      " * Low: MSE 0.087\tL1 0.213\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #504: Train loss [3.7751]; Val loss: MSE [1.9221], L1 [0.6009], G-Mean [0.2595]\n",
      "Epoch: [505][ 0/65]\tTime   0.62 (  0.62)\tData 0.6057 (0.6057)\tLoss (MSE) 2.373 (2.373)\n",
      "Epoch: [505][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 2.807 (3.697)\n",
      "Epoch: [505][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 4.249 (3.659)\n",
      "Epoch: [505][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 5.303 (3.952)\n",
      "Epoch: [505][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 7.342 (3.943)\n",
      "Epoch: [505][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.288 (3.867)\n",
      "Epoch: [505][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.051 (3.908)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.162\tL1 1.404\tG-Mean 1.344\n",
      " * Low: MSE 0.092\tL1 0.224\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #505: Train loss [3.8626]; Val loss: MSE [1.9252], L1 [0.5983], G-Mean [0.2600]\n",
      "Epoch: [506][ 0/65]\tTime   0.56 (  0.56)\tData 0.5553 (0.5553)\tLoss (MSE) 2.764 (2.764)\n",
      "Epoch: [506][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 3.830 (3.703)\n",
      "Epoch: [506][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 3.101 (3.923)\n",
      "Epoch: [506][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.851 (4.061)\n",
      "Epoch: [506][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.186 (3.923)\n",
      "Epoch: [506][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.022 (3.877)\n",
      "Epoch: [506][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.863 (3.816)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.156\tL1 1.401\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #506: Train loss [3.7841]; Val loss: MSE [1.9253], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [507][ 0/65]\tTime   0.57 (  0.57)\tData 0.5606 (0.5606)\tLoss (MSE) 5.858 (5.858)\n",
      "Epoch: [507][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 2.246 (4.346)\n",
      "Epoch: [507][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 7.015 (4.323)\n",
      "Epoch: [507][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.384 (3.902)\n",
      "Epoch: [507][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 1.960 (3.869)\n",
      "Epoch: [507][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.394 (3.986)\n",
      "Epoch: [507][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.900 (3.905)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.926\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.225\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #507: Train loss [3.8486]; Val loss: MSE [1.9258], L1 [0.5982], G-Mean [0.2603]\n",
      "Epoch: [508][ 0/65]\tTime   0.60 (  0.60)\tData 0.5825 (0.5825)\tLoss (MSE) 3.183 (3.183)\n",
      "Epoch: [508][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 3.249 (3.808)\n",
      "Epoch: [508][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 2.278 (3.645)\n",
      "Epoch: [508][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 2.404 (3.570)\n",
      "Epoch: [508][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.684 (3.700)\n",
      "Epoch: [508][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.680 (3.762)\n",
      "Epoch: [508][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.243 (3.732)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.926\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.345\n",
      " * Low: MSE 0.093\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #508: Train loss [3.7820]; Val loss: MSE [1.9255], L1 [0.5981], G-Mean [0.2602]\n",
      "Epoch: [509][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 3.456 (3.456)\n",
      "Epoch: [509][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0527)\tLoss (MSE) 4.129 (3.295)\n",
      "Epoch: [509][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.138 (3.434)\n",
      "Epoch: [509][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.074 (3.625)\n",
      "Epoch: [509][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.904 (3.692)\n",
      "Epoch: [509][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 5.467 (3.736)\n",
      "Epoch: [509][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.730 (3.858)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.337\tL1 1.028\tG-Mean 0.881\n",
      " * Median: MSE 2.131\tL1 1.393\tG-Mean 1.333\n",
      " * Low: MSE 0.089\tL1 0.214\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #509: Train loss [3.9178]; Val loss: MSE [1.9217], L1 [0.6006], G-Mean [0.2596]\n",
      "Epoch: [510][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 3.169 (3.169)\n",
      "Epoch: [510][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 5.843 (3.362)\n",
      "Epoch: [510][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 2.295 (3.364)\n",
      "Epoch: [510][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 2.675 (3.521)\n",
      "Epoch: [510][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 6.213 (3.513)\n",
      "Epoch: [510][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.802 (3.660)\n",
      "Epoch: [510][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.799 (3.711)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.336\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.131\tL1 1.393\tG-Mean 1.333\n",
      " * Low: MSE 0.089\tL1 0.214\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #510: Train loss [3.7685]; Val loss: MSE [1.9212], L1 [0.6005], G-Mean [0.2598]\n",
      "Epoch: [511][ 0/65]\tTime   0.57 (  0.57)\tData 0.5594 (0.5594)\tLoss (MSE) 4.260 (4.260)\n",
      "Epoch: [511][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 2.704 (3.470)\n",
      "Epoch: [511][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.234 (3.447)\n",
      "Epoch: [511][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.451 (3.526)\n",
      "Epoch: [511][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.422 (3.552)\n",
      "Epoch: [511][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.812 (3.580)\n",
      "Epoch: [511][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.013 (3.741)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.158\tL1 1.403\tG-Mean 1.344\n",
      " * Low: MSE 0.092\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #511: Train loss [3.7980]; Val loss: MSE [1.9239], L1 [0.5985], G-Mean [0.2607]\n",
      "Epoch: [512][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 2.199 (2.199)\n",
      "Epoch: [512][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0586)\tLoss (MSE) 2.726 (3.563)\n",
      "Epoch: [512][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 3.660 (3.893)\n",
      "Epoch: [512][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 2.936 (4.019)\n",
      "Epoch: [512][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.533 (3.861)\n",
      "Epoch: [512][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 1.784 (3.770)\n",
      "Epoch: [512][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.848 (3.822)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.340\n",
      " * Low: MSE 0.091\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #512: Train loss [3.7716]; Val loss: MSE [1.9218], L1 [0.5994], G-Mean [0.2609]\n",
      "Epoch: [513][ 0/65]\tTime   0.56 (  0.56)\tData 0.5572 (0.5572)\tLoss (MSE) 4.143 (4.143)\n",
      "Epoch: [513][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0564)\tLoss (MSE) 3.053 (3.634)\n",
      "Epoch: [513][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0296)\tLoss (MSE) 3.612 (4.110)\n",
      "Epoch: [513][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0200)\tLoss (MSE) 2.956 (3.958)\n",
      "Epoch: [513][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.229 (3.850)\n",
      "Epoch: [513][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.904 (3.832)\n",
      "Epoch: [513][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.251 (3.899)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #513: Train loss [3.8298]; Val loss: MSE [1.9217], L1 [0.5992], G-Mean [0.2609]\n",
      "Epoch: [514][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 3.713 (3.713)\n",
      "Epoch: [514][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0539)\tLoss (MSE) 3.143 (3.820)\n",
      "Epoch: [514][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 2.493 (3.956)\n",
      "Epoch: [514][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 4.015 (3.904)\n",
      "Epoch: [514][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.009 (3.884)\n",
      "Epoch: [514][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.310 (3.892)\n",
      "Epoch: [514][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.511 (3.791)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.345\n",
      " * Low: MSE 0.094\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #514: Train loss [3.7956]; Val loss: MSE [1.9239], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [515][ 0/65]\tTime   0.61 (  0.61)\tData 0.5974 (0.5974)\tLoss (MSE) 5.035 (5.035)\n",
      "Epoch: [515][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 4.268 (4.728)\n",
      "Epoch: [515][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 6.430 (4.391)\n",
      "Epoch: [515][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 3.767 (4.147)\n",
      "Epoch: [515][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.181 (4.055)\n",
      "Epoch: [515][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 5.551 (3.949)\n",
      "Epoch: [515][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.562 (3.871)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #515: Train loss [3.8959]; Val loss: MSE [1.9226], L1 [0.5992], G-Mean [0.2605]\n",
      "Epoch: [516][ 0/65]\tTime   0.56 (  0.56)\tData 0.5566 (0.5566)\tLoss (MSE) 2.716 (2.716)\n",
      "Epoch: [516][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 3.853 (3.307)\n",
      "Epoch: [516][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 2.090 (4.045)\n",
      "Epoch: [516][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.003 (3.998)\n",
      "Epoch: [516][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 5.559 (4.107)\n",
      "Epoch: [516][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 5.222 (4.048)\n",
      "Epoch: [516][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.538 (3.979)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.157\tL1 1.403\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #516: Train loss [3.9782]; Val loss: MSE [1.9236], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [517][ 0/65]\tTime   0.57 (  0.57)\tData 0.5595 (0.5595)\tLoss (MSE) 8.006 (8.006)\n",
      "Epoch: [517][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 3.029 (4.312)\n",
      "Epoch: [517][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.783 (4.022)\n",
      "Epoch: [517][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.987 (4.087)\n",
      "Epoch: [517][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.853 (4.098)\n",
      "Epoch: [517][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.024 (3.950)\n",
      "Epoch: [517][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.986 (3.879)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.926\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.316\tL1 1.013\tG-Mean 0.865\n",
      " * Median: MSE 2.177\tL1 1.409\tG-Mean 1.351\n",
      " * Low: MSE 0.095\tL1 0.230\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #517: Train loss [3.9007]; Val loss: MSE [1.9256], L1 [0.5973], G-Mean [0.2613]\n",
      "Epoch: [518][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 2.154 (2.154)\n",
      "Epoch: [518][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0595)\tLoss (MSE) 3.561 (3.765)\n",
      "Epoch: [518][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 1.769 (3.788)\n",
      "Epoch: [518][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 4.586 (3.812)\n",
      "Epoch: [518][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.188 (3.760)\n",
      "Epoch: [518][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 5.825 (3.801)\n",
      "Epoch: [518][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.860 (3.805)\n",
      "Val: [0/9]\tTime  0.623 ( 0.623)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.347\n",
      " * Low: MSE 0.093\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #518: Train loss [3.8328]; Val loss: MSE [1.9229], L1 [0.5981], G-Mean [0.2601]\n",
      "Epoch: [519][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 4.519 (4.519)\n",
      "Epoch: [519][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 2.508 (3.700)\n",
      "Epoch: [519][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.397 (3.839)\n",
      "Epoch: [519][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.795 (3.663)\n",
      "Epoch: [519][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.935 (3.636)\n",
      "Epoch: [519][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.762 (3.793)\n",
      "Epoch: [519][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.765 (3.812)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.041 (2.041)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.340\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.120\tL1 1.389\tG-Mean 1.330\n",
      " * Low: MSE 0.089\tL1 0.210\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #519: Train loss [3.8659]; Val loss: MSE [1.9187], L1 [0.6015], G-Mean [0.2608]\n",
      "Epoch: [520][ 0/65]\tTime   0.56 (  0.56)\tData 0.5471 (0.5471)\tLoss (MSE) 7.329 (7.329)\n",
      "Epoch: [520][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 2.952 (3.584)\n",
      "Epoch: [520][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 5.583 (3.497)\n",
      "Epoch: [520][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 3.797 (3.411)\n",
      "Epoch: [520][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 6.999 (3.519)\n",
      "Epoch: [520][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.725 (3.778)\n",
      "Epoch: [520][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 7.046 (3.792)\n",
      "Val: [0/9]\tTime  0.531 ( 0.531)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.159\tL1 1.403\tG-Mean 1.345\n",
      " * Low: MSE 0.094\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #520: Train loss [3.8127]; Val loss: MSE [1.9222], L1 [0.5984], G-Mean [0.2603]\n",
      "Epoch: [521][ 0/65]\tTime   0.55 (  0.55)\tData 0.5449 (0.5449)\tLoss (MSE) 4.440 (4.440)\n",
      "Epoch: [521][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 3.355 (4.882)\n",
      "Epoch: [521][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.643 (4.370)\n",
      "Epoch: [521][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.691 (4.050)\n",
      "Epoch: [521][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.613 (4.100)\n",
      "Epoch: [521][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.645 (3.930)\n",
      "Epoch: [521][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.346 (3.885)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.094\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #521: Train loss [3.8026]; Val loss: MSE [1.9218], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [522][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 2.429 (2.429)\n",
      "Epoch: [522][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 3.629 (3.112)\n",
      "Epoch: [522][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 1.993 (3.249)\n",
      "Epoch: [522][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.697 (3.574)\n",
      "Epoch: [522][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.570 (3.544)\n",
      "Epoch: [522][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.454 (3.746)\n",
      "Epoch: [522][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.858 (3.794)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.131\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.091\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #522: Train loss [3.7674]; Val loss: MSE [1.9190], L1 [0.6005], G-Mean [0.2604]\n",
      "Epoch: [523][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 2.614 (2.614)\n",
      "Epoch: [523][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.249 (3.551)\n",
      "Epoch: [523][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.123 (3.577)\n",
      "Epoch: [523][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.514 (3.484)\n",
      "Epoch: [523][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.047 (3.509)\n",
      "Epoch: [523][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.548 (3.674)\n",
      "Epoch: [523][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.694 (3.734)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.332\tL1 1.025\tG-Mean 0.879\n",
      " * Median: MSE 2.137\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #523: Train loss [3.7420]; Val loss: MSE [1.9206], L1 [0.6001], G-Mean [0.2593]\n",
      "Epoch: [524][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 3.351 (3.351)\n",
      "Epoch: [524][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 4.007 (3.947)\n",
      "Epoch: [524][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.107 (3.657)\n",
      "Epoch: [524][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.903 (3.628)\n",
      "Epoch: [524][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.094 (3.746)\n",
      "Epoch: [524][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 1.899 (3.748)\n",
      "Epoch: [524][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.750 (3.830)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.346\n",
      " * Low: MSE 0.095\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #524: Train loss [3.8405]; Val loss: MSE [1.9229], L1 [0.5982], G-Mean [0.2598]\n",
      "Epoch: [525][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 4.075 (4.075)\n",
      "Epoch: [525][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0578)\tLoss (MSE) 3.210 (3.740)\n",
      "Epoch: [525][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 3.350 (4.094)\n",
      "Epoch: [525][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 4.728 (4.101)\n",
      "Epoch: [525][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 5.590 (4.017)\n",
      "Epoch: [525][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 6.736 (4.043)\n",
      "Epoch: [525][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.455 (3.867)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.315\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.171\tL1 1.408\tG-Mean 1.349\n",
      " * Low: MSE 0.095\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #525: Train loss [3.8202]; Val loss: MSE [1.9221], L1 [0.5975], G-Mean [0.2613]\n",
      "Epoch: [526][ 0/65]\tTime   0.56 (  0.56)\tData 0.5477 (0.5477)\tLoss (MSE) 2.801 (2.801)\n",
      "Epoch: [526][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0574)\tLoss (MSE) 4.222 (3.612)\n",
      "Epoch: [526][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 4.143 (3.803)\n",
      "Epoch: [526][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 3.189 (3.821)\n",
      "Epoch: [526][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.418 (3.901)\n",
      "Epoch: [526][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.245 (3.791)\n",
      "Epoch: [526][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.673 (3.746)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.326\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.339\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #526: Train loss [3.8109]; Val loss: MSE [1.9188], L1 [0.5995], G-Mean [0.2599]\n",
      "Epoch: [527][ 0/65]\tTime   0.55 (  0.55)\tData 0.5468 (0.5468)\tLoss (MSE) 2.923 (2.923)\n",
      "Epoch: [527][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 5.862 (4.300)\n",
      "Epoch: [527][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 4.747 (3.918)\n",
      "Epoch: [527][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 2.708 (3.914)\n",
      "Epoch: [527][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.636 (3.959)\n",
      "Epoch: [527][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.588 (3.921)\n",
      "Epoch: [527][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.823 (3.875)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.319\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.161\tL1 1.404\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #527: Train loss [3.9731]; Val loss: MSE [1.9206], L1 [0.5982], G-Mean [0.2606]\n",
      "Epoch: [528][ 0/65]\tTime   0.56 (  0.56)\tData 0.5521 (0.5521)\tLoss (MSE) 8.447 (8.447)\n",
      "Epoch: [528][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 2.759 (4.171)\n",
      "Epoch: [528][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.178 (3.821)\n",
      "Epoch: [528][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 2.269 (3.637)\n",
      "Epoch: [528][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.639 (3.488)\n",
      "Epoch: [528][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.917 (3.575)\n",
      "Epoch: [528][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.159 (3.776)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.040 (2.040)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.337\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.121\tL1 1.390\tG-Mean 1.331\n",
      " * Low: MSE 0.089\tL1 0.211\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #528: Train loss [3.7793]; Val loss: MSE [1.9168], L1 [0.6014], G-Mean [0.2615]\n",
      "Epoch: [529][ 0/65]\tTime   0.55 (  0.55)\tData 0.5443 (0.5443)\tLoss (MSE) 6.364 (6.364)\n",
      "Epoch: [529][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0505)\tLoss (MSE) 3.377 (3.796)\n",
      "Epoch: [529][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 3.588 (4.102)\n",
      "Epoch: [529][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.901 (4.059)\n",
      "Epoch: [529][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.856 (3.866)\n",
      "Epoch: [529][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 2.580 (3.889)\n",
      "Epoch: [529][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 3.811 (3.830)\n",
      "Val: [0/9]\tTime  0.533 ( 0.533)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.339\n",
      " * Low: MSE 0.093\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #529: Train loss [3.8519]; Val loss: MSE [1.9194], L1 [0.5995], G-Mean [0.2605]\n",
      "Epoch: [530][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 5.235 (5.235)\n",
      "Epoch: [530][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 3.988 (4.118)\n",
      "Epoch: [530][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 4.426 (4.055)\n",
      "Epoch: [530][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.404 (3.668)\n",
      "Epoch: [530][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.886 (3.746)\n",
      "Epoch: [530][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.493 (3.866)\n",
      "Epoch: [530][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.801 (3.883)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.346\n",
      " * Low: MSE 0.094\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #530: Train loss [3.8457]; Val loss: MSE [1.9197], L1 [0.5980], G-Mean [0.2600]\n",
      "Epoch: [531][ 0/65]\tTime   0.54 (  0.54)\tData 0.5348 (0.5348)\tLoss (MSE) 6.315 (6.315)\n",
      "Epoch: [531][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0508)\tLoss (MSE) 6.880 (4.111)\n",
      "Epoch: [531][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.368 (4.036)\n",
      "Epoch: [531][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 3.007 (3.662)\n",
      "Epoch: [531][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.415 (3.716)\n",
      "Epoch: [531][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.138 (3.661)\n",
      "Epoch: [531][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.584 (3.687)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.156\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.094\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #531: Train loss [3.7656]; Val loss: MSE [1.9199], L1 [0.5984], G-Mean [0.2607]\n",
      "Epoch: [532][ 0/65]\tTime   0.55 (  0.55)\tData 0.5471 (0.5471)\tLoss (MSE) 2.098 (2.098)\n",
      "Epoch: [532][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0553)\tLoss (MSE) 4.910 (3.962)\n",
      "Epoch: [532][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 2.490 (3.701)\n",
      "Epoch: [532][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.940 (3.855)\n",
      "Epoch: [532][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 6.995 (3.932)\n",
      "Epoch: [532][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.989 (3.801)\n",
      "Epoch: [532][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.919 (3.796)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.041 (2.041)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.131\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.092\tL1 0.215\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #532: Train loss [3.7999]; Val loss: MSE [1.9175], L1 [0.6003], G-Mean [0.2602]\n",
      "Epoch: [533][ 0/65]\tTime   0.56 (  0.56)\tData 0.5521 (0.5521)\tLoss (MSE) 3.860 (3.860)\n",
      "Epoch: [533][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 1.903 (3.887)\n",
      "Epoch: [533][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.487 (3.937)\n",
      "Epoch: [533][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.602 (4.236)\n",
      "Epoch: [533][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.464 (3.874)\n",
      "Epoch: [533][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.085 (3.898)\n",
      "Epoch: [533][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.878 (3.903)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.148\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.093\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #533: Train loss [3.8789]; Val loss: MSE [1.9191], L1 [0.5990], G-Mean [0.2604]\n",
      "Epoch: [534][ 0/65]\tTime   0.55 (  0.55)\tData 0.5493 (0.5493)\tLoss (MSE) 4.221 (4.221)\n",
      "Epoch: [534][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 4.372 (3.624)\n",
      "Epoch: [534][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 5.046 (3.918)\n",
      "Epoch: [534][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 2.853 (3.861)\n",
      "Epoch: [534][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.352 (3.819)\n",
      "Epoch: [534][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 3.667 (3.862)\n",
      "Epoch: [534][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.777 (3.855)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.340\n",
      " * Low: MSE 0.093\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #534: Train loss [3.8689]; Val loss: MSE [1.9187], L1 [0.5991], G-Mean [0.2611]\n",
      "Epoch: [535][ 0/65]\tTime   0.55 (  0.55)\tData 0.5405 (0.5405)\tLoss (MSE) 4.116 (4.116)\n",
      "Epoch: [535][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0593)\tLoss (MSE) 2.880 (4.345)\n",
      "Epoch: [535][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 3.599 (4.256)\n",
      "Epoch: [535][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 3.806 (4.115)\n",
      "Epoch: [535][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 5.732 (4.022)\n",
      "Epoch: [535][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.115 (3.825)\n",
      "Epoch: [535][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.450 (3.819)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.327\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.140\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #535: Train loss [3.8313]; Val loss: MSE [1.9181], L1 [0.5996], G-Mean [0.2593]\n",
      "Epoch: [536][ 0/65]\tTime   0.55 (  0.55)\tData 0.5484 (0.5484)\tLoss (MSE) 3.637 (3.637)\n",
      "Epoch: [536][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 2.447 (3.660)\n",
      "Epoch: [536][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 4.708 (4.016)\n",
      "Epoch: [536][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 3.193 (3.883)\n",
      "Epoch: [536][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.645 (3.955)\n",
      "Epoch: [536][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.850 (3.845)\n",
      "Epoch: [536][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 7.966 (3.843)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.317\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.347\n",
      " * Low: MSE 0.094\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #536: Train loss [3.8980]; Val loss: MSE [1.9209], L1 [0.5978], G-Mean [0.2605]\n",
      "Epoch: [537][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 2.553 (2.553)\n",
      "Epoch: [537][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 3.532 (3.634)\n",
      "Epoch: [537][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.771 (3.910)\n",
      "Epoch: [537][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 5.495 (3.803)\n",
      "Epoch: [537][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 7.403 (3.769)\n",
      "Epoch: [537][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.747 (3.784)\n",
      "Epoch: [537][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.504 (3.808)\n",
      "Val: [0/9]\tTime  0.644 ( 0.644)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.319\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.345\n",
      " * Low: MSE 0.094\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #537: Train loss [3.8366]; Val loss: MSE [1.9205], L1 [0.5981], G-Mean [0.2608]\n",
      "Epoch: [538][ 0/65]\tTime   0.61 (  0.61)\tData 0.5899 (0.5899)\tLoss (MSE) 2.434 (2.434)\n",
      "Epoch: [538][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0567)\tLoss (MSE) 2.744 (3.321)\n",
      "Epoch: [538][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0297)\tLoss (MSE) 3.922 (3.807)\n",
      "Epoch: [538][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0201)\tLoss (MSE) 2.903 (3.818)\n",
      "Epoch: [538][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.120 (3.771)\n",
      "Epoch: [538][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.654 (3.733)\n",
      "Epoch: [538][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.477 (3.778)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.329\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.136\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #538: Train loss [3.7871]; Val loss: MSE [1.9184], L1 [0.5999], G-Mean [0.2599]\n",
      "Epoch: [539][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 2.435 (2.435)\n",
      "Epoch: [539][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 4.992 (3.524)\n",
      "Epoch: [539][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.418 (3.695)\n",
      "Epoch: [539][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.140 (3.843)\n",
      "Epoch: [539][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 1.866 (3.950)\n",
      "Epoch: [539][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.685 (4.009)\n",
      "Epoch: [539][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.480 (3.848)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.314\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.170\tL1 1.407\tG-Mean 1.349\n",
      " * Low: MSE 0.095\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #539: Train loss [3.8692]; Val loss: MSE [1.9219], L1 [0.5974], G-Mean [0.2619]\n",
      "Epoch: [540][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 2.764 (2.764)\n",
      "Epoch: [540][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 3.824 (3.780)\n",
      "Epoch: [540][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 6.555 (3.598)\n",
      "Epoch: [540][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 2.752 (3.660)\n",
      "Epoch: [540][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.415 (3.607)\n",
      "Epoch: [540][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.263 (3.765)\n",
      "Epoch: [540][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.729 (3.834)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.343\n",
      " * Low: MSE 0.093\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #540: Train loss [3.8354]; Val loss: MSE [1.9191], L1 [0.5983], G-Mean [0.2603]\n",
      "Epoch: [541][ 0/65]\tTime   0.55 (  0.55)\tData 0.5494 (0.5494)\tLoss (MSE) 3.609 (3.609)\n",
      "Epoch: [541][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0583)\tLoss (MSE) 1.652 (3.671)\n",
      "Epoch: [541][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 6.744 (4.028)\n",
      "Epoch: [541][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 2.319 (3.954)\n",
      "Epoch: [541][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 2.944 (3.786)\n",
      "Epoch: [541][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.742 (3.777)\n",
      "Epoch: [541][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.297 (3.822)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #541: Train loss [3.8037]; Val loss: MSE [1.9185], L1 [0.5991], G-Mean [0.2609]\n",
      "Epoch: [542][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 5.887 (5.887)\n",
      "Epoch: [542][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 1.968 (3.607)\n",
      "Epoch: [542][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.155 (3.475)\n",
      "Epoch: [542][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 4.289 (3.721)\n",
      "Epoch: [542][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.306 (3.831)\n",
      "Epoch: [542][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.223 (3.813)\n",
      "Epoch: [542][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.211 (3.769)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.640 (0.640)\n",
      " * Overall: MSE 1.923\tL1 0.596\tG-Mean 0.262\n",
      " * Many: MSE 2.309\tL1 1.009\tG-Mean 0.861\n",
      " * Median: MSE 2.183\tL1 1.412\tG-Mean 1.354\n",
      " * Low: MSE 0.095\tL1 0.232\tG-Mean 0.213\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #542: Train loss [3.7291]; Val loss: MSE [1.9232], L1 [0.5964], G-Mean [0.2617]\n",
      "Epoch: [543][ 0/65]\tTime   0.55 (  0.55)\tData 0.5465 (0.5465)\tLoss (MSE) 3.704 (3.704)\n",
      "Epoch: [543][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0536)\tLoss (MSE) 6.178 (4.293)\n",
      "Epoch: [543][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 2.529 (3.854)\n",
      "Epoch: [543][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 3.241 (3.998)\n",
      "Epoch: [543][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.072 (3.810)\n",
      "Epoch: [543][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.517 (3.775)\n",
      "Epoch: [543][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.146 (3.808)\n",
      "Val: [0/9]\tTime  0.530 ( 0.530)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.314\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.170\tL1 1.407\tG-Mean 1.349\n",
      " * Low: MSE 0.094\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #543: Train loss [3.7861]; Val loss: MSE [1.9218], L1 [0.5973], G-Mean [0.2615]\n",
      "Epoch: [544][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 2.857 (2.857)\n",
      "Epoch: [544][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 5.548 (3.854)\n",
      "Epoch: [544][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.480 (3.982)\n",
      "Epoch: [544][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.608 (3.773)\n",
      "Epoch: [544][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.624 (3.810)\n",
      "Epoch: [544][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.768 (3.775)\n",
      "Epoch: [544][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.387 (3.764)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.132\tL1 1.393\tG-Mean 1.334\n",
      " * Low: MSE 0.090\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #544: Train loss [3.7379]; Val loss: MSE [1.9174], L1 [0.6001], G-Mean [0.2605]\n",
      "Epoch: [545][ 0/65]\tTime   0.55 (  0.55)\tData 0.5442 (0.5442)\tLoss (MSE) 4.319 (4.319)\n",
      "Epoch: [545][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 6.207 (4.457)\n",
      "Epoch: [545][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 5.433 (3.978)\n",
      "Epoch: [545][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.745 (4.112)\n",
      "Epoch: [545][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.512 (4.002)\n",
      "Epoch: [545][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.096 (3.996)\n",
      "Epoch: [545][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.885 (3.981)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #545: Train loss [4.0388]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2610]\n",
      "Epoch: [546][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 4.708 (4.708)\n",
      "Epoch: [546][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 5.013 (3.959)\n",
      "Epoch: [546][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 6.525 (3.864)\n",
      "Epoch: [546][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.712 (3.803)\n",
      "Epoch: [546][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.558 (3.971)\n",
      "Epoch: [546][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.828 (3.970)\n",
      "Epoch: [546][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.105 (3.883)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.345\n",
      " * Low: MSE 0.093\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #546: Train loss [3.8459]; Val loss: MSE [1.9207], L1 [0.5979], G-Mean [0.2604]\n",
      "Epoch: [547][ 0/65]\tTime   0.55 (  0.55)\tData 0.5453 (0.5453)\tLoss (MSE) 4.722 (4.722)\n",
      "Epoch: [547][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0528)\tLoss (MSE) 4.868 (3.792)\n",
      "Epoch: [547][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.821 (3.973)\n",
      "Epoch: [547][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.072 (3.915)\n",
      "Epoch: [547][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 3.155 (3.849)\n",
      "Epoch: [547][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 4.166 (3.807)\n",
      "Epoch: [547][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.682 (3.821)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #547: Train loss [3.8306]; Val loss: MSE [1.9193], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [548][ 0/65]\tTime   0.56 (  0.56)\tData 0.5492 (0.5492)\tLoss (MSE) 3.831 (3.831)\n",
      "Epoch: [548][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0508)\tLoss (MSE) 3.537 (4.367)\n",
      "Epoch: [548][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 2.893 (4.309)\n",
      "Epoch: [548][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.043 (4.038)\n",
      "Epoch: [548][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.960 (4.098)\n",
      "Epoch: [548][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.844 (3.914)\n",
      "Epoch: [548][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.889 (3.925)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #548: Train loss [3.8306]; Val loss: MSE [1.9195], L1 [0.5986], G-Mean [0.2610]\n",
      "Epoch: [549][ 0/65]\tTime   0.65 (  0.65)\tData 0.6424 (0.6424)\tLoss (MSE) 5.380 (5.380)\n",
      "Epoch: [549][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0593)\tLoss (MSE) 3.177 (4.320)\n",
      "Epoch: [549][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0311)\tLoss (MSE) 6.080 (4.094)\n",
      "Epoch: [549][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0211)\tLoss (MSE) 3.024 (4.022)\n",
      "Epoch: [549][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 2.983 (3.989)\n",
      "Epoch: [549][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 2.011 (3.887)\n",
      "Epoch: [549][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 4.421 (3.929)\n",
      "Val: [0/9]\tTime  0.572 ( 0.572)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.346\n",
      " * Low: MSE 0.094\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #549: Train loss [3.8631]; Val loss: MSE [1.9202], L1 [0.5979], G-Mean [0.2603]\n",
      "Epoch: [550][ 0/65]\tTime   0.55 (  0.55)\tData 0.5453 (0.5453)\tLoss (MSE) 4.435 (4.435)\n",
      "Epoch: [550][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0565)\tLoss (MSE) 3.843 (4.405)\n",
      "Epoch: [550][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 1.668 (3.577)\n",
      "Epoch: [550][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 2.852 (3.771)\n",
      "Epoch: [550][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.593 (3.758)\n",
      "Epoch: [550][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.186 (3.883)\n",
      "Epoch: [550][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.386 (3.841)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.330\tL1 1.026\tG-Mean 0.879\n",
      " * Median: MSE 2.135\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.091\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #550: Train loss [3.8675]; Val loss: MSE [1.9178], L1 [0.5999], G-Mean [0.2603]\n",
      "Epoch: [551][ 0/65]\tTime   0.57 (  0.57)\tData 0.5669 (0.5669)\tLoss (MSE) 5.287 (5.287)\n",
      "Epoch: [551][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0526)\tLoss (MSE) 4.828 (3.464)\n",
      "Epoch: [551][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 5.147 (3.750)\n",
      "Epoch: [551][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 6.098 (3.761)\n",
      "Epoch: [551][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.579 (3.724)\n",
      "Epoch: [551][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.051 (3.729)\n",
      "Epoch: [551][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 6.635 (3.893)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.329\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.139\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #551: Train loss [3.8106]; Val loss: MSE [1.9195], L1 [0.5997], G-Mean [0.2596]\n",
      "Epoch: [552][ 0/65]\tTime   0.56 (  0.56)\tData 0.5532 (0.5532)\tLoss (MSE) 2.396 (2.396)\n",
      "Epoch: [552][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 3.641 (3.594)\n",
      "Epoch: [552][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.253 (3.731)\n",
      "Epoch: [552][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.428 (3.701)\n",
      "Epoch: [552][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.036 (3.712)\n",
      "Epoch: [552][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.040 (3.796)\n",
      "Epoch: [552][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.427 (3.707)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.329\tL1 1.024\tG-Mean 0.877\n",
      " * Median: MSE 2.140\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #552: Train loss [3.8635]; Val loss: MSE [1.9197], L1 [0.5996], G-Mean [0.2607]\n",
      "Epoch: [553][ 0/65]\tTime   0.60 (  0.60)\tData 0.5787 (0.5787)\tLoss (MSE) 5.355 (5.355)\n",
      "Epoch: [553][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 5.498 (3.887)\n",
      "Epoch: [553][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 5.309 (4.179)\n",
      "Epoch: [553][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 6.489 (4.111)\n",
      "Epoch: [553][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.389 (4.062)\n",
      "Epoch: [553][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.876 (3.932)\n",
      "Epoch: [553][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 5.033 (3.897)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.338\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.119\tL1 1.389\tG-Mean 1.330\n",
      " * Low: MSE 0.089\tL1 0.211\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #553: Train loss [3.8465]; Val loss: MSE [1.9178], L1 [0.6013], G-Mean [0.2614]\n",
      "Epoch: [554][ 0/65]\tTime   0.55 (  0.55)\tData 0.5446 (0.5446)\tLoss (MSE) 2.374 (2.374)\n",
      "Epoch: [554][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 5.626 (3.707)\n",
      "Epoch: [554][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 2.686 (3.768)\n",
      "Epoch: [554][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.596 (3.803)\n",
      "Epoch: [554][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.466 (3.783)\n",
      "Epoch: [554][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 5.273 (3.785)\n",
      "Epoch: [554][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.640 (3.822)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.342\n",
      " * Low: MSE 0.093\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #554: Train loss [3.8114]; Val loss: MSE [1.9225], L1 [0.5987], G-Mean [0.2604]\n",
      "Epoch: [555][ 0/65]\tTime   0.56 (  0.56)\tData 0.5515 (0.5515)\tLoss (MSE) 2.408 (2.408)\n",
      "Epoch: [555][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 5.423 (3.551)\n",
      "Epoch: [555][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 3.233 (3.368)\n",
      "Epoch: [555][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.518 (3.434)\n",
      "Epoch: [555][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 7.415 (3.734)\n",
      "Epoch: [555][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 4.103 (3.921)\n",
      "Epoch: [555][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.902 (3.905)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.141\tL1 1.397\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #555: Train loss [3.8887]; Val loss: MSE [1.9215], L1 [0.5997], G-Mean [0.2608]\n",
      "Epoch: [556][ 0/65]\tTime   0.56 (  0.56)\tData 0.5524 (0.5524)\tLoss (MSE) 6.117 (6.117)\n",
      "Epoch: [556][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 6.013 (4.588)\n",
      "Epoch: [556][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.808 (4.317)\n",
      "Epoch: [556][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.885 (4.160)\n",
      "Epoch: [556][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.201 (3.967)\n",
      "Epoch: [556][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.825 (3.981)\n",
      "Epoch: [556][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.868 (3.904)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.335\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.130\tL1 1.393\tG-Mean 1.334\n",
      " * Low: MSE 0.091\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #556: Train loss [3.9198]; Val loss: MSE [1.9200], L1 [0.6004], G-Mean [0.2600]\n",
      "Epoch: [557][ 0/65]\tTime   0.62 (  0.62)\tData 0.6002 (0.6002)\tLoss (MSE) 4.689 (4.689)\n",
      "Epoch: [557][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0564)\tLoss (MSE) 6.047 (4.116)\n",
      "Epoch: [557][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0296)\tLoss (MSE) 2.281 (3.878)\n",
      "Epoch: [557][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0200)\tLoss (MSE) 3.629 (3.670)\n",
      "Epoch: [557][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.589 (3.880)\n",
      "Epoch: [557][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 6.005 (3.963)\n",
      "Epoch: [557][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.998 (3.837)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.163\tL1 1.405\tG-Mean 1.346\n",
      " * Low: MSE 0.096\tL1 0.227\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #557: Train loss [3.8053]; Val loss: MSE [1.9233], L1 [0.5979], G-Mean [0.2608]\n",
      "Epoch: [558][ 0/65]\tTime   0.56 (  0.56)\tData 0.5477 (0.5477)\tLoss (MSE) 3.890 (3.890)\n",
      "Epoch: [558][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 3.216 (4.107)\n",
      "Epoch: [558][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 8.641 (4.058)\n",
      "Epoch: [558][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.958 (3.817)\n",
      "Epoch: [558][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.361 (3.846)\n",
      "Epoch: [558][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 1.922 (3.980)\n",
      "Epoch: [558][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.988 (3.924)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.924\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.318\tL1 1.014\tG-Mean 0.867\n",
      " * Median: MSE 2.167\tL1 1.406\tG-Mean 1.348\n",
      " * Low: MSE 0.097\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #558: Train loss [3.8520]; Val loss: MSE [1.9242], L1 [0.5977], G-Mean [0.2610]\n",
      "Epoch: [559][ 0/65]\tTime   0.57 (  0.57)\tData 0.5610 (0.5610)\tLoss (MSE) 5.125 (5.125)\n",
      "Epoch: [559][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0585)\tLoss (MSE) 5.780 (3.948)\n",
      "Epoch: [559][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0307)\tLoss (MSE) 3.829 (3.637)\n",
      "Epoch: [559][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 7.271 (3.814)\n",
      "Epoch: [559][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 5.426 (3.731)\n",
      "Epoch: [559][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.813 (3.629)\n",
      "Epoch: [559][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 5.933 (3.743)\n",
      "Val: [0/9]\tTime  0.535 ( 0.535)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.602\tG-Mean 0.261\n",
      " * Many: MSE 2.341\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.118\tL1 1.388\tG-Mean 1.329\n",
      " * Low: MSE 0.092\tL1 0.211\tG-Mean 0.190\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #559: Train loss [3.7872]; Val loss: MSE [1.9196], L1 [0.6015], G-Mean [0.2612]\n",
      "Epoch: [560][ 0/65]\tTime   0.56 (  0.56)\tData 0.5576 (0.5576)\tLoss (MSE) 5.569 (5.569)\n",
      "Epoch: [560][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0522)\tLoss (MSE) 3.717 (4.060)\n",
      "Epoch: [560][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.583 (3.857)\n",
      "Epoch: [560][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.545 (3.824)\n",
      "Epoch: [560][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.201 (3.873)\n",
      "Epoch: [560][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 8.382 (3.976)\n",
      "Epoch: [560][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.662 (3.933)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.163\tL1 1.405\tG-Mean 1.346\n",
      " * Low: MSE 0.098\tL1 0.227\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #560: Train loss [3.8811]; Val loss: MSE [1.9246], L1 [0.5981], G-Mean [0.2604]\n",
      "Epoch: [561][ 0/65]\tTime   0.57 (  0.57)\tData 0.5604 (0.5604)\tLoss (MSE) 2.823 (2.823)\n",
      "Epoch: [561][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 2.161 (3.448)\n",
      "Epoch: [561][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 2.597 (3.355)\n",
      "Epoch: [561][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.919 (3.418)\n",
      "Epoch: [561][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.854 (3.501)\n",
      "Epoch: [561][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.332 (3.694)\n",
      "Epoch: [561][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.583 (3.789)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.335\tL1 1.027\tG-Mean 0.880\n",
      " * Median: MSE 2.131\tL1 1.393\tG-Mean 1.334\n",
      " * Low: MSE 0.094\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #561: Train loss [3.8010]; Val loss: MSE [1.9209], L1 [0.6005], G-Mean [0.2605]\n",
      "Epoch: [562][ 0/65]\tTime   0.56 (  0.56)\tData 0.5573 (0.5573)\tLoss (MSE) 6.832 (6.832)\n",
      "Epoch: [562][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 3.554 (3.713)\n",
      "Epoch: [562][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.992 (3.829)\n",
      "Epoch: [562][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 5.130 (3.751)\n",
      "Epoch: [562][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 6.081 (3.828)\n",
      "Epoch: [562][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.030 (3.802)\n",
      "Epoch: [562][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.004 (3.781)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.342\n",
      " * Low: MSE 0.097\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #562: Train loss [3.8220]; Val loss: MSE [1.9232], L1 [0.5989], G-Mean [0.2605]\n",
      "Epoch: [563][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 3.073 (3.073)\n",
      "Epoch: [563][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 4.510 (3.758)\n",
      "Epoch: [563][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 3.817 (3.693)\n",
      "Epoch: [563][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.133 (3.681)\n",
      "Epoch: [563][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.675 (3.610)\n",
      "Epoch: [563][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.162 (3.697)\n",
      "Epoch: [563][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.844 (3.752)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.921\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.339\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.122\tL1 1.390\tG-Mean 1.331\n",
      " * Low: MSE 0.094\tL1 0.214\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #563: Train loss [3.7612]; Val loss: MSE [1.9207], L1 [0.6012], G-Mean [0.2599]\n",
      "Epoch: [564][ 0/65]\tTime   0.56 (  0.56)\tData 0.5554 (0.5554)\tLoss (MSE) 4.332 (4.332)\n",
      "Epoch: [564][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 2.441 (3.740)\n",
      "Epoch: [564][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 5.777 (4.201)\n",
      "Epoch: [564][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 2.338 (3.860)\n",
      "Epoch: [564][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.184 (3.815)\n",
      "Epoch: [564][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 5.558 (3.750)\n",
      "Epoch: [564][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 6.542 (3.805)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.339\n",
      " * Low: MSE 0.096\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #564: Train loss [3.8022]; Val loss: MSE [1.9231], L1 [0.5996], G-Mean [0.2609]\n",
      "Epoch: [565][ 0/65]\tTime   0.55 (  0.55)\tData 0.5495 (0.5495)\tLoss (MSE) 3.065 (3.065)\n",
      "Epoch: [565][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 3.926 (3.831)\n",
      "Epoch: [565][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 8.636 (3.896)\n",
      "Epoch: [565][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.235 (3.984)\n",
      "Epoch: [565][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 1.987 (3.943)\n",
      "Epoch: [565][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.705 (3.919)\n",
      "Epoch: [565][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.507 (3.809)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.018\tG-Mean 0.870\n",
      " * Median: MSE 2.156\tL1 1.402\tG-Mean 1.343\n",
      " * Low: MSE 0.098\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #565: Train loss [3.7796]; Val loss: MSE [1.9245], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [566][ 0/65]\tTime   0.55 (  0.55)\tData 0.5457 (0.5457)\tLoss (MSE) 3.566 (3.566)\n",
      "Epoch: [566][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 3.714 (4.029)\n",
      "Epoch: [566][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 3.524 (3.747)\n",
      "Epoch: [566][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.070 (3.706)\n",
      "Epoch: [566][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.152 (3.704)\n",
      "Epoch: [566][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.685 (3.734)\n",
      "Epoch: [566][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.934 (3.805)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.334\tL1 1.024\tG-Mean 0.877\n",
      " * Median: MSE 2.137\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.096\tL1 0.219\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #566: Train loss [3.8074]; Val loss: MSE [1.9234], L1 [0.6001], G-Mean [0.2599]\n",
      "Epoch: [567][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.264 (5.264)\n",
      "Epoch: [567][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 2.661 (3.969)\n",
      "Epoch: [567][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 5.380 (3.733)\n",
      "Epoch: [567][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.575 (3.949)\n",
      "Epoch: [567][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.876 (3.808)\n",
      "Epoch: [567][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.362 (3.800)\n",
      "Epoch: [567][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 8.261 (3.796)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.021\tG-Mean 0.873\n",
      " * Median: MSE 2.148\tL1 1.399\tG-Mean 1.340\n",
      " * Low: MSE 0.098\tL1 0.223\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #567: Train loss [3.8137]; Val loss: MSE [1.9241], L1 [0.5993], G-Mean [0.2611]\n",
      "Epoch: [568][ 0/65]\tTime   0.56 (  0.56)\tData 0.5492 (0.5492)\tLoss (MSE) 4.701 (4.701)\n",
      "Epoch: [568][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 4.484 (3.170)\n",
      "Epoch: [568][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 6.527 (3.457)\n",
      "Epoch: [568][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 5.169 (3.545)\n",
      "Epoch: [568][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.584 (3.675)\n",
      "Epoch: [568][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.126 (3.852)\n",
      "Epoch: [568][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.871 (3.893)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.331\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.143\tL1 1.397\tG-Mean 1.338\n",
      " * Low: MSE 0.097\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #568: Train loss [3.8202]; Val loss: MSE [1.9240], L1 [0.5997], G-Mean [0.2608]\n",
      "Epoch: [569][ 0/65]\tTime   0.55 (  0.55)\tData 0.5390 (0.5390)\tLoss (MSE) 3.168 (3.168)\n",
      "Epoch: [569][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 2.072 (3.473)\n",
      "Epoch: [569][20/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 4.165 (3.845)\n",
      "Epoch: [569][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.119 (3.875)\n",
      "Epoch: [569][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 4.223 (3.910)\n",
      "Epoch: [569][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.433 (3.841)\n",
      "Epoch: [569][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.849 (3.817)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.342\n",
      " * Low: MSE 0.097\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #569: Train loss [3.8534]; Val loss: MSE [1.9232], L1 [0.5988], G-Mean [0.2604]\n",
      "Epoch: [570][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 6.273 (6.273)\n",
      "Epoch: [570][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0507)\tLoss (MSE) 3.100 (3.840)\n",
      "Epoch: [570][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.516 (3.770)\n",
      "Epoch: [570][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.790 (4.043)\n",
      "Epoch: [570][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.893 (4.006)\n",
      "Epoch: [570][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.638 (3.930)\n",
      "Epoch: [570][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.026 (3.820)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.926\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.314\tL1 1.011\tG-Mean 0.863\n",
      " * Median: MSE 2.178\tL1 1.410\tG-Mean 1.351\n",
      " * Low: MSE 0.100\tL1 0.233\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #570: Train loss [3.8336]; Val loss: MSE [1.9261], L1 [0.5971], G-Mean [0.2611]\n",
      "Epoch: [571][ 0/65]\tTime   0.57 (  0.57)\tData 0.5652 (0.5652)\tLoss (MSE) 8.220 (8.220)\n",
      "Epoch: [571][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0571)\tLoss (MSE) 5.248 (4.196)\n",
      "Epoch: [571][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 2.403 (3.929)\n",
      "Epoch: [571][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.452 (3.805)\n",
      "Epoch: [571][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.626 (3.780)\n",
      "Epoch: [571][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.804 (3.747)\n",
      "Epoch: [571][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.872 (3.795)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.140\tL1 1.396\tG-Mean 1.337\n",
      " * Low: MSE 0.096\tL1 0.220\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #571: Train loss [3.8075]; Val loss: MSE [1.9224], L1 [0.5999], G-Mean [0.2603]\n",
      "Epoch: [572][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 6.061 (6.061)\n",
      "Epoch: [572][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0589)\tLoss (MSE) 3.687 (4.066)\n",
      "Epoch: [572][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0309)\tLoss (MSE) 2.133 (3.853)\n",
      "Epoch: [572][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 4.644 (3.988)\n",
      "Epoch: [572][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 2.520 (3.901)\n",
      "Epoch: [572][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 3.583 (3.769)\n",
      "Epoch: [572][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 5.507 (3.895)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.326\tL1 1.020\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.342\n",
      " * Low: MSE 0.098\tL1 0.224\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #572: Train loss [3.8407]; Val loss: MSE [1.9236], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [573][ 0/65]\tTime   0.62 (  0.62)\tData 0.6037 (0.6037)\tLoss (MSE) 4.037 (4.037)\n",
      "Epoch: [573][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 3.201 (3.710)\n",
      "Epoch: [573][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 3.433 (3.578)\n",
      "Epoch: [573][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 4.719 (3.776)\n",
      "Epoch: [573][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 5.490 (3.715)\n",
      "Epoch: [573][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.548 (3.815)\n",
      "Epoch: [573][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.508 (3.814)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.319\tL1 1.015\tG-Mean 0.867\n",
      " * Median: MSE 2.166\tL1 1.406\tG-Mean 1.347\n",
      " * Low: MSE 0.100\tL1 0.229\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #573: Train loss [3.8849]; Val loss: MSE [1.9246], L1 [0.5979], G-Mean [0.2608]\n",
      "Epoch: [574][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 1.927 (1.927)\n",
      "Epoch: [574][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 4.104 (4.202)\n",
      "Epoch: [574][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.196 (4.110)\n",
      "Epoch: [574][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 2.565 (3.928)\n",
      "Epoch: [574][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.274 (3.670)\n",
      "Epoch: [574][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.159 (4.012)\n",
      "Epoch: [574][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.001 (3.899)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.161\tL1 1.404\tG-Mean 1.345\n",
      " * Low: MSE 0.098\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #574: Train loss [3.8535]; Val loss: MSE [1.9231], L1 [0.5981], G-Mean [0.2589]\n",
      "Epoch: [575][ 0/65]\tTime   0.56 (  0.56)\tData 0.5525 (0.5525)\tLoss (MSE) 7.730 (7.730)\n",
      "Epoch: [575][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 2.722 (3.911)\n",
      "Epoch: [575][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 4.409 (3.670)\n",
      "Epoch: [575][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.312 (3.709)\n",
      "Epoch: [575][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.486 (3.713)\n",
      "Epoch: [575][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.922 (3.763)\n",
      "Epoch: [575][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.948 (3.702)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.326\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.341\n",
      " * Low: MSE 0.097\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #575: Train loss [3.7114]; Val loss: MSE [1.9230], L1 [0.5990], G-Mean [0.2610]\n",
      "Epoch: [576][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 5.969 (5.969)\n",
      "Epoch: [576][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0550)\tLoss (MSE) 3.502 (4.255)\n",
      "Epoch: [576][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.777 (3.861)\n",
      "Epoch: [576][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.551 (3.808)\n",
      "Epoch: [576][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.199 (3.885)\n",
      "Epoch: [576][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.287 (3.827)\n",
      "Epoch: [576][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.333 (3.918)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.921\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.137\tL1 1.395\tG-Mean 1.336\n",
      " * Low: MSE 0.096\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #576: Train loss [3.8758]; Val loss: MSE [1.9214], L1 [0.6000], G-Mean [0.2598]\n",
      "Epoch: [577][ 0/65]\tTime   0.57 (  0.57)\tData 0.5651 (0.5651)\tLoss (MSE) 3.454 (3.454)\n",
      "Epoch: [577][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 4.281 (3.175)\n",
      "Epoch: [577][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 4.620 (3.422)\n",
      "Epoch: [577][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.655 (3.663)\n",
      "Epoch: [577][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 5.620 (3.950)\n",
      "Epoch: [577][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.903 (3.852)\n",
      "Epoch: [577][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.822 (3.901)\n",
      "Val: [0/9]\tTime  0.529 ( 0.529)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.262\n",
      " * Many: MSE 2.318\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.167\tL1 1.406\tG-Mean 1.347\n",
      " * Low: MSE 0.099\tL1 0.229\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #577: Train loss [3.8155]; Val loss: MSE [1.9246], L1 [0.5977], G-Mean [0.2617]\n",
      "Epoch: [578][ 0/65]\tTime   0.54 (  0.54)\tData 0.5348 (0.5348)\tLoss (MSE) 5.673 (5.673)\n",
      "Epoch: [578][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0554)\tLoss (MSE) 2.965 (3.913)\n",
      "Epoch: [578][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 4.750 (4.085)\n",
      "Epoch: [578][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.654 (4.099)\n",
      "Epoch: [578][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.784 (3.917)\n",
      "Epoch: [578][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.897 (3.813)\n",
      "Epoch: [578][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.535 (3.857)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.156\tL1 1.402\tG-Mean 1.343\n",
      " * Low: MSE 0.098\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #578: Train loss [3.8076]; Val loss: MSE [1.9239], L1 [0.5985], G-Mean [0.2604]\n",
      "Epoch: [579][ 0/65]\tTime   0.54 (  0.54)\tData 0.5387 (0.5387)\tLoss (MSE) 4.347 (4.347)\n",
      "Epoch: [579][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0552)\tLoss (MSE) 3.382 (3.654)\n",
      "Epoch: [579][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.871 (3.791)\n",
      "Epoch: [579][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.798 (3.945)\n",
      "Epoch: [579][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.850 (4.070)\n",
      "Epoch: [579][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.795 (3.946)\n",
      "Epoch: [579][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.119 (3.959)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.020\tG-Mean 0.872\n",
      " * Median: MSE 2.151\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #579: Train loss [3.9689]; Val loss: MSE [1.9230], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [580][ 0/65]\tTime   0.58 (  0.58)\tData 0.5681 (0.5681)\tLoss (MSE) 4.374 (4.374)\n",
      "Epoch: [580][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 3.590 (3.599)\n",
      "Epoch: [580][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 2.316 (3.505)\n",
      "Epoch: [580][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 4.145 (3.906)\n",
      "Epoch: [580][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 5.700 (3.955)\n",
      "Epoch: [580][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 4.087 (4.013)\n",
      "Epoch: [580][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.439 (4.000)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.339\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #580: Train loss [3.9319]; Val loss: MSE [1.9219], L1 [0.5992], G-Mean [0.2609]\n",
      "Epoch: [581][ 0/65]\tTime   0.56 (  0.56)\tData 0.5504 (0.5504)\tLoss (MSE) 7.174 (7.174)\n",
      "Epoch: [581][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 2.352 (4.067)\n",
      "Epoch: [581][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.266 (3.745)\n",
      "Epoch: [581][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 5.541 (3.705)\n",
      "Epoch: [581][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.959 (3.808)\n",
      "Epoch: [581][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.365 (3.906)\n",
      "Epoch: [581][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.066 (3.885)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.143\tL1 1.397\tG-Mean 1.339\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #581: Train loss [3.8635]; Val loss: MSE [1.9204], L1 [0.5992], G-Mean [0.2611]\n",
      "Epoch: [582][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 4.056 (4.056)\n",
      "Epoch: [582][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 3.581 (3.452)\n",
      "Epoch: [582][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.801 (3.935)\n",
      "Epoch: [582][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.383 (4.044)\n",
      "Epoch: [582][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 5.672 (4.136)\n",
      "Epoch: [582][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.778 (4.023)\n",
      "Epoch: [582][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.662 (3.890)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.259\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.148\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #582: Train loss [3.8437]; Val loss: MSE [1.9203], L1 [0.5987], G-Mean [0.2593]\n",
      "Epoch: [583][ 0/65]\tTime   0.56 (  0.56)\tData 0.5528 (0.5528)\tLoss (MSE) 3.118 (3.118)\n",
      "Epoch: [583][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 3.474 (3.289)\n",
      "Epoch: [583][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.851 (3.741)\n",
      "Epoch: [583][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.715 (3.764)\n",
      "Epoch: [583][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.315 (3.789)\n",
      "Epoch: [583][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.639 (3.908)\n",
      "Epoch: [583][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.333 (3.957)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.916\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.336\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.118\tL1 1.389\tG-Mean 1.330\n",
      " * Low: MSE 0.089\tL1 0.211\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #583: Train loss [3.9145]; Val loss: MSE [1.9163], L1 [0.6011], G-Mean [0.2614]\n",
      "Epoch: [584][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 4.331 (4.331)\n",
      "Epoch: [584][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 3.268 (3.080)\n",
      "Epoch: [584][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 4.994 (3.848)\n",
      "Epoch: [584][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 4.466 (3.693)\n",
      "Epoch: [584][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 5.079 (3.811)\n",
      "Epoch: [584][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 2.018 (3.841)\n",
      "Epoch: [584][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.728 (3.848)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.094\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #584: Train loss [3.8317]; Val loss: MSE [1.9204], L1 [0.5984], G-Mean [0.2599]\n",
      "Epoch: [585][ 0/65]\tTime   0.54 (  0.54)\tData 0.5374 (0.5374)\tLoss (MSE) 5.735 (5.735)\n",
      "Epoch: [585][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 4.208 (4.158)\n",
      "Epoch: [585][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 6.925 (4.176)\n",
      "Epoch: [585][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.141 (4.038)\n",
      "Epoch: [585][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.219 (4.014)\n",
      "Epoch: [585][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.391 (4.049)\n",
      "Epoch: [585][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.866 (3.869)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.314\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.169\tL1 1.407\tG-Mean 1.349\n",
      " * Low: MSE 0.096\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #585: Train loss [3.8943]; Val loss: MSE [1.9221], L1 [0.5974], G-Mean [0.2619]\n",
      "Epoch: [586][ 0/65]\tTime   0.55 (  0.55)\tData 0.5464 (0.5464)\tLoss (MSE) 4.926 (4.926)\n",
      "Epoch: [586][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0522)\tLoss (MSE) 2.865 (3.664)\n",
      "Epoch: [586][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.190 (3.872)\n",
      "Epoch: [586][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.617 (3.929)\n",
      "Epoch: [586][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 5.166 (3.916)\n",
      "Epoch: [586][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 2.700 (3.880)\n",
      "Epoch: [586][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.730 (3.805)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #586: Train loss [3.8169]; Val loss: MSE [1.9209], L1 [0.5985], G-Mean [0.2601]\n",
      "Epoch: [587][ 0/65]\tTime   0.55 (  0.55)\tData 0.5471 (0.5471)\tLoss (MSE) 4.305 (4.305)\n",
      "Epoch: [587][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 2.791 (3.396)\n",
      "Epoch: [587][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 4.219 (3.789)\n",
      "Epoch: [587][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 6.622 (3.862)\n",
      "Epoch: [587][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.896 (3.770)\n",
      "Epoch: [587][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.591 (3.922)\n",
      "Epoch: [587][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.024 (3.843)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.158\tL1 1.403\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.225\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #587: Train loss [3.8429]; Val loss: MSE [1.9219], L1 [0.5982], G-Mean [0.2595]\n",
      "Epoch: [588][ 0/65]\tTime   0.55 (  0.55)\tData 0.5485 (0.5485)\tLoss (MSE) 7.330 (7.330)\n",
      "Epoch: [588][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0518)\tLoss (MSE) 2.526 (3.844)\n",
      "Epoch: [588][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.945 (3.910)\n",
      "Epoch: [588][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.329 (3.873)\n",
      "Epoch: [588][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.396 (3.892)\n",
      "Epoch: [588][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 6.265 (3.864)\n",
      "Epoch: [588][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.871 (3.874)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.130\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.092\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #588: Train loss [3.8641]; Val loss: MSE [1.9190], L1 [0.6004], G-Mean [0.2603]\n",
      "Epoch: [589][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 3.023 (3.023)\n",
      "Epoch: [589][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0598)\tLoss (MSE) 3.323 (3.893)\n",
      "Epoch: [589][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.130 (3.894)\n",
      "Epoch: [589][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 3.652 (3.711)\n",
      "Epoch: [589][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 3.213 (3.804)\n",
      "Epoch: [589][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 5.478 (3.898)\n",
      "Epoch: [589][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.484 (3.827)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.326\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #589: Train loss [3.7929]; Val loss: MSE [1.9201], L1 [0.5992], G-Mean [0.2609]\n",
      "Epoch: [590][ 0/65]\tTime   0.57 (  0.57)\tData 0.5670 (0.5670)\tLoss (MSE) 5.373 (5.373)\n",
      "Epoch: [590][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 4.063 (3.507)\n",
      "Epoch: [590][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 2.304 (3.604)\n",
      "Epoch: [590][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.407 (3.803)\n",
      "Epoch: [590][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.207 (3.762)\n",
      "Epoch: [590][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.287 (3.818)\n",
      "Epoch: [590][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.759 (3.829)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #590: Train loss [3.8126]; Val loss: MSE [1.9216], L1 [0.5988], G-Mean [0.2607]\n",
      "Epoch: [591][ 0/65]\tTime   0.60 (  0.60)\tData 0.5872 (0.5872)\tLoss (MSE) 5.119 (5.119)\n",
      "Epoch: [591][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 5.250 (4.701)\n",
      "Epoch: [591][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 4.057 (4.364)\n",
      "Epoch: [591][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.984 (4.200)\n",
      "Epoch: [591][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.718 (4.025)\n",
      "Epoch: [591][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.056 (3.972)\n",
      "Epoch: [591][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.651 (3.949)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.163\tL1 1.405\tG-Mean 1.347\n",
      " * Low: MSE 0.097\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #591: Train loss [3.9373]; Val loss: MSE [1.9229], L1 [0.5979], G-Mean [0.2603]\n",
      "Epoch: [592][ 0/65]\tTime   0.62 (  0.62)\tData 0.6157 (0.6157)\tLoss (MSE) 3.908 (3.908)\n",
      "Epoch: [592][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0608)\tLoss (MSE) 8.043 (3.904)\n",
      "Epoch: [592][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0318)\tLoss (MSE) 4.690 (3.782)\n",
      "Epoch: [592][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0216)\tLoss (MSE) 3.443 (3.861)\n",
      "Epoch: [592][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 2.694 (3.720)\n",
      "Epoch: [592][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 3.659 (3.767)\n",
      "Epoch: [592][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.605 (3.817)\n",
      "Val: [0/9]\tTime  0.652 ( 0.652)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.924\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.310\tL1 1.010\tG-Mean 0.862\n",
      " * Median: MSE 2.181\tL1 1.411\tG-Mean 1.354\n",
      " * Low: MSE 0.098\tL1 0.232\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #592: Train loss [3.8341]; Val loss: MSE [1.9241], L1 [0.5967], G-Mean [0.2619]\n",
      "Epoch: [593][ 0/65]\tTime   0.57 (  0.57)\tData 0.5652 (0.5652)\tLoss (MSE) 2.283 (2.283)\n",
      "Epoch: [593][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.282 (3.090)\n",
      "Epoch: [593][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 3.714 (3.417)\n",
      "Epoch: [593][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 2.839 (3.566)\n",
      "Epoch: [593][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.870 (3.747)\n",
      "Epoch: [593][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 2.860 (3.732)\n",
      "Epoch: [593][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 7.801 (3.779)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #593: Train loss [3.8076]; Val loss: MSE [1.9206], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [594][ 0/65]\tTime   0.55 (  0.55)\tData 0.5460 (0.5460)\tLoss (MSE) 4.099 (4.099)\n",
      "Epoch: [594][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 2.276 (3.977)\n",
      "Epoch: [594][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.737 (3.806)\n",
      "Epoch: [594][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.539 (3.826)\n",
      "Epoch: [594][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.855 (3.870)\n",
      "Epoch: [594][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.654 (3.838)\n",
      "Epoch: [594][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.624 (3.895)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.326\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #594: Train loss [3.8612]; Val loss: MSE [1.9200], L1 [0.5991], G-Mean [0.2603]\n",
      "Epoch: [595][ 0/65]\tTime   0.62 (  0.62)\tData 0.6031 (0.6031)\tLoss (MSE) 3.634 (3.634)\n",
      "Epoch: [595][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0573)\tLoss (MSE) 2.552 (3.349)\n",
      "Epoch: [595][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 4.907 (3.449)\n",
      "Epoch: [595][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 3.049 (3.441)\n",
      "Epoch: [595][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 7.700 (3.634)\n",
      "Epoch: [595][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.643 (3.663)\n",
      "Epoch: [595][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0104)\tLoss (MSE) 2.060 (3.727)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #595: Train loss [3.7371]; Val loss: MSE [1.9203], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [596][ 0/65]\tTime   0.55 (  0.55)\tData 0.5460 (0.5460)\tLoss (MSE) 4.231 (4.231)\n",
      "Epoch: [596][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 2.486 (3.911)\n",
      "Epoch: [596][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 3.038 (3.987)\n",
      "Epoch: [596][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 4.521 (3.869)\n",
      "Epoch: [596][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.162 (3.784)\n",
      "Epoch: [596][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.000 (3.751)\n",
      "Epoch: [596][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.381 (3.737)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.329\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.139\tL1 1.396\tG-Mean 1.339\n",
      " * Low: MSE 0.093\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #596: Train loss [3.7285]; Val loss: MSE [1.9198], L1 [0.5996], G-Mean [0.2594]\n",
      "Epoch: [597][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 5.923 (5.923)\n",
      "Epoch: [597][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0575)\tLoss (MSE) 2.963 (3.839)\n",
      "Epoch: [597][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 4.724 (3.890)\n",
      "Epoch: [597][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.497 (3.831)\n",
      "Epoch: [597][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.525 (3.862)\n",
      "Epoch: [597][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.260 (3.786)\n",
      "Epoch: [597][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.661 (3.870)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #597: Train loss [3.8291]; Val loss: MSE [1.9202], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [598][ 0/65]\tTime   0.55 (  0.55)\tData 0.5438 (0.5438)\tLoss (MSE) 4.837 (4.837)\n",
      "Epoch: [598][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 2.885 (4.230)\n",
      "Epoch: [598][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 9.131 (4.283)\n",
      "Epoch: [598][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.388 (4.045)\n",
      "Epoch: [598][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.577 (3.964)\n",
      "Epoch: [598][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.010 (3.959)\n",
      "Epoch: [598][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.311 (3.843)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.311\tL1 1.011\tG-Mean 0.864\n",
      " * Median: MSE 2.176\tL1 1.410\tG-Mean 1.353\n",
      " * Low: MSE 0.096\tL1 0.230\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #598: Train loss [3.8042]; Val loss: MSE [1.9225], L1 [0.5968], G-Mean [0.2615]\n",
      "Epoch: [599][ 0/65]\tTime   0.62 (  0.62)\tData 0.6027 (0.6027)\tLoss (MSE) 2.157 (2.157)\n",
      "Epoch: [599][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0593)\tLoss (MSE) 4.636 (3.885)\n",
      "Epoch: [599][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 2.381 (3.486)\n",
      "Epoch: [599][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 4.445 (3.630)\n",
      "Epoch: [599][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 4.313 (3.538)\n",
      "Epoch: [599][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.069 (3.731)\n",
      "Epoch: [599][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.886 (3.699)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.315\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.169\tL1 1.407\tG-Mean 1.350\n",
      " * Low: MSE 0.095\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #599: Train loss [3.7568]; Val loss: MSE [1.9220], L1 [0.5973], G-Mean [0.2607]\n",
      "Epoch: [600][ 0/65]\tTime   0.55 (  0.55)\tData 0.5482 (0.5482)\tLoss (MSE) 2.264 (2.264)\n",
      "Epoch: [600][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 3.413 (3.704)\n",
      "Epoch: [600][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.832 (3.616)\n",
      "Epoch: [600][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.024 (3.641)\n",
      "Epoch: [600][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 4.130 (3.808)\n",
      "Epoch: [600][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.974 (3.727)\n",
      "Epoch: [600][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.940 (3.821)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.259\n",
      " * Many: MSE 2.327\tL1 1.024\tG-Mean 0.877\n",
      " * Median: MSE 2.139\tL1 1.397\tG-Mean 1.339\n",
      " * Low: MSE 0.091\tL1 0.217\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #600: Train loss [3.7943]; Val loss: MSE [1.9186], L1 [0.5994], G-Mean [0.2591]\n",
      "Epoch: [601][ 0/65]\tTime   0.55 (  0.55)\tData 0.5433 (0.5433)\tLoss (MSE) 3.042 (3.042)\n",
      "Epoch: [601][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 3.018 (3.394)\n",
      "Epoch: [601][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.378 (3.711)\n",
      "Epoch: [601][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 5.326 (3.786)\n",
      "Epoch: [601][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 6.029 (3.938)\n",
      "Epoch: [601][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.346 (3.884)\n",
      "Epoch: [601][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.076 (3.809)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #601: Train loss [3.8438]; Val loss: MSE [1.9199], L1 [0.5984], G-Mean [0.2594]\n",
      "Epoch: [602][ 0/65]\tTime   0.59 (  0.59)\tData 0.5749 (0.5749)\tLoss (MSE) 4.326 (4.326)\n",
      "Epoch: [602][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 5.278 (4.344)\n",
      "Epoch: [602][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 3.163 (4.223)\n",
      "Epoch: [602][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.247 (3.992)\n",
      "Epoch: [602][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 5.550 (3.954)\n",
      "Epoch: [602][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 2.590 (3.909)\n",
      "Epoch: [602][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.613 (3.858)\n",
      "Val: [0/9]\tTime  0.534 ( 0.534)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.163\tL1 1.405\tG-Mean 1.348\n",
      " * Low: MSE 0.095\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #602: Train loss [3.8595]; Val loss: MSE [1.9217], L1 [0.5977], G-Mean [0.2598]\n",
      "Epoch: [603][ 0/65]\tTime   0.55 (  0.55)\tData 0.5414 (0.5414)\tLoss (MSE) 2.249 (2.249)\n",
      "Epoch: [603][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0503)\tLoss (MSE) 2.736 (3.984)\n",
      "Epoch: [603][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0264)\tLoss (MSE) 2.935 (4.019)\n",
      "Epoch: [603][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 6.109 (4.174)\n",
      "Epoch: [603][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 2.422 (3.977)\n",
      "Epoch: [603][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 3.344 (3.953)\n",
      "Epoch: [603][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 3.968 (3.950)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.924\tL1 0.596\tG-Mean 0.262\n",
      " * Many: MSE 2.308\tL1 1.008\tG-Mean 0.860\n",
      " * Median: MSE 2.185\tL1 1.413\tG-Mean 1.356\n",
      " * Low: MSE 0.097\tL1 0.233\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #603: Train loss [3.8722]; Val loss: MSE [1.9243], L1 [0.5961], G-Mean [0.2621]\n",
      "Epoch: [604][ 0/65]\tTime   0.56 (  0.56)\tData 0.5533 (0.5533)\tLoss (MSE) 4.628 (4.628)\n",
      "Epoch: [604][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 6.003 (4.104)\n",
      "Epoch: [604][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 4.173 (3.901)\n",
      "Epoch: [604][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 2.941 (3.819)\n",
      "Epoch: [604][40/65]\tTime   0.01 (  0.02)\tData 0.0001 (0.0143)\tLoss (MSE) 4.183 (3.753)\n",
      "Epoch: [604][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.417 (3.790)\n",
      "Epoch: [604][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.828 (3.829)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.338\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.117\tL1 1.389\tG-Mean 1.331\n",
      " * Low: MSE 0.089\tL1 0.210\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #604: Train loss [3.8160]; Val loss: MSE [1.9173], L1 [0.6012], G-Mean [0.2610]\n",
      "Epoch: [605][ 0/65]\tTime   0.55 (  0.55)\tData 0.5399 (0.5399)\tLoss (MSE) 3.014 (3.014)\n",
      "Epoch: [605][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 1.782 (2.788)\n",
      "Epoch: [605][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.117 (3.531)\n",
      "Epoch: [605][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.815 (3.480)\n",
      "Epoch: [605][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.865 (3.895)\n",
      "Epoch: [605][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.293 (3.850)\n",
      "Epoch: [605][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.271 (3.832)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.164\tL1 1.405\tG-Mean 1.348\n",
      " * Low: MSE 0.095\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #605: Train loss [3.7977]; Val loss: MSE [1.9228], L1 [0.5976], G-Mean [0.2605]\n",
      "Epoch: [606][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 2.879 (2.879)\n",
      "Epoch: [606][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0541)\tLoss (MSE) 3.016 (3.767)\n",
      "Epoch: [606][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 5.406 (3.832)\n",
      "Epoch: [606][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 2.660 (3.842)\n",
      "Epoch: [606][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.494 (3.827)\n",
      "Epoch: [606][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.024 (4.001)\n",
      "Epoch: [606][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.286 (3.930)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.057 (2.057)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.925\tL1 0.596\tG-Mean 0.262\n",
      " * Many: MSE 2.309\tL1 1.008\tG-Mean 0.860\n",
      " * Median: MSE 2.186\tL1 1.413\tG-Mean 1.356\n",
      " * Low: MSE 0.097\tL1 0.234\tG-Mean 0.214\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #606: Train loss [3.9722]; Val loss: MSE [1.9252], L1 [0.5961], G-Mean [0.2622]\n",
      "Epoch: [607][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 3.230 (3.230)\n",
      "Epoch: [607][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 3.705 (4.095)\n",
      "Epoch: [607][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 3.333 (3.872)\n",
      "Epoch: [607][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.017 (3.970)\n",
      "Epoch: [607][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.801 (3.972)\n",
      "Epoch: [607][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.470 (3.900)\n",
      "Epoch: [607][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 1.820 (3.771)\n",
      "Val: [0/9]\tTime  0.626 ( 0.626)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.327\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #607: Train loss [3.7780]; Val loss: MSE [1.9207], L1 [0.5992], G-Mean [0.2608]\n",
      "Epoch: [608][ 0/65]\tTime   0.65 (  0.65)\tData 0.6431 (0.6431)\tLoss (MSE) 5.696 (5.696)\n",
      "Epoch: [608][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0601)\tLoss (MSE) 3.605 (4.315)\n",
      "Epoch: [608][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0315)\tLoss (MSE) 3.761 (4.055)\n",
      "Epoch: [608][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 4.024 (3.932)\n",
      "Epoch: [608][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 6.631 (3.933)\n",
      "Epoch: [608][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 5.114 (3.842)\n",
      "Epoch: [608][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 2.532 (3.784)\n",
      "Val: [0/9]\tTime  0.564 ( 0.564)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.094\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #608: Train loss [3.8164]; Val loss: MSE [1.9228], L1 [0.5985], G-Mean [0.2597]\n",
      "Epoch: [609][ 0/65]\tTime   0.55 (  0.55)\tData 0.5427 (0.5427)\tLoss (MSE) 3.434 (3.434)\n",
      "Epoch: [609][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 4.714 (3.315)\n",
      "Epoch: [609][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 2.843 (3.480)\n",
      "Epoch: [609][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.747 (3.701)\n",
      "Epoch: [609][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.112 (3.699)\n",
      "Epoch: [609][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.052 (3.692)\n",
      "Epoch: [609][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.868 (3.770)\n",
      "Val: [0/9]\tTime  0.530 ( 0.530)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #609: Train loss [3.8090]; Val loss: MSE [1.9226], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [610][ 0/65]\tTime   0.57 (  0.57)\tData 0.5684 (0.5684)\tLoss (MSE) 5.596 (5.596)\n",
      "Epoch: [610][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 7.544 (3.905)\n",
      "Epoch: [610][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.841 (3.893)\n",
      "Epoch: [610][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 2.819 (3.949)\n",
      "Epoch: [610][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 2.758 (3.862)\n",
      "Epoch: [610][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.384 (3.848)\n",
      "Epoch: [610][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.698 (3.806)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.093\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #610: Train loss [3.8271]; Val loss: MSE [1.9226], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [611][ 0/65]\tTime   0.56 (  0.56)\tData 0.5509 (0.5509)\tLoss (MSE) 3.809 (3.809)\n",
      "Epoch: [611][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 5.923 (4.381)\n",
      "Epoch: [611][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 3.715 (4.050)\n",
      "Epoch: [611][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.856 (3.751)\n",
      "Epoch: [611][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.112 (3.781)\n",
      "Epoch: [611][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.522 (3.837)\n",
      "Epoch: [611][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.324 (3.792)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.318\tL1 1.015\tG-Mean 0.867\n",
      " * Median: MSE 2.167\tL1 1.406\tG-Mean 1.349\n",
      " * Low: MSE 0.095\tL1 0.227\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #611: Train loss [3.7780]; Val loss: MSE [1.9241], L1 [0.5977], G-Mean [0.2606]\n",
      "Epoch: [612][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 4.731 (4.731)\n",
      "Epoch: [612][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0585)\tLoss (MSE) 2.558 (3.435)\n",
      "Epoch: [612][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 3.228 (3.810)\n",
      "Epoch: [612][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 3.099 (3.680)\n",
      "Epoch: [612][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 5.946 (3.769)\n",
      "Epoch: [612][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.654 (3.717)\n",
      "Epoch: [612][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.732 (3.738)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #612: Train loss [3.7681]; Val loss: MSE [1.9224], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [613][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 2.232 (2.232)\n",
      "Epoch: [613][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 4.575 (3.857)\n",
      "Epoch: [613][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.219 (4.198)\n",
      "Epoch: [613][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.776 (4.048)\n",
      "Epoch: [613][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.649 (4.126)\n",
      "Epoch: [613][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 4.530 (3.962)\n",
      "Epoch: [613][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.707 (3.876)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.311\tL1 1.010\tG-Mean 0.862\n",
      " * Median: MSE 2.180\tL1 1.411\tG-Mean 1.355\n",
      " * Low: MSE 0.096\tL1 0.231\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #613: Train loss [3.8689]; Val loss: MSE [1.9245], L1 [0.5967], G-Mean [0.2615]\n",
      "Epoch: [614][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 4.918 (4.918)\n",
      "Epoch: [614][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 2.956 (3.696)\n",
      "Epoch: [614][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 5.961 (3.882)\n",
      "Epoch: [614][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 5.872 (3.698)\n",
      "Epoch: [614][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.852 (3.832)\n",
      "Epoch: [614][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.457 (3.802)\n",
      "Epoch: [614][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.813 (3.828)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.319\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.347\n",
      " * Low: MSE 0.093\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #614: Train loss [3.8601]; Val loss: MSE [1.9216], L1 [0.5980], G-Mean [0.2592]\n",
      "Epoch: [615][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 2.470 (2.470)\n",
      "Epoch: [615][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0568)\tLoss (MSE) 5.183 (4.479)\n",
      "Epoch: [615][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 4.693 (4.145)\n",
      "Epoch: [615][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 4.996 (3.962)\n",
      "Epoch: [615][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 1.770 (3.962)\n",
      "Epoch: [615][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.486 (3.829)\n",
      "Epoch: [615][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 1.847 (3.817)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.317\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.164\tL1 1.406\tG-Mean 1.349\n",
      " * Low: MSE 0.094\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #615: Train loss [3.7819]; Val loss: MSE [1.9219], L1 [0.5976], G-Mean [0.2604]\n",
      "Epoch: [616][ 0/65]\tTime   0.55 (  0.55)\tData 0.5485 (0.5485)\tLoss (MSE) 2.758 (2.758)\n",
      "Epoch: [616][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 4.773 (3.583)\n",
      "Epoch: [616][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.148 (3.636)\n",
      "Epoch: [616][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.586 (3.592)\n",
      "Epoch: [616][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 4.114 (3.594)\n",
      "Epoch: [616][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 2.696 (3.567)\n",
      "Epoch: [616][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.831 (3.731)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.332\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.132\tL1 1.394\tG-Mean 1.337\n",
      " * Low: MSE 0.090\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #616: Train loss [3.7555]; Val loss: MSE [1.9190], L1 [0.6002], G-Mean [0.2599]\n",
      "Epoch: [617][ 0/65]\tTime   0.54 (  0.54)\tData 0.5362 (0.5362)\tLoss (MSE) 5.129 (5.129)\n",
      "Epoch: [617][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0496)\tLoss (MSE) 3.871 (3.653)\n",
      "Epoch: [617][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0260)\tLoss (MSE) 4.788 (3.910)\n",
      "Epoch: [617][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0176)\tLoss (MSE) 1.502 (3.898)\n",
      "Epoch: [617][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 3.072 (3.889)\n",
      "Epoch: [617][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.344 (3.792)\n",
      "Epoch: [617][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0090)\tLoss (MSE) 6.120 (3.844)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.016\tG-Mean 0.868\n",
      " * Median: MSE 2.165\tL1 1.406\tG-Mean 1.349\n",
      " * Low: MSE 0.094\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #617: Train loss [3.8596]; Val loss: MSE [1.9229], L1 [0.5977], G-Mean [0.2603]\n",
      "Epoch: [618][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 2.219 (2.219)\n",
      "Epoch: [618][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0576)\tLoss (MSE) 4.809 (3.579)\n",
      "Epoch: [618][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 5.537 (3.758)\n",
      "Epoch: [618][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.665 (3.732)\n",
      "Epoch: [618][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.585 (3.809)\n",
      "Epoch: [618][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.047 (3.675)\n",
      "Epoch: [618][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.260 (3.773)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.330\tL1 1.025\tG-Mean 0.879\n",
      " * Median: MSE 2.137\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.090\tL1 0.216\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #618: Train loss [3.7999]; Val loss: MSE [1.9196], L1 [0.5998], G-Mean [0.2596]\n",
      "Epoch: [619][ 0/65]\tTime   0.56 (  0.56)\tData 0.5602 (0.5602)\tLoss (MSE) 3.108 (3.108)\n",
      "Epoch: [619][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0597)\tLoss (MSE) 2.694 (4.468)\n",
      "Epoch: [619][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.744 (4.106)\n",
      "Epoch: [619][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 4.480 (4.147)\n",
      "Epoch: [619][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 2.149 (4.011)\n",
      "Epoch: [619][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 4.569 (3.952)\n",
      "Epoch: [619][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 5.704 (3.896)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.163\tL1 1.405\tG-Mean 1.348\n",
      " * Low: MSE 0.093\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #619: Train loss [3.8694]; Val loss: MSE [1.9227], L1 [0.5979], G-Mean [0.2596]\n",
      "Epoch: [620][ 0/65]\tTime   0.56 (  0.56)\tData 0.5532 (0.5532)\tLoss (MSE) 4.140 (4.140)\n",
      "Epoch: [620][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0507)\tLoss (MSE) 2.493 (3.621)\n",
      "Epoch: [620][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 4.317 (3.495)\n",
      "Epoch: [620][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.112 (3.744)\n",
      "Epoch: [620][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.135 (3.703)\n",
      "Epoch: [620][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.517 (3.670)\n",
      "Epoch: [620][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.543 (3.736)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.321\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.158\tL1 1.403\tG-Mean 1.346\n",
      " * Low: MSE 0.093\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #620: Train loss [3.7608]; Val loss: MSE [1.9221], L1 [0.5982], G-Mean [0.2591]\n",
      "Epoch: [621][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 4.460 (4.460)\n",
      "Epoch: [621][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0548)\tLoss (MSE) 2.439 (4.473)\n",
      "Epoch: [621][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 4.160 (4.066)\n",
      "Epoch: [621][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 4.576 (3.945)\n",
      "Epoch: [621][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.900 (3.900)\n",
      "Epoch: [621][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 2.300 (3.874)\n",
      "Epoch: [621][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.938 (3.797)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.159\tL1 1.404\tG-Mean 1.346\n",
      " * Low: MSE 0.094\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #621: Train loss [3.7800]; Val loss: MSE [1.9224], L1 [0.5982], G-Mean [0.2591]\n",
      "Epoch: [622][ 0/65]\tTime   0.57 (  0.57)\tData 0.5600 (0.5600)\tLoss (MSE) 2.659 (2.659)\n",
      "Epoch: [622][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 4.240 (3.533)\n",
      "Epoch: [622][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 2.504 (3.676)\n",
      "Epoch: [622][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 5.705 (3.908)\n",
      "Epoch: [622][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 2.632 (3.820)\n",
      "Epoch: [622][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.892 (3.788)\n",
      "Epoch: [622][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.502 (3.753)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.094\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #622: Train loss [3.8051]; Val loss: MSE [1.9220], L1 [0.5987], G-Mean [0.2602]\n",
      "Epoch: [623][ 0/65]\tTime   0.57 (  0.57)\tData 0.5666 (0.5666)\tLoss (MSE) 3.709 (3.709)\n",
      "Epoch: [623][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0585)\tLoss (MSE) 2.960 (4.103)\n",
      "Epoch: [623][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.513 (3.711)\n",
      "Epoch: [623][30/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 3.703 (3.695)\n",
      "Epoch: [623][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.677 (3.736)\n",
      "Epoch: [623][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.711 (3.760)\n",
      "Epoch: [623][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0106)\tLoss (MSE) 2.871 (3.818)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.921\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.330\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.138\tL1 1.396\tG-Mean 1.339\n",
      " * Low: MSE 0.093\tL1 0.217\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #623: Train loss [3.7644]; Val loss: MSE [1.9206], L1 [0.5997], G-Mean [0.2599]\n",
      "Epoch: [624][ 0/65]\tTime   0.57 (  0.57)\tData 0.5658 (0.5658)\tLoss (MSE) 2.550 (2.550)\n",
      "Epoch: [624][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0559)\tLoss (MSE) 3.409 (3.671)\n",
      "Epoch: [624][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.324 (3.660)\n",
      "Epoch: [624][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.601 (3.847)\n",
      "Epoch: [624][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 4.590 (3.965)\n",
      "Epoch: [624][50/65]\tTime   0.01 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.953 (3.900)\n",
      "Epoch: [624][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.913 (3.791)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.325\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.092\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #624: Train loss [3.8684]; Val loss: MSE [1.9211], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [625][ 0/65]\tTime   0.55 (  0.55)\tData 0.5426 (0.5426)\tLoss (MSE) 5.313 (5.313)\n",
      "Epoch: [625][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0555)\tLoss (MSE) 4.561 (3.632)\n",
      "Epoch: [625][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0291)\tLoss (MSE) 1.826 (4.060)\n",
      "Epoch: [625][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0197)\tLoss (MSE) 3.278 (4.009)\n",
      "Epoch: [625][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.329 (4.064)\n",
      "Epoch: [625][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 1.828 (4.011)\n",
      "Epoch: [625][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.279 (3.935)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.091\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #625: Train loss [3.9455]; Val loss: MSE [1.9189], L1 [0.5989], G-Mean [0.2603]\n",
      "Epoch: [626][ 0/65]\tTime   0.56 (  0.56)\tData 0.5494 (0.5494)\tLoss (MSE) 3.099 (3.099)\n",
      "Epoch: [626][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 3.109 (3.722)\n",
      "Epoch: [626][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 4.653 (3.868)\n",
      "Epoch: [626][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 4.719 (4.094)\n",
      "Epoch: [626][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 5.800 (4.070)\n",
      "Epoch: [626][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.917 (3.957)\n",
      "Epoch: [626][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.405 (3.815)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.922\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.313\tL1 1.013\tG-Mean 0.866\n",
      " * Median: MSE 2.171\tL1 1.408\tG-Mean 1.351\n",
      " * Low: MSE 0.094\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #626: Train loss [3.7599]; Val loss: MSE [1.9218], L1 [0.5971], G-Mean [0.2616]\n",
      "Epoch: [627][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 2.265 (2.265)\n",
      "Epoch: [627][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 2.758 (3.925)\n",
      "Epoch: [627][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 2.643 (3.608)\n",
      "Epoch: [627][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 5.510 (3.658)\n",
      "Epoch: [627][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 7.691 (3.716)\n",
      "Epoch: [627][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.318 (3.721)\n",
      "Epoch: [627][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 6.176 (3.799)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.092\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #627: Train loss [3.7985]; Val loss: MSE [1.9218], L1 [0.5985], G-Mean [0.2596]\n",
      "Epoch: [628][ 0/65]\tTime   0.58 (  0.58)\tData 0.5691 (0.5691)\tLoss (MSE) 1.861 (1.861)\n",
      "Epoch: [628][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 2.696 (3.695)\n",
      "Epoch: [628][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 4.795 (3.864)\n",
      "Epoch: [628][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.930 (3.884)\n",
      "Epoch: [628][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.613 (3.898)\n",
      "Epoch: [628][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.266 (3.899)\n",
      "Epoch: [628][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.905 (3.894)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.333\tL1 1.028\tG-Mean 0.882\n",
      " * Median: MSE 2.128\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.089\tL1 0.213\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #628: Train loss [3.8618]; Val loss: MSE [1.9184], L1 [0.6005], G-Mean [0.2605]\n",
      "Epoch: [629][ 0/65]\tTime   0.58 (  0.58)\tData 0.5716 (0.5716)\tLoss (MSE) 1.862 (1.862)\n",
      "Epoch: [629][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 3.569 (3.661)\n",
      "Epoch: [629][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 2.593 (3.488)\n",
      "Epoch: [629][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 5.316 (3.737)\n",
      "Epoch: [629][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.910 (3.899)\n",
      "Epoch: [629][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.793 (3.862)\n",
      "Epoch: [629][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.335 (3.814)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.332\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.130\tL1 1.393\tG-Mean 1.336\n",
      " * Low: MSE 0.090\tL1 0.214\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #629: Train loss [3.8725]; Val loss: MSE [1.9187], L1 [0.6003], G-Mean [0.2597]\n",
      "Epoch: [630][ 0/65]\tTime   0.67 (  0.67)\tData 0.6634 (0.6634)\tLoss (MSE) 4.399 (4.399)\n",
      "Epoch: [630][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0655)\tLoss (MSE) 4.812 (4.412)\n",
      "Epoch: [630][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0343)\tLoss (MSE) 3.016 (3.836)\n",
      "Epoch: [630][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0233)\tLoss (MSE) 5.202 (4.054)\n",
      "Epoch: [630][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0176)\tLoss (MSE) 3.033 (3.907)\n",
      "Epoch: [630][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.750 (3.845)\n",
      "Epoch: [630][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.033 (3.817)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.093\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #630: Train loss [3.8601]; Val loss: MSE [1.9218], L1 [0.5985], G-Mean [0.2597]\n",
      "Epoch: [631][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 2.153 (2.153)\n",
      "Epoch: [631][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0588)\tLoss (MSE) 2.869 (3.576)\n",
      "Epoch: [631][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 2.115 (3.852)\n",
      "Epoch: [631][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 2.821 (3.539)\n",
      "Epoch: [631][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.634 (3.663)\n",
      "Epoch: [631][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.296 (3.775)\n",
      "Epoch: [631][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.890 (3.856)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.130\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.090\tL1 0.214\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #631: Train loss [3.8454]; Val loss: MSE [1.9196], L1 [0.6005], G-Mean [0.2596]\n",
      "Epoch: [632][ 0/65]\tTime   0.61 (  0.61)\tData 0.5925 (0.5925)\tLoss (MSE) 3.312 (3.312)\n",
      "Epoch: [632][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0567)\tLoss (MSE) 5.677 (4.020)\n",
      "Epoch: [632][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0297)\tLoss (MSE) 2.962 (3.879)\n",
      "Epoch: [632][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0201)\tLoss (MSE) 4.161 (3.782)\n",
      "Epoch: [632][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.716 (3.699)\n",
      "Epoch: [632][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.084 (3.771)\n",
      "Epoch: [632][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.862 (3.880)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.329\tL1 1.024\tG-Mean 0.877\n",
      " * Median: MSE 2.138\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.091\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #632: Train loss [3.8692]; Val loss: MSE [1.9205], L1 [0.5998], G-Mean [0.2601]\n",
      "Epoch: [633][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 3.036 (3.036)\n",
      "Epoch: [633][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 2.818 (4.546)\n",
      "Epoch: [633][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.696 (4.213)\n",
      "Epoch: [633][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.084 (3.882)\n",
      "Epoch: [633][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.242 (3.843)\n",
      "Epoch: [633][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.823 (3.852)\n",
      "Epoch: [633][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.276 (3.767)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.023\tG-Mean 0.877\n",
      " * Median: MSE 2.139\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.091\tL1 0.218\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #633: Train loss [3.8299]; Val loss: MSE [1.9220], L1 [0.5997], G-Mean [0.2608]\n",
      "Epoch: [634][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 3.222 (3.222)\n",
      "Epoch: [634][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0560)\tLoss (MSE) 3.782 (4.130)\n",
      "Epoch: [634][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.574 (3.640)\n",
      "Epoch: [634][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.362 (3.537)\n",
      "Epoch: [634][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 2.638 (3.532)\n",
      "Epoch: [634][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.629 (3.687)\n",
      "Epoch: [634][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 6.653 (3.800)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.023\tG-Mean 0.876\n",
      " * Median: MSE 2.141\tL1 1.397\tG-Mean 1.339\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #634: Train loss [3.8157]; Val loss: MSE [1.9226], L1 [0.5996], G-Mean [0.2606]\n",
      "Epoch: [635][ 0/65]\tTime   0.61 (  0.61)\tData 0.5999 (0.5999)\tLoss (MSE) 5.925 (5.925)\n",
      "Epoch: [635][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 4.351 (3.576)\n",
      "Epoch: [635][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 4.100 (3.557)\n",
      "Epoch: [635][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.180 (3.615)\n",
      "Epoch: [635][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.669 (3.647)\n",
      "Epoch: [635][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 7.209 (3.633)\n",
      "Epoch: [635][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.535 (3.691)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.335\tL1 1.026\tG-Mean 0.879\n",
      " * Median: MSE 2.132\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #635: Train loss [3.7221]; Val loss: MSE [1.9226], L1 [0.6004], G-Mean [0.2602]\n",
      "Epoch: [636][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 3.888 (3.888)\n",
      "Epoch: [636][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0599)\tLoss (MSE) 4.089 (4.195)\n",
      "Epoch: [636][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 4.178 (4.082)\n",
      "Epoch: [636][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 3.034 (3.939)\n",
      "Epoch: [636][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 2.391 (3.874)\n",
      "Epoch: [636][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 4.080 (3.817)\n",
      "Epoch: [636][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 4.894 (3.836)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.329\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.146\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #636: Train loss [3.8225]; Val loss: MSE [1.9245], L1 [0.5993], G-Mean [0.2611]\n",
      "Epoch: [637][ 0/65]\tTime   0.57 (  0.57)\tData 0.5592 (0.5592)\tLoss (MSE) 8.383 (8.383)\n",
      "Epoch: [637][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.464 (4.667)\n",
      "Epoch: [637][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.608 (4.106)\n",
      "Epoch: [637][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.541 (4.101)\n",
      "Epoch: [637][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.198 (3.912)\n",
      "Epoch: [637][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.602 (3.893)\n",
      "Epoch: [637][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.812 (3.753)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.056 (2.056)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.928\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.318\tL1 1.012\tG-Mean 0.863\n",
      " * Median: MSE 2.174\tL1 1.408\tG-Mean 1.350\n",
      " * Low: MSE 0.098\tL1 0.231\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #637: Train loss [3.7686]; Val loss: MSE [1.9282], L1 [0.5974], G-Mean [0.2618]\n",
      "Epoch: [638][ 0/65]\tTime   0.60 (  0.60)\tData 0.5866 (0.5866)\tLoss (MSE) 8.119 (8.119)\n",
      "Epoch: [638][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0556)\tLoss (MSE) 3.671 (4.024)\n",
      "Epoch: [638][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.727 (4.203)\n",
      "Epoch: [638][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 2.672 (4.026)\n",
      "Epoch: [638][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.358 (3.848)\n",
      "Epoch: [638][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.979 (3.822)\n",
      "Epoch: [638][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.993 (3.887)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.922\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.339\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.122\tL1 1.390\tG-Mean 1.331\n",
      " * Low: MSE 0.091\tL1 0.213\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #638: Train loss [3.8683]; Val loss: MSE [1.9215], L1 [0.6012], G-Mean [0.2607]\n",
      "Epoch: [639][ 0/65]\tTime   0.56 (  0.56)\tData 0.5561 (0.5561)\tLoss (MSE) 9.408 (9.408)\n",
      "Epoch: [639][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 3.263 (4.249)\n",
      "Epoch: [639][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 4.078 (3.998)\n",
      "Epoch: [639][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 6.038 (4.083)\n",
      "Epoch: [639][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.320 (3.888)\n",
      "Epoch: [639][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 7.997 (3.964)\n",
      "Epoch: [639][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.479 (3.857)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.927\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.316\tL1 1.012\tG-Mean 0.863\n",
      " * Median: MSE 2.175\tL1 1.409\tG-Mean 1.352\n",
      " * Low: MSE 0.097\tL1 0.231\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #639: Train loss [3.8347]; Val loss: MSE [1.9270], L1 [0.5973], G-Mean [0.2616]\n",
      "Epoch: [640][ 0/65]\tTime   0.56 (  0.56)\tData 0.5568 (0.5568)\tLoss (MSE) 3.469 (3.469)\n",
      "Epoch: [640][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 5.106 (3.998)\n",
      "Epoch: [640][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.156 (3.649)\n",
      "Epoch: [640][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.784 (3.751)\n",
      "Epoch: [640][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.921 (3.709)\n",
      "Epoch: [640][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.300 (3.745)\n",
      "Epoch: [640][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.318 (3.747)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.159\tL1 1.403\tG-Mean 1.345\n",
      " * Low: MSE 0.096\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #640: Train loss [3.7932]; Val loss: MSE [1.9253], L1 [0.5984], G-Mean [0.2604]\n",
      "Epoch: [641][ 0/65]\tTime   0.63 (  0.63)\tData 0.6098 (0.6098)\tLoss (MSE) 3.811 (3.811)\n",
      "Epoch: [641][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 1.656 (4.114)\n",
      "Epoch: [641][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.080 (4.134)\n",
      "Epoch: [641][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.781 (3.846)\n",
      "Epoch: [641][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.702 (3.768)\n",
      "Epoch: [641][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.508 (3.733)\n",
      "Epoch: [641][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.093 (3.787)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.924\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.335\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.135\tL1 1.394\tG-Mean 1.336\n",
      " * Low: MSE 0.093\tL1 0.218\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #641: Train loss [3.7840]; Val loss: MSE [1.9239], L1 [0.6003], G-Mean [0.2597]\n",
      "Epoch: [642][ 0/65]\tTime   0.55 (  0.55)\tData 0.5462 (0.5462)\tLoss (MSE) 3.551 (3.551)\n",
      "Epoch: [642][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0558)\tLoss (MSE) 3.506 (4.242)\n",
      "Epoch: [642][20/65]\tTime   0.01 (  0.04)\tData 0.0001 (0.0293)\tLoss (MSE) 4.585 (4.117)\n",
      "Epoch: [642][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0198)\tLoss (MSE) 5.089 (3.922)\n",
      "Epoch: [642][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.395 (3.916)\n",
      "Epoch: [642][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.250 (3.856)\n",
      "Epoch: [642][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.046 (3.756)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.926\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.157\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.226\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #642: Train loss [3.7576]; Val loss: MSE [1.9262], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [643][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 2.569 (2.569)\n",
      "Epoch: [643][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 3.906 (4.089)\n",
      "Epoch: [643][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 5.459 (4.058)\n",
      "Epoch: [643][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.416 (3.943)\n",
      "Epoch: [643][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.186 (3.772)\n",
      "Epoch: [643][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.134 (3.698)\n",
      "Epoch: [643][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.753 (3.794)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.326\tL1 1.019\tG-Mean 0.871\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #643: Train loss [3.7933]; Val loss: MSE [1.9255], L1 [0.5989], G-Mean [0.2604]\n",
      "Epoch: [644][ 0/65]\tTime   0.57 (  0.57)\tData 0.5601 (0.5601)\tLoss (MSE) 6.731 (6.731)\n",
      "Epoch: [644][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 2.714 (4.112)\n",
      "Epoch: [644][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 3.635 (4.101)\n",
      "Epoch: [644][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 4.547 (3.988)\n",
      "Epoch: [644][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 2.674 (3.786)\n",
      "Epoch: [644][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 1.880 (3.784)\n",
      "Epoch: [644][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.496 (3.739)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.326\tL1 1.019\tG-Mean 0.871\n",
      " * Median: MSE 2.154\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #644: Train loss [3.7888]; Val loss: MSE [1.9251], L1 [0.5988], G-Mean [0.2602]\n",
      "Epoch: [645][ 0/65]\tTime   0.63 (  0.63)\tData 0.6130 (0.6130)\tLoss (MSE) 2.574 (2.574)\n",
      "Epoch: [645][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 6.428 (4.177)\n",
      "Epoch: [645][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 6.289 (4.161)\n",
      "Epoch: [645][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 2.462 (3.725)\n",
      "Epoch: [645][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 6.904 (3.839)\n",
      "Epoch: [645][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.232 (3.691)\n",
      "Epoch: [645][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.675 (3.771)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.135\tL1 1.394\tG-Mean 1.336\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.197\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #645: Train loss [3.8027]; Val loss: MSE [1.9220], L1 [0.6001], G-Mean [0.2599]\n",
      "Epoch: [646][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 3.537 (3.537)\n",
      "Epoch: [646][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 2.238 (3.555)\n",
      "Epoch: [646][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 2.213 (3.548)\n",
      "Epoch: [646][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.252 (3.735)\n",
      "Epoch: [646][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.623 (3.752)\n",
      "Epoch: [646][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.296 (3.773)\n",
      "Epoch: [646][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.412 (3.822)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.923\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.328\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.146\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #646: Train loss [3.7697]; Val loss: MSE [1.9234], L1 [0.5993], G-Mean [0.2608]\n",
      "Epoch: [647][ 0/65]\tTime   0.57 (  0.57)\tData 0.5593 (0.5593)\tLoss (MSE) 2.626 (2.626)\n",
      "Epoch: [647][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0586)\tLoss (MSE) 6.995 (4.263)\n",
      "Epoch: [647][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0307)\tLoss (MSE) 3.408 (3.826)\n",
      "Epoch: [647][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 1.952 (3.749)\n",
      "Epoch: [647][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.681 (3.790)\n",
      "Epoch: [647][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.104 (3.721)\n",
      "Epoch: [647][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.463 (3.809)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.338\tL1 1.030\tG-Mean 0.883\n",
      " * Median: MSE 2.121\tL1 1.389\tG-Mean 1.331\n",
      " * Low: MSE 0.090\tL1 0.212\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #647: Train loss [3.8275]; Val loss: MSE [1.9197], L1 [0.6012], G-Mean [0.2602]\n",
      "Epoch: [648][ 0/65]\tTime   0.57 (  0.57)\tData 0.5580 (0.5580)\tLoss (MSE) 1.950 (1.950)\n",
      "Epoch: [648][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 3.658 (3.769)\n",
      "Epoch: [648][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.858 (3.544)\n",
      "Epoch: [648][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.383 (3.679)\n",
      "Epoch: [648][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.811 (3.723)\n",
      "Epoch: [648][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.842 (3.757)\n",
      "Epoch: [648][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.459 (3.699)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.641 (0.641)\n",
      " * Overall: MSE 1.925\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.315\tL1 1.012\tG-Mean 0.864\n",
      " * Median: MSE 2.174\tL1 1.409\tG-Mean 1.351\n",
      " * Low: MSE 0.096\tL1 0.230\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #648: Train loss [3.7728]; Val loss: MSE [1.9253], L1 [0.5972], G-Mean [0.2614]\n",
      "Epoch: [649][ 0/65]\tTime   0.57 (  0.57)\tData 0.5626 (0.5626)\tLoss (MSE) 5.050 (5.050)\n",
      "Epoch: [649][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 2.975 (3.731)\n",
      "Epoch: [649][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 9.101 (4.376)\n",
      "Epoch: [649][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 2.297 (3.970)\n",
      "Epoch: [649][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.721 (3.932)\n",
      "Epoch: [649][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.381 (3.853)\n",
      "Epoch: [649][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.850 (3.777)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.326\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #649: Train loss [3.8167]; Val loss: MSE [1.9222], L1 [0.5991], G-Mean [0.2609]\n",
      "Epoch: [650][ 0/65]\tTime   0.58 (  0.58)\tData 0.5704 (0.5704)\tLoss (MSE) 7.074 (7.074)\n",
      "Epoch: [650][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0588)\tLoss (MSE) 3.610 (3.604)\n",
      "Epoch: [650][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 7.408 (3.773)\n",
      "Epoch: [650][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 2.766 (3.771)\n",
      "Epoch: [650][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.465 (3.845)\n",
      "Epoch: [650][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.235 (3.939)\n",
      "Epoch: [650][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.717 (3.936)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.017\tG-Mean 0.869\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.346\n",
      " * Low: MSE 0.094\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #650: Train loss [3.8443]; Val loss: MSE [1.9233], L1 [0.5981], G-Mean [0.2605]\n",
      "Epoch: [651][ 0/65]\tTime   0.55 (  0.55)\tData 0.5465 (0.5465)\tLoss (MSE) 2.517 (2.517)\n",
      "Epoch: [651][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0572)\tLoss (MSE) 4.750 (4.559)\n",
      "Epoch: [651][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 6.251 (3.888)\n",
      "Epoch: [651][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 2.228 (3.778)\n",
      "Epoch: [651][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 5.336 (3.738)\n",
      "Epoch: [651][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.342 (3.852)\n",
      "Epoch: [651][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.143 (3.831)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.925\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.316\tL1 1.013\tG-Mean 0.865\n",
      " * Median: MSE 2.171\tL1 1.407\tG-Mean 1.350\n",
      " * Low: MSE 0.095\tL1 0.229\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #651: Train loss [3.8219]; Val loss: MSE [1.9246], L1 [0.5974], G-Mean [0.2613]\n",
      "Epoch: [652][ 0/65]\tTime   0.56 (  0.56)\tData 0.5562 (0.5562)\tLoss (MSE) 4.846 (4.846)\n",
      "Epoch: [652][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 2.960 (3.403)\n",
      "Epoch: [652][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.540 (3.637)\n",
      "Epoch: [652][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.112 (3.636)\n",
      "Epoch: [652][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.000 (3.618)\n",
      "Epoch: [652][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.416 (3.667)\n",
      "Epoch: [652][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.804 (3.748)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.092\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #652: Train loss [3.8235]; Val loss: MSE [1.9209], L1 [0.5987], G-Mean [0.2599]\n",
      "Epoch: [653][ 0/65]\tTime   0.57 (  0.57)\tData 0.5617 (0.5617)\tLoss (MSE) 2.770 (2.770)\n",
      "Epoch: [653][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 2.343 (3.852)\n",
      "Epoch: [653][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 4.268 (4.091)\n",
      "Epoch: [653][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.363 (3.998)\n",
      "Epoch: [653][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.469 (3.978)\n",
      "Epoch: [653][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.738 (3.879)\n",
      "Epoch: [653][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.333 (3.817)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.924\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.311\tL1 1.011\tG-Mean 0.863\n",
      " * Median: MSE 2.178\tL1 1.410\tG-Mean 1.353\n",
      " * Low: MSE 0.095\tL1 0.231\tG-Mean 0.212\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #653: Train loss [3.7916]; Val loss: MSE [1.9243], L1 [0.5968], G-Mean [0.2620]\n",
      "Epoch: [654][ 0/65]\tTime   0.56 (  0.56)\tData 0.5501 (0.5501)\tLoss (MSE) 7.510 (7.510)\n",
      "Epoch: [654][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0575)\tLoss (MSE) 4.266 (3.784)\n",
      "Epoch: [654][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0301)\tLoss (MSE) 3.615 (3.632)\n",
      "Epoch: [654][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 2.328 (3.539)\n",
      "Epoch: [654][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.730 (3.768)\n",
      "Epoch: [654][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.195 (3.799)\n",
      "Epoch: [654][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.562 (3.783)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.091\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #654: Train loss [3.8231]; Val loss: MSE [1.9205], L1 [0.5983], G-Mean [0.2598]\n",
      "Epoch: [655][ 0/65]\tTime   0.65 (  0.65)\tData 0.6370 (0.6370)\tLoss (MSE) 8.680 (8.680)\n",
      "Epoch: [655][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0583)\tLoss (MSE) 4.213 (3.893)\n",
      "Epoch: [655][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.852 (3.648)\n",
      "Epoch: [655][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 3.947 (3.644)\n",
      "Epoch: [655][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.487 (3.756)\n",
      "Epoch: [655][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.683 (3.784)\n",
      "Epoch: [655][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.468 (3.771)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.091\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #655: Train loss [3.8055]; Val loss: MSE [1.9204], L1 [0.5987], G-Mean [0.2600]\n",
      "Epoch: [656][ 0/65]\tTime   0.57 (  0.57)\tData 0.5604 (0.5604)\tLoss (MSE) 3.741 (3.741)\n",
      "Epoch: [656][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 2.900 (3.722)\n",
      "Epoch: [656][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 4.766 (3.928)\n",
      "Epoch: [656][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 6.156 (3.850)\n",
      "Epoch: [656][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.814 (3.837)\n",
      "Epoch: [656][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.470 (3.838)\n",
      "Epoch: [656][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.005 (3.844)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.332\tL1 1.028\tG-Mean 0.882\n",
      " * Median: MSE 2.127\tL1 1.392\tG-Mean 1.334\n",
      " * Low: MSE 0.088\tL1 0.213\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #656: Train loss [3.7779]; Val loss: MSE [1.9174], L1 [0.6004], G-Mean [0.2607]\n",
      "Epoch: [657][ 0/65]\tTime   0.62 (  0.62)\tData 0.6042 (0.6042)\tLoss (MSE) 2.144 (2.144)\n",
      "Epoch: [657][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 4.178 (3.558)\n",
      "Epoch: [657][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 3.889 (3.677)\n",
      "Epoch: [657][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.764 (3.701)\n",
      "Epoch: [657][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.893 (3.569)\n",
      "Epoch: [657][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 6.963 (3.684)\n",
      "Epoch: [657][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.911 (3.794)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.328\tL1 1.025\tG-Mean 0.878\n",
      " * Median: MSE 2.135\tL1 1.395\tG-Mean 1.337\n",
      " * Low: MSE 0.090\tL1 0.216\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #657: Train loss [3.7990]; Val loss: MSE [1.9182], L1 [0.5997], G-Mean [0.2589]\n",
      "Epoch: [658][ 0/65]\tTime   0.56 (  0.56)\tData 0.5531 (0.5531)\tLoss (MSE) 6.308 (6.308)\n",
      "Epoch: [658][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0530)\tLoss (MSE) 3.299 (4.450)\n",
      "Epoch: [658][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 4.914 (4.090)\n",
      "Epoch: [658][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 7.385 (4.099)\n",
      "Epoch: [658][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.924 (3.992)\n",
      "Epoch: [658][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.701 (3.826)\n",
      "Epoch: [658][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.386 (3.812)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.916\tL1 0.601\tG-Mean 0.262\n",
      " * Many: MSE 2.336\tL1 1.031\tG-Mean 0.885\n",
      " * Median: MSE 2.117\tL1 1.388\tG-Mean 1.331\n",
      " * Low: MSE 0.088\tL1 0.210\tG-Mean 0.189\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #658: Train loss [3.8155]; Val loss: MSE [1.9160], L1 [0.6012], G-Mean [0.2618]\n",
      "Epoch: [659][ 0/65]\tTime   0.57 (  0.57)\tData 0.5592 (0.5592)\tLoss (MSE) 6.474 (6.474)\n",
      "Epoch: [659][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 1.831 (3.910)\n",
      "Epoch: [659][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.820 (4.048)\n",
      "Epoch: [659][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 6.061 (3.949)\n",
      "Epoch: [659][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.978 (3.830)\n",
      "Epoch: [659][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.395 (3.805)\n",
      "Epoch: [659][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.474 (3.807)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.092\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #659: Train loss [3.8741]; Val loss: MSE [1.9177], L1 [0.5990], G-Mean [0.2604]\n",
      "Epoch: [660][ 0/65]\tTime   0.56 (  0.56)\tData 0.5564 (0.5564)\tLoss (MSE) 5.235 (5.235)\n",
      "Epoch: [660][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0540)\tLoss (MSE) 3.692 (3.753)\n",
      "Epoch: [660][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 2.581 (3.518)\n",
      "Epoch: [660][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 3.379 (3.643)\n",
      "Epoch: [660][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 2.307 (3.730)\n",
      "Epoch: [660][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.090 (3.770)\n",
      "Epoch: [660][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.609 (3.757)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #660: Train loss [3.7789]; Val loss: MSE [1.9187], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [661][ 0/65]\tTime   0.55 (  0.55)\tData 0.5487 (0.5487)\tLoss (MSE) 4.264 (4.264)\n",
      "Epoch: [661][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0591)\tLoss (MSE) 3.499 (4.089)\n",
      "Epoch: [661][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 4.680 (3.865)\n",
      "Epoch: [661][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 4.132 (4.060)\n",
      "Epoch: [661][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.531 (3.884)\n",
      "Epoch: [661][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.926 (3.917)\n",
      "Epoch: [661][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.590 (3.857)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.309\tL1 1.011\tG-Mean 0.864\n",
      " * Median: MSE 2.176\tL1 1.410\tG-Mean 1.353\n",
      " * Low: MSE 0.096\tL1 0.230\tG-Mean 0.210\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #661: Train loss [3.9170]; Val loss: MSE [1.9213], L1 [0.5967], G-Mean [0.2615]\n",
      "Epoch: [662][ 0/65]\tTime   0.56 (  0.56)\tData 0.5566 (0.5566)\tLoss (MSE) 6.623 (6.623)\n",
      "Epoch: [662][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 2.333 (3.999)\n",
      "Epoch: [662][20/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.856 (3.725)\n",
      "Epoch: [662][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.513 (3.722)\n",
      "Epoch: [662][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.641 (3.788)\n",
      "Epoch: [662][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.315 (3.742)\n",
      "Epoch: [662][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.573 (3.792)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.310\tL1 1.012\tG-Mean 0.864\n",
      " * Median: MSE 2.174\tL1 1.409\tG-Mean 1.352\n",
      " * Low: MSE 0.095\tL1 0.229\tG-Mean 0.209\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #662: Train loss [3.7482]; Val loss: MSE [1.9208], L1 [0.5968], G-Mean [0.2615]\n",
      "Epoch: [663][ 0/65]\tTime   0.56 (  0.56)\tData 0.5483 (0.5483)\tLoss (MSE) 7.445 (7.445)\n",
      "Epoch: [663][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0510)\tLoss (MSE) 2.717 (3.952)\n",
      "Epoch: [663][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.658 (3.955)\n",
      "Epoch: [663][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.597 (3.785)\n",
      "Epoch: [663][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.843 (3.705)\n",
      "Epoch: [663][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.713 (3.862)\n",
      "Epoch: [663][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.643 (3.891)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.092\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #663: Train loss [3.8802]; Val loss: MSE [1.9176], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [664][ 0/65]\tTime   0.56 (  0.56)\tData 0.5598 (0.5598)\tLoss (MSE) 3.287 (3.287)\n",
      "Epoch: [664][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0617)\tLoss (MSE) 4.058 (3.852)\n",
      "Epoch: [664][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0323)\tLoss (MSE) 4.773 (3.717)\n",
      "Epoch: [664][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0219)\tLoss (MSE) 2.704 (3.789)\n",
      "Epoch: [664][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0166)\tLoss (MSE) 3.704 (3.657)\n",
      "Epoch: [664][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 3.564 (3.563)\n",
      "Epoch: [664][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.959 (3.725)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.915\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.123\tL1 1.391\tG-Mean 1.333\n",
      " * Low: MSE 0.089\tL1 0.212\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #664: Train loss [3.7829]; Val loss: MSE [1.9150], L1 [0.6006], G-Mean [0.2602]\n",
      "Epoch: [665][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 3.561 (3.561)\n",
      "Epoch: [665][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 8.335 (3.885)\n",
      "Epoch: [665][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 2.560 (3.952)\n",
      "Epoch: [665][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.119 (3.725)\n",
      "Epoch: [665][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.166 (3.660)\n",
      "Epoch: [665][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 1.680 (3.628)\n",
      "Epoch: [665][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.580 (3.808)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.319\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #665: Train loss [3.7945]; Val loss: MSE [1.9172], L1 [0.5984], G-Mean [0.2610]\n",
      "Epoch: [666][ 0/65]\tTime   0.61 (  0.61)\tData 0.5959 (0.5959)\tLoss (MSE) 4.525 (4.525)\n",
      "Epoch: [666][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 4.218 (3.454)\n",
      "Epoch: [666][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.127 (3.389)\n",
      "Epoch: [666][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.124 (3.769)\n",
      "Epoch: [666][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 2.946 (3.943)\n",
      "Epoch: [666][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.594 (3.836)\n",
      "Epoch: [666][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.809 (3.852)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.092\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #666: Train loss [3.8342]; Val loss: MSE [1.9179], L1 [0.5987], G-Mean [0.2613]\n",
      "Epoch: [667][ 0/65]\tTime   0.57 (  0.57)\tData 0.5614 (0.5614)\tLoss (MSE) 2.773 (2.773)\n",
      "Epoch: [667][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0530)\tLoss (MSE) 2.751 (3.369)\n",
      "Epoch: [667][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.578 (4.118)\n",
      "Epoch: [667][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.899 (3.911)\n",
      "Epoch: [667][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.898 (3.982)\n",
      "Epoch: [667][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.000 (4.057)\n",
      "Epoch: [667][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.873 (3.940)\n",
      "Val: [0/9]\tTime  0.577 ( 0.577)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.310\tL1 1.013\tG-Mean 0.866\n",
      " * Median: MSE 2.169\tL1 1.407\tG-Mean 1.351\n",
      " * Low: MSE 0.094\tL1 0.227\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #667: Train loss [3.8594]; Val loss: MSE [1.9193], L1 [0.5971], G-Mean [0.2613]\n",
      "Epoch: [668][ 0/65]\tTime   0.69 (  0.69)\tData 0.6845 (0.6845)\tLoss (MSE) 3.631 (3.631)\n",
      "Epoch: [668][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0698)\tLoss (MSE) 3.349 (3.977)\n",
      "Epoch: [668][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0366)\tLoss (MSE) 4.951 (4.169)\n",
      "Epoch: [668][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0248)\tLoss (MSE) 2.976 (3.934)\n",
      "Epoch: [668][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.710 (3.877)\n",
      "Epoch: [668][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 1.948 (3.795)\n",
      "Epoch: [668][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.915 (3.807)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.918\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.316\tL1 1.017\tG-Mean 0.871\n",
      " * Median: MSE 2.157\tL1 1.403\tG-Mean 1.346\n",
      " * Low: MSE 0.092\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #668: Train loss [3.7855]; Val loss: MSE [1.9179], L1 [0.5978], G-Mean [0.2601]\n",
      "Epoch: [669][ 0/65]\tTime   0.55 (  0.55)\tData 0.5458 (0.5458)\tLoss (MSE) 5.528 (5.528)\n",
      "Epoch: [669][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 3.705 (4.132)\n",
      "Epoch: [669][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0295)\tLoss (MSE) 5.189 (3.945)\n",
      "Epoch: [669][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.107 (3.969)\n",
      "Epoch: [669][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.844 (3.803)\n",
      "Epoch: [669][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.371 (3.829)\n",
      "Epoch: [669][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.015 (3.839)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.090\tL1 0.218\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #669: Train loss [3.7936]; Val loss: MSE [1.9168], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [670][ 0/65]\tTime   0.56 (  0.56)\tData 0.5581 (0.5581)\tLoss (MSE) 2.568 (2.568)\n",
      "Epoch: [670][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 3.388 (3.883)\n",
      "Epoch: [670][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 6.912 (3.717)\n",
      "Epoch: [670][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 3.400 (3.739)\n",
      "Epoch: [670][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 4.623 (3.637)\n",
      "Epoch: [670][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.000 (3.671)\n",
      "Epoch: [670][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.049 (3.717)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.917\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.318\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.091\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #670: Train loss [3.7567]; Val loss: MSE [1.9173], L1 [0.5983], G-Mean [0.2608]\n",
      "Epoch: [671][ 0/65]\tTime   0.55 (  0.55)\tData 0.5483 (0.5483)\tLoss (MSE) 2.187 (2.187)\n",
      "Epoch: [671][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0580)\tLoss (MSE) 5.718 (3.741)\n",
      "Epoch: [671][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 1.573 (3.944)\n",
      "Epoch: [671][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 4.529 (3.901)\n",
      "Epoch: [671][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.475 (3.826)\n",
      "Epoch: [671][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.358 (3.841)\n",
      "Epoch: [671][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.335 (3.733)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.918\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.311\tL1 1.014\tG-Mean 0.867\n",
      " * Median: MSE 2.167\tL1 1.407\tG-Mean 1.350\n",
      " * Low: MSE 0.093\tL1 0.226\tG-Mean 0.206\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #671: Train loss [3.7528]; Val loss: MSE [1.9182], L1 [0.5971], G-Mean [0.2609]\n",
      "Epoch: [672][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 5.390 (5.390)\n",
      "Epoch: [672][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 3.422 (4.196)\n",
      "Epoch: [672][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 3.491 (3.999)\n",
      "Epoch: [672][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.902 (3.908)\n",
      "Epoch: [672][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.472 (3.785)\n",
      "Epoch: [672][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.906 (3.794)\n",
      "Epoch: [672][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.892 (3.902)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.915\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.136\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.090\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #672: Train loss [3.8327]; Val loss: MSE [1.9152], L1 [0.5994], G-Mean [0.2596]\n",
      "Epoch: [673][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 3.963 (3.963)\n",
      "Epoch: [673][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 2.726 (3.874)\n",
      "Epoch: [673][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 4.349 (3.913)\n",
      "Epoch: [673][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.489 (3.746)\n",
      "Epoch: [673][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.219 (3.744)\n",
      "Epoch: [673][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.558 (3.643)\n",
      "Epoch: [673][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.416 (3.736)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.042 (2.042)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.916\tL1 0.600\tG-Mean 0.261\n",
      " * Many: MSE 2.330\tL1 1.027\tG-Mean 0.882\n",
      " * Median: MSE 2.127\tL1 1.392\tG-Mean 1.334\n",
      " * Low: MSE 0.090\tL1 0.213\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #673: Train loss [3.7721]; Val loss: MSE [1.9158], L1 [0.6003], G-Mean [0.2609]\n",
      "Epoch: [674][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 2.353 (2.353)\n",
      "Epoch: [674][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 3.515 (3.398)\n",
      "Epoch: [674][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.587 (3.411)\n",
      "Epoch: [674][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.351 (3.634)\n",
      "Epoch: [674][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.078 (3.710)\n",
      "Epoch: [674][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.282 (3.712)\n",
      "Epoch: [674][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.084 (3.840)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.138\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #674: Train loss [3.8215]; Val loss: MSE [1.9171], L1 [0.5994], G-Mean [0.2600]\n",
      "Epoch: [675][ 0/65]\tTime   0.56 (  0.56)\tData 0.5485 (0.5485)\tLoss (MSE) 2.320 (2.320)\n",
      "Epoch: [675][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0512)\tLoss (MSE) 3.635 (3.492)\n",
      "Epoch: [675][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.873 (3.759)\n",
      "Epoch: [675][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.881 (3.995)\n",
      "Epoch: [675][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.726 (4.062)\n",
      "Epoch: [675][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.195 (3.875)\n",
      "Epoch: [675][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.435 (3.860)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.093\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #675: Train loss [3.8698]; Val loss: MSE [1.9186], L1 [0.5985], G-Mean [0.2610]\n",
      "Epoch: [676][ 0/65]\tTime   0.57 (  0.57)\tData 0.5674 (0.5674)\tLoss (MSE) 2.873 (2.873)\n",
      "Epoch: [676][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0600)\tLoss (MSE) 3.208 (3.763)\n",
      "Epoch: [676][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 3.461 (3.867)\n",
      "Epoch: [676][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 2.702 (4.105)\n",
      "Epoch: [676][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 4.504 (3.926)\n",
      "Epoch: [676][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 2.812 (3.771)\n",
      "Epoch: [676][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 7.297 (3.770)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.043 (2.043)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.328\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.132\tL1 1.394\tG-Mean 1.336\n",
      " * Low: MSE 0.092\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #676: Train loss [3.8285]; Val loss: MSE [1.9166], L1 [0.5999], G-Mean [0.2599]\n",
      "Epoch: [677][ 0/65]\tTime   0.63 (  0.63)\tData 0.6091 (0.6091)\tLoss (MSE) 3.304 (3.304)\n",
      "Epoch: [677][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0586)\tLoss (MSE) 5.225 (4.162)\n",
      "Epoch: [677][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 1.871 (4.056)\n",
      "Epoch: [677][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 3.920 (3.987)\n",
      "Epoch: [677][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.891 (3.916)\n",
      "Epoch: [677][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 3.280 (3.793)\n",
      "Epoch: [677][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.253 (3.732)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.326\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.136\tL1 1.395\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #677: Train loss [3.7983]; Val loss: MSE [1.9173], L1 [0.5996], G-Mean [0.2602]\n",
      "Epoch: [678][ 0/65]\tTime   0.57 (  0.57)\tData 0.5616 (0.5616)\tLoss (MSE) 4.114 (4.114)\n",
      "Epoch: [678][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0551)\tLoss (MSE) 4.893 (4.517)\n",
      "Epoch: [678][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.254 (3.932)\n",
      "Epoch: [678][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.801 (3.651)\n",
      "Epoch: [678][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.514 (3.718)\n",
      "Epoch: [678][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 3.616 (3.705)\n",
      "Epoch: [678][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.000 (3.736)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #678: Train loss [3.7232]; Val loss: MSE [1.9187], L1 [0.5986], G-Mean [0.2615]\n",
      "Epoch: [679][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 4.482 (4.482)\n",
      "Epoch: [679][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0570)\tLoss (MSE) 2.194 (3.397)\n",
      "Epoch: [679][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.499 (3.874)\n",
      "Epoch: [679][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 5.035 (4.063)\n",
      "Epoch: [679][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.192 (3.880)\n",
      "Epoch: [679][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.140 (3.802)\n",
      "Epoch: [679][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.619 (3.863)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #679: Train loss [3.8377]; Val loss: MSE [1.9189], L1 [0.5985], G-Mean [0.2611]\n",
      "Epoch: [680][ 0/65]\tTime   0.56 (  0.56)\tData 0.5556 (0.5556)\tLoss (MSE) 2.470 (2.470)\n",
      "Epoch: [680][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 6.633 (4.206)\n",
      "Epoch: [680][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.845 (3.938)\n",
      "Epoch: [680][30/65]\tTime   0.00 (  0.02)\tData 0.0001 (0.0183)\tLoss (MSE) 3.127 (3.988)\n",
      "Epoch: [680][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.522 (3.890)\n",
      "Epoch: [680][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.287 (3.911)\n",
      "Epoch: [680][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.489 (3.930)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.018\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #680: Train loss [3.9431]; Val loss: MSE [1.9189], L1 [0.5981], G-Mean [0.2597]\n",
      "Epoch: [681][ 0/65]\tTime   0.63 (  0.63)\tData 0.6119 (0.6119)\tLoss (MSE) 4.726 (4.726)\n",
      "Epoch: [681][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0596)\tLoss (MSE) 5.058 (4.420)\n",
      "Epoch: [681][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 2.756 (4.241)\n",
      "Epoch: [681][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 2.968 (4.065)\n",
      "Epoch: [681][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 2.752 (3.938)\n",
      "Epoch: [681][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.879 (3.886)\n",
      "Epoch: [681][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0108)\tLoss (MSE) 3.256 (3.834)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #681: Train loss [3.8078]; Val loss: MSE [1.9183], L1 [0.5984], G-Mean [0.2612]\n",
      "Epoch: [682][ 0/65]\tTime   0.70 (  0.70)\tData 0.6912 (0.6912)\tLoss (MSE) 3.342 (3.342)\n",
      "Epoch: [682][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0644)\tLoss (MSE) 2.243 (3.820)\n",
      "Epoch: [682][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0337)\tLoss (MSE) 4.062 (3.725)\n",
      "Epoch: [682][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0229)\tLoss (MSE) 4.760 (3.629)\n",
      "Epoch: [682][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0173)\tLoss (MSE) 3.737 (3.672)\n",
      "Epoch: [682][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.884 (3.781)\n",
      "Epoch: [682][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.534 (3.837)\n",
      "Val: [0/9]\tTime  0.597 ( 0.597)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.916\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.329\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.129\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.089\tL1 0.213\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #682: Train loss [3.8002]; Val loss: MSE [1.9157], L1 [0.5999], G-Mean [0.2603]\n",
      "Epoch: [683][ 0/65]\tTime   0.56 (  0.56)\tData 0.5561 (0.5561)\tLoss (MSE) 5.343 (5.343)\n",
      "Epoch: [683][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 4.833 (3.710)\n",
      "Epoch: [683][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 3.924 (3.867)\n",
      "Epoch: [683][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.773 (3.747)\n",
      "Epoch: [683][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.683 (3.919)\n",
      "Epoch: [683][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.409 (3.772)\n",
      "Epoch: [683][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.997 (3.915)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.918\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.018\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.092\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #683: Train loss [3.9027]; Val loss: MSE [1.9183], L1 [0.5980], G-Mean [0.2599]\n",
      "Epoch: [684][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 2.259 (2.259)\n",
      "Epoch: [684][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 3.544 (4.232)\n",
      "Epoch: [684][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.248 (4.114)\n",
      "Epoch: [684][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 6.057 (3.965)\n",
      "Epoch: [684][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.255 (3.904)\n",
      "Epoch: [684][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.466 (3.894)\n",
      "Epoch: [684][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.340 (3.805)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.317\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.158\tL1 1.403\tG-Mean 1.346\n",
      " * Low: MSE 0.093\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #684: Train loss [3.7965]; Val loss: MSE [1.9194], L1 [0.5978], G-Mean [0.2601]\n",
      "Epoch: [685][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 3.269 (3.269)\n",
      "Epoch: [685][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0590)\tLoss (MSE) 2.276 (3.795)\n",
      "Epoch: [685][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0309)\tLoss (MSE) 2.628 (3.897)\n",
      "Epoch: [685][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 3.453 (3.842)\n",
      "Epoch: [685][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 2.228 (3.873)\n",
      "Epoch: [685][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.722 (3.777)\n",
      "Epoch: [685][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.972 (3.774)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.047 (2.047)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.092\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #685: Train loss [3.7303]; Val loss: MSE [1.9188], L1 [0.5985], G-Mean [0.2611]\n",
      "Epoch: [686][ 0/65]\tTime   0.55 (  0.55)\tData 0.5472 (0.5472)\tLoss (MSE) 2.849 (2.849)\n",
      "Epoch: [686][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0595)\tLoss (MSE) 3.380 (3.554)\n",
      "Epoch: [686][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 3.303 (3.827)\n",
      "Epoch: [686][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 2.364 (3.708)\n",
      "Epoch: [686][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.735 (3.920)\n",
      "Epoch: [686][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.683 (3.850)\n",
      "Epoch: [686][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.732 (3.860)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.317\tL1 1.016\tG-Mean 0.869\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.346\n",
      " * Low: MSE 0.094\tL1 0.225\tG-Mean 0.205\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #686: Train loss [3.8159]; Val loss: MSE [1.9205], L1 [0.5978], G-Mean [0.2596]\n",
      "Epoch: [687][ 0/65]\tTime   0.57 (  0.57)\tData 0.5599 (0.5599)\tLoss (MSE) 3.343 (3.343)\n",
      "Epoch: [687][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0564)\tLoss (MSE) 5.130 (3.776)\n",
      "Epoch: [687][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0296)\tLoss (MSE) 2.037 (3.634)\n",
      "Epoch: [687][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 7.880 (3.812)\n",
      "Epoch: [687][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.906 (3.714)\n",
      "Epoch: [687][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.645 (3.716)\n",
      "Epoch: [687][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.511 (3.857)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.330\tL1 1.027\tG-Mean 0.881\n",
      " * Median: MSE 2.130\tL1 1.393\tG-Mean 1.335\n",
      " * Low: MSE 0.091\tL1 0.214\tG-Mean 0.193\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #687: Train loss [3.8451]; Val loss: MSE [1.9174], L1 [0.6001], G-Mean [0.2600]\n",
      "Epoch: [688][ 0/65]\tTime   0.57 (  0.57)\tData 0.5635 (0.5635)\tLoss (MSE) 4.707 (4.707)\n",
      "Epoch: [688][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 4.064 (4.132)\n",
      "Epoch: [688][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 3.713 (3.773)\n",
      "Epoch: [688][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.922 (3.743)\n",
      "Epoch: [688][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.341 (3.690)\n",
      "Epoch: [688][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 7.861 (3.849)\n",
      "Epoch: [688][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.660 (3.781)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.923\tL1 0.597\tG-Mean 0.262\n",
      " * Many: MSE 2.310\tL1 1.011\tG-Mean 0.863\n",
      " * Median: MSE 2.177\tL1 1.410\tG-Mean 1.353\n",
      " * Low: MSE 0.097\tL1 0.231\tG-Mean 0.211\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #688: Train loss [3.7519]; Val loss: MSE [1.9225], L1 [0.5967], G-Mean [0.2618]\n",
      "Epoch: [689][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 4.162 (4.162)\n",
      "Epoch: [689][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 4.610 (4.129)\n",
      "Epoch: [689][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 6.046 (4.180)\n",
      "Epoch: [689][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.300 (3.959)\n",
      "Epoch: [689][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.408 (3.886)\n",
      "Epoch: [689][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.968 (3.879)\n",
      "Epoch: [689][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.687 (3.869)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.049 (2.049)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.093\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #689: Train loss [3.8339]; Val loss: MSE [1.9194], L1 [0.5984], G-Mean [0.2592]\n",
      "Epoch: [690][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 2.354 (2.354)\n",
      "Epoch: [690][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0539)\tLoss (MSE) 2.534 (3.405)\n",
      "Epoch: [690][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.905 (3.363)\n",
      "Epoch: [690][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 5.239 (3.597)\n",
      "Epoch: [690][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 4.953 (3.670)\n",
      "Epoch: [690][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.129 (3.649)\n",
      "Epoch: [690][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.106 (3.755)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.046 (2.046)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.918\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.327\tL1 1.024\tG-Mean 0.878\n",
      " * Median: MSE 2.137\tL1 1.396\tG-Mean 1.338\n",
      " * Low: MSE 0.092\tL1 0.217\tG-Mean 0.196\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #690: Train loss [3.7984]; Val loss: MSE [1.9180], L1 [0.5996], G-Mean [0.2600]\n",
      "Epoch: [691][ 0/65]\tTime   0.56 (  0.56)\tData 0.5530 (0.5530)\tLoss (MSE) 3.756 (3.756)\n",
      "Epoch: [691][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 4.585 (3.590)\n",
      "Epoch: [691][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 1.682 (3.685)\n",
      "Epoch: [691][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 4.787 (3.788)\n",
      "Epoch: [691][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.172 (3.738)\n",
      "Epoch: [691][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.331 (3.676)\n",
      "Epoch: [691][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.858 (3.816)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.601\tG-Mean 0.260\n",
      " * Many: MSE 2.333\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.123\tL1 1.391\tG-Mean 1.333\n",
      " * Low: MSE 0.091\tL1 0.212\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #691: Train loss [3.8012]; Val loss: MSE [1.9165], L1 [0.6007], G-Mean [0.2605]\n",
      "Epoch: [692][ 0/65]\tTime   0.74 (  0.74)\tData 0.7191 (0.7191)\tLoss (MSE) 2.973 (2.973)\n",
      "Epoch: [692][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0667)\tLoss (MSE) 3.952 (3.902)\n",
      "Epoch: [692][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0350)\tLoss (MSE) 4.463 (3.604)\n",
      "Epoch: [692][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0237)\tLoss (MSE) 5.284 (3.757)\n",
      "Epoch: [692][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0179)\tLoss (MSE) 1.917 (3.639)\n",
      "Epoch: [692][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 5.357 (3.621)\n",
      "Epoch: [692][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 7.764 (3.789)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.045 (2.045)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.917\tL1 0.600\tG-Mean 0.259\n",
      " * Many: MSE 2.328\tL1 1.026\tG-Mean 0.880\n",
      " * Median: MSE 2.133\tL1 1.394\tG-Mean 1.337\n",
      " * Low: MSE 0.091\tL1 0.215\tG-Mean 0.194\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #692: Train loss [3.8079]; Val loss: MSE [1.9171], L1 [0.5999], G-Mean [0.2588]\n",
      "Epoch: [693][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 2.260 (2.260)\n",
      "Epoch: [693][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 2.057 (3.136)\n",
      "Epoch: [693][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 2.379 (3.223)\n",
      "Epoch: [693][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.823 (3.548)\n",
      "Epoch: [693][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 4.756 (3.754)\n",
      "Epoch: [693][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.994 (3.804)\n",
      "Epoch: [693][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.706 (3.877)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.044 (2.044)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.916\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.331\tL1 1.028\tG-Mean 0.883\n",
      " * Median: MSE 2.126\tL1 1.392\tG-Mean 1.334\n",
      " * Low: MSE 0.090\tL1 0.212\tG-Mean 0.192\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #693: Train loss [3.8507]; Val loss: MSE [1.9160], L1 [0.6004], G-Mean [0.2597]\n",
      "Epoch: [694][ 0/65]\tTime   0.62 (  0.62)\tData 0.6028 (0.6028)\tLoss (MSE) 4.438 (4.438)\n",
      "Epoch: [694][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0583)\tLoss (MSE) 4.599 (3.961)\n",
      "Epoch: [694][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.997 (4.117)\n",
      "Epoch: [694][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 4.343 (3.827)\n",
      "Epoch: [694][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.489 (3.928)\n",
      "Epoch: [694][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.225 (3.854)\n",
      "Epoch: [694][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.866 (3.835)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.317\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.160\tL1 1.404\tG-Mean 1.347\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #694: Train loss [3.8581]; Val loss: MSE [1.9201], L1 [0.5978], G-Mean [0.2588]\n",
      "Epoch: [695][ 0/65]\tTime   0.57 (  0.57)\tData 0.5632 (0.5632)\tLoss (MSE) 2.338 (2.338)\n",
      "Epoch: [695][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 4.079 (3.870)\n",
      "Epoch: [695][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 2.937 (3.798)\n",
      "Epoch: [695][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 5.362 (3.713)\n",
      "Epoch: [695][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.477 (3.796)\n",
      "Epoch: [695][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.506 (3.960)\n",
      "Epoch: [695][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.047 (3.919)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.642 (0.642)\n",
      " * Overall: MSE 1.921\tL1 0.597\tG-Mean 0.261\n",
      " * Many: MSE 2.312\tL1 1.014\tG-Mean 0.866\n",
      " * Median: MSE 2.170\tL1 1.408\tG-Mean 1.351\n",
      " * Low: MSE 0.096\tL1 0.228\tG-Mean 0.208\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #695: Train loss [3.9053]; Val loss: MSE [1.9210], L1 [0.5971], G-Mean [0.2612]\n",
      "Epoch: [696][ 0/65]\tTime   0.56 (  0.56)\tData 0.5541 (0.5541)\tLoss (MSE) 2.340 (2.340)\n",
      "Epoch: [696][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0521)\tLoss (MSE) 3.104 (3.299)\n",
      "Epoch: [696][20/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 6.008 (3.849)\n",
      "Epoch: [696][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.581 (3.858)\n",
      "Epoch: [696][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.554 (3.714)\n",
      "Epoch: [696][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 2.673 (3.707)\n",
      "Epoch: [696][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.547 (3.815)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #696: Train loss [3.8276]; Val loss: MSE [1.9198], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [697][ 0/65]\tTime   0.56 (  0.56)\tData 0.5577 (0.5577)\tLoss (MSE) 4.799 (4.799)\n",
      "Epoch: [697][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 2.689 (3.687)\n",
      "Epoch: [697][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 2.379 (3.425)\n",
      "Epoch: [697][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 6.433 (3.644)\n",
      "Epoch: [697][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.570 (3.743)\n",
      "Epoch: [697][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.212 (3.732)\n",
      "Epoch: [697][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.932 (3.734)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.050 (2.050)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.600\tG-Mean 0.260\n",
      " * Many: MSE 2.329\tL1 1.025\tG-Mean 0.879\n",
      " * Median: MSE 2.134\tL1 1.395\tG-Mean 1.337\n",
      " * Low: MSE 0.093\tL1 0.216\tG-Mean 0.195\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #697: Train loss [3.7499]; Val loss: MSE [1.9187], L1 [0.5999], G-Mean [0.2597]\n",
      "Epoch: [698][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 5.361 (5.361)\n",
      "Epoch: [698][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 2.409 (3.958)\n",
      "Epoch: [698][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 3.453 (3.504)\n",
      "Epoch: [698][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.015 (3.594)\n",
      "Epoch: [698][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.843 (3.761)\n",
      "Epoch: [698][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 3.587 (3.739)\n",
      "Epoch: [698][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.856 (3.841)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.048 (2.048)\tLoss (L1) 0.645 (0.645)\n",
      " * Overall: MSE 1.918\tL1 0.601\tG-Mean 0.261\n",
      " * Many: MSE 2.334\tL1 1.029\tG-Mean 0.883\n",
      " * Median: MSE 2.124\tL1 1.391\tG-Mean 1.333\n",
      " * Low: MSE 0.091\tL1 0.213\tG-Mean 0.191\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #698: Train loss [3.8682]; Val loss: MSE [1.9178], L1 [0.6008], G-Mean [0.2606]\n",
      "Epoch: [699][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 4.325 (4.325)\n",
      "Epoch: [699][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 2.857 (3.679)\n",
      "Epoch: [699][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.314 (3.965)\n",
      "Epoch: [699][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.303 (3.773)\n",
      "Epoch: [699][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.223 (3.743)\n",
      "Epoch: [699][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.978 (3.771)\n",
      "Epoch: [699][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.966 (3.724)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.055 (2.055)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.922\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.315\tL1 1.015\tG-Mean 0.867\n",
      " * Median: MSE 2.167\tL1 1.406\tG-Mean 1.349\n",
      " * Low: MSE 0.097\tL1 0.227\tG-Mean 0.207\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #699: Train loss [3.7407]; Val loss: MSE [1.9222], L1 [0.5975], G-Mean [0.2604]\n",
      "Epoch: [700][ 0/65]\tTime   0.61 (  0.61)\tData 0.5921 (0.5921)\tLoss (MSE) 2.785 (2.785)\n",
      "Epoch: [700][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 4.607 (3.444)\n",
      "Epoch: [700][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 5.306 (3.608)\n",
      "Epoch: [700][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.017 (3.544)\n",
      "Epoch: [700][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 1.874 (3.458)\n",
      "Epoch: [700][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.706 (3.558)\n",
      "Epoch: [700][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.353 (3.700)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #700: Train loss [3.7650]; Val loss: MSE [1.9206], L1 [0.5986], G-Mean [0.2595]\n",
      "Epoch: [701][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 3.745 (3.745)\n",
      "Epoch: [701][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 6.589 (4.637)\n",
      "Epoch: [701][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0293)\tLoss (MSE) 2.945 (4.135)\n",
      "Epoch: [701][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 4.264 (4.166)\n",
      "Epoch: [701][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.295 (4.141)\n",
      "Epoch: [701][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.330 (4.031)\n",
      "Epoch: [701][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.624 (3.877)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #701: Train loss [3.8405]; Val loss: MSE [1.9209], L1 [0.5984], G-Mean [0.2594]\n",
      "Epoch: [702][ 0/65]\tTime   0.57 (  0.57)\tData 0.5685 (0.5685)\tLoss (MSE) 1.991 (1.991)\n",
      "Epoch: [702][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 5.438 (3.868)\n",
      "Epoch: [702][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 2.294 (3.678)\n",
      "Epoch: [702][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 6.711 (3.915)\n",
      "Epoch: [702][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.133 (3.782)\n",
      "Epoch: [702][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 2.861 (3.767)\n",
      "Epoch: [702][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.350 (3.768)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #702: Train loss [3.8382]; Val loss: MSE [1.9206], L1 [0.5986], G-Mean [0.2598]\n",
      "Epoch: [703][ 0/65]\tTime   0.56 (  0.56)\tData 0.5548 (0.5548)\tLoss (MSE) 3.197 (3.197)\n",
      "Epoch: [703][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.016 (3.492)\n",
      "Epoch: [703][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.978 (3.574)\n",
      "Epoch: [703][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.373 (3.577)\n",
      "Epoch: [703][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 4.925 (3.735)\n",
      "Epoch: [703][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.337 (3.685)\n",
      "Epoch: [703][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.559 (3.716)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #703: Train loss [3.7740]; Val loss: MSE [1.9202], L1 [0.5989], G-Mean [0.2606]\n",
      "Epoch: [704][ 0/65]\tTime   0.55 (  0.55)\tData 0.5461 (0.5461)\tLoss (MSE) 2.989 (2.989)\n",
      "Epoch: [704][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0527)\tLoss (MSE) 4.871 (3.756)\n",
      "Epoch: [704][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 4.171 (3.751)\n",
      "Epoch: [704][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.087 (3.533)\n",
      "Epoch: [704][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.133 (3.632)\n",
      "Epoch: [704][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 4.707 (3.600)\n",
      "Epoch: [704][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.386 (3.759)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #704: Train loss [3.7806]; Val loss: MSE [1.9204], L1 [0.5987], G-Mean [0.2604]\n",
      "Epoch: [705][ 0/65]\tTime   0.56 (  0.56)\tData 0.5491 (0.5491)\tLoss (MSE) 3.554 (3.554)\n",
      "Epoch: [705][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 4.827 (4.279)\n",
      "Epoch: [705][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.537 (4.305)\n",
      "Epoch: [705][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.428 (4.045)\n",
      "Epoch: [705][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.925 (3.993)\n",
      "Epoch: [705][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.094 (3.815)\n",
      "Epoch: [705][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.101 (3.805)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.156\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #705: Train loss [3.8132]; Val loss: MSE [1.9210], L1 [0.5983], G-Mean [0.2595]\n",
      "Epoch: [706][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 2.820 (2.820)\n",
      "Epoch: [706][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0512)\tLoss (MSE) 3.723 (3.705)\n",
      "Epoch: [706][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.592 (3.595)\n",
      "Epoch: [706][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.482 (3.613)\n",
      "Epoch: [706][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.309 (3.758)\n",
      "Epoch: [706][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.923 (3.760)\n",
      "Epoch: [706][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.305 (3.791)\n",
      "Val: [0/9]\tTime  0.587 ( 0.587)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.259\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #706: Train loss [3.7892]; Val loss: MSE [1.9205], L1 [0.5986], G-Mean [0.2594]\n",
      "Epoch: [707][ 0/65]\tTime   0.71 (  0.71)\tData 0.6997 (0.6997)\tLoss (MSE) 5.614 (5.614)\n",
      "Epoch: [707][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0645)\tLoss (MSE) 2.669 (3.849)\n",
      "Epoch: [707][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0338)\tLoss (MSE) 3.793 (3.845)\n",
      "Epoch: [707][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0229)\tLoss (MSE) 9.336 (4.120)\n",
      "Epoch: [707][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0173)\tLoss (MSE) 3.088 (3.902)\n",
      "Epoch: [707][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.549 (3.925)\n",
      "Epoch: [707][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.498 (3.818)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #707: Train loss [3.8041]; Val loss: MSE [1.9203], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [708][ 0/65]\tTime   0.55 (  0.55)\tData 0.5438 (0.5438)\tLoss (MSE) 4.140 (4.140)\n",
      "Epoch: [708][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0573)\tLoss (MSE) 3.236 (3.736)\n",
      "Epoch: [708][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 2.399 (3.847)\n",
      "Epoch: [708][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.399 (3.919)\n",
      "Epoch: [708][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 2.974 (3.931)\n",
      "Epoch: [708][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.659 (3.896)\n",
      "Epoch: [708][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.589 (3.793)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #708: Train loss [3.8149]; Val loss: MSE [1.9203], L1 [0.5988], G-Mean [0.2605]\n",
      "Epoch: [709][ 0/65]\tTime   0.57 (  0.57)\tData 0.5642 (0.5642)\tLoss (MSE) 2.210 (2.210)\n",
      "Epoch: [709][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.039 (3.767)\n",
      "Epoch: [709][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.671 (4.075)\n",
      "Epoch: [709][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.757 (3.827)\n",
      "Epoch: [709][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.572 (3.738)\n",
      "Epoch: [709][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 2.531 (3.799)\n",
      "Epoch: [709][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.006 (3.801)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #709: Train loss [3.8375]; Val loss: MSE [1.9199], L1 [0.5991], G-Mean [0.2605]\n",
      "Epoch: [710][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 5.857 (5.857)\n",
      "Epoch: [710][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 2.690 (3.871)\n",
      "Epoch: [710][20/65]\tTime   0.01 (  0.03)\tData 0.0001 (0.0278)\tLoss (MSE) 2.310 (4.006)\n",
      "Epoch: [710][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 3.670 (4.012)\n",
      "Epoch: [710][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 3.045 (3.823)\n",
      "Epoch: [710][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 2.703 (3.826)\n",
      "Epoch: [710][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 4.605 (3.878)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #710: Train loss [3.8331]; Val loss: MSE [1.9200], L1 [0.5989], G-Mean [0.2605]\n",
      "Epoch: [711][ 0/65]\tTime   0.56 (  0.56)\tData 0.5533 (0.5533)\tLoss (MSE) 2.556 (2.556)\n",
      "Epoch: [711][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 2.501 (2.890)\n",
      "Epoch: [711][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.269 (3.260)\n",
      "Epoch: [711][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 5.155 (3.360)\n",
      "Epoch: [711][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.162 (3.668)\n",
      "Epoch: [711][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 7.216 (3.801)\n",
      "Epoch: [711][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.505 (3.668)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #711: Train loss [3.7250]; Val loss: MSE [1.9197], L1 [0.5990], G-Mean [0.2604]\n",
      "Epoch: [712][ 0/65]\tTime   0.56 (  0.56)\tData 0.5525 (0.5525)\tLoss (MSE) 3.326 (3.326)\n",
      "Epoch: [712][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0573)\tLoss (MSE) 2.618 (3.454)\n",
      "Epoch: [712][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.618 (3.700)\n",
      "Epoch: [712][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 2.484 (3.597)\n",
      "Epoch: [712][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.127 (3.791)\n",
      "Epoch: [712][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.589 (3.837)\n",
      "Epoch: [712][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 7.135 (3.860)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #712: Train loss [3.8204]; Val loss: MSE [1.9199], L1 [0.5990], G-Mean [0.2601]\n",
      "Epoch: [713][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 4.753 (4.753)\n",
      "Epoch: [713][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0583)\tLoss (MSE) 2.950 (4.306)\n",
      "Epoch: [713][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.667 (4.087)\n",
      "Epoch: [713][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 5.043 (4.022)\n",
      "Epoch: [713][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 5.166 (3.784)\n",
      "Epoch: [713][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.665 (3.842)\n",
      "Epoch: [713][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.631 (3.843)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #713: Train loss [3.7888]; Val loss: MSE [1.9203], L1 [0.5987], G-Mean [0.2601]\n",
      "Epoch: [714][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 2.850 (2.850)\n",
      "Epoch: [714][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 4.802 (3.852)\n",
      "Epoch: [714][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0295)\tLoss (MSE) 3.761 (3.770)\n",
      "Epoch: [714][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.855 (3.791)\n",
      "Epoch: [714][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.841 (3.827)\n",
      "Epoch: [714][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.087 (3.838)\n",
      "Epoch: [714][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.398 (3.804)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #714: Train loss [3.9451]; Val loss: MSE [1.9200], L1 [0.5989], G-Mean [0.2605]\n",
      "Epoch: [715][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 5.657 (5.657)\n",
      "Epoch: [715][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 5.073 (4.093)\n",
      "Epoch: [715][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.754 (4.030)\n",
      "Epoch: [715][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.178 (3.889)\n",
      "Epoch: [715][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.408 (3.786)\n",
      "Epoch: [715][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.454 (3.759)\n",
      "Epoch: [715][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.147 (3.819)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #715: Train loss [3.8206]; Val loss: MSE [1.9203], L1 [0.5988], G-Mean [0.2604]\n",
      "Epoch: [716][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 4.088 (4.088)\n",
      "Epoch: [716][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 6.325 (3.861)\n",
      "Epoch: [716][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.641 (4.071)\n",
      "Epoch: [716][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.707 (3.976)\n",
      "Epoch: [716][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.554 (3.900)\n",
      "Epoch: [716][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.897 (3.803)\n",
      "Epoch: [716][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.164 (3.763)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #716: Train loss [3.7719]; Val loss: MSE [1.9207], L1 [0.5985], G-Mean [0.2597]\n",
      "Epoch: [717][ 0/65]\tTime   0.63 (  0.63)\tData 0.6144 (0.6144)\tLoss (MSE) 4.562 (4.562)\n",
      "Epoch: [717][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0592)\tLoss (MSE) 4.001 (3.883)\n",
      "Epoch: [717][20/65]\tTime   0.01 (  0.04)\tData 0.0001 (0.0310)\tLoss (MSE) 4.169 (3.959)\n",
      "Epoch: [717][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 4.676 (4.156)\n",
      "Epoch: [717][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 6.281 (4.037)\n",
      "Epoch: [717][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.259 (3.869)\n",
      "Epoch: [717][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0107)\tLoss (MSE) 4.190 (3.840)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #717: Train loss [3.8357]; Val loss: MSE [1.9205], L1 [0.5985], G-Mean [0.2595]\n",
      "Epoch: [718][ 0/65]\tTime   0.64 (  0.64)\tData 0.6172 (0.6172)\tLoss (MSE) 2.883 (2.883)\n",
      "Epoch: [718][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0599)\tLoss (MSE) 2.679 (3.218)\n",
      "Epoch: [718][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 3.403 (3.503)\n",
      "Epoch: [718][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 2.788 (3.588)\n",
      "Epoch: [718][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 5.463 (3.622)\n",
      "Epoch: [718][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.174 (3.743)\n",
      "Epoch: [718][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.959 (3.840)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #718: Train loss [3.8498]; Val loss: MSE [1.9201], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [719][ 0/65]\tTime   0.56 (  0.56)\tData 0.5565 (0.5565)\tLoss (MSE) 5.839 (5.839)\n",
      "Epoch: [719][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0594)\tLoss (MSE) 3.773 (3.793)\n",
      "Epoch: [719][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0311)\tLoss (MSE) 3.357 (3.810)\n",
      "Epoch: [719][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0211)\tLoss (MSE) 3.451 (3.869)\n",
      "Epoch: [719][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 2.008 (3.839)\n",
      "Epoch: [719][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.679 (3.907)\n",
      "Epoch: [719][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.863 (3.810)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #719: Train loss [3.7989]; Val loss: MSE [1.9205], L1 [0.5985], G-Mean [0.2599]\n",
      "Epoch: [720][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 2.684 (2.684)\n",
      "Epoch: [720][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0513)\tLoss (MSE) 3.109 (3.669)\n",
      "Epoch: [720][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 4.079 (3.843)\n",
      "Epoch: [720][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.019 (3.898)\n",
      "Epoch: [720][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.004 (3.840)\n",
      "Epoch: [720][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.231 (3.815)\n",
      "Epoch: [720][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.677 (3.816)\n",
      "Val: [0/9]\tTime  0.659 ( 0.659)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #720: Train loss [3.8214]; Val loss: MSE [1.9205], L1 [0.5985], G-Mean [0.2598]\n",
      "Epoch: [721][ 0/65]\tTime   0.66 (  0.66)\tData 0.6546 (0.6546)\tLoss (MSE) 7.078 (7.078)\n",
      "Epoch: [721][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0653)\tLoss (MSE) 2.221 (3.740)\n",
      "Epoch: [721][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0342)\tLoss (MSE) 3.437 (3.374)\n",
      "Epoch: [721][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0232)\tLoss (MSE) 4.625 (3.217)\n",
      "Epoch: [721][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0175)\tLoss (MSE) 2.924 (3.470)\n",
      "Epoch: [721][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 4.822 (3.620)\n",
      "Epoch: [721][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.762 (3.773)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #721: Train loss [3.7632]; Val loss: MSE [1.9201], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [722][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 4.278 (4.278)\n",
      "Epoch: [722][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 5.761 (3.628)\n",
      "Epoch: [722][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.706 (3.768)\n",
      "Epoch: [722][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.444 (3.844)\n",
      "Epoch: [722][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.239 (3.713)\n",
      "Epoch: [722][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.187 (3.713)\n",
      "Epoch: [722][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.061 (3.713)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #722: Train loss [3.7126]; Val loss: MSE [1.9201], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [723][ 0/65]\tTime   0.57 (  0.57)\tData 0.5646 (0.5646)\tLoss (MSE) 3.841 (3.841)\n",
      "Epoch: [723][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0597)\tLoss (MSE) 2.630 (4.643)\n",
      "Epoch: [723][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.081 (4.112)\n",
      "Epoch: [723][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0212)\tLoss (MSE) 1.991 (3.942)\n",
      "Epoch: [723][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.691 (3.832)\n",
      "Epoch: [723][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.982 (3.824)\n",
      "Epoch: [723][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.399 (3.832)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #723: Train loss [3.8712]; Val loss: MSE [1.9200], L1 [0.5989], G-Mean [0.2605]\n",
      "Epoch: [724][ 0/65]\tTime   0.56 (  0.56)\tData 0.5601 (0.5601)\tLoss (MSE) 4.858 (4.858)\n",
      "Epoch: [724][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 2.792 (3.484)\n",
      "Epoch: [724][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.791 (4.148)\n",
      "Epoch: [724][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.269 (4.029)\n",
      "Epoch: [724][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.269 (4.051)\n",
      "Epoch: [724][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.925 (3.949)\n",
      "Epoch: [724][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.429 (3.879)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #724: Train loss [3.8376]; Val loss: MSE [1.9202], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [725][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 2.471 (2.471)\n",
      "Epoch: [725][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0514)\tLoss (MSE) 5.753 (3.684)\n",
      "Epoch: [725][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.621 (3.723)\n",
      "Epoch: [725][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.619 (3.952)\n",
      "Epoch: [725][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.184 (3.806)\n",
      "Epoch: [725][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.033 (3.687)\n",
      "Epoch: [725][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.902 (3.758)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #725: Train loss [3.7652]; Val loss: MSE [1.9201], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [726][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 1.999 (1.999)\n",
      "Epoch: [726][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 4.752 (4.452)\n",
      "Epoch: [726][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 5.334 (4.170)\n",
      "Epoch: [726][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.214 (3.931)\n",
      "Epoch: [726][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.922 (4.049)\n",
      "Epoch: [726][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.619 (3.906)\n",
      "Epoch: [726][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.289 (3.814)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #726: Train loss [3.8038]; Val loss: MSE [1.9206], L1 [0.5985], G-Mean [0.2597]\n",
      "Epoch: [727][ 0/65]\tTime   0.57 (  0.57)\tData 0.5580 (0.5580)\tLoss (MSE) 2.619 (2.619)\n",
      "Epoch: [727][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 2.529 (3.958)\n",
      "Epoch: [727][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 6.867 (3.863)\n",
      "Epoch: [727][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.478 (3.804)\n",
      "Epoch: [727][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.204 (3.716)\n",
      "Epoch: [727][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.549 (3.735)\n",
      "Epoch: [727][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.223 (3.766)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #727: Train loss [3.7951]; Val loss: MSE [1.9201], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [728][ 0/65]\tTime   0.56 (  0.56)\tData 0.5564 (0.5564)\tLoss (MSE) 5.091 (5.091)\n",
      "Epoch: [728][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.029 (4.321)\n",
      "Epoch: [728][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 1.904 (4.011)\n",
      "Epoch: [728][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.363 (3.814)\n",
      "Epoch: [728][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.465 (3.879)\n",
      "Epoch: [728][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 1.927 (3.787)\n",
      "Epoch: [728][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.694 (3.813)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #728: Train loss [3.7819]; Val loss: MSE [1.9205], L1 [0.5986], G-Mean [0.2599]\n",
      "Epoch: [729][ 0/65]\tTime   0.57 (  0.57)\tData 0.5588 (0.5588)\tLoss (MSE) 2.915 (2.915)\n",
      "Epoch: [729][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 5.524 (3.959)\n",
      "Epoch: [729][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.639 (4.005)\n",
      "Epoch: [729][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.175 (3.852)\n",
      "Epoch: [729][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.770 (3.871)\n",
      "Epoch: [729][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.588 (3.869)\n",
      "Epoch: [729][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.940 (3.878)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #729: Train loss [3.8473]; Val loss: MSE [1.9205], L1 [0.5987], G-Mean [0.2601]\n",
      "Epoch: [730][ 0/65]\tTime   0.61 (  0.61)\tData 0.6032 (0.6032)\tLoss (MSE) 4.714 (4.714)\n",
      "Epoch: [730][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0623)\tLoss (MSE) 5.431 (5.037)\n",
      "Epoch: [730][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0326)\tLoss (MSE) 3.112 (4.425)\n",
      "Epoch: [730][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0221)\tLoss (MSE) 3.585 (4.264)\n",
      "Epoch: [730][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0167)\tLoss (MSE) 3.234 (4.085)\n",
      "Epoch: [730][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 2.697 (4.065)\n",
      "Epoch: [730][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.819 (3.905)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #730: Train loss [3.8405]; Val loss: MSE [1.9205], L1 [0.5986], G-Mean [0.2600]\n",
      "Epoch: [731][ 0/65]\tTime   0.57 (  0.57)\tData 0.5602 (0.5602)\tLoss (MSE) 3.366 (3.366)\n",
      "Epoch: [731][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 4.391 (3.552)\n",
      "Epoch: [731][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0304)\tLoss (MSE) 2.839 (3.776)\n",
      "Epoch: [731][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 5.332 (3.944)\n",
      "Epoch: [731][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.492 (3.942)\n",
      "Epoch: [731][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.980 (3.826)\n",
      "Epoch: [731][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.579 (3.809)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #731: Train loss [3.7746]; Val loss: MSE [1.9205], L1 [0.5987], G-Mean [0.2602]\n",
      "Epoch: [732][ 0/65]\tTime   0.55 (  0.55)\tData 0.5492 (0.5492)\tLoss (MSE) 2.333 (2.333)\n",
      "Epoch: [732][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0588)\tLoss (MSE) 4.205 (3.951)\n",
      "Epoch: [732][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 2.513 (3.755)\n",
      "Epoch: [732][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 3.291 (3.811)\n",
      "Epoch: [732][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 5.685 (3.943)\n",
      "Epoch: [732][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.881 (4.000)\n",
      "Epoch: [732][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.576 (3.935)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #732: Train loss [3.8864]; Val loss: MSE [1.9199], L1 [0.5991], G-Mean [0.2601]\n",
      "Epoch: [733][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 4.364 (4.364)\n",
      "Epoch: [733][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 3.276 (3.350)\n",
      "Epoch: [733][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.508 (3.857)\n",
      "Epoch: [733][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 4.243 (3.785)\n",
      "Epoch: [733][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 5.866 (3.845)\n",
      "Epoch: [733][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 5.296 (3.823)\n",
      "Epoch: [733][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.059 (3.869)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #733: Train loss [3.8207]; Val loss: MSE [1.9208], L1 [0.5985], G-Mean [0.2596]\n",
      "Epoch: [734][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 3.767 (3.767)\n",
      "Epoch: [734][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 4.461 (3.314)\n",
      "Epoch: [734][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 3.898 (3.314)\n",
      "Epoch: [734][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 3.079 (3.451)\n",
      "Epoch: [734][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 4.634 (3.687)\n",
      "Epoch: [734][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0117)\tLoss (MSE) 6.287 (3.795)\n",
      "Epoch: [734][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.034 (3.820)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #734: Train loss [3.8098]; Val loss: MSE [1.9209], L1 [0.5985], G-Mean [0.2597]\n",
      "Epoch: [735][ 0/65]\tTime   0.61 (  0.61)\tData 0.5952 (0.5952)\tLoss (MSE) 4.488 (4.488)\n",
      "Epoch: [735][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0561)\tLoss (MSE) 3.167 (3.193)\n",
      "Epoch: [735][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0294)\tLoss (MSE) 3.439 (3.646)\n",
      "Epoch: [735][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 3.746 (3.601)\n",
      "Epoch: [735][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.543 (3.873)\n",
      "Epoch: [735][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.944 (3.894)\n",
      "Epoch: [735][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 1.913 (3.888)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #735: Train loss [3.8800]; Val loss: MSE [1.9204], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [736][ 0/65]\tTime   0.56 (  0.56)\tData 0.5497 (0.5497)\tLoss (MSE) 4.518 (4.518)\n",
      "Epoch: [736][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 2.827 (3.463)\n",
      "Epoch: [736][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.069 (3.810)\n",
      "Epoch: [736][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.168 (3.867)\n",
      "Epoch: [736][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.259 (4.077)\n",
      "Epoch: [736][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.792 (4.054)\n",
      "Epoch: [736][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.450 (3.933)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #736: Train loss [3.9301]; Val loss: MSE [1.9203], L1 [0.5988], G-Mean [0.2607]\n",
      "Epoch: [737][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 2.961 (2.961)\n",
      "Epoch: [737][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 3.155 (4.384)\n",
      "Epoch: [737][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.709 (4.173)\n",
      "Epoch: [737][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.006 (3.982)\n",
      "Epoch: [737][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 4.798 (3.840)\n",
      "Epoch: [737][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.331 (3.794)\n",
      "Epoch: [737][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.005 (3.748)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #737: Train loss [3.7797]; Val loss: MSE [1.9205], L1 [0.5987], G-Mean [0.2605]\n",
      "Epoch: [738][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 4.886 (4.886)\n",
      "Epoch: [738][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0527)\tLoss (MSE) 4.157 (4.305)\n",
      "Epoch: [738][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 2.941 (4.292)\n",
      "Epoch: [738][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 3.516 (4.236)\n",
      "Epoch: [738][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 1.807 (4.102)\n",
      "Epoch: [738][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.169 (3.930)\n",
      "Epoch: [738][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.648 (3.899)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #738: Train loss [3.8196]; Val loss: MSE [1.9203], L1 [0.5988], G-Mean [0.2607]\n",
      "Epoch: [739][ 0/65]\tTime   0.56 (  0.56)\tData 0.5573 (0.5573)\tLoss (MSE) 2.253 (2.253)\n",
      "Epoch: [739][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 7.396 (3.945)\n",
      "Epoch: [739][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.411 (3.637)\n",
      "Epoch: [739][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.089 (3.487)\n",
      "Epoch: [739][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.828 (3.663)\n",
      "Epoch: [739][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.207 (3.910)\n",
      "Epoch: [739][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.993 (3.858)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #739: Train loss [3.8116]; Val loss: MSE [1.9204], L1 [0.5988], G-Mean [0.2607]\n",
      "Epoch: [740][ 0/65]\tTime   0.55 (  0.55)\tData 0.5420 (0.5420)\tLoss (MSE) 3.666 (3.666)\n",
      "Epoch: [740][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0553)\tLoss (MSE) 2.901 (4.203)\n",
      "Epoch: [740][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 3.849 (3.929)\n",
      "Epoch: [740][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.552 (3.823)\n",
      "Epoch: [740][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 5.370 (3.787)\n",
      "Epoch: [740][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 3.790 (3.983)\n",
      "Epoch: [740][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.784 (3.868)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #740: Train loss [3.8406]; Val loss: MSE [1.9207], L1 [0.5985], G-Mean [0.2593]\n",
      "Epoch: [741][ 0/65]\tTime   0.56 (  0.56)\tData 0.5582 (0.5582)\tLoss (MSE) 4.533 (4.533)\n",
      "Epoch: [741][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0540)\tLoss (MSE) 4.443 (3.712)\n",
      "Epoch: [741][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 4.808 (4.047)\n",
      "Epoch: [741][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 2.327 (3.867)\n",
      "Epoch: [741][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 7.038 (3.845)\n",
      "Epoch: [741][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 5.766 (3.955)\n",
      "Epoch: [741][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.556 (3.838)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.156\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.096\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #741: Train loss [3.8237]; Val loss: MSE [1.9209], L1 [0.5983], G-Mean [0.2598]\n",
      "Epoch: [742][ 0/65]\tTime   0.56 (  0.56)\tData 0.5508 (0.5508)\tLoss (MSE) 2.222 (2.222)\n",
      "Epoch: [742][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0507)\tLoss (MSE) 5.797 (3.558)\n",
      "Epoch: [742][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 3.424 (3.998)\n",
      "Epoch: [742][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 5.602 (4.207)\n",
      "Epoch: [742][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.346 (4.079)\n",
      "Epoch: [742][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.221 (3.916)\n",
      "Epoch: [742][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 1.946 (3.871)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #742: Train loss [3.8450]; Val loss: MSE [1.9206], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [743][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 3.671 (3.671)\n",
      "Epoch: [743][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0578)\tLoss (MSE) 5.091 (4.146)\n",
      "Epoch: [743][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 4.693 (4.028)\n",
      "Epoch: [743][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.014 (3.836)\n",
      "Epoch: [743][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.642 (3.771)\n",
      "Epoch: [743][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.605 (3.789)\n",
      "Epoch: [743][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.177 (3.773)\n",
      "Val: [0/9]\tTime  0.567 ( 0.567)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #743: Train loss [3.7905]; Val loss: MSE [1.9206], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [744][ 0/65]\tTime   0.55 (  0.55)\tData 0.5488 (0.5488)\tLoss (MSE) 3.909 (3.909)\n",
      "Epoch: [744][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0593)\tLoss (MSE) 3.684 (3.436)\n",
      "Epoch: [744][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 4.767 (3.501)\n",
      "Epoch: [744][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 4.917 (3.538)\n",
      "Epoch: [744][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 1.908 (3.609)\n",
      "Epoch: [744][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 5.774 (3.686)\n",
      "Epoch: [744][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 4.045 (3.697)\n",
      "Val: [0/9]\tTime  0.560 ( 0.560)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #744: Train loss [3.7759]; Val loss: MSE [1.9204], L1 [0.5987], G-Mean [0.2601]\n",
      "Epoch: [745][ 0/65]\tTime   0.66 (  0.66)\tData 0.6557 (0.6557)\tLoss (MSE) 2.944 (2.944)\n",
      "Epoch: [745][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0639)\tLoss (MSE) 3.772 (3.540)\n",
      "Epoch: [745][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0335)\tLoss (MSE) 2.504 (3.492)\n",
      "Epoch: [745][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0227)\tLoss (MSE) 2.956 (3.470)\n",
      "Epoch: [745][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0172)\tLoss (MSE) 2.806 (3.688)\n",
      "Epoch: [745][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.864 (3.797)\n",
      "Epoch: [745][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 5.195 (3.820)\n",
      "Val: [0/9]\tTime  0.590 ( 0.590)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #745: Train loss [3.8392]; Val loss: MSE [1.9199], L1 [0.5990], G-Mean [0.2605]\n",
      "Epoch: [746][ 0/65]\tTime   0.57 (  0.57)\tData 0.5611 (0.5611)\tLoss (MSE) 4.072 (4.072)\n",
      "Epoch: [746][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0574)\tLoss (MSE) 3.751 (4.193)\n",
      "Epoch: [746][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 4.649 (4.160)\n",
      "Epoch: [746][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 3.340 (3.893)\n",
      "Epoch: [746][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.134 (3.910)\n",
      "Epoch: [746][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 7.049 (3.883)\n",
      "Epoch: [746][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.741 (3.882)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #746: Train loss [3.9036]; Val loss: MSE [1.9207], L1 [0.5985], G-Mean [0.2600]\n",
      "Epoch: [747][ 0/65]\tTime   0.55 (  0.55)\tData 0.5490 (0.5490)\tLoss (MSE) 2.948 (2.948)\n",
      "Epoch: [747][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 5.109 (3.982)\n",
      "Epoch: [747][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 4.404 (3.716)\n",
      "Epoch: [747][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 3.634 (3.960)\n",
      "Epoch: [747][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.477 (3.896)\n",
      "Epoch: [747][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.685 (3.814)\n",
      "Epoch: [747][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.267 (3.773)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #747: Train loss [3.7710]; Val loss: MSE [1.9202], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [748][ 0/65]\tTime   0.56 (  0.56)\tData 0.5563 (0.5563)\tLoss (MSE) 2.667 (2.667)\n",
      "Epoch: [748][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0587)\tLoss (MSE) 3.518 (3.410)\n",
      "Epoch: [748][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 2.846 (3.814)\n",
      "Epoch: [748][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 3.516 (4.082)\n",
      "Epoch: [748][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 4.064 (4.034)\n",
      "Epoch: [748][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.293 (3.932)\n",
      "Epoch: [748][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.831 (3.887)\n",
      "Val: [0/9]\tTime  0.562 ( 0.562)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #748: Train loss [3.8634]; Val loss: MSE [1.9207], L1 [0.5984], G-Mean [0.2594]\n",
      "Epoch: [749][ 0/65]\tTime   0.59 (  0.59)\tData 0.5737 (0.5737)\tLoss (MSE) 2.823 (2.823)\n",
      "Epoch: [749][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 3.271 (3.848)\n",
      "Epoch: [749][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.695 (3.607)\n",
      "Epoch: [749][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.852 (3.589)\n",
      "Epoch: [749][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 5.832 (3.734)\n",
      "Epoch: [749][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.678 (3.756)\n",
      "Epoch: [749][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.761 (3.778)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #749: Train loss [3.8122]; Val loss: MSE [1.9199], L1 [0.5988], G-Mean [0.2607]\n",
      "Epoch: [750][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 1.849 (1.849)\n",
      "Epoch: [750][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.532 (3.264)\n",
      "Epoch: [750][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.219 (3.754)\n",
      "Epoch: [750][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.264 (3.670)\n",
      "Epoch: [750][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.420 (3.776)\n",
      "Epoch: [750][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.797 (3.817)\n",
      "Epoch: [750][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.042 (3.823)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #750: Train loss [3.8056]; Val loss: MSE [1.9200], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [751][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 3.044 (3.044)\n",
      "Epoch: [751][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 3.947 (4.070)\n",
      "Epoch: [751][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 2.404 (3.710)\n",
      "Epoch: [751][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.038 (3.582)\n",
      "Epoch: [751][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.061 (3.540)\n",
      "Epoch: [751][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.554 (3.670)\n",
      "Epoch: [751][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.754 (3.741)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #751: Train loss [3.7747]; Val loss: MSE [1.9196], L1 [0.5990], G-Mean [0.2605]\n",
      "Epoch: [752][ 0/65]\tTime   0.55 (  0.55)\tData 0.5452 (0.5452)\tLoss (MSE) 3.495 (3.495)\n",
      "Epoch: [752][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0530)\tLoss (MSE) 2.167 (3.356)\n",
      "Epoch: [752][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 8.263 (3.999)\n",
      "Epoch: [752][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 2.206 (3.717)\n",
      "Epoch: [752][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 4.395 (3.874)\n",
      "Epoch: [752][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 3.697 (3.851)\n",
      "Epoch: [752][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.336 (3.771)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #752: Train loss [3.7979]; Val loss: MSE [1.9201], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [753][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 3.096 (3.096)\n",
      "Epoch: [753][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0546)\tLoss (MSE) 3.620 (3.593)\n",
      "Epoch: [753][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.755 (3.946)\n",
      "Epoch: [753][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 1.654 (3.750)\n",
      "Epoch: [753][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.577 (3.769)\n",
      "Epoch: [753][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.242 (3.763)\n",
      "Epoch: [753][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.495 (3.764)\n",
      "Val: [0/9]\tTime  0.568 ( 0.568)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #753: Train loss [3.7996]; Val loss: MSE [1.9202], L1 [0.5986], G-Mean [0.2600]\n",
      "Epoch: [754][ 0/65]\tTime   0.55 (  0.55)\tData 0.5467 (0.5467)\tLoss (MSE) 4.820 (4.820)\n",
      "Epoch: [754][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0583)\tLoss (MSE) 2.754 (3.673)\n",
      "Epoch: [754][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 3.681 (3.837)\n",
      "Epoch: [754][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 4.689 (3.935)\n",
      "Epoch: [754][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.941 (4.069)\n",
      "Epoch: [754][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.230 (3.919)\n",
      "Epoch: [754][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.119 (3.903)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #754: Train loss [3.8430]; Val loss: MSE [1.9196], L1 [0.5990], G-Mean [0.2605]\n",
      "Epoch: [755][ 0/65]\tTime   0.56 (  0.56)\tData 0.5557 (0.5557)\tLoss (MSE) 2.793 (2.793)\n",
      "Epoch: [755][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 3.753 (3.910)\n",
      "Epoch: [755][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 3.882 (3.718)\n",
      "Epoch: [755][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.100 (3.730)\n",
      "Epoch: [755][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.588 (3.783)\n",
      "Epoch: [755][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.293 (3.785)\n",
      "Epoch: [755][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.492 (3.796)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #755: Train loss [3.8129]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [756][ 0/65]\tTime   0.56 (  0.56)\tData 0.5533 (0.5533)\tLoss (MSE) 4.666 (4.666)\n",
      "Epoch: [756][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 3.900 (3.468)\n",
      "Epoch: [756][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 4.727 (3.947)\n",
      "Epoch: [756][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.363 (3.938)\n",
      "Epoch: [756][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.849 (3.977)\n",
      "Epoch: [756][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.218 (3.898)\n",
      "Epoch: [756][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 5.863 (3.875)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #756: Train loss [3.8414]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [757][ 0/65]\tTime   0.56 (  0.56)\tData 0.5551 (0.5551)\tLoss (MSE) 2.629 (2.629)\n",
      "Epoch: [757][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 5.377 (4.674)\n",
      "Epoch: [757][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 2.836 (4.230)\n",
      "Epoch: [757][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.304 (3.972)\n",
      "Epoch: [757][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.430 (4.076)\n",
      "Epoch: [757][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0112)\tLoss (MSE) 2.483 (3.841)\n",
      "Epoch: [757][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.497 (3.891)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #757: Train loss [3.8814]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [758][ 0/65]\tTime   0.56 (  0.56)\tData 0.5545 (0.5545)\tLoss (MSE) 5.292 (5.292)\n",
      "Epoch: [758][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0556)\tLoss (MSE) 3.912 (3.778)\n",
      "Epoch: [758][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 5.582 (3.917)\n",
      "Epoch: [758][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.877 (3.872)\n",
      "Epoch: [758][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.129 (3.821)\n",
      "Epoch: [758][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.716 (3.820)\n",
      "Epoch: [758][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.473 (3.871)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #758: Train loss [3.8089]; Val loss: MSE [1.9198], L1 [0.5988], G-Mean [0.2608]\n",
      "Epoch: [759][ 0/65]\tTime   0.58 (  0.58)\tData 0.5727 (0.5727)\tLoss (MSE) 3.660 (3.660)\n",
      "Epoch: [759][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0550)\tLoss (MSE) 3.105 (3.983)\n",
      "Epoch: [759][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 1.747 (3.845)\n",
      "Epoch: [759][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.020 (3.886)\n",
      "Epoch: [759][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 6.338 (3.883)\n",
      "Epoch: [759][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.458 (3.943)\n",
      "Epoch: [759][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.244 (3.968)\n",
      "Val: [0/9]\tTime  0.650 ( 0.650)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #759: Train loss [3.9463]; Val loss: MSE [1.9204], L1 [0.5984], G-Mean [0.2596]\n",
      "Epoch: [760][ 0/65]\tTime   0.57 (  0.57)\tData 0.5679 (0.5679)\tLoss (MSE) 3.374 (3.374)\n",
      "Epoch: [760][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0567)\tLoss (MSE) 2.650 (3.844)\n",
      "Epoch: [760][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 7.043 (3.920)\n",
      "Epoch: [760][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 2.629 (3.787)\n",
      "Epoch: [760][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.313 (3.883)\n",
      "Epoch: [760][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.304 (3.776)\n",
      "Epoch: [760][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.712 (3.833)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #760: Train loss [3.8157]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [761][ 0/65]\tTime   0.56 (  0.56)\tData 0.5503 (0.5503)\tLoss (MSE) 4.358 (4.358)\n",
      "Epoch: [761][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0513)\tLoss (MSE) 3.486 (3.461)\n",
      "Epoch: [761][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.766 (3.340)\n",
      "Epoch: [761][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.072 (3.412)\n",
      "Epoch: [761][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.905 (3.321)\n",
      "Epoch: [761][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.894 (3.495)\n",
      "Epoch: [761][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 7.712 (3.714)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #761: Train loss [3.7993]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [762][ 0/65]\tTime   0.56 (  0.56)\tData 0.5563 (0.5563)\tLoss (MSE) 3.973 (3.973)\n",
      "Epoch: [762][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0516)\tLoss (MSE) 2.678 (3.441)\n",
      "Epoch: [762][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.380 (3.906)\n",
      "Epoch: [762][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 1.839 (3.802)\n",
      "Epoch: [762][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.024 (3.872)\n",
      "Epoch: [762][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.485 (3.897)\n",
      "Epoch: [762][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.443 (3.817)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #762: Train loss [3.7844]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [763][ 0/65]\tTime   0.56 (  0.56)\tData 0.5533 (0.5533)\tLoss (MSE) 6.040 (6.040)\n",
      "Epoch: [763][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 4.060 (3.911)\n",
      "Epoch: [763][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.072 (3.785)\n",
      "Epoch: [763][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 2.770 (3.823)\n",
      "Epoch: [763][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 2.849 (3.903)\n",
      "Epoch: [763][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.929 (3.850)\n",
      "Epoch: [763][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.052 (3.797)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #763: Train loss [3.7942]; Val loss: MSE [1.9192], L1 [0.5991], G-Mean [0.2601]\n",
      "Epoch: [764][ 0/65]\tTime   0.66 (  0.66)\tData 0.6429 (0.6429)\tLoss (MSE) 4.856 (4.856)\n",
      "Epoch: [764][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0586)\tLoss (MSE) 5.411 (4.300)\n",
      "Epoch: [764][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0307)\tLoss (MSE) 2.654 (3.960)\n",
      "Epoch: [764][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 4.560 (4.015)\n",
      "Epoch: [764][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 2.868 (3.892)\n",
      "Epoch: [764][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.927 (3.938)\n",
      "Epoch: [764][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.649 (3.854)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #764: Train loss [3.8028]; Val loss: MSE [1.9198], L1 [0.5988], G-Mean [0.2608]\n",
      "Epoch: [765][ 0/65]\tTime   0.58 (  0.58)\tData 0.5692 (0.5692)\tLoss (MSE) 3.884 (3.884)\n",
      "Epoch: [765][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0567)\tLoss (MSE) 2.756 (3.699)\n",
      "Epoch: [765][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 3.476 (3.884)\n",
      "Epoch: [765][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 4.550 (3.786)\n",
      "Epoch: [765][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 4.798 (3.888)\n",
      "Epoch: [765][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.663 (3.839)\n",
      "Epoch: [765][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.534 (3.830)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #765: Train loss [3.7887]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [766][ 0/65]\tTime   0.55 (  0.55)\tData 0.5459 (0.5459)\tLoss (MSE) 3.746 (3.746)\n",
      "Epoch: [766][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 5.162 (3.933)\n",
      "Epoch: [766][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 4.305 (3.678)\n",
      "Epoch: [766][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 6.166 (4.041)\n",
      "Epoch: [766][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 4.596 (4.079)\n",
      "Epoch: [766][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.982 (3.927)\n",
      "Epoch: [766][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.011 (3.865)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #766: Train loss [3.8017]; Val loss: MSE [1.9202], L1 [0.5985], G-Mean [0.2601]\n",
      "Epoch: [767][ 0/65]\tTime   0.61 (  0.61)\tData 0.5914 (0.5914)\tLoss (MSE) 4.156 (4.156)\n",
      "Epoch: [767][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 4.223 (3.877)\n",
      "Epoch: [767][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 2.281 (3.771)\n",
      "Epoch: [767][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.357 (3.686)\n",
      "Epoch: [767][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.255 (3.687)\n",
      "Epoch: [767][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.660 (3.779)\n",
      "Epoch: [767][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.115 (3.697)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #767: Train loss [3.7447]; Val loss: MSE [1.9193], L1 [0.5992], G-Mean [0.2600]\n",
      "Epoch: [768][ 0/65]\tTime   0.56 (  0.56)\tData 0.5575 (0.5575)\tLoss (MSE) 1.974 (1.974)\n",
      "Epoch: [768][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 2.497 (3.406)\n",
      "Epoch: [768][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 3.828 (3.351)\n",
      "Epoch: [768][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 5.084 (3.501)\n",
      "Epoch: [768][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.989 (3.646)\n",
      "Epoch: [768][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.187 (3.706)\n",
      "Epoch: [768][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.207 (3.874)\n",
      "Val: [0/9]\tTime  0.596 ( 0.596)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #768: Train loss [3.8663]; Val loss: MSE [1.9194], L1 [0.5992], G-Mean [0.2599]\n",
      "Epoch: [769][ 0/65]\tTime   0.56 (  0.56)\tData 0.5501 (0.5501)\tLoss (MSE) 4.746 (4.746)\n",
      "Epoch: [769][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 3.695 (3.783)\n",
      "Epoch: [769][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 4.429 (3.978)\n",
      "Epoch: [769][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.984 (4.207)\n",
      "Epoch: [769][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.875 (4.051)\n",
      "Epoch: [769][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.988 (3.940)\n",
      "Epoch: [769][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.561 (3.852)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #769: Train loss [3.8455]; Val loss: MSE [1.9203], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [770][ 0/65]\tTime   0.56 (  0.56)\tData 0.5506 (0.5506)\tLoss (MSE) 3.343 (3.343)\n",
      "Epoch: [770][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 4.552 (3.651)\n",
      "Epoch: [770][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 2.648 (4.186)\n",
      "Epoch: [770][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.188 (4.108)\n",
      "Epoch: [770][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.421 (4.082)\n",
      "Epoch: [770][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.362 (4.004)\n",
      "Epoch: [770][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.583 (3.854)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.156\tL1 1.403\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #770: Train loss [3.8303]; Val loss: MSE [1.9208], L1 [0.5982], G-Mean [0.2596]\n",
      "Epoch: [771][ 0/65]\tTime   0.56 (  0.56)\tData 0.5598 (0.5598)\tLoss (MSE) 2.563 (2.563)\n",
      "Epoch: [771][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0607)\tLoss (MSE) 5.316 (3.881)\n",
      "Epoch: [771][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0318)\tLoss (MSE) 3.427 (4.237)\n",
      "Epoch: [771][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0216)\tLoss (MSE) 3.084 (4.100)\n",
      "Epoch: [771][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 4.220 (3.941)\n",
      "Epoch: [771][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 4.077 (3.804)\n",
      "Epoch: [771][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 7.344 (3.781)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #771: Train loss [3.8201]; Val loss: MSE [1.9204], L1 [0.5985], G-Mean [0.2600]\n",
      "Epoch: [772][ 0/65]\tTime   0.57 (  0.57)\tData 0.5583 (0.5583)\tLoss (MSE) 4.395 (4.395)\n",
      "Epoch: [772][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0583)\tLoss (MSE) 5.022 (4.248)\n",
      "Epoch: [772][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.879 (3.881)\n",
      "Epoch: [772][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 2.630 (3.769)\n",
      "Epoch: [772][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.469 (3.702)\n",
      "Epoch: [772][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.921 (3.744)\n",
      "Epoch: [772][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.720 (3.765)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #772: Train loss [3.7992]; Val loss: MSE [1.9202], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [773][ 0/65]\tTime   0.56 (  0.56)\tData 0.5512 (0.5512)\tLoss (MSE) 4.848 (4.848)\n",
      "Epoch: [773][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0578)\tLoss (MSE) 7.092 (3.868)\n",
      "Epoch: [773][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 2.437 (3.680)\n",
      "Epoch: [773][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 2.656 (3.769)\n",
      "Epoch: [773][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.469 (3.808)\n",
      "Epoch: [773][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.337 (3.816)\n",
      "Epoch: [773][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.988 (3.839)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #773: Train loss [3.8226]; Val loss: MSE [1.9200], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [774][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 5.031 (5.031)\n",
      "Epoch: [774][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 6.008 (4.652)\n",
      "Epoch: [774][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 7.025 (4.200)\n",
      "Epoch: [774][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 3.420 (4.027)\n",
      "Epoch: [774][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 2.374 (4.128)\n",
      "Epoch: [774][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.551 (4.086)\n",
      "Epoch: [774][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.796 (4.007)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #774: Train loss [3.9640]; Val loss: MSE [1.9199], L1 [0.5988], G-Mean [0.2608]\n",
      "Epoch: [775][ 0/65]\tTime   0.57 (  0.57)\tData 0.5649 (0.5649)\tLoss (MSE) 4.564 (4.564)\n",
      "Epoch: [775][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0556)\tLoss (MSE) 3.506 (4.872)\n",
      "Epoch: [775][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0291)\tLoss (MSE) 3.116 (4.643)\n",
      "Epoch: [775][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.646 (4.155)\n",
      "Epoch: [775][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 2.252 (4.018)\n",
      "Epoch: [775][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 1.959 (3.879)\n",
      "Epoch: [775][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.789 (3.870)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.318\tL1 1.017\tG-Mean 0.870\n",
      " * Median: MSE 2.158\tL1 1.403\tG-Mean 1.346\n",
      " * Low: MSE 0.095\tL1 0.224\tG-Mean 0.204\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #775: Train loss [3.8594]; Val loss: MSE [1.9209], L1 [0.5981], G-Mean [0.2598]\n",
      "Epoch: [776][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 3.587 (3.587)\n",
      "Epoch: [776][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0573)\tLoss (MSE) 2.849 (3.987)\n",
      "Epoch: [776][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 2.734 (3.583)\n",
      "Epoch: [776][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 6.779 (3.754)\n",
      "Epoch: [776][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.282 (3.699)\n",
      "Epoch: [776][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 5.245 (3.781)\n",
      "Epoch: [776][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.897 (3.805)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #776: Train loss [3.8720]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [777][ 0/65]\tTime   0.57 (  0.57)\tData 0.5666 (0.5666)\tLoss (MSE) 5.268 (5.268)\n",
      "Epoch: [777][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 3.750 (4.192)\n",
      "Epoch: [777][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 3.198 (3.509)\n",
      "Epoch: [777][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.768 (3.476)\n",
      "Epoch: [777][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.784 (3.536)\n",
      "Epoch: [777][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.605 (3.727)\n",
      "Epoch: [777][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.698 (3.778)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #777: Train loss [3.7971]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2600]\n",
      "Epoch: [778][ 0/65]\tTime   0.56 (  0.56)\tData 0.5495 (0.5495)\tLoss (MSE) 6.926 (6.926)\n",
      "Epoch: [778][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0578)\tLoss (MSE) 5.430 (3.765)\n",
      "Epoch: [778][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 3.039 (4.137)\n",
      "Epoch: [778][30/65]\tTime   0.00 (  0.03)\tData 0.0001 (0.0205)\tLoss (MSE) 2.353 (4.002)\n",
      "Epoch: [778][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.984 (3.869)\n",
      "Epoch: [778][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.434 (3.828)\n",
      "Epoch: [778][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.639 (3.786)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #778: Train loss [3.8011]; Val loss: MSE [1.9204], L1 [0.5983], G-Mean [0.2594]\n",
      "Epoch: [779][ 0/65]\tTime   0.63 (  0.63)\tData 0.6067 (0.6067)\tLoss (MSE) 4.736 (4.736)\n",
      "Epoch: [779][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0578)\tLoss (MSE) 2.400 (4.711)\n",
      "Epoch: [779][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 5.691 (4.297)\n",
      "Epoch: [779][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 1.971 (4.113)\n",
      "Epoch: [779][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.906 (3.903)\n",
      "Epoch: [779][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.818 (3.883)\n",
      "Epoch: [779][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0105)\tLoss (MSE) 3.016 (3.842)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #779: Train loss [3.8525]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [780][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 5.152 (5.152)\n",
      "Epoch: [780][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0591)\tLoss (MSE) 2.775 (3.722)\n",
      "Epoch: [780][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0310)\tLoss (MSE) 3.495 (4.137)\n",
      "Epoch: [780][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0210)\tLoss (MSE) 2.698 (3.829)\n",
      "Epoch: [780][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 2.444 (3.876)\n",
      "Epoch: [780][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.610 (3.868)\n",
      "Epoch: [780][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.249 (3.816)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #780: Train loss [3.8220]; Val loss: MSE [1.9197], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [781][ 0/65]\tTime   0.56 (  0.56)\tData 0.5498 (0.5498)\tLoss (MSE) 4.281 (4.281)\n",
      "Epoch: [781][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 4.052 (3.616)\n",
      "Epoch: [781][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 2.014 (3.629)\n",
      "Epoch: [781][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.670 (3.831)\n",
      "Epoch: [781][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.717 (3.794)\n",
      "Epoch: [781][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 4.814 (3.902)\n",
      "Epoch: [781][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.901 (3.887)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #781: Train loss [3.8164]; Val loss: MSE [1.9194], L1 [0.5992], G-Mean [0.2597]\n",
      "Epoch: [782][ 0/65]\tTime   0.57 (  0.57)\tData 0.5672 (0.5672)\tLoss (MSE) 5.431 (5.431)\n",
      "Epoch: [782][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0565)\tLoss (MSE) 3.929 (3.880)\n",
      "Epoch: [782][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 2.337 (3.831)\n",
      "Epoch: [782][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.359 (3.974)\n",
      "Epoch: [782][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 4.223 (3.935)\n",
      "Epoch: [782][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.322 (3.873)\n",
      "Epoch: [782][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 6.408 (3.874)\n",
      "Val: [0/9]\tTime  0.574 ( 0.574)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #782: Train loss [3.8222]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [783][ 0/65]\tTime   0.69 (  0.69)\tData 0.6803 (0.6803)\tLoss (MSE) 2.638 (2.638)\n",
      "Epoch: [783][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0669)\tLoss (MSE) 4.341 (3.391)\n",
      "Epoch: [783][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0351)\tLoss (MSE) 3.828 (4.119)\n",
      "Epoch: [783][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0238)\tLoss (MSE) 4.232 (4.119)\n",
      "Epoch: [783][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 3.835 (3.971)\n",
      "Epoch: [783][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.751 (3.907)\n",
      "Epoch: [783][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.214 (3.800)\n",
      "Val: [0/9]\tTime  0.623 ( 0.623)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #783: Train loss [3.7120]; Val loss: MSE [1.9197], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [784][ 0/65]\tTime   0.56 (  0.56)\tData 0.5542 (0.5542)\tLoss (MSE) 7.227 (7.227)\n",
      "Epoch: [784][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0574)\tLoss (MSE) 2.477 (3.884)\n",
      "Epoch: [784][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 4.437 (4.054)\n",
      "Epoch: [784][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 4.112 (4.137)\n",
      "Epoch: [784][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.536 (4.025)\n",
      "Epoch: [784][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.591 (4.028)\n",
      "Epoch: [784][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.644 (3.859)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #784: Train loss [3.8287]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2599]\n",
      "Epoch: [785][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 2.078 (2.078)\n",
      "Epoch: [785][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 2.930 (3.478)\n",
      "Epoch: [785][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.965 (3.418)\n",
      "Epoch: [785][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 1.941 (3.514)\n",
      "Epoch: [785][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 5.918 (3.605)\n",
      "Epoch: [785][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.326 (3.624)\n",
      "Epoch: [785][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.926 (3.883)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #785: Train loss [3.8403]; Val loss: MSE [1.9201], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [786][ 0/65]\tTime   0.56 (  0.56)\tData 0.5570 (0.5570)\tLoss (MSE) 5.480 (5.480)\n",
      "Epoch: [786][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 3.186 (3.643)\n",
      "Epoch: [786][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 5.251 (3.759)\n",
      "Epoch: [786][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.072 (3.820)\n",
      "Epoch: [786][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 6.381 (3.676)\n",
      "Epoch: [786][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 5.009 (3.775)\n",
      "Epoch: [786][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.642 (3.765)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #786: Train loss [3.8017]; Val loss: MSE [1.9198], L1 [0.5990], G-Mean [0.2603]\n",
      "Epoch: [787][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 2.419 (2.419)\n",
      "Epoch: [787][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0570)\tLoss (MSE) 6.551 (3.593)\n",
      "Epoch: [787][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0299)\tLoss (MSE) 2.039 (3.957)\n",
      "Epoch: [787][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 4.470 (3.887)\n",
      "Epoch: [787][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.523 (3.742)\n",
      "Epoch: [787][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.695 (3.745)\n",
      "Epoch: [787][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.870 (3.826)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #787: Train loss [3.8165]; Val loss: MSE [1.9204], L1 [0.5985], G-Mean [0.2600]\n",
      "Epoch: [788][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 4.616 (4.616)\n",
      "Epoch: [788][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0581)\tLoss (MSE) 2.408 (4.411)\n",
      "Epoch: [788][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 2.401 (3.931)\n",
      "Epoch: [788][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 6.125 (4.104)\n",
      "Epoch: [788][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.344 (4.083)\n",
      "Epoch: [788][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.717 (3.969)\n",
      "Epoch: [788][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 5.224 (3.875)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #788: Train loss [3.8424]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2599]\n",
      "Epoch: [789][ 0/65]\tTime   0.62 (  0.62)\tData 0.6034 (0.6034)\tLoss (MSE) 3.892 (3.892)\n",
      "Epoch: [789][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 5.438 (3.903)\n",
      "Epoch: [789][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 2.094 (3.576)\n",
      "Epoch: [789][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 6.145 (3.950)\n",
      "Epoch: [789][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.485 (3.776)\n",
      "Epoch: [789][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.058 (3.700)\n",
      "Epoch: [789][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.233 (3.770)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #789: Train loss [3.7621]; Val loss: MSE [1.9204], L1 [0.5984], G-Mean [0.2599]\n",
      "Epoch: [790][ 0/65]\tTime   0.57 (  0.57)\tData 0.5594 (0.5594)\tLoss (MSE) 4.975 (4.975)\n",
      "Epoch: [790][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0542)\tLoss (MSE) 2.899 (3.740)\n",
      "Epoch: [790][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 5.425 (3.755)\n",
      "Epoch: [790][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.276 (3.990)\n",
      "Epoch: [790][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.330 (3.859)\n",
      "Epoch: [790][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.510 (3.818)\n",
      "Epoch: [790][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.196 (3.897)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #790: Train loss [3.8883]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [791][ 0/65]\tTime   0.56 (  0.56)\tData 0.5500 (0.5500)\tLoss (MSE) 4.872 (4.872)\n",
      "Epoch: [791][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 2.857 (4.078)\n",
      "Epoch: [791][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 7.003 (4.168)\n",
      "Epoch: [791][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 2.777 (3.916)\n",
      "Epoch: [791][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 6.958 (3.891)\n",
      "Epoch: [791][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 5.256 (3.877)\n",
      "Epoch: [791][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.004 (3.838)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #791: Train loss [3.8638]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [792][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 2.671 (2.671)\n",
      "Epoch: [792][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 2.666 (4.225)\n",
      "Epoch: [792][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 6.195 (4.202)\n",
      "Epoch: [792][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 4.184 (3.939)\n",
      "Epoch: [792][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.959 (3.930)\n",
      "Epoch: [792][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.236 (3.868)\n",
      "Epoch: [792][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.408 (3.913)\n",
      "Val: [0/9]\tTime  0.565 ( 0.565)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #792: Train loss [3.8957]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [793][ 0/65]\tTime   0.57 (  0.57)\tData 0.5639 (0.5639)\tLoss (MSE) 2.283 (2.283)\n",
      "Epoch: [793][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0527)\tLoss (MSE) 5.438 (3.364)\n",
      "Epoch: [793][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 3.689 (3.766)\n",
      "Epoch: [793][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 3.701 (3.667)\n",
      "Epoch: [793][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.674 (3.679)\n",
      "Epoch: [793][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 4.886 (3.662)\n",
      "Epoch: [793][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.533 (3.712)\n",
      "Val: [0/9]\tTime  0.566 ( 0.566)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #793: Train loss [3.7603]; Val loss: MSE [1.9193], L1 [0.5989], G-Mean [0.2606]\n",
      "Epoch: [794][ 0/65]\tTime   0.56 (  0.56)\tData 0.5540 (0.5540)\tLoss (MSE) 3.632 (3.632)\n",
      "Epoch: [794][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 2.221 (3.895)\n",
      "Epoch: [794][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.480 (3.651)\n",
      "Epoch: [794][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.845 (3.677)\n",
      "Epoch: [794][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.909 (3.654)\n",
      "Epoch: [794][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.431 (3.745)\n",
      "Epoch: [794][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.768 (3.726)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #794: Train loss [3.7475]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [795][ 0/65]\tTime   0.56 (  0.56)\tData 0.5548 (0.5548)\tLoss (MSE) 2.317 (2.317)\n",
      "Epoch: [795][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0567)\tLoss (MSE) 2.857 (2.741)\n",
      "Epoch: [795][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0297)\tLoss (MSE) 4.171 (3.557)\n",
      "Epoch: [795][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 6.278 (3.878)\n",
      "Epoch: [795][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 5.981 (3.892)\n",
      "Epoch: [795][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.407 (3.805)\n",
      "Epoch: [795][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.595 (3.809)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #795: Train loss [3.8794]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [796][ 0/65]\tTime   0.56 (  0.56)\tData 0.5556 (0.5556)\tLoss (MSE) 2.409 (2.409)\n",
      "Epoch: [796][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0555)\tLoss (MSE) 3.479 (3.590)\n",
      "Epoch: [796][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.520 (3.408)\n",
      "Epoch: [796][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 5.151 (3.618)\n",
      "Epoch: [796][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 1.845 (3.847)\n",
      "Epoch: [796][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 5.200 (3.803)\n",
      "Epoch: [796][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.380 (3.777)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.325\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #796: Train loss [3.7571]; Val loss: MSE [1.9191], L1 [0.5992], G-Mean [0.2600]\n",
      "Epoch: [797][ 0/65]\tTime   0.56 (  0.56)\tData 0.5560 (0.5560)\tLoss (MSE) 4.215 (4.215)\n",
      "Epoch: [797][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 3.698 (3.425)\n",
      "Epoch: [797][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 4.116 (3.630)\n",
      "Epoch: [797][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 4.045 (3.642)\n",
      "Epoch: [797][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.196 (3.831)\n",
      "Epoch: [797][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.539 (3.943)\n",
      "Epoch: [797][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.092 (3.826)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #797: Train loss [3.8383]; Val loss: MSE [1.9199], L1 [0.5986], G-Mean [0.2606]\n",
      "Epoch: [798][ 0/65]\tTime   0.61 (  0.61)\tData 0.6031 (0.6031)\tLoss (MSE) 2.992 (2.992)\n",
      "Epoch: [798][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0612)\tLoss (MSE) 1.895 (3.515)\n",
      "Epoch: [798][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0321)\tLoss (MSE) 4.349 (3.598)\n",
      "Epoch: [798][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0217)\tLoss (MSE) 3.300 (3.656)\n",
      "Epoch: [798][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0164)\tLoss (MSE) 4.409 (3.706)\n",
      "Epoch: [798][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 2.571 (3.734)\n",
      "Epoch: [798][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.067 (3.795)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #798: Train loss [3.8225]; Val loss: MSE [1.9193], L1 [0.5991], G-Mean [0.2604]\n",
      "Epoch: [799][ 0/65]\tTime   0.56 (  0.56)\tData 0.5475 (0.5475)\tLoss (MSE) 1.765 (1.765)\n",
      "Epoch: [799][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0543)\tLoss (MSE) 4.265 (3.134)\n",
      "Epoch: [799][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 5.287 (3.344)\n",
      "Epoch: [799][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.735 (3.504)\n",
      "Epoch: [799][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.256 (3.760)\n",
      "Epoch: [799][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.963 (3.809)\n",
      "Epoch: [799][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.924 (3.787)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #799: Train loss [3.7954]; Val loss: MSE [1.9193], L1 [0.5991], G-Mean [0.2604]\n",
      "Epoch: [800][ 0/65]\tTime   0.56 (  0.56)\tData 0.5561 (0.5561)\tLoss (MSE) 4.759 (4.759)\n",
      "Epoch: [800][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 4.126 (3.324)\n",
      "Epoch: [800][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 4.023 (3.494)\n",
      "Epoch: [800][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.002 (3.619)\n",
      "Epoch: [800][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.459 (3.885)\n",
      "Epoch: [800][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 2.961 (3.894)\n",
      "Epoch: [800][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.960 (3.942)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #800: Train loss [3.8900]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [801][ 0/65]\tTime   0.57 (  0.57)\tData 0.5597 (0.5597)\tLoss (MSE) 2.668 (2.668)\n",
      "Epoch: [801][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 1.944 (3.737)\n",
      "Epoch: [801][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.029 (3.811)\n",
      "Epoch: [801][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 4.143 (3.746)\n",
      "Epoch: [801][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.710 (3.704)\n",
      "Epoch: [801][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 5.250 (3.853)\n",
      "Epoch: [801][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.185 (3.803)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #801: Train loss [3.7990]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [802][ 0/65]\tTime   0.55 (  0.55)\tData 0.5452 (0.5452)\tLoss (MSE) 4.165 (4.165)\n",
      "Epoch: [802][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 4.663 (4.263)\n",
      "Epoch: [802][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0295)\tLoss (MSE) 2.434 (4.017)\n",
      "Epoch: [802][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.488 (3.904)\n",
      "Epoch: [802][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.731 (3.769)\n",
      "Epoch: [802][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.820 (3.731)\n",
      "Epoch: [802][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.709 (3.738)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #802: Train loss [3.7796]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [803][ 0/65]\tTime   0.60 (  0.60)\tData 0.5796 (0.5796)\tLoss (MSE) 3.026 (3.026)\n",
      "Epoch: [803][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0548)\tLoss (MSE) 2.318 (3.893)\n",
      "Epoch: [803][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 2.931 (3.869)\n",
      "Epoch: [803][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.150 (4.131)\n",
      "Epoch: [803][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.482 (3.960)\n",
      "Epoch: [803][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.947 (3.947)\n",
      "Epoch: [803][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.677 (3.929)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #803: Train loss [3.8696]; Val loss: MSE [1.9196], L1 [0.5986], G-Mean [0.2607]\n",
      "Epoch: [804][ 0/65]\tTime   0.55 (  0.55)\tData 0.5481 (0.5481)\tLoss (MSE) 2.168 (2.168)\n",
      "Epoch: [804][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0509)\tLoss (MSE) 3.825 (3.681)\n",
      "Epoch: [804][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 2.657 (3.431)\n",
      "Epoch: [804][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 2.234 (3.605)\n",
      "Epoch: [804][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.987 (3.633)\n",
      "Epoch: [804][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 4.597 (3.756)\n",
      "Epoch: [804][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.097 (3.784)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #804: Train loss [3.8112]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [805][ 0/65]\tTime   0.61 (  0.61)\tData 0.5964 (0.5964)\tLoss (MSE) 3.139 (3.139)\n",
      "Epoch: [805][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0560)\tLoss (MSE) 4.738 (4.203)\n",
      "Epoch: [805][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 5.198 (3.797)\n",
      "Epoch: [805][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 5.356 (3.724)\n",
      "Epoch: [805][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.062 (3.812)\n",
      "Epoch: [805][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.746 (3.790)\n",
      "Epoch: [805][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.905 (3.747)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #805: Train loss [3.7751]; Val loss: MSE [1.9195], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [806][ 0/65]\tTime   0.57 (  0.57)\tData 0.5617 (0.5617)\tLoss (MSE) 5.609 (5.609)\n",
      "Epoch: [806][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 3.308 (3.916)\n",
      "Epoch: [806][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 3.509 (3.724)\n",
      "Epoch: [806][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 2.685 (3.825)\n",
      "Epoch: [806][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 6.169 (3.896)\n",
      "Epoch: [806][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 4.254 (3.957)\n",
      "Epoch: [806][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 5.001 (3.875)\n",
      "Val: [0/9]\tTime  0.601 ( 0.601)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #806: Train loss [3.8003]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [807][ 0/65]\tTime   0.57 (  0.57)\tData 0.5627 (0.5627)\tLoss (MSE) 5.092 (5.092)\n",
      "Epoch: [807][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0533)\tLoss (MSE) 3.839 (3.335)\n",
      "Epoch: [807][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 1.795 (3.225)\n",
      "Epoch: [807][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.534 (3.515)\n",
      "Epoch: [807][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.297 (3.421)\n",
      "Epoch: [807][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 4.486 (3.646)\n",
      "Epoch: [807][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 3.039 (3.790)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #807: Train loss [3.7995]; Val loss: MSE [1.9193], L1 [0.5991], G-Mean [0.2606]\n",
      "Epoch: [808][ 0/65]\tTime   0.56 (  0.56)\tData 0.5580 (0.5580)\tLoss (MSE) 2.717 (2.717)\n",
      "Epoch: [808][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 2.778 (3.664)\n",
      "Epoch: [808][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 4.077 (3.773)\n",
      "Epoch: [808][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.545 (3.843)\n",
      "Epoch: [808][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.485 (3.842)\n",
      "Epoch: [808][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.677 (3.763)\n",
      "Epoch: [808][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 7.044 (3.863)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #808: Train loss [3.8374]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [809][ 0/65]\tTime   0.56 (  0.56)\tData 0.5570 (0.5570)\tLoss (MSE) 2.584 (2.584)\n",
      "Epoch: [809][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.385 (3.637)\n",
      "Epoch: [809][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.478 (3.616)\n",
      "Epoch: [809][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 4.281 (3.962)\n",
      "Epoch: [809][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.248 (3.910)\n",
      "Epoch: [809][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.323 (3.923)\n",
      "Epoch: [809][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.166 (3.884)\n",
      "Val: [0/9]\tTime  0.555 ( 0.555)\tLoss (MSE) 2.051 (2.051)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #809: Train loss [3.8108]; Val loss: MSE [1.9191], L1 [0.5991], G-Mean [0.2603]\n",
      "Epoch: [810][ 0/65]\tTime   0.56 (  0.56)\tData 0.5544 (0.5544)\tLoss (MSE) 3.363 (3.363)\n",
      "Epoch: [810][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0537)\tLoss (MSE) 2.000 (4.008)\n",
      "Epoch: [810][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 3.370 (3.764)\n",
      "Epoch: [810][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 1.809 (3.838)\n",
      "Epoch: [810][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 5.460 (3.716)\n",
      "Epoch: [810][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.301 (3.834)\n",
      "Epoch: [810][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.808 (3.793)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #810: Train loss [3.8161]; Val loss: MSE [1.9202], L1 [0.5984], G-Mean [0.2599]\n",
      "Epoch: [811][ 0/65]\tTime   0.57 (  0.57)\tData 0.5609 (0.5609)\tLoss (MSE) 4.819 (4.819)\n",
      "Epoch: [811][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.030 (3.587)\n",
      "Epoch: [811][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.652 (3.928)\n",
      "Epoch: [811][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 5.373 (3.881)\n",
      "Epoch: [811][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 5.401 (3.916)\n",
      "Epoch: [811][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.023 (3.787)\n",
      "Epoch: [811][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.800 (3.772)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #811: Train loss [3.7870]; Val loss: MSE [1.9202], L1 [0.5984], G-Mean [0.2591]\n",
      "Epoch: [812][ 0/65]\tTime   0.55 (  0.55)\tData 0.5418 (0.5418)\tLoss (MSE) 4.598 (4.598)\n",
      "Epoch: [812][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0589)\tLoss (MSE) 3.249 (3.881)\n",
      "Epoch: [812][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 4.504 (3.666)\n",
      "Epoch: [812][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 1.907 (3.691)\n",
      "Epoch: [812][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 5.325 (3.709)\n",
      "Epoch: [812][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 1.619 (3.666)\n",
      "Epoch: [812][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 3.570 (3.821)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #812: Train loss [3.8158]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [813][ 0/65]\tTime   0.58 (  0.58)\tData 0.5685 (0.5685)\tLoss (MSE) 2.800 (2.800)\n",
      "Epoch: [813][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 2.584 (3.464)\n",
      "Epoch: [813][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 5.088 (3.734)\n",
      "Epoch: [813][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.582 (3.683)\n",
      "Epoch: [813][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 5.611 (3.824)\n",
      "Epoch: [813][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 1.844 (3.700)\n",
      "Epoch: [813][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 6.358 (3.820)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #813: Train loss [3.8232]; Val loss: MSE [1.9192], L1 [0.5991], G-Mean [0.2607]\n",
      "Epoch: [814][ 0/65]\tTime   0.56 (  0.56)\tData 0.5494 (0.5494)\tLoss (MSE) 3.480 (3.480)\n",
      "Epoch: [814][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.672 (3.655)\n",
      "Epoch: [814][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 6.581 (3.755)\n",
      "Epoch: [814][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.786 (3.907)\n",
      "Epoch: [814][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.892 (3.718)\n",
      "Epoch: [814][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0113)\tLoss (MSE) 4.563 (3.742)\n",
      "Epoch: [814][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.497 (3.795)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #814: Train loss [3.8060]; Val loss: MSE [1.9200], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [815][ 0/65]\tTime   0.55 (  0.55)\tData 0.5468 (0.5468)\tLoss (MSE) 3.493 (3.493)\n",
      "Epoch: [815][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0513)\tLoss (MSE) 4.586 (3.801)\n",
      "Epoch: [815][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.191 (3.549)\n",
      "Epoch: [815][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.542 (3.714)\n",
      "Epoch: [815][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.599 (3.821)\n",
      "Epoch: [815][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 4.327 (3.838)\n",
      "Epoch: [815][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.376 (3.779)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #815: Train loss [3.8012]; Val loss: MSE [1.9198], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [816][ 0/65]\tTime   0.55 (  0.55)\tData 0.5488 (0.5488)\tLoss (MSE) 5.556 (5.556)\n",
      "Epoch: [816][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 4.130 (4.353)\n",
      "Epoch: [816][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 4.396 (4.113)\n",
      "Epoch: [816][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.945 (3.983)\n",
      "Epoch: [816][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.920 (3.852)\n",
      "Epoch: [816][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 3.793 (3.796)\n",
      "Epoch: [816][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.538 (3.845)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #816: Train loss [3.8457]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [817][ 0/65]\tTime   0.57 (  0.57)\tData 0.5592 (0.5592)\tLoss (MSE) 4.452 (4.452)\n",
      "Epoch: [817][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0526)\tLoss (MSE) 3.262 (3.590)\n",
      "Epoch: [817][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 3.970 (3.531)\n",
      "Epoch: [817][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 3.876 (3.559)\n",
      "Epoch: [817][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.180 (3.496)\n",
      "Epoch: [817][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.637 (3.501)\n",
      "Epoch: [817][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.323 (3.783)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #817: Train loss [3.8023]; Val loss: MSE [1.9193], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [818][ 0/65]\tTime   0.55 (  0.55)\tData 0.5461 (0.5461)\tLoss (MSE) 3.130 (3.130)\n",
      "Epoch: [818][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0538)\tLoss (MSE) 6.243 (4.213)\n",
      "Epoch: [818][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.468 (3.950)\n",
      "Epoch: [818][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.986 (3.763)\n",
      "Epoch: [818][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.186 (3.788)\n",
      "Epoch: [818][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 2.508 (3.644)\n",
      "Epoch: [818][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 4.106 (3.805)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #818: Train loss [3.8223]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [819][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 2.971 (2.971)\n",
      "Epoch: [819][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 4.634 (4.457)\n",
      "Epoch: [819][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.299 (4.536)\n",
      "Epoch: [819][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.375 (4.049)\n",
      "Epoch: [819][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.882 (3.869)\n",
      "Epoch: [819][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.894 (3.886)\n",
      "Epoch: [819][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.964 (3.861)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #819: Train loss [3.8093]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [820][ 0/65]\tTime   0.56 (  0.56)\tData 0.5579 (0.5579)\tLoss (MSE) 2.803 (2.803)\n",
      "Epoch: [820][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0536)\tLoss (MSE) 7.363 (3.874)\n",
      "Epoch: [820][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 2.841 (4.003)\n",
      "Epoch: [820][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 2.312 (3.977)\n",
      "Epoch: [820][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.498 (3.785)\n",
      "Epoch: [820][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.108 (3.835)\n",
      "Epoch: [820][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.318 (3.819)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #820: Train loss [3.8070]; Val loss: MSE [1.9196], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [821][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 2.305 (2.305)\n",
      "Epoch: [821][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 3.415 (3.815)\n",
      "Epoch: [821][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.308 (3.582)\n",
      "Epoch: [821][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.596 (3.694)\n",
      "Epoch: [821][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.636 (3.756)\n",
      "Epoch: [821][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 2.984 (3.740)\n",
      "Epoch: [821][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.506 (3.749)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #821: Train loss [3.7810]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [822][ 0/65]\tTime   0.60 (  0.60)\tData 0.5925 (0.5925)\tLoss (MSE) 3.200 (3.200)\n",
      "Epoch: [822][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0554)\tLoss (MSE) 4.348 (3.594)\n",
      "Epoch: [822][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 2.094 (3.650)\n",
      "Epoch: [822][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 3.573 (3.875)\n",
      "Epoch: [822][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 3.717 (3.824)\n",
      "Epoch: [822][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 5.361 (3.780)\n",
      "Epoch: [822][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.179 (3.738)\n",
      "Val: [0/9]\tTime  0.611 ( 0.611)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #822: Train loss [3.7695]; Val loss: MSE [1.9195], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [823][ 0/65]\tTime   0.56 (  0.56)\tData 0.5540 (0.5540)\tLoss (MSE) 5.210 (5.210)\n",
      "Epoch: [823][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0585)\tLoss (MSE) 3.263 (4.849)\n",
      "Epoch: [823][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0306)\tLoss (MSE) 2.460 (4.451)\n",
      "Epoch: [823][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0208)\tLoss (MSE) 3.001 (4.140)\n",
      "Epoch: [823][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 4.226 (4.108)\n",
      "Epoch: [823][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 2.944 (3.948)\n",
      "Epoch: [823][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 6.624 (3.925)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #823: Train loss [3.8932]; Val loss: MSE [1.9202], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [824][ 0/65]\tTime   0.56 (  0.56)\tData 0.5518 (0.5518)\tLoss (MSE) 2.142 (2.142)\n",
      "Epoch: [824][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0546)\tLoss (MSE) 2.067 (3.464)\n",
      "Epoch: [824][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 2.357 (3.481)\n",
      "Epoch: [824][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 5.648 (3.602)\n",
      "Epoch: [824][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.781 (3.618)\n",
      "Epoch: [824][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 2.861 (3.781)\n",
      "Epoch: [824][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.618 (3.846)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #824: Train loss [3.8287]; Val loss: MSE [1.9201], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [825][ 0/65]\tTime   0.56 (  0.56)\tData 0.5575 (0.5575)\tLoss (MSE) 2.877 (2.877)\n",
      "Epoch: [825][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0583)\tLoss (MSE) 2.753 (3.679)\n",
      "Epoch: [825][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0305)\tLoss (MSE) 2.180 (3.705)\n",
      "Epoch: [825][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 5.591 (4.007)\n",
      "Epoch: [825][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.222 (3.935)\n",
      "Epoch: [825][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.307 (3.902)\n",
      "Epoch: [825][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.520 (3.833)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #825: Train loss [3.8044]; Val loss: MSE [1.9198], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [826][ 0/65]\tTime   0.56 (  0.56)\tData 0.5500 (0.5500)\tLoss (MSE) 2.213 (2.213)\n",
      "Epoch: [826][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0591)\tLoss (MSE) 4.115 (3.174)\n",
      "Epoch: [826][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 6.646 (3.992)\n",
      "Epoch: [826][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 4.943 (3.867)\n",
      "Epoch: [826][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 2.834 (3.748)\n",
      "Epoch: [826][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.772 (3.729)\n",
      "Epoch: [826][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 4.404 (3.811)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #826: Train loss [3.7537]; Val loss: MSE [1.9202], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [827][ 0/65]\tTime   0.56 (  0.56)\tData 0.5551 (0.5551)\tLoss (MSE) 1.974 (1.974)\n",
      "Epoch: [827][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0596)\tLoss (MSE) 2.670 (3.453)\n",
      "Epoch: [827][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 4.274 (3.576)\n",
      "Epoch: [827][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 3.170 (3.571)\n",
      "Epoch: [827][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.025 (3.482)\n",
      "Epoch: [827][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 6.310 (3.760)\n",
      "Epoch: [827][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.320 (3.769)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #827: Train loss [3.8125]; Val loss: MSE [1.9197], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [828][ 0/65]\tTime   0.56 (  0.56)\tData 0.5502 (0.5502)\tLoss (MSE) 2.832 (2.832)\n",
      "Epoch: [828][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0510)\tLoss (MSE) 3.395 (4.065)\n",
      "Epoch: [828][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 2.221 (3.991)\n",
      "Epoch: [828][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 3.550 (3.792)\n",
      "Epoch: [828][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.724 (3.868)\n",
      "Epoch: [828][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.970 (3.861)\n",
      "Epoch: [828][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 5.416 (3.836)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #828: Train loss [3.8431]; Val loss: MSE [1.9204], L1 [0.5985], G-Mean [0.2599]\n",
      "Epoch: [829][ 0/65]\tTime   0.56 (  0.56)\tData 0.5562 (0.5562)\tLoss (MSE) 4.621 (4.621)\n",
      "Epoch: [829][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0534)\tLoss (MSE) 5.206 (3.834)\n",
      "Epoch: [829][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0280)\tLoss (MSE) 2.392 (4.150)\n",
      "Epoch: [829][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 4.992 (4.079)\n",
      "Epoch: [829][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.082 (3.989)\n",
      "Epoch: [829][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 2.310 (3.946)\n",
      "Epoch: [829][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.560 (3.915)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #829: Train loss [3.8449]; Val loss: MSE [1.9202], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [830][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 3.048 (3.048)\n",
      "Epoch: [830][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0543)\tLoss (MSE) 5.284 (4.049)\n",
      "Epoch: [830][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 2.276 (3.851)\n",
      "Epoch: [830][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 4.687 (3.869)\n",
      "Epoch: [830][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.559 (3.819)\n",
      "Epoch: [830][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.034 (3.750)\n",
      "Epoch: [830][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.256 (3.901)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #830: Train loss [3.8634]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [831][ 0/65]\tTime   0.57 (  0.57)\tData 0.5647 (0.5647)\tLoss (MSE) 2.688 (2.688)\n",
      "Epoch: [831][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.088 (3.404)\n",
      "Epoch: [831][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 8.864 (4.230)\n",
      "Epoch: [831][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.929 (4.131)\n",
      "Epoch: [831][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.256 (4.008)\n",
      "Epoch: [831][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 5.337 (3.939)\n",
      "Epoch: [831][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.131 (3.875)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #831: Train loss [3.8114]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [832][ 0/65]\tTime   0.56 (  0.56)\tData 0.5548 (0.5548)\tLoss (MSE) 3.276 (3.276)\n",
      "Epoch: [832][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 2.785 (4.264)\n",
      "Epoch: [832][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 2.886 (4.018)\n",
      "Epoch: [832][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.823 (3.771)\n",
      "Epoch: [832][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.272 (3.793)\n",
      "Epoch: [832][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.105 (3.767)\n",
      "Epoch: [832][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.400 (3.787)\n",
      "Val: [0/9]\tTime  0.557 ( 0.557)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #832: Train loss [3.8253]; Val loss: MSE [1.9197], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [833][ 0/65]\tTime   0.57 (  0.57)\tData 0.5607 (0.5607)\tLoss (MSE) 3.971 (3.971)\n",
      "Epoch: [833][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.681 (3.539)\n",
      "Epoch: [833][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 2.796 (3.778)\n",
      "Epoch: [833][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.099 (3.836)\n",
      "Epoch: [833][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 6.160 (3.896)\n",
      "Epoch: [833][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.293 (3.806)\n",
      "Epoch: [833][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.197 (3.720)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #833: Train loss [3.7732]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [834][ 0/65]\tTime   0.56 (  0.56)\tData 0.5565 (0.5565)\tLoss (MSE) 2.724 (2.724)\n",
      "Epoch: [834][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0551)\tLoss (MSE) 2.424 (3.457)\n",
      "Epoch: [834][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.459 (3.877)\n",
      "Epoch: [834][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 4.777 (3.697)\n",
      "Epoch: [834][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 6.802 (3.761)\n",
      "Epoch: [834][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 7.960 (3.833)\n",
      "Epoch: [834][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 5.087 (3.737)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #834: Train loss [3.7592]; Val loss: MSE [1.9197], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [835][ 0/65]\tTime   0.56 (  0.56)\tData 0.5519 (0.5519)\tLoss (MSE) 3.567 (3.567)\n",
      "Epoch: [835][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 4.357 (4.428)\n",
      "Epoch: [835][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.801 (4.071)\n",
      "Epoch: [835][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.619 (3.824)\n",
      "Epoch: [835][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.257 (3.899)\n",
      "Epoch: [835][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.723 (4.005)\n",
      "Epoch: [835][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 2.760 (3.849)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #835: Train loss [3.8452]; Val loss: MSE [1.9198], L1 [0.5990], G-Mean [0.2603]\n",
      "Epoch: [836][ 0/65]\tTime   0.61 (  0.61)\tData 0.5923 (0.5923)\tLoss (MSE) 4.480 (4.480)\n",
      "Epoch: [836][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 5.326 (3.830)\n",
      "Epoch: [836][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0295)\tLoss (MSE) 3.853 (4.190)\n",
      "Epoch: [836][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0200)\tLoss (MSE) 3.763 (4.086)\n",
      "Epoch: [836][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.398 (3.979)\n",
      "Epoch: [836][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.080 (4.016)\n",
      "Epoch: [836][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.679 (3.887)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #836: Train loss [3.8581]; Val loss: MSE [1.9201], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [837][ 0/65]\tTime   0.57 (  0.57)\tData 0.5604 (0.5604)\tLoss (MSE) 5.129 (5.129)\n",
      "Epoch: [837][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0569)\tLoss (MSE) 2.933 (3.749)\n",
      "Epoch: [837][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 4.359 (3.673)\n",
      "Epoch: [837][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 3.182 (3.505)\n",
      "Epoch: [837][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 6.231 (3.568)\n",
      "Epoch: [837][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.288 (3.707)\n",
      "Epoch: [837][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 2.239 (3.813)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #837: Train loss [3.8230]; Val loss: MSE [1.9200], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [838][ 0/65]\tTime   0.56 (  0.56)\tData 0.5535 (0.5535)\tLoss (MSE) 2.469 (2.469)\n",
      "Epoch: [838][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 5.141 (3.252)\n",
      "Epoch: [838][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 2.825 (3.653)\n",
      "Epoch: [838][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.819 (3.714)\n",
      "Epoch: [838][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.740 (3.730)\n",
      "Epoch: [838][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.360 (3.811)\n",
      "Epoch: [838][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.630 (3.800)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #838: Train loss [3.7638]; Val loss: MSE [1.9200], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [839][ 0/65]\tTime   0.55 (  0.55)\tData 0.5470 (0.5470)\tLoss (MSE) 3.560 (3.560)\n",
      "Epoch: [839][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 3.751 (4.045)\n",
      "Epoch: [839][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 4.168 (4.023)\n",
      "Epoch: [839][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.525 (3.913)\n",
      "Epoch: [839][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.956 (3.867)\n",
      "Epoch: [839][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.744 (3.873)\n",
      "Epoch: [839][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.502 (3.835)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #839: Train loss [3.8202]; Val loss: MSE [1.9201], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [840][ 0/65]\tTime   0.56 (  0.56)\tData 0.5522 (0.5522)\tLoss (MSE) 3.106 (3.106)\n",
      "Epoch: [840][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0577)\tLoss (MSE) 4.254 (3.621)\n",
      "Epoch: [840][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0303)\tLoss (MSE) 7.053 (3.831)\n",
      "Epoch: [840][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0205)\tLoss (MSE) 3.717 (3.703)\n",
      "Epoch: [840][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.133 (3.651)\n",
      "Epoch: [840][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.211 (3.624)\n",
      "Epoch: [840][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 7.686 (3.665)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #840: Train loss [3.7526]; Val loss: MSE [1.9201], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [841][ 0/65]\tTime   0.55 (  0.55)\tData 0.5478 (0.5478)\tLoss (MSE) 7.151 (7.151)\n",
      "Epoch: [841][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0529)\tLoss (MSE) 2.480 (4.940)\n",
      "Epoch: [841][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 2.384 (4.442)\n",
      "Epoch: [841][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 2.934 (4.166)\n",
      "Epoch: [841][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.489 (3.918)\n",
      "Epoch: [841][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 3.297 (3.908)\n",
      "Epoch: [841][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.969 (3.840)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #841: Train loss [3.7996]; Val loss: MSE [1.9208], L1 [0.5985], G-Mean [0.2595]\n",
      "Epoch: [842][ 0/65]\tTime   0.55 (  0.55)\tData 0.5482 (0.5482)\tLoss (MSE) 3.378 (3.378)\n",
      "Epoch: [842][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0512)\tLoss (MSE) 6.204 (3.550)\n",
      "Epoch: [842][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 3.736 (3.629)\n",
      "Epoch: [842][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.136 (3.865)\n",
      "Epoch: [842][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.635 (4.016)\n",
      "Epoch: [842][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.991 (3.888)\n",
      "Epoch: [842][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.903 (3.849)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #842: Train loss [3.8502]; Val loss: MSE [1.9202], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [843][ 0/65]\tTime   0.56 (  0.56)\tData 0.5559 (0.5559)\tLoss (MSE) 4.214 (4.214)\n",
      "Epoch: [843][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 3.511 (4.054)\n",
      "Epoch: [843][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 3.217 (3.897)\n",
      "Epoch: [843][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.540 (4.033)\n",
      "Epoch: [843][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.684 (3.923)\n",
      "Epoch: [843][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.067 (3.801)\n",
      "Epoch: [843][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.121 (3.845)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #843: Train loss [3.7858]; Val loss: MSE [1.9207], L1 [0.5985], G-Mean [0.2595]\n",
      "Epoch: [844][ 0/65]\tTime   0.56 (  0.56)\tData 0.5577 (0.5577)\tLoss (MSE) 3.056 (3.056)\n",
      "Epoch: [844][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0588)\tLoss (MSE) 2.926 (3.516)\n",
      "Epoch: [844][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0308)\tLoss (MSE) 2.312 (3.417)\n",
      "Epoch: [844][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 3.175 (3.449)\n",
      "Epoch: [844][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.014 (3.533)\n",
      "Epoch: [844][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 5.538 (3.754)\n",
      "Epoch: [844][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.175 (3.857)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #844: Train loss [3.8089]; Val loss: MSE [1.9199], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [845][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 3.608 (3.608)\n",
      "Epoch: [845][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0566)\tLoss (MSE) 3.173 (4.058)\n",
      "Epoch: [845][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 3.591 (3.833)\n",
      "Epoch: [845][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 5.642 (3.749)\n",
      "Epoch: [845][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.973 (3.661)\n",
      "Epoch: [845][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 1.606 (3.682)\n",
      "Epoch: [845][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 8.970 (3.866)\n",
      "Val: [0/9]\tTime  0.682 ( 0.682)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #845: Train loss [3.8015]; Val loss: MSE [1.9206], L1 [0.5985], G-Mean [0.2599]\n",
      "Epoch: [846][ 0/65]\tTime   0.63 (  0.63)\tData 0.6244 (0.6244)\tLoss (MSE) 2.332 (2.332)\n",
      "Epoch: [846][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0588)\tLoss (MSE) 4.153 (4.340)\n",
      "Epoch: [846][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0308)\tLoss (MSE) 2.503 (3.840)\n",
      "Epoch: [846][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 3.919 (3.701)\n",
      "Epoch: [846][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.994 (3.803)\n",
      "Epoch: [846][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.900 (3.715)\n",
      "Epoch: [846][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.982 (3.718)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.921\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #846: Train loss [3.7927]; Val loss: MSE [1.9206], L1 [0.5984], G-Mean [0.2595]\n",
      "Epoch: [847][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 2.341 (2.341)\n",
      "Epoch: [847][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0516)\tLoss (MSE) 5.445 (4.186)\n",
      "Epoch: [847][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.903 (4.055)\n",
      "Epoch: [847][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.879 (3.978)\n",
      "Epoch: [847][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.845 (3.900)\n",
      "Epoch: [847][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.499 (3.896)\n",
      "Epoch: [847][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.375 (3.821)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #847: Train loss [3.8170]; Val loss: MSE [1.9200], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [848][ 0/65]\tTime   0.60 (  0.60)\tData 0.5813 (0.5813)\tLoss (MSE) 4.920 (4.920)\n",
      "Epoch: [848][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0569)\tLoss (MSE) 3.880 (3.315)\n",
      "Epoch: [848][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0298)\tLoss (MSE) 3.575 (3.654)\n",
      "Epoch: [848][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0202)\tLoss (MSE) 5.815 (3.864)\n",
      "Epoch: [848][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 4.923 (4.016)\n",
      "Epoch: [848][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.331 (4.034)\n",
      "Epoch: [848][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.367 (3.891)\n",
      "Val: [0/9]\tTime  0.560 ( 0.560)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #848: Train loss [3.8585]; Val loss: MSE [1.9199], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [849][ 0/65]\tTime   0.56 (  0.56)\tData 0.5577 (0.5577)\tLoss (MSE) 6.229 (6.229)\n",
      "Epoch: [849][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 3.801 (4.034)\n",
      "Epoch: [849][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 2.365 (4.032)\n",
      "Epoch: [849][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 7.192 (4.128)\n",
      "Epoch: [849][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.086 (4.133)\n",
      "Epoch: [849][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.160 (4.014)\n",
      "Epoch: [849][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.520 (3.867)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #849: Train loss [3.8548]; Val loss: MSE [1.9199], L1 [0.5989], G-Mean [0.2611]\n",
      "Epoch: [850][ 0/65]\tTime   0.62 (  0.62)\tData 0.5998 (0.5998)\tLoss (MSE) 4.162 (4.162)\n",
      "Epoch: [850][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0569)\tLoss (MSE) 3.640 (3.877)\n",
      "Epoch: [850][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 3.503 (3.809)\n",
      "Epoch: [850][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 4.203 (3.750)\n",
      "Epoch: [850][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.013 (3.753)\n",
      "Epoch: [850][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.324 (3.743)\n",
      "Epoch: [850][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.986 (3.831)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #850: Train loss [3.8802]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [851][ 0/65]\tTime   0.57 (  0.57)\tData 0.5621 (0.5621)\tLoss (MSE) 3.418 (3.418)\n",
      "Epoch: [851][10/65]\tTime   0.00 (  0.07)\tData 0.0001 (0.0605)\tLoss (MSE) 5.536 (3.944)\n",
      "Epoch: [851][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0317)\tLoss (MSE) 3.549 (4.150)\n",
      "Epoch: [851][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0215)\tLoss (MSE) 4.403 (4.177)\n",
      "Epoch: [851][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0163)\tLoss (MSE) 4.085 (4.033)\n",
      "Epoch: [851][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 3.252 (3.837)\n",
      "Epoch: [851][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 5.696 (3.883)\n",
      "Val: [0/9]\tTime  0.573 ( 0.573)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #851: Train loss [3.8183]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [852][ 0/65]\tTime   0.56 (  0.56)\tData 0.5487 (0.5487)\tLoss (MSE) 2.461 (2.461)\n",
      "Epoch: [852][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0527)\tLoss (MSE) 7.772 (4.316)\n",
      "Epoch: [852][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 4.740 (4.070)\n",
      "Epoch: [852][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.580 (3.989)\n",
      "Epoch: [852][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.830 (3.892)\n",
      "Epoch: [852][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 5.157 (3.871)\n",
      "Epoch: [852][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.921 (3.949)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #852: Train loss [3.8617]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [853][ 0/65]\tTime   0.57 (  0.57)\tData 0.5620 (0.5620)\tLoss (MSE) 2.503 (2.503)\n",
      "Epoch: [853][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0540)\tLoss (MSE) 2.164 (3.559)\n",
      "Epoch: [853][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0283)\tLoss (MSE) 2.605 (3.477)\n",
      "Epoch: [853][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0192)\tLoss (MSE) 5.190 (3.582)\n",
      "Epoch: [853][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.322 (3.645)\n",
      "Epoch: [853][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 3.335 (3.687)\n",
      "Epoch: [853][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 4.464 (3.758)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #853: Train loss [3.7224]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [854][ 0/65]\tTime   0.57 (  0.57)\tData 0.5630 (0.5630)\tLoss (MSE) 2.545 (2.545)\n",
      "Epoch: [854][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.889 (3.884)\n",
      "Epoch: [854][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 1.917 (3.857)\n",
      "Epoch: [854][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 5.986 (3.943)\n",
      "Epoch: [854][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.776 (3.869)\n",
      "Epoch: [854][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.125 (3.800)\n",
      "Epoch: [854][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.509 (3.779)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #854: Train loss [3.7806]; Val loss: MSE [1.9194], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [855][ 0/65]\tTime   0.56 (  0.56)\tData 0.5529 (0.5529)\tLoss (MSE) 4.870 (4.870)\n",
      "Epoch: [855][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0619)\tLoss (MSE) 3.874 (4.167)\n",
      "Epoch: [855][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0324)\tLoss (MSE) 3.842 (3.811)\n",
      "Epoch: [855][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0220)\tLoss (MSE) 4.249 (3.709)\n",
      "Epoch: [855][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0166)\tLoss (MSE) 3.111 (3.639)\n",
      "Epoch: [855][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0134)\tLoss (MSE) 4.805 (3.725)\n",
      "Epoch: [855][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0112)\tLoss (MSE) 4.701 (3.745)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.144\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #855: Train loss [3.7441]; Val loss: MSE [1.9192], L1 [0.5992], G-Mean [0.2605]\n",
      "Epoch: [856][ 0/65]\tTime   0.57 (  0.57)\tData 0.5601 (0.5601)\tLoss (MSE) 2.908 (2.908)\n",
      "Epoch: [856][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 5.131 (4.035)\n",
      "Epoch: [856][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 5.271 (3.873)\n",
      "Epoch: [856][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 5.080 (3.820)\n",
      "Epoch: [856][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.058 (3.818)\n",
      "Epoch: [856][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 7.427 (3.926)\n",
      "Epoch: [856][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.176 (3.896)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #856: Train loss [3.8519]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2605]\n",
      "Epoch: [857][ 0/65]\tTime   0.55 (  0.55)\tData 0.5430 (0.5430)\tLoss (MSE) 4.602 (4.602)\n",
      "Epoch: [857][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.790 (4.086)\n",
      "Epoch: [857][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.269 (3.852)\n",
      "Epoch: [857][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.271 (4.018)\n",
      "Epoch: [857][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.826 (3.955)\n",
      "Epoch: [857][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 2.083 (3.855)\n",
      "Epoch: [857][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.625 (3.842)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #857: Train loss [3.7939]; Val loss: MSE [1.9194], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [858][ 0/65]\tTime   0.56 (  0.56)\tData 0.5501 (0.5501)\tLoss (MSE) 3.490 (3.490)\n",
      "Epoch: [858][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0560)\tLoss (MSE) 7.186 (3.690)\n",
      "Epoch: [858][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 2.740 (3.956)\n",
      "Epoch: [858][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 1.340 (3.808)\n",
      "Epoch: [858][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.439 (3.831)\n",
      "Epoch: [858][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.508 (3.827)\n",
      "Epoch: [858][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.581 (3.788)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #858: Train loss [3.7976]; Val loss: MSE [1.9200], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [859][ 0/65]\tTime   0.56 (  0.56)\tData 0.5558 (0.5558)\tLoss (MSE) 3.318 (3.318)\n",
      "Epoch: [859][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0537)\tLoss (MSE) 5.151 (4.267)\n",
      "Epoch: [859][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 3.992 (4.046)\n",
      "Epoch: [859][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 2.662 (3.967)\n",
      "Epoch: [859][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 3.508 (3.823)\n",
      "Epoch: [859][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 2.574 (3.806)\n",
      "Epoch: [859][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 3.218 (3.826)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #859: Train loss [3.8075]; Val loss: MSE [1.9193], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [860][ 0/65]\tTime   0.60 (  0.60)\tData 0.5897 (0.5897)\tLoss (MSE) 2.457 (2.457)\n",
      "Epoch: [860][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 3.104 (3.476)\n",
      "Epoch: [860][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 2.998 (3.675)\n",
      "Epoch: [860][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 4.349 (3.684)\n",
      "Epoch: [860][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.018 (3.572)\n",
      "Epoch: [860][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 5.021 (3.671)\n",
      "Epoch: [860][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 5.418 (3.713)\n",
      "Val: [0/9]\tTime  0.640 ( 0.640)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #860: Train loss [3.7598]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [861][ 0/65]\tTime   0.59 (  0.59)\tData 0.5868 (0.5868)\tLoss (MSE) 3.531 (3.531)\n",
      "Epoch: [861][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0614)\tLoss (MSE) 5.216 (4.161)\n",
      "Epoch: [861][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0322)\tLoss (MSE) 3.806 (3.993)\n",
      "Epoch: [861][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0218)\tLoss (MSE) 3.645 (3.873)\n",
      "Epoch: [861][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 4.564 (3.760)\n",
      "Epoch: [861][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 3.994 (3.665)\n",
      "Epoch: [861][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 7.036 (3.773)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.319\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.096\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #861: Train loss [3.8129]; Val loss: MSE [1.9202], L1 [0.5984], G-Mean [0.2592]\n",
      "Epoch: [862][ 0/65]\tTime   0.57 (  0.57)\tData 0.5651 (0.5651)\tLoss (MSE) 3.487 (3.487)\n",
      "Epoch: [862][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0544)\tLoss (MSE) 4.745 (4.287)\n",
      "Epoch: [862][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.955 (3.977)\n",
      "Epoch: [862][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 4.525 (3.887)\n",
      "Epoch: [862][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.554 (3.961)\n",
      "Epoch: [862][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 1.654 (3.835)\n",
      "Epoch: [862][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.622 (3.816)\n",
      "Val: [0/9]\tTime  0.565 ( 0.565)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #862: Train loss [3.8545]; Val loss: MSE [1.9194], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [863][ 0/65]\tTime   0.56 (  0.56)\tData 0.5530 (0.5530)\tLoss (MSE) 4.298 (4.298)\n",
      "Epoch: [863][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0575)\tLoss (MSE) 5.251 (3.752)\n",
      "Epoch: [863][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 2.719 (3.866)\n",
      "Epoch: [863][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 2.438 (3.865)\n",
      "Epoch: [863][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 4.629 (3.893)\n",
      "Epoch: [863][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.640 (3.812)\n",
      "Epoch: [863][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.359 (3.720)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #863: Train loss [3.7449]; Val loss: MSE [1.9194], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [864][ 0/65]\tTime   0.57 (  0.57)\tData 0.5604 (0.5604)\tLoss (MSE) 2.682 (2.682)\n",
      "Epoch: [864][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 3.823 (3.398)\n",
      "Epoch: [864][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.477 (3.828)\n",
      "Epoch: [864][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 3.807 (3.722)\n",
      "Epoch: [864][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.473 (3.746)\n",
      "Epoch: [864][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 5.834 (3.793)\n",
      "Epoch: [864][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 5.753 (3.829)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #864: Train loss [3.7765]; Val loss: MSE [1.9193], L1 [0.5990], G-Mean [0.2606]\n",
      "Epoch: [865][ 0/65]\tTime   0.56 (  0.56)\tData 0.5498 (0.5498)\tLoss (MSE) 3.984 (3.984)\n",
      "Epoch: [865][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 4.504 (3.859)\n",
      "Epoch: [865][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0293)\tLoss (MSE) 1.914 (3.659)\n",
      "Epoch: [865][30/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0199)\tLoss (MSE) 5.247 (3.886)\n",
      "Epoch: [865][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.068 (3.893)\n",
      "Epoch: [865][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.787 (3.711)\n",
      "Epoch: [865][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.185 (3.706)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #865: Train loss [3.7386]; Val loss: MSE [1.9198], L1 [0.5987], G-Mean [0.2604]\n",
      "Epoch: [866][ 0/65]\tTime   0.56 (  0.56)\tData 0.5566 (0.5566)\tLoss (MSE) 2.649 (2.649)\n",
      "Epoch: [866][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.292 (3.554)\n",
      "Epoch: [866][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.178 (4.038)\n",
      "Epoch: [866][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 3.990 (3.958)\n",
      "Epoch: [866][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 4.319 (3.966)\n",
      "Epoch: [866][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.722 (3.956)\n",
      "Epoch: [866][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.225 (3.865)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #866: Train loss [3.8392]; Val loss: MSE [1.9194], L1 [0.5990], G-Mean [0.2604]\n",
      "Epoch: [867][ 0/65]\tTime   0.56 (  0.56)\tData 0.5574 (0.5574)\tLoss (MSE) 2.509 (2.509)\n",
      "Epoch: [867][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 6.476 (3.915)\n",
      "Epoch: [867][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 5.509 (3.859)\n",
      "Epoch: [867][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.357 (3.881)\n",
      "Epoch: [867][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 6.343 (3.820)\n",
      "Epoch: [867][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.934 (3.833)\n",
      "Epoch: [867][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.640 (3.847)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #867: Train loss [3.7993]; Val loss: MSE [1.9195], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [868][ 0/65]\tTime   0.57 (  0.57)\tData 0.5601 (0.5601)\tLoss (MSE) 4.474 (4.474)\n",
      "Epoch: [868][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0519)\tLoss (MSE) 6.051 (3.741)\n",
      "Epoch: [868][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.246 (3.691)\n",
      "Epoch: [868][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 4.218 (3.729)\n",
      "Epoch: [868][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 5.689 (3.905)\n",
      "Epoch: [868][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 6.096 (3.941)\n",
      "Epoch: [868][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 8.102 (3.879)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #868: Train loss [3.8664]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [869][ 0/65]\tTime   0.62 (  0.62)\tData 0.6046 (0.6046)\tLoss (MSE) 3.039 (3.039)\n",
      "Epoch: [869][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 3.762 (4.250)\n",
      "Epoch: [869][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 3.590 (4.061)\n",
      "Epoch: [869][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.785 (3.923)\n",
      "Epoch: [869][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.145 (3.990)\n",
      "Epoch: [869][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 1.775 (3.785)\n",
      "Epoch: [869][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.438 (3.807)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #869: Train loss [3.7761]; Val loss: MSE [1.9199], L1 [0.5987], G-Mean [0.2600]\n",
      "Epoch: [870][ 0/65]\tTime   0.56 (  0.56)\tData 0.5539 (0.5539)\tLoss (MSE) 6.120 (6.120)\n",
      "Epoch: [870][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0522)\tLoss (MSE) 3.140 (4.053)\n",
      "Epoch: [870][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 5.998 (4.159)\n",
      "Epoch: [870][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 6.222 (4.049)\n",
      "Epoch: [870][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.071 (4.014)\n",
      "Epoch: [870][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.138 (3.869)\n",
      "Epoch: [870][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.663 (3.786)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #870: Train loss [3.8009]; Val loss: MSE [1.9201], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [871][ 0/65]\tTime   0.55 (  0.55)\tData 0.5471 (0.5471)\tLoss (MSE) 4.313 (4.313)\n",
      "Epoch: [871][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0508)\tLoss (MSE) 5.416 (3.688)\n",
      "Epoch: [871][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0266)\tLoss (MSE) 5.232 (3.590)\n",
      "Epoch: [871][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 5.214 (3.812)\n",
      "Epoch: [871][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.559 (3.796)\n",
      "Epoch: [871][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 6.370 (3.834)\n",
      "Epoch: [871][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 6.279 (3.815)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #871: Train loss [3.8251]; Val loss: MSE [1.9202], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [872][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 2.035 (2.035)\n",
      "Epoch: [872][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0511)\tLoss (MSE) 3.481 (4.395)\n",
      "Epoch: [872][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.348 (3.904)\n",
      "Epoch: [872][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.531 (3.964)\n",
      "Epoch: [872][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 6.664 (3.915)\n",
      "Epoch: [872][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.053 (3.810)\n",
      "Epoch: [872][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.986 (3.846)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #872: Train loss [3.9093]; Val loss: MSE [1.9200], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [873][ 0/65]\tTime   0.56 (  0.56)\tData 0.5561 (0.5561)\tLoss (MSE) 2.936 (2.936)\n",
      "Epoch: [873][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0581)\tLoss (MSE) 3.173 (3.406)\n",
      "Epoch: [873][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.185 (3.636)\n",
      "Epoch: [873][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0206)\tLoss (MSE) 3.241 (3.699)\n",
      "Epoch: [873][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.711 (3.882)\n",
      "Epoch: [873][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.393 (3.761)\n",
      "Epoch: [873][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 6.323 (3.831)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #873: Train loss [3.8214]; Val loss: MSE [1.9197], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [874][ 0/65]\tTime   0.56 (  0.56)\tData 0.5535 (0.5535)\tLoss (MSE) 2.962 (2.962)\n",
      "Epoch: [874][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0613)\tLoss (MSE) 3.033 (3.774)\n",
      "Epoch: [874][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0321)\tLoss (MSE) 3.691 (3.541)\n",
      "Epoch: [874][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 3.417 (3.603)\n",
      "Epoch: [874][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 6.049 (3.714)\n",
      "Epoch: [874][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 2.353 (3.780)\n",
      "Epoch: [874][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.354 (3.785)\n",
      "Val: [0/9]\tTime  0.622 ( 0.622)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #874: Train loss [3.7792]; Val loss: MSE [1.9199], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [875][ 0/65]\tTime   0.65 (  0.65)\tData 0.6487 (0.6487)\tLoss (MSE) 3.221 (3.221)\n",
      "Epoch: [875][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0655)\tLoss (MSE) 4.627 (4.277)\n",
      "Epoch: [875][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0343)\tLoss (MSE) 2.864 (3.862)\n",
      "Epoch: [875][30/65]\tTime   0.01 (  0.03)\tData 0.0000 (0.0233)\tLoss (MSE) 2.768 (3.686)\n",
      "Epoch: [875][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0176)\tLoss (MSE) 4.837 (3.752)\n",
      "Epoch: [875][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 4.865 (3.684)\n",
      "Epoch: [875][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 2.376 (3.805)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #875: Train loss [3.7499]; Val loss: MSE [1.9200], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [876][ 0/65]\tTime   0.56 (  0.56)\tData 0.5494 (0.5494)\tLoss (MSE) 3.989 (3.989)\n",
      "Epoch: [876][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0528)\tLoss (MSE) 2.446 (3.645)\n",
      "Epoch: [876][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0277)\tLoss (MSE) 3.985 (3.706)\n",
      "Epoch: [876][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 4.243 (3.983)\n",
      "Epoch: [876][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 2.265 (3.932)\n",
      "Epoch: [876][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.326 (3.949)\n",
      "Epoch: [876][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.435 (3.793)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #876: Train loss [3.7425]; Val loss: MSE [1.9202], L1 [0.5987], G-Mean [0.2603]\n",
      "Epoch: [877][ 0/65]\tTime   0.56 (  0.56)\tData 0.5569 (0.5569)\tLoss (MSE) 4.765 (4.765)\n",
      "Epoch: [877][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 3.337 (4.212)\n",
      "Epoch: [877][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 3.365 (4.224)\n",
      "Epoch: [877][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.004 (3.978)\n",
      "Epoch: [877][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.569 (3.767)\n",
      "Epoch: [877][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.951 (3.834)\n",
      "Epoch: [877][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 4.020 (3.887)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #877: Train loss [3.8760]; Val loss: MSE [1.9204], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [878][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 3.937 (3.937)\n",
      "Epoch: [878][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0613)\tLoss (MSE) 3.706 (3.674)\n",
      "Epoch: [878][20/65]\tTime   0.01 (  0.04)\tData 0.0001 (0.0322)\tLoss (MSE) 4.678 (3.604)\n",
      "Epoch: [878][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 2.732 (3.869)\n",
      "Epoch: [878][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 4.329 (3.810)\n",
      "Epoch: [878][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 4.179 (3.791)\n",
      "Epoch: [878][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0111)\tLoss (MSE) 2.966 (3.743)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #878: Train loss [3.7977]; Val loss: MSE [1.9198], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [879][ 0/65]\tTime   0.56 (  0.56)\tData 0.5528 (0.5528)\tLoss (MSE) 5.583 (5.583)\n",
      "Epoch: [879][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0590)\tLoss (MSE) 1.910 (3.701)\n",
      "Epoch: [879][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0309)\tLoss (MSE) 2.373 (3.494)\n",
      "Epoch: [879][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0210)\tLoss (MSE) 3.516 (3.654)\n",
      "Epoch: [879][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.062 (3.815)\n",
      "Epoch: [879][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 4.795 (3.832)\n",
      "Epoch: [879][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.575 (3.856)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #879: Train loss [3.8535]; Val loss: MSE [1.9196], L1 [0.5991], G-Mean [0.2605]\n",
      "Epoch: [880][ 0/65]\tTime   0.56 (  0.56)\tData 0.5507 (0.5507)\tLoss (MSE) 2.808 (2.808)\n",
      "Epoch: [880][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0537)\tLoss (MSE) 2.869 (3.878)\n",
      "Epoch: [880][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 3.483 (4.006)\n",
      "Epoch: [880][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 3.263 (3.846)\n",
      "Epoch: [880][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 4.024 (3.774)\n",
      "Epoch: [880][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0116)\tLoss (MSE) 4.651 (3.843)\n",
      "Epoch: [880][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.756 (3.764)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #880: Train loss [3.7465]; Val loss: MSE [1.9203], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [881][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 3.796 (3.796)\n",
      "Epoch: [881][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0595)\tLoss (MSE) 5.184 (4.269)\n",
      "Epoch: [881][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 4.188 (4.214)\n",
      "Epoch: [881][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0211)\tLoss (MSE) 2.571 (4.067)\n",
      "Epoch: [881][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 4.525 (3.919)\n",
      "Epoch: [881][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 3.502 (3.865)\n",
      "Epoch: [881][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.459 (3.782)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #881: Train loss [3.7725]; Val loss: MSE [1.9203], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [882][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 6.024 (6.024)\n",
      "Epoch: [882][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0597)\tLoss (MSE) 4.115 (4.114)\n",
      "Epoch: [882][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.544 (3.841)\n",
      "Epoch: [882][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 4.597 (3.639)\n",
      "Epoch: [882][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.681 (3.662)\n",
      "Epoch: [882][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.422 (3.758)\n",
      "Epoch: [882][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.682 (3.816)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #882: Train loss [3.7870]; Val loss: MSE [1.9198], L1 [0.5989], G-Mean [0.2605]\n",
      "Epoch: [883][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 3.285 (3.285)\n",
      "Epoch: [883][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0546)\tLoss (MSE) 3.372 (3.673)\n",
      "Epoch: [883][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.568 (3.499)\n",
      "Epoch: [883][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 7.037 (3.713)\n",
      "Epoch: [883][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.435 (3.837)\n",
      "Epoch: [883][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.648 (3.726)\n",
      "Epoch: [883][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 4.770 (3.851)\n",
      "Val: [0/9]\tTime  0.674 ( 0.674)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #883: Train loss [3.8422]; Val loss: MSE [1.9198], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [884][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 2.977 (2.977)\n",
      "Epoch: [884][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0550)\tLoss (MSE) 4.038 (3.849)\n",
      "Epoch: [884][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.784 (3.635)\n",
      "Epoch: [884][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 2.545 (3.552)\n",
      "Epoch: [884][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.000 (3.838)\n",
      "Epoch: [884][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.314 (3.816)\n",
      "Epoch: [884][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.747 (3.778)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #884: Train loss [3.8100]; Val loss: MSE [1.9195], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [885][ 0/65]\tTime   0.57 (  0.57)\tData 0.5671 (0.5671)\tLoss (MSE) 3.797 (3.797)\n",
      "Epoch: [885][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 4.322 (3.920)\n",
      "Epoch: [885][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 3.881 (3.803)\n",
      "Epoch: [885][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.100 (3.821)\n",
      "Epoch: [885][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.288 (3.961)\n",
      "Epoch: [885][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 1.670 (3.919)\n",
      "Epoch: [885][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.356 (3.963)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #885: Train loss [3.9340]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2608]\n",
      "Epoch: [886][ 0/65]\tTime   0.57 (  0.57)\tData 0.5605 (0.5605)\tLoss (MSE) 5.322 (5.322)\n",
      "Epoch: [886][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.983 (3.786)\n",
      "Epoch: [886][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.405 (4.241)\n",
      "Epoch: [886][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 5.445 (4.228)\n",
      "Epoch: [886][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.473 (4.053)\n",
      "Epoch: [886][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 3.546 (4.027)\n",
      "Epoch: [886][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.021 (3.899)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #886: Train loss [3.8344]; Val loss: MSE [1.9194], L1 [0.5991], G-Mean [0.2608]\n",
      "Epoch: [887][ 0/65]\tTime   0.59 (  0.59)\tData 0.5754 (0.5754)\tLoss (MSE) 3.119 (3.119)\n",
      "Epoch: [887][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 5.102 (4.002)\n",
      "Epoch: [887][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 3.269 (3.586)\n",
      "Epoch: [887][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.852 (3.767)\n",
      "Epoch: [887][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.140 (3.789)\n",
      "Epoch: [887][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 5.867 (3.844)\n",
      "Epoch: [887][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.637 (3.926)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #887: Train loss [3.8726]; Val loss: MSE [1.9199], L1 [0.5988], G-Mean [0.2604]\n",
      "Epoch: [888][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 2.577 (2.577)\n",
      "Epoch: [888][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0546)\tLoss (MSE) 5.420 (3.385)\n",
      "Epoch: [888][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.631 (3.759)\n",
      "Epoch: [888][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 2.919 (3.589)\n",
      "Epoch: [888][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.335 (3.762)\n",
      "Epoch: [888][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 4.794 (3.679)\n",
      "Epoch: [888][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 5.732 (3.768)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #888: Train loss [3.8515]; Val loss: MSE [1.9198], L1 [0.5988], G-Mean [0.2603]\n",
      "Epoch: [889][ 0/65]\tTime   0.55 (  0.55)\tData 0.5463 (0.5463)\tLoss (MSE) 4.848 (4.848)\n",
      "Epoch: [889][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0505)\tLoss (MSE) 5.739 (3.799)\n",
      "Epoch: [889][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0265)\tLoss (MSE) 4.435 (3.965)\n",
      "Epoch: [889][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0180)\tLoss (MSE) 4.563 (4.032)\n",
      "Epoch: [889][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.614 (3.893)\n",
      "Epoch: [889][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0109)\tLoss (MSE) 5.333 (3.826)\n",
      "Epoch: [889][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0091)\tLoss (MSE) 2.598 (3.770)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #889: Train loss [3.7774]; Val loss: MSE [1.9198], L1 [0.5988], G-Mean [0.2605]\n",
      "Epoch: [890][ 0/65]\tTime   0.58 (  0.58)\tData 0.5672 (0.5672)\tLoss (MSE) 3.104 (3.104)\n",
      "Epoch: [890][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0532)\tLoss (MSE) 5.963 (3.701)\n",
      "Epoch: [890][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0279)\tLoss (MSE) 4.544 (3.544)\n",
      "Epoch: [890][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 4.218 (3.636)\n",
      "Epoch: [890][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 3.910 (3.796)\n",
      "Epoch: [890][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 3.574 (3.784)\n",
      "Epoch: [890][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 5.999 (3.794)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #890: Train loss [3.7710]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2608]\n",
      "Epoch: [891][ 0/65]\tTime   0.56 (  0.56)\tData 0.5540 (0.5540)\tLoss (MSE) 3.704 (3.704)\n",
      "Epoch: [891][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0560)\tLoss (MSE) 2.026 (3.561)\n",
      "Epoch: [891][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 4.463 (3.617)\n",
      "Epoch: [891][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.984 (3.838)\n",
      "Epoch: [891][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.667 (3.813)\n",
      "Epoch: [891][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.548 (3.858)\n",
      "Epoch: [891][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.327 (3.882)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #891: Train loss [3.8873]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [892][ 0/65]\tTime   0.56 (  0.56)\tData 0.5516 (0.5516)\tLoss (MSE) 7.351 (7.351)\n",
      "Epoch: [892][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 6.830 (4.511)\n",
      "Epoch: [892][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0285)\tLoss (MSE) 3.929 (4.084)\n",
      "Epoch: [892][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 2.761 (3.879)\n",
      "Epoch: [892][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.904 (3.715)\n",
      "Epoch: [892][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 3.714 (3.686)\n",
      "Epoch: [892][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 6.404 (3.780)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #892: Train loss [3.7874]; Val loss: MSE [1.9199], L1 [0.5985], G-Mean [0.2604]\n",
      "Epoch: [893][ 0/65]\tTime   0.56 (  0.56)\tData 0.5500 (0.5500)\tLoss (MSE) 3.653 (3.653)\n",
      "Epoch: [893][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 3.260 (3.598)\n",
      "Epoch: [893][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0300)\tLoss (MSE) 4.094 (3.728)\n",
      "Epoch: [893][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.016 (3.865)\n",
      "Epoch: [893][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.588 (3.884)\n",
      "Epoch: [893][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.767 (3.833)\n",
      "Epoch: [893][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 5.901 (3.848)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #893: Train loss [3.8406]; Val loss: MSE [1.9194], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [894][ 0/65]\tTime   0.56 (  0.56)\tData 0.5582 (0.5582)\tLoss (MSE) 4.911 (4.911)\n",
      "Epoch: [894][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 4.462 (3.878)\n",
      "Epoch: [894][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.700 (3.595)\n",
      "Epoch: [894][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.402 (3.760)\n",
      "Epoch: [894][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 5.060 (3.898)\n",
      "Epoch: [894][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0120)\tLoss (MSE) 3.352 (3.844)\n",
      "Epoch: [894][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 2.766 (3.779)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #894: Train loss [3.7619]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [895][ 0/65]\tTime   0.56 (  0.56)\tData 0.5513 (0.5513)\tLoss (MSE) 3.894 (3.894)\n",
      "Epoch: [895][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0525)\tLoss (MSE) 2.883 (3.759)\n",
      "Epoch: [895][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 6.184 (3.967)\n",
      "Epoch: [895][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 2.143 (3.676)\n",
      "Epoch: [895][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.862 (3.684)\n",
      "Epoch: [895][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.928 (3.710)\n",
      "Epoch: [895][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.165 (3.725)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #895: Train loss [3.7791]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [896][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 2.489 (2.489)\n",
      "Epoch: [896][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0586)\tLoss (MSE) 4.019 (3.484)\n",
      "Epoch: [896][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 2.371 (3.485)\n",
      "Epoch: [896][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 4.459 (3.785)\n",
      "Epoch: [896][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.729 (3.937)\n",
      "Epoch: [896][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.707 (3.836)\n",
      "Epoch: [896][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 6.737 (3.886)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #896: Train loss [3.9017]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [897][ 0/65]\tTime   0.56 (  0.56)\tData 0.5520 (0.5520)\tLoss (MSE) 2.894 (2.894)\n",
      "Epoch: [897][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0599)\tLoss (MSE) 3.710 (3.504)\n",
      "Epoch: [897][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 3.793 (3.730)\n",
      "Epoch: [897][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 4.890 (3.757)\n",
      "Epoch: [897][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 5.916 (3.940)\n",
      "Epoch: [897][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 2.855 (3.850)\n",
      "Epoch: [897][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.852 (3.855)\n",
      "Val: [0/9]\tTime  0.538 ( 0.538)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #897: Train loss [3.8512]; Val loss: MSE [1.9200], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [898][ 0/65]\tTime   0.56 (  0.56)\tData 0.5571 (0.5571)\tLoss (MSE) 5.458 (5.458)\n",
      "Epoch: [898][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0518)\tLoss (MSE) 4.098 (3.992)\n",
      "Epoch: [898][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 4.188 (4.141)\n",
      "Epoch: [898][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0184)\tLoss (MSE) 2.963 (4.005)\n",
      "Epoch: [898][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.857 (3.977)\n",
      "Epoch: [898][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.208 (4.017)\n",
      "Epoch: [898][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.455 (3.865)\n",
      "Val: [0/9]\tTime  0.645 ( 0.645)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #898: Train loss [3.8741]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2606]\n",
      "Epoch: [899][ 0/65]\tTime   0.63 (  0.63)\tData 0.6229 (0.6229)\tLoss (MSE) 2.654 (2.654)\n",
      "Epoch: [899][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0580)\tLoss (MSE) 3.942 (3.242)\n",
      "Epoch: [899][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0304)\tLoss (MSE) 4.315 (3.984)\n",
      "Epoch: [899][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 2.768 (3.851)\n",
      "Epoch: [899][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 4.467 (3.859)\n",
      "Epoch: [899][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.532 (3.861)\n",
      "Epoch: [899][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.118 (3.804)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #899: Train loss [3.7868]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [900][ 0/65]\tTime   0.56 (  0.56)\tData 0.5586 (0.5586)\tLoss (MSE) 2.180 (2.180)\n",
      "Epoch: [900][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0520)\tLoss (MSE) 3.299 (3.077)\n",
      "Epoch: [900][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0272)\tLoss (MSE) 4.559 (3.809)\n",
      "Epoch: [900][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.965 (3.817)\n",
      "Epoch: [900][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.691 (3.774)\n",
      "Epoch: [900][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.748 (3.917)\n",
      "Epoch: [900][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.608 (3.873)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #900: Train loss [3.8620]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [901][ 0/65]\tTime   0.57 (  0.57)\tData 0.5667 (0.5667)\tLoss (MSE) 3.205 (3.205)\n",
      "Epoch: [901][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0604)\tLoss (MSE) 2.181 (4.248)\n",
      "Epoch: [901][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0317)\tLoss (MSE) 1.956 (3.765)\n",
      "Epoch: [901][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0215)\tLoss (MSE) 3.479 (3.820)\n",
      "Epoch: [901][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0162)\tLoss (MSE) 3.063 (3.749)\n",
      "Epoch: [901][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0131)\tLoss (MSE) 3.706 (3.764)\n",
      "Epoch: [901][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0109)\tLoss (MSE) 5.736 (3.827)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #901: Train loss [3.8510]; Val loss: MSE [1.9200], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [902][ 0/65]\tTime   0.56 (  0.56)\tData 0.5480 (0.5480)\tLoss (MSE) 2.543 (2.543)\n",
      "Epoch: [902][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 4.783 (3.913)\n",
      "Epoch: [902][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.864 (3.986)\n",
      "Epoch: [902][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.994 (3.917)\n",
      "Epoch: [902][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.746 (3.850)\n",
      "Epoch: [902][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.360 (3.839)\n",
      "Epoch: [902][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.214 (3.795)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #902: Train loss [3.8643]; Val loss: MSE [1.9201], L1 [0.5985], G-Mean [0.2601]\n",
      "Epoch: [903][ 0/65]\tTime   0.60 (  0.60)\tData 0.5801 (0.5801)\tLoss (MSE) 4.025 (4.025)\n",
      "Epoch: [903][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0545)\tLoss (MSE) 3.599 (4.255)\n",
      "Epoch: [903][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 2.570 (3.543)\n",
      "Epoch: [903][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 3.092 (3.637)\n",
      "Epoch: [903][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.692 (3.632)\n",
      "Epoch: [903][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.901 (3.839)\n",
      "Epoch: [903][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.523 (3.832)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #903: Train loss [3.8516]; Val loss: MSE [1.9192], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [904][ 0/65]\tTime   0.55 (  0.55)\tData 0.5478 (0.5478)\tLoss (MSE) 5.966 (5.966)\n",
      "Epoch: [904][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 4.117 (4.246)\n",
      "Epoch: [904][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 5.360 (4.169)\n",
      "Epoch: [904][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 2.953 (3.960)\n",
      "Epoch: [904][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.902 (3.840)\n",
      "Epoch: [904][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.606 (3.821)\n",
      "Epoch: [904][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 6.122 (3.837)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #904: Train loss [3.8231]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [905][ 0/65]\tTime   0.56 (  0.56)\tData 0.5529 (0.5529)\tLoss (MSE) 3.072 (3.072)\n",
      "Epoch: [905][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0523)\tLoss (MSE) 2.202 (4.021)\n",
      "Epoch: [905][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0274)\tLoss (MSE) 3.380 (3.807)\n",
      "Epoch: [905][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 5.494 (3.970)\n",
      "Epoch: [905][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 1.964 (3.784)\n",
      "Epoch: [905][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.781 (3.830)\n",
      "Epoch: [905][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.671 (3.881)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #905: Train loss [3.8187]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [906][ 0/65]\tTime   0.55 (  0.55)\tData 0.5478 (0.5478)\tLoss (MSE) 6.018 (6.018)\n",
      "Epoch: [906][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0513)\tLoss (MSE) 2.997 (3.628)\n",
      "Epoch: [906][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 8.864 (3.933)\n",
      "Epoch: [906][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 2.884 (3.869)\n",
      "Epoch: [906][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.825 (3.885)\n",
      "Epoch: [906][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 1.971 (3.841)\n",
      "Epoch: [906][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.565 (3.782)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #906: Train loss [3.7583]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [907][ 0/65]\tTime   0.56 (  0.56)\tData 0.5576 (0.5576)\tLoss (MSE) 2.636 (2.636)\n",
      "Epoch: [907][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.454 (3.516)\n",
      "Epoch: [907][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 1.989 (3.436)\n",
      "Epoch: [907][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 6.170 (3.594)\n",
      "Epoch: [907][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.442 (3.698)\n",
      "Epoch: [907][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 4.721 (3.705)\n",
      "Epoch: [907][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.384 (3.815)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #907: Train loss [3.7959]; Val loss: MSE [1.9192], L1 [0.5991], G-Mean [0.2607]\n",
      "Epoch: [908][ 0/65]\tTime   0.55 (  0.55)\tData 0.5465 (0.5465)\tLoss (MSE) 3.454 (3.454)\n",
      "Epoch: [908][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 3.548 (3.687)\n",
      "Epoch: [908][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 2.545 (3.860)\n",
      "Epoch: [908][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 4.539 (4.045)\n",
      "Epoch: [908][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.820 (3.906)\n",
      "Epoch: [908][50/65]\tTime   0.00 (  0.02)\tData 0.0001 (0.0120)\tLoss (MSE) 6.325 (3.902)\n",
      "Epoch: [908][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.405 (3.877)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #908: Train loss [3.8889]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2611]\n",
      "Epoch: [909][ 0/65]\tTime   0.56 (  0.56)\tData 0.5526 (0.5526)\tLoss (MSE) 5.969 (5.969)\n",
      "Epoch: [909][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 3.295 (3.564)\n",
      "Epoch: [909][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 4.872 (3.830)\n",
      "Epoch: [909][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.948 (3.759)\n",
      "Epoch: [909][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.122 (3.841)\n",
      "Epoch: [909][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 5.564 (3.830)\n",
      "Epoch: [909][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 2.772 (3.922)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #909: Train loss [3.8707]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [910][ 0/65]\tTime   0.62 (  0.62)\tData 0.6025 (0.6025)\tLoss (MSE) 3.932 (3.932)\n",
      "Epoch: [910][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0564)\tLoss (MSE) 5.870 (4.159)\n",
      "Epoch: [910][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 2.158 (3.647)\n",
      "Epoch: [910][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.266 (3.840)\n",
      "Epoch: [910][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 4.042 (3.890)\n",
      "Epoch: [910][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.196 (3.905)\n",
      "Epoch: [910][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.823 (3.823)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #910: Train loss [3.8669]; Val loss: MSE [1.9200], L1 [0.5985], G-Mean [0.2605]\n",
      "Epoch: [911][ 0/65]\tTime   0.56 (  0.56)\tData 0.5537 (0.5537)\tLoss (MSE) 3.764 (3.764)\n",
      "Epoch: [911][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0579)\tLoss (MSE) 2.109 (3.254)\n",
      "Epoch: [911][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0303)\tLoss (MSE) 3.420 (3.732)\n",
      "Epoch: [911][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0206)\tLoss (MSE) 3.449 (3.927)\n",
      "Epoch: [911][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.227 (4.036)\n",
      "Epoch: [911][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.568 (4.019)\n",
      "Epoch: [911][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.183 (3.858)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #911: Train loss [3.8525]; Val loss: MSE [1.9191], L1 [0.5991], G-Mean [0.2608]\n",
      "Epoch: [912][ 0/65]\tTime   0.56 (  0.56)\tData 0.5566 (0.5566)\tLoss (MSE) 3.910 (3.910)\n",
      "Epoch: [912][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0546)\tLoss (MSE) 3.544 (3.450)\n",
      "Epoch: [912][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.635 (3.412)\n",
      "Epoch: [912][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 1.948 (3.527)\n",
      "Epoch: [912][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.484 (3.622)\n",
      "Epoch: [912][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 3.107 (3.572)\n",
      "Epoch: [912][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 1.754 (3.676)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #912: Train loss [3.8001]; Val loss: MSE [1.9194], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [913][ 0/65]\tTime   0.69 (  0.69)\tData 0.6760 (0.6760)\tLoss (MSE) 3.312 (3.312)\n",
      "Epoch: [913][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0627)\tLoss (MSE) 3.222 (3.518)\n",
      "Epoch: [913][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0329)\tLoss (MSE) 3.053 (3.757)\n",
      "Epoch: [913][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0223)\tLoss (MSE) 3.486 (3.912)\n",
      "Epoch: [913][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0169)\tLoss (MSE) 3.671 (3.903)\n",
      "Epoch: [913][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 2.579 (3.819)\n",
      "Epoch: [913][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.213 (3.744)\n",
      "Val: [0/9]\tTime  0.570 ( 0.570)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #913: Train loss [3.8469]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [914][ 0/65]\tTime   0.56 (  0.56)\tData 0.5544 (0.5544)\tLoss (MSE) 4.634 (4.634)\n",
      "Epoch: [914][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 4.430 (4.478)\n",
      "Epoch: [914][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.616 (4.118)\n",
      "Epoch: [914][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 7.312 (3.989)\n",
      "Epoch: [914][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 2.709 (3.959)\n",
      "Epoch: [914][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.622 (3.870)\n",
      "Epoch: [914][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.870 (3.790)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #914: Train loss [3.8359]; Val loss: MSE [1.9194], L1 [0.5989], G-Mean [0.2611]\n",
      "Epoch: [915][ 0/65]\tTime   0.56 (  0.56)\tData 0.5488 (0.5488)\tLoss (MSE) 4.713 (4.713)\n",
      "Epoch: [915][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0584)\tLoss (MSE) 3.424 (4.129)\n",
      "Epoch: [915][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 3.304 (3.962)\n",
      "Epoch: [915][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 2.385 (3.857)\n",
      "Epoch: [915][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 5.464 (3.869)\n",
      "Epoch: [915][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 3.412 (3.758)\n",
      "Epoch: [915][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.640 (3.820)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #915: Train loss [3.7828]; Val loss: MSE [1.9197], L1 [0.5985], G-Mean [0.2606]\n",
      "Epoch: [916][ 0/65]\tTime   0.56 (  0.56)\tData 0.5528 (0.5528)\tLoss (MSE) 6.892 (6.892)\n",
      "Epoch: [916][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 4.793 (4.681)\n",
      "Epoch: [916][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.473 (4.391)\n",
      "Epoch: [916][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.199 (3.888)\n",
      "Epoch: [916][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 4.612 (3.847)\n",
      "Epoch: [916][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.652 (3.811)\n",
      "Epoch: [916][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.343 (3.781)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #916: Train loss [3.7875]; Val loss: MSE [1.9197], L1 [0.5985], G-Mean [0.2606]\n",
      "Epoch: [917][ 0/65]\tTime   0.56 (  0.56)\tData 0.5553 (0.5553)\tLoss (MSE) 3.184 (3.184)\n",
      "Epoch: [917][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0514)\tLoss (MSE) 4.068 (3.898)\n",
      "Epoch: [917][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0269)\tLoss (MSE) 1.567 (3.990)\n",
      "Epoch: [917][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 3.346 (3.941)\n",
      "Epoch: [917][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.740 (3.928)\n",
      "Epoch: [917][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 5.140 (4.007)\n",
      "Epoch: [917][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 3.319 (3.880)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #917: Train loss [3.8793]; Val loss: MSE [1.9193], L1 [0.5988], G-Mean [0.2611]\n",
      "Epoch: [918][ 0/65]\tTime   0.56 (  0.56)\tData 0.5505 (0.5505)\tLoss (MSE) 3.043 (3.043)\n",
      "Epoch: [918][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0522)\tLoss (MSE) 3.748 (3.963)\n",
      "Epoch: [918][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 3.540 (3.797)\n",
      "Epoch: [918][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.715 (3.692)\n",
      "Epoch: [918][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.785 (3.693)\n",
      "Epoch: [918][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 2.503 (3.607)\n",
      "Epoch: [918][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.562 (3.686)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #918: Train loss [3.7376]; Val loss: MSE [1.9197], L1 [0.5985], G-Mean [0.2606]\n",
      "Epoch: [919][ 0/65]\tTime   0.56 (  0.56)\tData 0.5527 (0.5527)\tLoss (MSE) 2.338 (2.338)\n",
      "Epoch: [919][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0562)\tLoss (MSE) 2.335 (3.429)\n",
      "Epoch: [919][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 3.686 (3.519)\n",
      "Epoch: [919][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.328 (3.767)\n",
      "Epoch: [919][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.605 (3.815)\n",
      "Epoch: [919][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.101 (3.757)\n",
      "Epoch: [919][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.052 (3.773)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #919: Train loss [3.7982]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [920][ 0/65]\tTime   0.55 (  0.55)\tData 0.5500 (0.5500)\tLoss (MSE) 4.701 (4.701)\n",
      "Epoch: [920][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0562)\tLoss (MSE) 4.122 (4.056)\n",
      "Epoch: [920][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 4.041 (4.292)\n",
      "Epoch: [920][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.362 (4.080)\n",
      "Epoch: [920][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.046 (4.040)\n",
      "Epoch: [920][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 4.206 (3.871)\n",
      "Epoch: [920][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.581 (3.832)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #920: Train loss [3.8058]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [921][ 0/65]\tTime   0.63 (  0.63)\tData 0.6057 (0.6057)\tLoss (MSE) 3.442 (3.442)\n",
      "Epoch: [921][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0560)\tLoss (MSE) 2.629 (4.343)\n",
      "Epoch: [921][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 3.691 (4.117)\n",
      "Epoch: [921][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.734 (3.931)\n",
      "Epoch: [921][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.962 (4.050)\n",
      "Epoch: [921][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.923 (3.857)\n",
      "Epoch: [921][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.067 (3.840)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.319\tL1 1.018\tG-Mean 0.871\n",
      " * Median: MSE 2.155\tL1 1.402\tG-Mean 1.345\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.203\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #921: Train loss [3.8207]; Val loss: MSE [1.9201], L1 [0.5982], G-Mean [0.2592]\n",
      "Epoch: [922][ 0/65]\tTime   0.66 (  0.66)\tData 0.6527 (0.6527)\tLoss (MSE) 5.144 (5.144)\n",
      "Epoch: [922][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0627)\tLoss (MSE) 6.568 (4.134)\n",
      "Epoch: [922][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0329)\tLoss (MSE) 2.284 (3.771)\n",
      "Epoch: [922][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0223)\tLoss (MSE) 2.861 (3.992)\n",
      "Epoch: [922][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0169)\tLoss (MSE) 1.954 (3.800)\n",
      "Epoch: [922][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 3.014 (3.720)\n",
      "Epoch: [922][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.653 (3.702)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #922: Train loss [3.7849]; Val loss: MSE [1.9194], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [923][ 0/65]\tTime   0.59 (  0.59)\tData 0.5813 (0.5813)\tLoss (MSE) 3.047 (3.047)\n",
      "Epoch: [923][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0543)\tLoss (MSE) 2.419 (3.564)\n",
      "Epoch: [923][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 4.641 (3.857)\n",
      "Epoch: [923][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 3.764 (4.127)\n",
      "Epoch: [923][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.936 (4.115)\n",
      "Epoch: [923][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 2.964 (3.897)\n",
      "Epoch: [923][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 2.419 (3.779)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #923: Train loss [3.7439]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [924][ 0/65]\tTime   0.55 (  0.55)\tData 0.5437 (0.5437)\tLoss (MSE) 2.655 (2.655)\n",
      "Epoch: [924][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0556)\tLoss (MSE) 2.579 (3.534)\n",
      "Epoch: [924][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.922 (3.565)\n",
      "Epoch: [924][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.328 (3.590)\n",
      "Epoch: [924][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 4.058 (3.582)\n",
      "Epoch: [924][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 5.480 (3.633)\n",
      "Epoch: [924][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.050 (3.706)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #924: Train loss [3.7610]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [925][ 0/65]\tTime   0.55 (  0.55)\tData 0.5494 (0.5494)\tLoss (MSE) 3.498 (3.498)\n",
      "Epoch: [925][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0547)\tLoss (MSE) 3.678 (3.485)\n",
      "Epoch: [925][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 5.571 (3.840)\n",
      "Epoch: [925][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 5.095 (3.801)\n",
      "Epoch: [925][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 4.207 (3.916)\n",
      "Epoch: [925][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.172 (3.795)\n",
      "Epoch: [925][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 1.977 (3.809)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #925: Train loss [3.7722]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2610]\n",
      "Epoch: [926][ 0/65]\tTime   0.56 (  0.56)\tData 0.5538 (0.5538)\tLoss (MSE) 3.068 (3.068)\n",
      "Epoch: [926][10/65]\tTime   0.00 (  0.06)\tData 0.0001 (0.0596)\tLoss (MSE) 4.804 (3.663)\n",
      "Epoch: [926][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 6.689 (3.830)\n",
      "Epoch: [926][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 3.597 (3.720)\n",
      "Epoch: [926][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 2.338 (3.647)\n",
      "Epoch: [926][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 2.264 (3.787)\n",
      "Epoch: [926][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 7.391 (3.780)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #926: Train loss [3.7878]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [927][ 0/65]\tTime   0.55 (  0.55)\tData 0.5487 (0.5487)\tLoss (MSE) 4.638 (4.638)\n",
      "Epoch: [927][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 4.850 (3.520)\n",
      "Epoch: [927][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 3.387 (3.496)\n",
      "Epoch: [927][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 2.473 (3.631)\n",
      "Epoch: [927][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.685 (3.824)\n",
      "Epoch: [927][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.104 (3.786)\n",
      "Epoch: [927][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.003 (3.789)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.095\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #927: Train loss [3.7705]; Val loss: MSE [1.9192], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [928][ 0/65]\tTime   0.56 (  0.56)\tData 0.5467 (0.5467)\tLoss (MSE) 2.805 (2.805)\n",
      "Epoch: [928][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0557)\tLoss (MSE) 3.323 (3.362)\n",
      "Epoch: [928][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 3.721 (3.537)\n",
      "Epoch: [928][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 1.776 (3.444)\n",
      "Epoch: [928][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 5.857 (3.653)\n",
      "Epoch: [928][50/65]\tTime   0.01 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.694 (3.748)\n",
      "Epoch: [928][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.291 (3.784)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #928: Train loss [3.7581]; Val loss: MSE [1.9194], L1 [0.5988], G-Mean [0.2611]\n",
      "Epoch: [929][ 0/65]\tTime   0.63 (  0.63)\tData 0.6129 (0.6129)\tLoss (MSE) 5.044 (5.044)\n",
      "Epoch: [929][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0588)\tLoss (MSE) 2.320 (3.738)\n",
      "Epoch: [929][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0308)\tLoss (MSE) 2.640 (3.515)\n",
      "Epoch: [929][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0209)\tLoss (MSE) 3.768 (3.928)\n",
      "Epoch: [929][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 4.374 (3.853)\n",
      "Epoch: [929][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 2.233 (3.842)\n",
      "Epoch: [929][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.038 (3.877)\n",
      "Val: [0/9]\tTime  0.563 ( 0.563)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #929: Train loss [3.8626]; Val loss: MSE [1.9190], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [930][ 0/65]\tTime   0.55 (  0.55)\tData 0.5483 (0.5483)\tLoss (MSE) 3.828 (3.828)\n",
      "Epoch: [930][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0557)\tLoss (MSE) 4.889 (3.630)\n",
      "Epoch: [930][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0292)\tLoss (MSE) 4.157 (3.945)\n",
      "Epoch: [930][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 5.029 (3.786)\n",
      "Epoch: [930][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.767 (3.816)\n",
      "Epoch: [930][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 2.942 (3.766)\n",
      "Epoch: [930][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 2.144 (3.835)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #930: Train loss [3.8054]; Val loss: MSE [1.9190], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [931][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 3.935 (3.935)\n",
      "Epoch: [931][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 3.561 (3.413)\n",
      "Epoch: [931][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 3.462 (3.520)\n",
      "Epoch: [931][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 3.854 (3.562)\n",
      "Epoch: [931][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.075 (3.631)\n",
      "Epoch: [931][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.565 (3.858)\n",
      "Epoch: [931][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.218 (3.797)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #931: Train loss [3.8331]; Val loss: MSE [1.9196], L1 [0.5985], G-Mean [0.2605]\n",
      "Epoch: [932][ 0/65]\tTime   0.57 (  0.57)\tData 0.5607 (0.5607)\tLoss (MSE) 4.124 (4.124)\n",
      "Epoch: [932][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 5.008 (3.508)\n",
      "Epoch: [932][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0290)\tLoss (MSE) 4.838 (3.757)\n",
      "Epoch: [932][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 5.142 (3.750)\n",
      "Epoch: [932][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.134 (3.871)\n",
      "Epoch: [932][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 6.998 (3.838)\n",
      "Epoch: [932][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 4.454 (3.836)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.398\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #932: Train loss [3.9080]; Val loss: MSE [1.9188], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [933][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 3.192 (3.192)\n",
      "Epoch: [933][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0593)\tLoss (MSE) 6.444 (3.690)\n",
      "Epoch: [933][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0311)\tLoss (MSE) 2.703 (3.733)\n",
      "Epoch: [933][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 5.164 (3.773)\n",
      "Epoch: [933][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.854 (3.876)\n",
      "Epoch: [933][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 2.837 (3.880)\n",
      "Epoch: [933][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.747 (3.838)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #933: Train loss [3.8444]; Val loss: MSE [1.9195], L1 [0.5984], G-Mean [0.2604]\n",
      "Epoch: [934][ 0/65]\tTime   0.56 (  0.56)\tData 0.5572 (0.5572)\tLoss (MSE) 3.161 (3.161)\n",
      "Epoch: [934][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0577)\tLoss (MSE) 2.425 (3.380)\n",
      "Epoch: [934][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 3.409 (3.801)\n",
      "Epoch: [934][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 2.135 (3.891)\n",
      "Epoch: [934][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.974 (3.785)\n",
      "Epoch: [934][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 2.007 (3.748)\n",
      "Epoch: [934][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 5.668 (3.766)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #934: Train loss [3.7777]; Val loss: MSE [1.9188], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [935][ 0/65]\tTime   0.56 (  0.56)\tData 0.5578 (0.5578)\tLoss (MSE) 6.088 (6.088)\n",
      "Epoch: [935][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0595)\tLoss (MSE) 2.805 (4.296)\n",
      "Epoch: [935][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 5.245 (3.949)\n",
      "Epoch: [935][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0211)\tLoss (MSE) 3.550 (3.856)\n",
      "Epoch: [935][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.786 (3.807)\n",
      "Epoch: [935][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 8.093 (3.858)\n",
      "Epoch: [935][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.894 (3.856)\n",
      "Val: [0/9]\tTime  0.612 ( 0.612)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #935: Train loss [3.8723]; Val loss: MSE [1.9191], L1 [0.5987], G-Mean [0.2610]\n",
      "Epoch: [936][ 0/65]\tTime   0.66 (  0.66)\tData 0.6511 (0.6511)\tLoss (MSE) 2.657 (2.657)\n",
      "Epoch: [936][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0634)\tLoss (MSE) 6.291 (4.341)\n",
      "Epoch: [936][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0332)\tLoss (MSE) 3.227 (3.963)\n",
      "Epoch: [936][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0225)\tLoss (MSE) 6.475 (3.866)\n",
      "Epoch: [936][40/65]\tTime   0.01 (  0.02)\tData 0.0000 (0.0170)\tLoss (MSE) 7.015 (3.949)\n",
      "Epoch: [936][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 4.690 (3.914)\n",
      "Epoch: [936][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.471 (3.845)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #936: Train loss [3.8991]; Val loss: MSE [1.9193], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [937][ 0/65]\tTime   0.62 (  0.62)\tData 0.6067 (0.6067)\tLoss (MSE) 6.439 (6.439)\n",
      "Epoch: [937][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0567)\tLoss (MSE) 5.902 (3.785)\n",
      "Epoch: [937][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 2.394 (3.727)\n",
      "Epoch: [937][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 3.437 (3.678)\n",
      "Epoch: [937][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 5.921 (3.852)\n",
      "Epoch: [937][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 6.314 (3.875)\n",
      "Epoch: [937][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 2.814 (3.808)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.873\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #937: Train loss [3.7708]; Val loss: MSE [1.9196], L1 [0.5985], G-Mean [0.2605]\n",
      "Epoch: [938][ 0/65]\tTime   0.57 (  0.57)\tData 0.5598 (0.5598)\tLoss (MSE) 4.679 (4.679)\n",
      "Epoch: [938][10/65]\tTime   0.00 (  0.07)\tData 0.0001 (0.0592)\tLoss (MSE) 5.442 (4.202)\n",
      "Epoch: [938][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 4.987 (3.949)\n",
      "Epoch: [938][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0210)\tLoss (MSE) 5.381 (3.723)\n",
      "Epoch: [938][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 2.269 (3.743)\n",
      "Epoch: [938][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 4.537 (3.747)\n",
      "Epoch: [938][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.016 (3.740)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #938: Train loss [3.7136]; Val loss: MSE [1.9193], L1 [0.5987], G-Mean [0.2610]\n",
      "Epoch: [939][ 0/65]\tTime   0.55 (  0.55)\tData 0.5477 (0.5477)\tLoss (MSE) 6.267 (6.267)\n",
      "Epoch: [939][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0526)\tLoss (MSE) 2.360 (3.551)\n",
      "Epoch: [939][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0276)\tLoss (MSE) 4.638 (3.718)\n",
      "Epoch: [939][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 4.985 (3.672)\n",
      "Epoch: [939][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.779 (3.743)\n",
      "Epoch: [939][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 3.688 (3.650)\n",
      "Epoch: [939][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 4.348 (3.779)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #939: Train loss [3.7932]; Val loss: MSE [1.9188], L1 [0.5990], G-Mean [0.2609]\n",
      "Epoch: [940][ 0/65]\tTime   0.56 (  0.56)\tData 0.5484 (0.5484)\tLoss (MSE) 2.185 (2.185)\n",
      "Epoch: [940][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0538)\tLoss (MSE) 6.148 (3.290)\n",
      "Epoch: [940][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0282)\tLoss (MSE) 6.812 (3.671)\n",
      "Epoch: [940][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0191)\tLoss (MSE) 5.133 (3.995)\n",
      "Epoch: [940][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 4.295 (4.024)\n",
      "Epoch: [940][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 4.178 (3.909)\n",
      "Epoch: [940][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 2.182 (3.851)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #940: Train loss [3.8860]; Val loss: MSE [1.9191], L1 [0.5987], G-Mean [0.2610]\n",
      "Epoch: [941][ 0/65]\tTime   0.62 (  0.62)\tData 0.6047 (0.6047)\tLoss (MSE) 1.966 (1.966)\n",
      "Epoch: [941][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0574)\tLoss (MSE) 3.329 (3.512)\n",
      "Epoch: [941][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0301)\tLoss (MSE) 4.668 (3.837)\n",
      "Epoch: [941][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0204)\tLoss (MSE) 3.545 (3.891)\n",
      "Epoch: [941][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 4.573 (3.760)\n",
      "Epoch: [941][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 2.751 (3.754)\n",
      "Epoch: [941][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.777 (3.761)\n",
      "Val: [0/9]\tTime  0.556 ( 0.556)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #941: Train loss [3.7462]; Val loss: MSE [1.9194], L1 [0.5985], G-Mean [0.2605]\n",
      "Epoch: [942][ 0/65]\tTime   0.55 (  0.55)\tData 0.5425 (0.5425)\tLoss (MSE) 4.423 (4.423)\n",
      "Epoch: [942][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.520 (4.340)\n",
      "Epoch: [942][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 4.051 (4.196)\n",
      "Epoch: [942][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.700 (4.146)\n",
      "Epoch: [942][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 3.229 (3.957)\n",
      "Epoch: [942][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0119)\tLoss (MSE) 3.738 (3.861)\n",
      "Epoch: [942][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.814 (3.845)\n",
      "Val: [0/9]\tTime  0.549 ( 0.549)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #942: Train loss [3.8383]; Val loss: MSE [1.9188], L1 [0.5989], G-Mean [0.2610]\n",
      "Epoch: [943][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 7.260 (7.260)\n",
      "Epoch: [943][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 2.490 (3.588)\n",
      "Epoch: [943][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 4.342 (4.262)\n",
      "Epoch: [943][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.169 (4.003)\n",
      "Epoch: [943][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 3.073 (3.913)\n",
      "Epoch: [943][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 4.634 (3.856)\n",
      "Epoch: [943][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.407 (3.767)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #943: Train loss [3.7684]; Val loss: MSE [1.9195], L1 [0.5984], G-Mean [0.2598]\n",
      "Epoch: [944][ 0/65]\tTime   0.56 (  0.56)\tData 0.5545 (0.5545)\tLoss (MSE) 3.186 (3.186)\n",
      "Epoch: [944][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0590)\tLoss (MSE) 3.874 (4.843)\n",
      "Epoch: [944][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0309)\tLoss (MSE) 2.775 (4.228)\n",
      "Epoch: [944][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0209)\tLoss (MSE) 2.708 (3.858)\n",
      "Epoch: [944][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0158)\tLoss (MSE) 3.657 (3.845)\n",
      "Epoch: [944][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0127)\tLoss (MSE) 3.557 (3.886)\n",
      "Epoch: [944][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 2.952 (3.773)\n",
      "Val: [0/9]\tTime  0.558 ( 0.558)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #944: Train loss [3.7613]; Val loss: MSE [1.9186], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [945][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 4.515 (4.515)\n",
      "Epoch: [945][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0566)\tLoss (MSE) 2.874 (4.752)\n",
      "Epoch: [945][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0297)\tLoss (MSE) 3.363 (4.309)\n",
      "Epoch: [945][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0201)\tLoss (MSE) 3.757 (3.987)\n",
      "Epoch: [945][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.679 (3.793)\n",
      "Epoch: [945][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 5.853 (3.776)\n",
      "Epoch: [945][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 5.678 (3.841)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #945: Train loss [3.7904]; Val loss: MSE [1.9191], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [946][ 0/65]\tTime   0.62 (  0.62)\tData 0.6039 (0.6039)\tLoss (MSE) 2.835 (2.835)\n",
      "Epoch: [946][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0573)\tLoss (MSE) 2.380 (3.410)\n",
      "Epoch: [946][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0300)\tLoss (MSE) 2.838 (3.713)\n",
      "Epoch: [946][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0203)\tLoss (MSE) 5.986 (3.963)\n",
      "Epoch: [946][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.249 (3.812)\n",
      "Epoch: [946][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 3.275 (3.739)\n",
      "Epoch: [946][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 2.634 (3.713)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #946: Train loss [3.7828]; Val loss: MSE [1.9191], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [947][ 0/65]\tTime   0.56 (  0.56)\tData 0.5516 (0.5516)\tLoss (MSE) 4.781 (4.781)\n",
      "Epoch: [947][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 4.966 (4.433)\n",
      "Epoch: [947][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 5.374 (4.150)\n",
      "Epoch: [947][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 5.928 (4.140)\n",
      "Epoch: [947][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 3.172 (3.970)\n",
      "Epoch: [947][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.568 (3.888)\n",
      "Epoch: [947][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.861 (3.872)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #947: Train loss [3.8661]; Val loss: MSE [1.9187], L1 [0.5990], G-Mean [0.2608]\n",
      "Epoch: [948][ 0/65]\tTime   0.56 (  0.56)\tData 0.5489 (0.5489)\tLoss (MSE) 3.829 (3.829)\n",
      "Epoch: [948][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0536)\tLoss (MSE) 3.796 (3.523)\n",
      "Epoch: [948][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0281)\tLoss (MSE) 8.313 (3.907)\n",
      "Epoch: [948][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0190)\tLoss (MSE) 2.533 (3.968)\n",
      "Epoch: [948][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0144)\tLoss (MSE) 2.173 (3.788)\n",
      "Epoch: [948][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0116)\tLoss (MSE) 3.178 (3.760)\n",
      "Epoch: [948][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0097)\tLoss (MSE) 1.908 (3.893)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #948: Train loss [3.8473]; Val loss: MSE [1.9194], L1 [0.5985], G-Mean [0.2605]\n",
      "Epoch: [949][ 0/65]\tTime   0.56 (  0.56)\tData 0.5534 (0.5534)\tLoss (MSE) 2.531 (2.531)\n",
      "Epoch: [949][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0509)\tLoss (MSE) 3.901 (3.479)\n",
      "Epoch: [949][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0267)\tLoss (MSE) 4.190 (3.550)\n",
      "Epoch: [949][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 5.814 (3.916)\n",
      "Epoch: [949][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.825 (4.006)\n",
      "Epoch: [949][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 3.209 (3.893)\n",
      "Epoch: [949][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 4.230 (3.886)\n",
      "Val: [0/9]\tTime  0.537 ( 0.537)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.022\tG-Mean 0.875\n",
      " * Median: MSE 2.145\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #949: Train loss [3.8306]; Val loss: MSE [1.9187], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [950][ 0/65]\tTime   0.68 (  0.68)\tData 0.6754 (0.6754)\tLoss (MSE) 2.590 (2.590)\n",
      "Epoch: [950][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0624)\tLoss (MSE) 2.060 (3.805)\n",
      "Epoch: [950][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0327)\tLoss (MSE) 3.960 (3.698)\n",
      "Epoch: [950][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0222)\tLoss (MSE) 4.945 (3.690)\n",
      "Epoch: [950][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0168)\tLoss (MSE) 4.078 (3.688)\n",
      "Epoch: [950][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0135)\tLoss (MSE) 2.488 (3.750)\n",
      "Epoch: [950][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 2.149 (3.683)\n",
      "Val: [0/9]\tTime  0.624 ( 0.624)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #950: Train loss [3.7601]; Val loss: MSE [1.9193], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [951][ 0/65]\tTime   0.56 (  0.56)\tData 0.5562 (0.5562)\tLoss (MSE) 2.243 (2.243)\n",
      "Epoch: [951][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0582)\tLoss (MSE) 3.028 (3.711)\n",
      "Epoch: [951][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0305)\tLoss (MSE) 2.292 (3.477)\n",
      "Epoch: [951][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0207)\tLoss (MSE) 3.030 (3.697)\n",
      "Epoch: [951][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 5.276 (3.672)\n",
      "Epoch: [951][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.795 (3.890)\n",
      "Epoch: [951][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 4.514 (3.748)\n",
      "Val: [0/9]\tTime  0.532 ( 0.532)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #951: Train loss [3.8140]; Val loss: MSE [1.9193], L1 [0.5986], G-Mean [0.2607]\n",
      "Epoch: [952][ 0/65]\tTime   0.56 (  0.56)\tData 0.5595 (0.5595)\tLoss (MSE) 4.464 (4.464)\n",
      "Epoch: [952][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0596)\tLoss (MSE) 3.668 (4.105)\n",
      "Epoch: [952][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0312)\tLoss (MSE) 3.720 (4.142)\n",
      "Epoch: [952][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 2.503 (3.828)\n",
      "Epoch: [952][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 2.647 (3.750)\n",
      "Epoch: [952][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 3.375 (3.859)\n",
      "Epoch: [952][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.063 (3.777)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #952: Train loss [3.7228]; Val loss: MSE [1.9194], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [953][ 0/65]\tTime   0.56 (  0.56)\tData 0.5490 (0.5490)\tLoss (MSE) 2.735 (2.735)\n",
      "Epoch: [953][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 2.126 (3.598)\n",
      "Epoch: [953][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 2.691 (3.432)\n",
      "Epoch: [953][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 3.369 (3.709)\n",
      "Epoch: [953][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.628 (3.866)\n",
      "Epoch: [953][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 4.175 (3.737)\n",
      "Epoch: [953][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.149 (3.777)\n",
      "Val: [0/9]\tTime  0.554 ( 0.554)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #953: Train loss [3.8047]; Val loss: MSE [1.9196], L1 [0.5985], G-Mean [0.2604]\n",
      "Epoch: [954][ 0/65]\tTime   0.56 (  0.56)\tData 0.5491 (0.5491)\tLoss (MSE) 5.572 (5.572)\n",
      "Epoch: [954][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0545)\tLoss (MSE) 3.060 (4.174)\n",
      "Epoch: [954][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 6.513 (3.806)\n",
      "Epoch: [954][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 2.902 (3.958)\n",
      "Epoch: [954][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.791 (3.957)\n",
      "Epoch: [954][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 3.223 (3.883)\n",
      "Epoch: [954][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.937 (3.760)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #954: Train loss [3.7766]; Val loss: MSE [1.9193], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [955][ 0/65]\tTime   0.55 (  0.55)\tData 0.5493 (0.5493)\tLoss (MSE) 3.828 (3.828)\n",
      "Epoch: [955][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0612)\tLoss (MSE) 3.946 (3.324)\n",
      "Epoch: [955][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0321)\tLoss (MSE) 6.910 (3.471)\n",
      "Epoch: [955][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 2.701 (3.516)\n",
      "Epoch: [955][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 4.527 (3.636)\n",
      "Epoch: [955][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0132)\tLoss (MSE) 5.164 (3.705)\n",
      "Epoch: [955][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0111)\tLoss (MSE) 2.678 (3.728)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.918\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.142\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.198\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #955: Train loss [3.7356]; Val loss: MSE [1.9184], L1 [0.5992], G-Mean [0.2603]\n",
      "Epoch: [956][ 0/65]\tTime   0.56 (  0.56)\tData 0.5564 (0.5564)\tLoss (MSE) 2.982 (2.982)\n",
      "Epoch: [956][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0517)\tLoss (MSE) 4.116 (3.613)\n",
      "Epoch: [956][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 3.888 (4.147)\n",
      "Epoch: [956][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 5.076 (4.318)\n",
      "Epoch: [956][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 3.664 (3.984)\n",
      "Epoch: [956][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.842 (3.919)\n",
      "Epoch: [956][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 2.083 (3.792)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #956: Train loss [3.8087]; Val loss: MSE [1.9194], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [957][ 0/65]\tTime   0.56 (  0.56)\tData 0.5569 (0.5569)\tLoss (MSE) 3.264 (3.264)\n",
      "Epoch: [957][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0572)\tLoss (MSE) 5.296 (4.065)\n",
      "Epoch: [957][20/65]\tTime   0.01 (  0.04)\tData 0.0001 (0.0300)\tLoss (MSE) 4.118 (4.078)\n",
      "Epoch: [957][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0204)\tLoss (MSE) 4.001 (4.052)\n",
      "Epoch: [957][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0154)\tLoss (MSE) 3.937 (3.955)\n",
      "Epoch: [957][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.880 (3.849)\n",
      "Epoch: [957][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0104)\tLoss (MSE) 5.937 (3.854)\n",
      "Val: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #957: Train loss [3.8263]; Val loss: MSE [1.9193], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [958][ 0/65]\tTime   0.57 (  0.57)\tData 0.5603 (0.5603)\tLoss (MSE) 4.099 (4.099)\n",
      "Epoch: [958][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0577)\tLoss (MSE) 2.849 (3.978)\n",
      "Epoch: [958][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0302)\tLoss (MSE) 2.206 (3.756)\n",
      "Epoch: [958][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.188 (3.723)\n",
      "Epoch: [958][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.741 (3.796)\n",
      "Epoch: [958][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0125)\tLoss (MSE) 7.184 (3.764)\n",
      "Epoch: [958][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 3.003 (3.771)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #958: Train loss [3.7874]; Val loss: MSE [1.9193], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [959][ 0/65]\tTime   0.56 (  0.56)\tData 0.5510 (0.5510)\tLoss (MSE) 3.835 (3.835)\n",
      "Epoch: [959][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0555)\tLoss (MSE) 4.765 (4.658)\n",
      "Epoch: [959][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0291)\tLoss (MSE) 3.439 (4.012)\n",
      "Epoch: [959][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0197)\tLoss (MSE) 4.044 (3.887)\n",
      "Epoch: [959][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0149)\tLoss (MSE) 5.472 (3.874)\n",
      "Epoch: [959][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0120)\tLoss (MSE) 4.750 (3.853)\n",
      "Epoch: [959][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.009 (3.782)\n",
      "Val: [0/9]\tTime  0.615 ( 0.615)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #959: Train loss [3.8171]; Val loss: MSE [1.9191], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [960][ 0/65]\tTime   0.59 (  0.59)\tData 0.5874 (0.5874)\tLoss (MSE) 8.269 (8.269)\n",
      "Epoch: [960][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0615)\tLoss (MSE) 5.594 (3.791)\n",
      "Epoch: [960][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0322)\tLoss (MSE) 8.962 (3.857)\n",
      "Epoch: [960][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0218)\tLoss (MSE) 3.332 (3.716)\n",
      "Epoch: [960][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0165)\tLoss (MSE) 2.847 (3.724)\n",
      "Epoch: [960][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0133)\tLoss (MSE) 2.575 (3.665)\n",
      "Epoch: [960][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 6.112 (3.833)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #960: Train loss [3.7966]; Val loss: MSE [1.9196], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [961][ 0/65]\tTime   0.63 (  0.63)\tData 0.6138 (0.6138)\tLoss (MSE) 21.630 (21.630)\n",
      "Epoch: [961][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 3.753 (6.436)\n",
      "Epoch: [961][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 3.864 (5.066)\n",
      "Epoch: [961][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 3.195 (4.635)\n",
      "Epoch: [961][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 2.251 (4.346)\n",
      "Epoch: [961][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.389 (4.193)\n",
      "Epoch: [961][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 4.211 (4.142)\n",
      "Val: [0/9]\tTime  0.562 ( 0.562)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.319\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #961: Train loss [4.0651]; Val loss: MSE [1.9198], L1 [0.5983], G-Mean [0.2597]\n",
      "Epoch: [962][ 0/65]\tTime   0.57 (  0.57)\tData 0.5639 (0.5639)\tLoss (MSE) 4.686 (4.686)\n",
      "Epoch: [962][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0600)\tLoss (MSE) 3.997 (4.134)\n",
      "Epoch: [962][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0314)\tLoss (MSE) 4.577 (3.933)\n",
      "Epoch: [962][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0213)\tLoss (MSE) 5.552 (3.972)\n",
      "Epoch: [962][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 2.445 (3.896)\n",
      "Epoch: [962][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 3.411 (3.962)\n",
      "Epoch: [962][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 3.157 (3.867)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #962: Train loss [3.8325]; Val loss: MSE [1.9189], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [963][ 0/65]\tTime   0.56 (  0.56)\tData 0.5499 (0.5499)\tLoss (MSE) 7.131 (7.131)\n",
      "Epoch: [963][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 2.564 (3.853)\n",
      "Epoch: [963][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 3.263 (3.451)\n",
      "Epoch: [963][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 3.751 (3.613)\n",
      "Epoch: [963][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 1.992 (3.722)\n",
      "Epoch: [963][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 5.972 (3.805)\n",
      "Epoch: [963][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.203 (3.761)\n",
      "Val: [0/9]\tTime  0.559 ( 0.559)\tLoss (MSE) 2.052 (2.052)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.324\tL1 1.022\tG-Mean 0.876\n",
      " * Median: MSE 2.143\tL1 1.398\tG-Mean 1.340\n",
      " * Low: MSE 0.094\tL1 0.219\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #963: Train loss [3.7852]; Val loss: MSE [1.9188], L1 [0.5991], G-Mean [0.2605]\n",
      "Epoch: [964][ 0/65]\tTime   0.56 (  0.56)\tData 0.5543 (0.5543)\tLoss (MSE) 6.583 (6.583)\n",
      "Epoch: [964][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.491 (4.194)\n",
      "Epoch: [964][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 5.142 (4.395)\n",
      "Epoch: [964][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 3.585 (4.164)\n",
      "Epoch: [964][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.562 (3.976)\n",
      "Epoch: [964][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 2.728 (3.909)\n",
      "Epoch: [964][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.694 (3.821)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #964: Train loss [3.7927]; Val loss: MSE [1.9192], L1 [0.5989], G-Mean [0.2606]\n",
      "Epoch: [965][ 0/65]\tTime   0.57 (  0.57)\tData 0.5619 (0.5619)\tLoss (MSE) 1.655 (1.655)\n",
      "Epoch: [965][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0521)\tLoss (MSE) 4.281 (3.627)\n",
      "Epoch: [965][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 4.092 (3.757)\n",
      "Epoch: [965][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 5.169 (3.936)\n",
      "Epoch: [965][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 2.404 (4.071)\n",
      "Epoch: [965][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 4.930 (3.970)\n",
      "Epoch: [965][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 2.542 (3.822)\n",
      "Val: [0/9]\tTime  0.548 ( 0.548)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #965: Train loss [3.7836]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [966][ 0/65]\tTime   0.57 (  0.57)\tData 0.5644 (0.5644)\tLoss (MSE) 4.691 (4.691)\n",
      "Epoch: [966][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0568)\tLoss (MSE) 3.575 (4.375)\n",
      "Epoch: [966][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0298)\tLoss (MSE) 5.253 (4.206)\n",
      "Epoch: [966][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0202)\tLoss (MSE) 2.252 (4.004)\n",
      "Epoch: [966][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 3.551 (3.710)\n",
      "Epoch: [966][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 2.691 (3.786)\n",
      "Epoch: [966][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.136 (3.782)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #966: Train loss [3.8135]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [967][ 0/65]\tTime   0.57 (  0.57)\tData 0.5650 (0.5650)\tLoss (MSE) 3.791 (3.791)\n",
      "Epoch: [967][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 3.429 (4.211)\n",
      "Epoch: [967][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 2.668 (3.993)\n",
      "Epoch: [967][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 2.865 (3.825)\n",
      "Epoch: [967][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 2.616 (3.886)\n",
      "Epoch: [967][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.759 (3.800)\n",
      "Epoch: [967][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 2.618 (3.795)\n",
      "Val: [0/9]\tTime  0.553 ( 0.553)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.341\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #967: Train loss [3.7930]; Val loss: MSE [1.9192], L1 [0.5990], G-Mean [0.2605]\n",
      "Epoch: [968][ 0/65]\tTime   0.56 (  0.56)\tData 0.5564 (0.5564)\tLoss (MSE) 3.263 (3.263)\n",
      "Epoch: [968][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0531)\tLoss (MSE) 3.366 (3.471)\n",
      "Epoch: [968][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 2.168 (3.987)\n",
      "Epoch: [968][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0189)\tLoss (MSE) 2.656 (3.890)\n",
      "Epoch: [968][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0143)\tLoss (MSE) 2.420 (3.900)\n",
      "Epoch: [968][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0115)\tLoss (MSE) 4.989 (3.822)\n",
      "Epoch: [968][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.459 (3.816)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #968: Train loss [3.7958]; Val loss: MSE [1.9198], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [969][ 0/65]\tTime   0.57 (  0.57)\tData 0.5632 (0.5632)\tLoss (MSE) 4.085 (4.085)\n",
      "Epoch: [969][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0524)\tLoss (MSE) 4.106 (3.567)\n",
      "Epoch: [969][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.945 (3.558)\n",
      "Epoch: [969][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0186)\tLoss (MSE) 3.306 (3.526)\n",
      "Epoch: [969][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 3.463 (3.596)\n",
      "Epoch: [969][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0113)\tLoss (MSE) 3.963 (3.680)\n",
      "Epoch: [969][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 1.896 (3.735)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #969: Train loss [3.7857]; Val loss: MSE [1.9198], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [970][ 0/65]\tTime   0.57 (  0.57)\tData 0.5670 (0.5670)\tLoss (MSE) 2.280 (2.280)\n",
      "Epoch: [970][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0630)\tLoss (MSE) 4.753 (3.742)\n",
      "Epoch: [970][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0330)\tLoss (MSE) 4.539 (3.827)\n",
      "Epoch: [970][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0224)\tLoss (MSE) 3.527 (3.797)\n",
      "Epoch: [970][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0169)\tLoss (MSE) 2.970 (3.882)\n",
      "Epoch: [970][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0136)\tLoss (MSE) 5.156 (3.960)\n",
      "Epoch: [970][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0114)\tLoss (MSE) 3.852 (3.798)\n",
      "Val: [0/9]\tTime  0.562 ( 0.562)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #970: Train loss [3.7730]; Val loss: MSE [1.9193], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [971][ 0/65]\tTime   0.56 (  0.56)\tData 0.5583 (0.5583)\tLoss (MSE) 4.792 (4.792)\n",
      "Epoch: [971][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0585)\tLoss (MSE) 4.712 (3.938)\n",
      "Epoch: [971][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0307)\tLoss (MSE) 4.194 (4.317)\n",
      "Epoch: [971][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 7.463 (4.142)\n",
      "Epoch: [971][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.150 (3.937)\n",
      "Epoch: [971][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.774 (3.944)\n",
      "Epoch: [971][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 2.162 (3.870)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #971: Train loss [3.7844]; Val loss: MSE [1.9200], L1 [0.5985], G-Mean [0.2602]\n",
      "Epoch: [972][ 0/65]\tTime   0.56 (  0.56)\tData 0.5569 (0.5569)\tLoss (MSE) 2.887 (2.887)\n",
      "Epoch: [972][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0516)\tLoss (MSE) 3.655 (3.859)\n",
      "Epoch: [972][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0271)\tLoss (MSE) 4.524 (3.955)\n",
      "Epoch: [972][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.340 (3.690)\n",
      "Epoch: [972][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0139)\tLoss (MSE) 2.913 (3.776)\n",
      "Epoch: [972][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 2.423 (3.735)\n",
      "Epoch: [972][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.346 (3.767)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #972: Train loss [3.8269]; Val loss: MSE [1.9199], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [973][ 0/65]\tTime   0.57 (  0.57)\tData 0.5649 (0.5649)\tLoss (MSE) 4.976 (4.976)\n",
      "Epoch: [973][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0542)\tLoss (MSE) 4.233 (4.159)\n",
      "Epoch: [973][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0284)\tLoss (MSE) 1.676 (3.909)\n",
      "Epoch: [973][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0193)\tLoss (MSE) 6.000 (3.941)\n",
      "Epoch: [973][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 3.122 (3.880)\n",
      "Epoch: [973][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0117)\tLoss (MSE) 4.441 (3.845)\n",
      "Epoch: [973][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0098)\tLoss (MSE) 3.865 (3.866)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #973: Train loss [3.9301]; Val loss: MSE [1.9194], L1 [0.5989], G-Mean [0.2608]\n",
      "Epoch: [974][ 0/65]\tTime   0.57 (  0.57)\tData 0.5634 (0.5634)\tLoss (MSE) 2.005 (2.005)\n",
      "Epoch: [974][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0549)\tLoss (MSE) 4.157 (3.218)\n",
      "Epoch: [974][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0288)\tLoss (MSE) 1.677 (3.562)\n",
      "Epoch: [974][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0195)\tLoss (MSE) 2.944 (3.525)\n",
      "Epoch: [974][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 6.282 (3.723)\n",
      "Epoch: [974][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 4.039 (3.814)\n",
      "Epoch: [974][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 2.602 (3.792)\n",
      "Val: [0/9]\tTime  0.641 ( 0.641)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.148\tL1 1.400\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #974: Train loss [3.8217]; Val loss: MSE [1.9195], L1 [0.5988], G-Mean [0.2609]\n",
      "Epoch: [975][ 0/65]\tTime   0.65 (  0.65)\tData 0.6456 (0.6456)\tLoss (MSE) 2.484 (2.484)\n",
      "Epoch: [975][10/65]\tTime   0.01 (  0.07)\tData 0.0000 (0.0673)\tLoss (MSE) 7.324 (3.807)\n",
      "Epoch: [975][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0353)\tLoss (MSE) 3.389 (4.170)\n",
      "Epoch: [975][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0239)\tLoss (MSE) 4.368 (3.873)\n",
      "Epoch: [975][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0181)\tLoss (MSE) 1.703 (3.874)\n",
      "Epoch: [975][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0145)\tLoss (MSE) 3.381 (3.930)\n",
      "Epoch: [975][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.743 (3.945)\n",
      "Val: [0/9]\tTime  0.618 ( 0.618)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #975: Train loss [3.8901]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2605]\n",
      "Epoch: [976][ 0/65]\tTime   0.55 (  0.55)\tData 0.5469 (0.5469)\tLoss (MSE) 2.796 (2.796)\n",
      "Epoch: [976][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0520)\tLoss (MSE) 5.246 (3.998)\n",
      "Epoch: [976][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0273)\tLoss (MSE) 8.376 (4.185)\n",
      "Epoch: [976][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0185)\tLoss (MSE) 4.106 (4.061)\n",
      "Epoch: [976][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0140)\tLoss (MSE) 3.587 (3.971)\n",
      "Epoch: [976][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0112)\tLoss (MSE) 3.095 (3.819)\n",
      "Epoch: [976][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0094)\tLoss (MSE) 3.032 (3.816)\n",
      "Val: [0/9]\tTime  0.551 ( 0.551)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #976: Train loss [3.8017]; Val loss: MSE [1.9197], L1 [0.5987], G-Mean [0.2606]\n",
      "Epoch: [977][ 0/65]\tTime   0.57 (  0.57)\tData 0.5577 (0.5577)\tLoss (MSE) 3.239 (3.239)\n",
      "Epoch: [977][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0530)\tLoss (MSE) 3.157 (3.693)\n",
      "Epoch: [977][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0278)\tLoss (MSE) 4.406 (3.448)\n",
      "Epoch: [977][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0188)\tLoss (MSE) 6.591 (3.829)\n",
      "Epoch: [977][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0142)\tLoss (MSE) 3.585 (3.929)\n",
      "Epoch: [977][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0115)\tLoss (MSE) 5.493 (3.924)\n",
      "Epoch: [977][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0096)\tLoss (MSE) 2.661 (3.807)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #977: Train loss [3.8333]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [978][ 0/65]\tTime   0.56 (  0.56)\tData 0.5567 (0.5567)\tLoss (MSE) 4.009 (4.009)\n",
      "Epoch: [978][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0546)\tLoss (MSE) 3.569 (3.495)\n",
      "Epoch: [978][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0286)\tLoss (MSE) 3.011 (3.986)\n",
      "Epoch: [978][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 2.731 (3.815)\n",
      "Epoch: [978][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 3.405 (3.681)\n",
      "Epoch: [978][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0118)\tLoss (MSE) 4.765 (3.911)\n",
      "Epoch: [978][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.496 (3.859)\n",
      "Val: [0/9]\tTime  0.543 ( 0.543)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #978: Train loss [3.8394]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [979][ 0/65]\tTime   0.57 (  0.57)\tData 0.5578 (0.5578)\tLoss (MSE) 3.985 (3.985)\n",
      "Epoch: [979][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0571)\tLoss (MSE) 2.973 (3.698)\n",
      "Epoch: [979][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0299)\tLoss (MSE) 3.155 (3.788)\n",
      "Epoch: [979][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0203)\tLoss (MSE) 4.099 (3.854)\n",
      "Epoch: [979][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0153)\tLoss (MSE) 6.316 (3.836)\n",
      "Epoch: [979][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 8.006 (3.963)\n",
      "Epoch: [979][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.444 (3.804)\n",
      "Val: [0/9]\tTime  0.540 ( 0.540)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.643 (0.643)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.259\n",
      " * Many: MSE 2.319\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.154\tL1 1.402\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.223\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #979: Train loss [3.8463]; Val loss: MSE [1.9201], L1 [0.5984], G-Mean [0.2595]\n",
      "Epoch: [980][ 0/65]\tTime   0.55 (  0.55)\tData 0.5427 (0.5427)\tLoss (MSE) 3.484 (3.484)\n",
      "Epoch: [980][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0563)\tLoss (MSE) 3.081 (3.806)\n",
      "Epoch: [980][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0295)\tLoss (MSE) 4.020 (4.022)\n",
      "Epoch: [980][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 3.400 (3.825)\n",
      "Epoch: [980][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.389 (3.717)\n",
      "Epoch: [980][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.678 (3.664)\n",
      "Epoch: [980][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 3.380 (3.733)\n",
      "Val: [0/9]\tTime  0.552 ( 0.552)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #980: Train loss [3.7504]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [981][ 0/65]\tTime   0.56 (  0.56)\tData 0.5549 (0.5549)\tLoss (MSE) 2.779 (2.779)\n",
      "Epoch: [981][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0515)\tLoss (MSE) 3.307 (3.786)\n",
      "Epoch: [981][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 4.179 (4.110)\n",
      "Epoch: [981][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 2.602 (3.899)\n",
      "Epoch: [981][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 3.678 (4.060)\n",
      "Epoch: [981][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 2.863 (3.933)\n",
      "Epoch: [981][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 5.449 (3.937)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #981: Train loss [3.9163]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [982][ 0/65]\tTime   0.57 (  0.57)\tData 0.5618 (0.5618)\tLoss (MSE) 5.265 (5.265)\n",
      "Epoch: [982][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0564)\tLoss (MSE) 2.857 (3.774)\n",
      "Epoch: [982][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0296)\tLoss (MSE) 2.598 (4.026)\n",
      "Epoch: [982][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0200)\tLoss (MSE) 2.696 (3.889)\n",
      "Epoch: [982][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 3.339 (3.743)\n",
      "Epoch: [982][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 3.997 (3.715)\n",
      "Epoch: [982][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0102)\tLoss (MSE) 4.601 (3.783)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #982: Train loss [3.7847]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [983][ 0/65]\tTime   0.57 (  0.57)\tData 0.5606 (0.5606)\tLoss (MSE) 4.567 (4.567)\n",
      "Epoch: [983][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0559)\tLoss (MSE) 3.105 (3.310)\n",
      "Epoch: [983][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 5.570 (4.055)\n",
      "Epoch: [983][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 5.698 (3.896)\n",
      "Epoch: [983][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 4.008 (3.942)\n",
      "Epoch: [983][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0121)\tLoss (MSE) 3.720 (3.760)\n",
      "Epoch: [983][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 5.104 (3.785)\n",
      "Val: [0/9]\tTime  0.544 ( 0.544)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #983: Train loss [3.7819]; Val loss: MSE [1.9198], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [984][ 0/65]\tTime   0.56 (  0.56)\tData 0.5565 (0.5565)\tLoss (MSE) 3.640 (3.640)\n",
      "Epoch: [984][10/65]\tTime   0.01 (  0.06)\tData 0.0001 (0.0582)\tLoss (MSE) 5.935 (4.229)\n",
      "Epoch: [984][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0305)\tLoss (MSE) 2.285 (3.621)\n",
      "Epoch: [984][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0207)\tLoss (MSE) 3.286 (3.672)\n",
      "Epoch: [984][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0156)\tLoss (MSE) 3.496 (3.657)\n",
      "Epoch: [984][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 5.233 (3.778)\n",
      "Epoch: [984][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0105)\tLoss (MSE) 3.847 (3.758)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #984: Train loss [3.7403]; Val loss: MSE [1.9193], L1 [0.5989], G-Mean [0.2609]\n",
      "Epoch: [985][ 0/65]\tTime   0.56 (  0.56)\tData 0.5594 (0.5594)\tLoss (MSE) 6.045 (6.045)\n",
      "Epoch: [985][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0558)\tLoss (MSE) 3.167 (3.943)\n",
      "Epoch: [985][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0293)\tLoss (MSE) 4.283 (4.027)\n",
      "Epoch: [985][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0198)\tLoss (MSE) 5.554 (3.934)\n",
      "Epoch: [985][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0150)\tLoss (MSE) 3.842 (3.946)\n",
      "Epoch: [985][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 2.621 (3.905)\n",
      "Epoch: [985][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 3.153 (3.835)\n",
      "Val: [0/9]\tTime  0.536 ( 0.536)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #985: Train loss [3.7814]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [986][ 0/65]\tTime   0.55 (  0.55)\tData 0.5471 (0.5471)\tLoss (MSE) 3.674 (3.674)\n",
      "Epoch: [986][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0552)\tLoss (MSE) 3.297 (3.440)\n",
      "Epoch: [986][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0289)\tLoss (MSE) 3.344 (3.616)\n",
      "Epoch: [986][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0196)\tLoss (MSE) 2.494 (3.722)\n",
      "Epoch: [986][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0148)\tLoss (MSE) 4.274 (3.905)\n",
      "Epoch: [986][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0119)\tLoss (MSE) 5.151 (3.889)\n",
      "Epoch: [986][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0100)\tLoss (MSE) 3.910 (3.834)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #986: Train loss [3.8408]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2602]\n",
      "Epoch: [987][ 0/65]\tTime   0.55 (  0.55)\tData 0.5480 (0.5480)\tLoss (MSE) 3.489 (3.489)\n",
      "Epoch: [987][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0600)\tLoss (MSE) 1.561 (3.639)\n",
      "Epoch: [987][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0314)\tLoss (MSE) 4.346 (3.537)\n",
      "Epoch: [987][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0213)\tLoss (MSE) 3.585 (3.843)\n",
      "Epoch: [987][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0161)\tLoss (MSE) 3.335 (3.769)\n",
      "Epoch: [987][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0130)\tLoss (MSE) 3.916 (3.761)\n",
      "Epoch: [987][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.266 (3.779)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.151\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #987: Train loss [3.7784]; Val loss: MSE [1.9197], L1 [0.5986], G-Mean [0.2603]\n",
      "Epoch: [988][ 0/65]\tTime   0.56 (  0.56)\tData 0.5552 (0.5552)\tLoss (MSE) 2.632 (2.632)\n",
      "Epoch: [988][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0515)\tLoss (MSE) 5.357 (3.376)\n",
      "Epoch: [988][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0270)\tLoss (MSE) 2.522 (3.569)\n",
      "Epoch: [988][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0183)\tLoss (MSE) 3.487 (3.766)\n",
      "Epoch: [988][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0138)\tLoss (MSE) 5.326 (3.812)\n",
      "Epoch: [988][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.466 (3.816)\n",
      "Epoch: [988][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0093)\tLoss (MSE) 4.426 (3.796)\n",
      "Val: [0/9]\tTime  0.577 ( 0.577)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.322\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #988: Train loss [3.7831]; Val loss: MSE [1.9196], L1 [0.5988], G-Mean [0.2606]\n",
      "Epoch: [989][ 0/65]\tTime   0.65 (  0.65)\tData 0.6398 (0.6398)\tLoss (MSE) 2.761 (2.761)\n",
      "Epoch: [989][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0677)\tLoss (MSE) 4.979 (3.300)\n",
      "Epoch: [989][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0355)\tLoss (MSE) 5.937 (3.654)\n",
      "Epoch: [989][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0240)\tLoss (MSE) 5.143 (3.934)\n",
      "Epoch: [989][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 7.666 (3.888)\n",
      "Epoch: [989][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0146)\tLoss (MSE) 2.576 (3.925)\n",
      "Epoch: [989][60/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0122)\tLoss (MSE) 2.467 (3.795)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #989: Train loss [3.8055]; Val loss: MSE [1.9198], L1 [0.5987], G-Mean [0.2605]\n",
      "Epoch: [990][ 0/65]\tTime   0.57 (  0.57)\tData 0.5603 (0.5603)\tLoss (MSE) 3.275 (3.275)\n",
      "Epoch: [990][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0567)\tLoss (MSE) 5.465 (3.665)\n",
      "Epoch: [990][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0297)\tLoss (MSE) 3.269 (3.882)\n",
      "Epoch: [990][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0201)\tLoss (MSE) 3.606 (3.814)\n",
      "Epoch: [990][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0152)\tLoss (MSE) 2.657 (3.888)\n",
      "Epoch: [990][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0123)\tLoss (MSE) 3.489 (3.844)\n",
      "Epoch: [990][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0103)\tLoss (MSE) 3.880 (3.826)\n",
      "Val: [0/9]\tTime  0.539 ( 0.539)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.874\n",
      " * Median: MSE 2.147\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.200\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #990: Train loss [3.8234]; Val loss: MSE [1.9193], L1 [0.5989], G-Mean [0.2607]\n",
      "Epoch: [991][ 0/65]\tTime   0.57 (  0.57)\tData 0.5603 (0.5603)\tLoss (MSE) 2.473 (2.473)\n",
      "Epoch: [991][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0526)\tLoss (MSE) 5.518 (3.599)\n",
      "Epoch: [991][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0275)\tLoss (MSE) 4.257 (3.795)\n",
      "Epoch: [991][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0187)\tLoss (MSE) 8.356 (4.136)\n",
      "Epoch: [991][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0141)\tLoss (MSE) 8.611 (4.058)\n",
      "Epoch: [991][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0114)\tLoss (MSE) 2.081 (3.908)\n",
      "Epoch: [991][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0095)\tLoss (MSE) 3.026 (3.851)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #991: Train loss [3.8166]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [992][ 0/65]\tTime   0.63 (  0.63)\tData 0.6140 (0.6140)\tLoss (MSE) 3.609 (3.609)\n",
      "Epoch: [992][10/65]\tTime   0.00 (  0.07)\tData 0.0000 (0.0597)\tLoss (MSE) 2.838 (3.715)\n",
      "Epoch: [992][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0313)\tLoss (MSE) 3.980 (3.890)\n",
      "Epoch: [992][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0212)\tLoss (MSE) 3.452 (3.921)\n",
      "Epoch: [992][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0160)\tLoss (MSE) 3.807 (3.914)\n",
      "Epoch: [992][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0129)\tLoss (MSE) 2.796 (3.751)\n",
      "Epoch: [992][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0108)\tLoss (MSE) 2.692 (3.719)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.260\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.401\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #992: Train loss [3.7639]; Val loss: MSE [1.9196], L1 [0.5986], G-Mean [0.2604]\n",
      "Epoch: [993][ 0/65]\tTime   0.56 (  0.56)\tData 0.5483 (0.5483)\tLoss (MSE) 4.110 (4.110)\n",
      "Epoch: [993][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0511)\tLoss (MSE) 2.825 (3.638)\n",
      "Epoch: [993][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 6.372 (3.970)\n",
      "Epoch: [993][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 1.846 (3.687)\n",
      "Epoch: [993][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 2.497 (3.730)\n",
      "Epoch: [993][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0110)\tLoss (MSE) 5.323 (3.947)\n",
      "Epoch: [993][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.091 (3.855)\n",
      "Val: [0/9]\tTime  0.541 ( 0.541)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.094\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #993: Train loss [3.8007]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2607]\n",
      "Epoch: [994][ 0/65]\tTime   0.57 (  0.57)\tData 0.5644 (0.5644)\tLoss (MSE) 3.580 (3.580)\n",
      "Epoch: [994][10/65]\tTime   0.01 (  0.06)\tData 0.0000 (0.0576)\tLoss (MSE) 4.692 (3.238)\n",
      "Epoch: [994][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0302)\tLoss (MSE) 2.561 (3.670)\n",
      "Epoch: [994][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0205)\tLoss (MSE) 3.966 (3.642)\n",
      "Epoch: [994][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0155)\tLoss (MSE) 2.844 (3.592)\n",
      "Epoch: [994][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0124)\tLoss (MSE) 4.686 (3.554)\n",
      "Epoch: [994][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0104)\tLoss (MSE) 4.517 (3.720)\n",
      "Val: [0/9]\tTime  0.542 ( 0.542)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #994: Train loss [3.7410]; Val loss: MSE [1.9196], L1 [0.5987], G-Mean [0.2608]\n",
      "Epoch: [995][ 0/65]\tTime   0.56 (  0.56)\tData 0.5523 (0.5523)\tLoss (MSE) 3.432 (3.432)\n",
      "Epoch: [995][10/65]\tTime   0.00 (  0.05)\tData 0.0000 (0.0512)\tLoss (MSE) 2.700 (3.181)\n",
      "Epoch: [995][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0268)\tLoss (MSE) 2.191 (3.526)\n",
      "Epoch: [995][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0182)\tLoss (MSE) 5.451 (3.557)\n",
      "Epoch: [995][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0137)\tLoss (MSE) 3.396 (3.604)\n",
      "Epoch: [995][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0111)\tLoss (MSE) 3.261 (3.702)\n",
      "Epoch: [995][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0092)\tLoss (MSE) 3.102 (3.731)\n",
      "Val: [0/9]\tTime  0.547 ( 0.547)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.919\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.323\tL1 1.021\tG-Mean 0.875\n",
      " * Median: MSE 2.146\tL1 1.399\tG-Mean 1.342\n",
      " * Low: MSE 0.094\tL1 0.220\tG-Mean 0.199\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #995: Train loss [3.7549]; Val loss: MSE [1.9192], L1 [0.5990], G-Mean [0.2607]\n",
      "Epoch: [996][ 0/65]\tTime   0.55 (  0.55)\tData 0.5447 (0.5447)\tLoss (MSE) 2.924 (2.924)\n",
      "Epoch: [996][10/65]\tTime   0.01 (  0.07)\tData 0.0001 (0.0585)\tLoss (MSE) 3.851 (3.934)\n",
      "Epoch: [996][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0306)\tLoss (MSE) 6.486 (4.064)\n",
      "Epoch: [996][30/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0208)\tLoss (MSE) 3.904 (3.853)\n",
      "Epoch: [996][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0157)\tLoss (MSE) 3.082 (3.839)\n",
      "Epoch: [996][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0126)\tLoss (MSE) 4.915 (3.898)\n",
      "Epoch: [996][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0106)\tLoss (MSE) 4.448 (3.848)\n",
      "Val: [0/9]\tTime  0.546 ( 0.546)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.874\n",
      " * Median: MSE 2.149\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #996: Train loss [3.8696]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [997][ 0/65]\tTime   0.59 (  0.59)\tData 0.5845 (0.5845)\tLoss (MSE) 2.643 (2.643)\n",
      "Epoch: [997][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0547)\tLoss (MSE) 3.144 (3.975)\n",
      "Epoch: [997][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0287)\tLoss (MSE) 4.100 (4.191)\n",
      "Epoch: [997][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0194)\tLoss (MSE) 4.038 (4.021)\n",
      "Epoch: [997][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0147)\tLoss (MSE) 2.576 (3.958)\n",
      "Epoch: [997][50/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0118)\tLoss (MSE) 5.099 (3.838)\n",
      "Epoch: [997][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0099)\tLoss (MSE) 3.723 (3.854)\n",
      "Val: [0/9]\tTime  0.564 ( 0.564)\tLoss (MSE) 2.053 (2.053)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.599\tG-Mean 0.261\n",
      " * Many: MSE 2.321\tL1 1.020\tG-Mean 0.873\n",
      " * Median: MSE 2.150\tL1 1.400\tG-Mean 1.343\n",
      " * Low: MSE 0.095\tL1 0.221\tG-Mean 0.201\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #997: Train loss [3.8367]; Val loss: MSE [1.9195], L1 [0.5987], G-Mean [0.2609]\n",
      "Epoch: [998][ 0/65]\tTime   0.64 (  0.64)\tData 0.6345 (0.6345)\tLoss (MSE) 2.381 (2.381)\n",
      "Epoch: [998][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0592)\tLoss (MSE) 6.607 (4.246)\n",
      "Epoch: [998][20/65]\tTime   0.00 (  0.04)\tData 0.0000 (0.0310)\tLoss (MSE) 4.136 (4.085)\n",
      "Epoch: [998][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0210)\tLoss (MSE) 4.776 (4.063)\n",
      "Epoch: [998][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0159)\tLoss (MSE) 3.521 (3.872)\n",
      "Epoch: [998][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0128)\tLoss (MSE) 1.978 (3.784)\n",
      "Epoch: [998][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0107)\tLoss (MSE) 3.922 (3.844)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.153\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #998: Train loss [3.8235]; Val loss: MSE [1.9199], L1 [0.5985], G-Mean [0.2603]\n",
      "Epoch: [999][ 0/65]\tTime   0.55 (  0.55)\tData 0.5473 (0.5473)\tLoss (MSE) 3.284 (3.284)\n",
      "Epoch: [999][10/65]\tTime   0.00 (  0.06)\tData 0.0000 (0.0561)\tLoss (MSE) 2.731 (3.510)\n",
      "Epoch: [999][20/65]\tTime   0.00 (  0.03)\tData 0.0000 (0.0294)\tLoss (MSE) 2.544 (3.663)\n",
      "Epoch: [999][30/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0199)\tLoss (MSE) 2.530 (3.674)\n",
      "Epoch: [999][40/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0151)\tLoss (MSE) 2.999 (3.690)\n",
      "Epoch: [999][50/65]\tTime   0.00 (  0.02)\tData 0.0000 (0.0121)\tLoss (MSE) 3.254 (3.732)\n",
      "Epoch: [999][60/65]\tTime   0.00 (  0.01)\tData 0.0000 (0.0101)\tLoss (MSE) 4.238 (3.793)\n",
      "Val: [0/9]\tTime  0.545 ( 0.545)\tLoss (MSE) 2.054 (2.054)\tLoss (L1) 0.644 (0.644)\n",
      " * Overall: MSE 1.920\tL1 0.598\tG-Mean 0.260\n",
      " * Many: MSE 2.320\tL1 1.019\tG-Mean 0.872\n",
      " * Median: MSE 2.152\tL1 1.401\tG-Mean 1.344\n",
      " * Low: MSE 0.095\tL1 0.222\tG-Mean 0.202\n",
      "Best MSE Loss: 1.792\n",
      "Epoch #999: Train loss [3.7566]; Val loss: MSE [1.9199], L1 [0.5985], G-Mean [0.2603]\n",
      "========================================================================================================================\n",
      "Test best model on testset...\n",
      "Test: [0/9]\tTime  0.550 ( 0.550)\tLoss (MSE) 1.164 (1.164)\tLoss (L1) 0.509 (0.509)\n",
      " * Overall: MSE 1.982\tL1 0.573\tG-Mean 0.254\n",
      " * Many: MSE 2.739\tL1 1.052\tG-Mean 0.881\n",
      " * Median: MSE 2.353\tL1 1.466\tG-Mean 1.406\n",
      " * Low: MSE 0.106\tL1 0.214\tG-Mean 0.188\n",
      "Test loss: MSE [1.9822], L1 [0.5734], G-Mean [0.2542]\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train.py Part 2: Train/Evaluate the model.\n",
    "args.store_name = ''\n",
    "args.start_epoch, args.best_loss = 0, 1e5\n",
    "\n",
    "# if len(args.store_name):\n",
    "#     args.store_name = f'_{args.store_name}'\n",
    "# if not args.lds and args.reweight != 'none':\n",
    "#     args.store_name += f'_{args.reweight}'\n",
    "# if args.lds:\n",
    "#     args.store_name += f'_lds_{args.lds_kernel[:3]}_{args.lds_ks}'\n",
    "#     if args.lds_kernel in ['gaussian', 'laplace']:\n",
    "#         args.store_name += f'_{args.lds_sigma}'\n",
    "# args.store_name = f\"{args.dataset}_{args.model}{args.store_name}_{args.optimizer}_{args.loss}_{args.lr}_{args.batch_size}\"\n",
    "\n",
    "# prepare_folders(args)\n",
    "\n",
    "# print(f\"Args: {args}\")\n",
    "# print(f\"Store name: {args.store_name}\")\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def main():\n",
    "    if args.gpu is not None:\n",
    "        print(f\"Use GPU: {args.gpu} for training\") \n",
    "   \n",
    "    print('=====> Preparing data...')\n",
    "    x_train=pd.read_excel('data/promoter_w_20799.xlsx',header=None).to_numpy().reshape(-1)\n",
    "    y_train=pd.read_excel('data/mapped_labels.xlsx',header=None).to_numpy().reshape(-1)\n",
    "\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "    val_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.5, random_state=42)\n",
    "    \n",
    "    train_dataset = DNA_loader(labels=train_labels, dna=train_data,split='train',\n",
    "                          reweight='inverse', lds=True, lds_kernel='gaussian', lds_ks=10, lds_sigma=2)\n",
    "    val_dataset = DNA_loader(labels=val_labels, dna=val_data,split='train',\n",
    "                          reweight='inverse', lds=True, lds_kernel='gaussian', lds_ks=5, lds_sigma=2)\n",
    "    test_dataset = DNA_loader(labels=test_labels, dna=test_data,split='train',\n",
    "                          reweight='inverse', lds=True, lds_kernel='gaussian', lds_ks=5, lds_sigma=2)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                              num_workers=args.workers, pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                            num_workers=args.workers, pin_memory=True, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                             num_workers=args.workers, pin_memory=True, drop_last=False)\n",
    "    print(f\"Training data size: {len(train_dataset)}\")\n",
    "    print(f\"Validation data size: {len(val_dataset)}\")\n",
    "    print(f\"Test data size: {len(test_dataset)}\")\n",
    "    # Random Seed\n",
    "    np.random.seed(999)\n",
    "    # random.seed(999)\n",
    "    torch.manual_seed(999)\n",
    "\n",
    "    # Model\n",
    "    print('=====> Building model...')\n",
    "    model = fcnet1()\n",
    "    if not args.cpu_only:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # # evaluate only\n",
    "    # if args.evaluate:\n",
    "    #     assert args.resume, 'Specify a trained model using [args.resume]'\n",
    "    #     checkpoint = torch.load(args.resume)\n",
    "    #     model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    #     print(f\"===> Checkpoint '{args.resume}' loaded (epoch [{checkpoint['epoch']}]), testing...\")\n",
    "    #     validate(test_loader, model, train_labels=train_labels, prefix='Test')\n",
    "    #     return\n",
    "\n",
    "    # Loss and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr) if args.optimizer == 'adam' else \\\n",
    "        torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    # if args.resume:\n",
    "    #     if os.path.isfile(args.resume):\n",
    "    #         print(f\"===> Loading checkpoint '{args.resume}'\")\n",
    "    #         checkpoint = torch.load(args.resume) if args.gpu is None else \\\n",
    "    #             torch.load(args.resume, map_location=torch.device(f'cuda:{str(args.gpu)}'))\n",
    "    #         args.start_epoch = checkpoint['epoch']\n",
    "    #         args.best_loss = checkpoint['best_loss']\n",
    "    #         model.load_state_dict(checkpoint['state_dict'])\n",
    "    #         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    #         print(f\"===> Loaded checkpoint '{args.resume}' (Epoch [{checkpoint['epoch']}])\")\n",
    "    #     else:\n",
    "    #         print(f\"===> No checkpoint found at '{args.resume}'\")\n",
    "\n",
    "    if not args.cpu_only:\n",
    "        cudnn.benchmark = True\n",
    "    losses_train = []\n",
    "    losses_val=[]\n",
    "     #启动tensorboard\n",
    "    writer = SummaryWriter()\n",
    "  \n",
    "    for epoch in range(args.start_epoch, args.epoch):\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "        train_loss = train(train_loader, model, optimizer, epoch)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "\n",
    "        val_loss_mse, val_loss_l1, val_loss_gmean= validate(val_loader, model, train_labels=train_labels)\n",
    "        writer.add_scalar(\"Loss/val_mse\", val_loss_mse, epoch)\n",
    "\n",
    "         # 将val_loss_l1写入TensorBoard\n",
    "        writer.add_scalar(\"Loss/val_l1\", val_loss_l1, epoch)\n",
    "\n",
    "        loss_metric = val_loss_mse if args.loss == 'mse' else val_loss_l1\n",
    "        is_best = loss_metric < args.best_loss\n",
    "        args.best_loss = min(loss_metric, args.best_loss)\n",
    "        print(f\"Best {'L1' if 'l1' in args.loss else 'MSE'} Loss: {args.best_loss:.3f}\")\n",
    "        # save_checkpoint(args, {\n",
    "        #     'epoch': epoch + 1,\n",
    "        #     'model': args.model,\n",
    "        #     'best_loss': args.best_loss,\n",
    "        #     'state_dict': model.state_dict(),\n",
    "        #     'optimizer': optimizer.state_dict(),\n",
    "        # }, is_best)\n",
    "        print(f\"Epoch #{epoch}: Train loss [{train_loss:.4f}]; \"\n",
    "              f\"Val loss: MSE [{val_loss_mse:.4f}], L1 [{val_loss_l1:.4f}], G-Mean [{val_loss_gmean:.4f}]\")\n",
    "        losses_train.append(train_loss)\n",
    "        losses_val.append(val_loss_mse)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    # test with best checkpoint\n",
    "    print(\"=\" * 120)\n",
    "    print(\"Test best model on testset...\")\n",
    "    # checkpoint = torch.load(f\"{args.store_root}/{args.store_name}/ckpt.best.pth.tar\")\n",
    "    # model.load_state_dict(checkpoint['state_dict'])\n",
    "    # print(f\"Loaded best model, epoch {checkpoint['epoch']}, best val loss {checkpoint['best_loss']:.4f}\")\n",
    "    test_loss_mse, test_loss_l1, test_loss_gmean = validate(test_loader, model, train_labels=train_labels, prefix='Test')\n",
    "    print(f\"Test loss: MSE [{test_loss_mse:.4f}], L1 [{test_loss_l1:.4f}], G-Mean [{test_loss_gmean:.4f}]\\nDone\")\n",
    "def train(train_loader, model, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.2f')\n",
    "    data_time = AverageMeter('Data', ':6.4f')\n",
    "    losses = AverageMeter(f'Loss ({args.loss.upper()})', ':.3f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch)\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for idx, (inputs, targets, weights) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        if not args.cpu_only:\n",
    "            inputs, targets, weights = \\\n",
    "                inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True), weights.cuda(non_blocking=True)\n",
    "        outputs = model(inputs, targets, epoch)\n",
    "\n",
    "        loss = globals()[f\"weighted_{args.loss}_loss\"](outputs, targets, weights.unsqueeze(1) )\n",
    "        assert not (np.isnan(loss.item()) or loss.item() > 1e6), f\"Loss explosion: {loss.item()}\"\n",
    "\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if idx % args.print_freq == 0:\n",
    "            progress.display(idx)\n",
    "    \n",
    "    return losses.avg\n",
    "\n",
    "def validate(val_loader, model, train_labels=None, prefix='Val'):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses_mse = AverageMeter('Loss (MSE)', ':.3f')\n",
    "    losses_l1 = AverageMeter('Loss (L1)', ':.3f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses_mse, losses_l1],\n",
    "        prefix=f'{prefix}: '\n",
    "    )\n",
    "\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    criterion_l1 = nn.L1Loss()\n",
    "    criterion_gmean = nn.L1Loss(reduction='none')\n",
    "\n",
    "    model.eval()\n",
    "    losses_all = []\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (inputs, targets, _) in enumerate(val_loader):\n",
    "            if not args.cpu_only:\n",
    "                inputs, targets = inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            preds.extend(outputs.data.cpu().numpy())\n",
    "            labels.extend(targets.data.cpu().numpy())\n",
    "\n",
    "            loss_mse = criterion_mse(outputs, targets)\n",
    "            loss_l1 = criterion_l1(outputs, targets)\n",
    "            loss_all = criterion_gmean(outputs, targets)\n",
    "            losses_all.extend(loss_all.cpu().numpy())\n",
    "\n",
    "            losses_mse.update(loss_mse.item(), inputs.size(0))\n",
    "            losses_l1.update(loss_l1.item(), inputs.size(0))\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            if idx % args.print_freq == 0:\n",
    "                progress.display(idx)\n",
    "\n",
    "        shot_dict = shot_metrics(np.hstack(preds), np.hstack(labels), train_labels)\n",
    "        loss_gmean = gmean(np.hstack(losses_all), axis=None).astype(float)\n",
    "        print(f\" * Overall: MSE {losses_mse.avg:.3f}\\tL1 {losses_l1.avg:.3f}\\tG-Mean {loss_gmean:.3f}\")\n",
    "        print(f\" * Many: MSE {shot_dict['many']['mse']:.3f}\\t\"\n",
    "              f\"L1 {shot_dict['many']['l1']:.3f}\\tG-Mean {shot_dict['many']['gmean']:.3f}\")\n",
    "        print(f\" * Median: MSE {shot_dict['median']['mse']:.3f}\\t\"\n",
    "              f\"L1 {shot_dict['median']['l1']:.3f}\\tG-Mean {shot_dict['median']['gmean']:.3f}\")\n",
    "        print(f\" * Low: MSE {shot_dict['low']['mse']:.3f}\\t\"\n",
    "              f\"L1 {shot_dict['low']['l1']:.3f}\\tG-Mean {shot_dict['low']['gmean']:.3f}\")\n",
    "    # # 如果是验证集，绘制loss曲线\n",
    "    # if prefix == 'Val':\n",
    "    #     plt.plot(loss_all, label='val_loss')\n",
    "    #     plt.xlabel('epoch')\n",
    "    #     plt.ylabel('loss')\n",
    "    #     plt.legend()\n",
    "    if prefix == 'Test':\n",
    "        plt.plot(labels[:200], label='labels', marker='o', linestyle='None')\n",
    "        plt.plot(preds[:200], label='preds', marker='x',linestyle='None')\n",
    "        plt.xlabel('index')\n",
    "        plt.ylabel('value')\n",
    "        plt.legend()\n",
    "    return losses_mse.avg, losses_l1.avg, loss_gmean\n",
    "\n",
    "def shot_metrics(preds, labels, train_labels, many_shot_thr=10, low_shot_thr=2):\n",
    "    train_labels = np.array(train_labels).astype(int)\n",
    "\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "    elif isinstance(preds, np.ndarray):\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError(f'Type ({type(preds)}) of predictions not supported')\n",
    "\n",
    "    labels = np.array(labels).astype(int)\n",
    "\n",
    "    train_class_count, test_class_count = [], []\n",
    "    mse_per_class, l1_per_class, l1_all_per_class = [], [], []\n",
    "    for l in np.unique(labels):\n",
    "        train_class_count.append(len(train_labels[train_labels == l]))\n",
    "        test_class_count.append(len(labels[labels == l]))\n",
    "        mse_per_class.append(np.sum((preds[labels == l] - labels[labels == l]) ** 2))\n",
    "        l1_per_class.append(np.sum(np.abs(preds[labels == l] - labels[labels == l])))\n",
    "        l1_all_per_class.append(np.abs(preds[labels == l] - labels[labels == l]))\n",
    "\n",
    "    many_shot_mse, median_shot_mse, low_shot_mse = [], [], []\n",
    "    many_shot_l1, median_shot_l1, low_shot_l1 = [], [], []\n",
    "    many_shot_gmean, median_shot_gmean, low_shot_gmean = [], [], []\n",
    "    many_shot_cnt, median_shot_cnt, low_shot_cnt = [], [], []\n",
    "\n",
    "    for i in range(len(train_class_count)):\n",
    "        if train_class_count[i] > many_shot_thr:\n",
    "            many_shot_mse.append(mse_per_class[i])\n",
    "            many_shot_l1.append(l1_per_class[i])\n",
    "            many_shot_gmean += list(l1_all_per_class[i])\n",
    "            many_shot_cnt.append(test_class_count[i])\n",
    "        elif train_class_count[i] < low_shot_thr:\n",
    "            low_shot_mse.append(mse_per_class[i])\n",
    "            low_shot_l1.append(l1_per_class[i])\n",
    "            low_shot_gmean += list(l1_all_per_class[i])\n",
    "            low_shot_cnt.append(test_class_count[i])\n",
    "        else:\n",
    "            median_shot_mse.append(mse_per_class[i])\n",
    "            median_shot_l1.append(l1_per_class[i])\n",
    "            median_shot_gmean += list(l1_all_per_class[i])\n",
    "            median_shot_cnt.append(test_class_count[i])\n",
    "\n",
    "    shot_dict = defaultdict(dict)\n",
    "    shot_dict['many']['mse'] = np.sum(many_shot_mse) / np.sum(many_shot_cnt)\n",
    "    shot_dict['many']['l1'] = np.sum(many_shot_l1) / np.sum(many_shot_cnt)\n",
    "    shot_dict['many']['gmean'] = gmean(np.hstack(many_shot_gmean), axis=None).astype(float)\n",
    "    shot_dict['median']['mse'] = np.sum(median_shot_mse) / np.sum(median_shot_cnt)\n",
    "    shot_dict['median']['l1'] = np.sum(median_shot_l1) / np.sum(median_shot_cnt)\n",
    "    shot_dict['median']['gmean'] = gmean(np.hstack(median_shot_gmean), axis=None).astype(float)\n",
    "    shot_dict['low']['mse'] = np.sum(low_shot_mse) / np.sum(low_shot_cnt)\n",
    "    shot_dict['low']['l1'] = np.sum(low_shot_l1) / np.sum(low_shot_cnt)\n",
    "    shot_dict['low']['gmean'] = gmean(np.hstack(low_shot_gmean), axis=None).astype(float)\n",
    "\n",
    "    return shot_dict\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss', color='b')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='r')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_imbalance_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
